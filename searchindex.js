Search.setIndex({"docnames": ["index", "reference/collectors", "reference/data", "reference/envs", "reference/generated/knowledge_base/DEBUGGING_RL", "reference/generated/knowledge_base/GYM", "reference/generated/knowledge_base/HABITAT", "reference/generated/knowledge_base/MUJOCO_INSTALLATION", "reference/generated/knowledge_base/PRO-TIPS", "reference/generated/knowledge_base/RESOURCES", "reference/generated/knowledge_base/VERSIONING_ISSUES", "reference/generated/torchrl._utils.implement_for", "reference/generated/torchrl.collectors.collectors.DataCollectorBase", "reference/generated/torchrl.collectors.collectors.MultiSyncDataCollector", "reference/generated/torchrl.collectors.collectors.MultiaSyncDataCollector", "reference/generated/torchrl.collectors.collectors.RandomPolicy", "reference/generated/torchrl.collectors.collectors.SyncDataCollector", "reference/generated/torchrl.collectors.collectors.aSyncDataCollector", "reference/generated/torchrl.collectors.distributed.DistributedDataCollector", "reference/generated/torchrl.collectors.distributed.DistributedSyncDataCollector", "reference/generated/torchrl.collectors.distributed.RPCDataCollector", "reference/generated/torchrl.collectors.distributed.RayCollector", "reference/generated/torchrl.collectors.distributed.submitit_delayed_launcher", "reference/generated/torchrl.collectors.utils.split_trajectories", "reference/generated/torchrl.data.BinaryDiscreteTensorSpec", "reference/generated/torchrl.data.BoundedTensorSpec", "reference/generated/torchrl.data.CompositeSpec", "reference/generated/torchrl.data.DiscreteTensorSpec", "reference/generated/torchrl.data.LazyStackedCompositeSpec", "reference/generated/torchrl.data.LazyStackedTensorSpec", "reference/generated/torchrl.data.MultiDiscreteTensorSpec", "reference/generated/torchrl.data.MultiOneHotDiscreteTensorSpec", "reference/generated/torchrl.data.MultiStep", "reference/generated/torchrl.data.OneHotDiscreteTensorSpec", "reference/generated/torchrl.data.PairwiseDataset", "reference/generated/torchrl.data.PrioritizedReplayBuffer", "reference/generated/torchrl.data.PromptData", "reference/generated/torchrl.data.PromptTensorDictTokenizer", "reference/generated/torchrl.data.ReplayBuffer", "reference/generated/torchrl.data.RewardData", "reference/generated/torchrl.data.RolloutFromModel", "reference/generated/torchrl.data.TensorDictPrioritizedReplayBuffer", "reference/generated/torchrl.data.TensorDictReplayBuffer", "reference/generated/torchrl.data.TensorDictTokenizer", "reference/generated/torchrl.data.TensorSpec", "reference/generated/torchrl.data.TokenizedDatasetLoader", "reference/generated/torchrl.data.UnboundedContinuousTensorSpec", "reference/generated/torchrl.data.UnboundedDiscreteTensorSpec", "reference/generated/torchrl.data.check_no_exclusive_keys", "reference/generated/torchrl.data.consolidate_spec", "reference/generated/torchrl.data.contains_lazy_spec", "reference/generated/torchrl.data.create_infinite_iterator", "reference/generated/torchrl.data.datasets.D4RLExperienceReplay", "reference/generated/torchrl.data.datasets.MinariExperienceReplay", "reference/generated/torchrl.data.datasets.OpenMLExperienceReplay", "reference/generated/torchrl.data.datasets.RobosetExperienceReplay", "reference/generated/torchrl.data.datasets.VD4RLExperienceReplay", "reference/generated/torchrl.data.get_dataloader", "reference/generated/torchrl.data.replay_buffers.LazyMemmapStorage", "reference/generated/torchrl.data.replay_buffers.LazyTensorStorage", "reference/generated/torchrl.data.replay_buffers.ListStorage", "reference/generated/torchrl.data.replay_buffers.PrioritizedSampler", "reference/generated/torchrl.data.replay_buffers.RandomSampler", "reference/generated/torchrl.data.replay_buffers.RoundRobinWriter", "reference/generated/torchrl.data.replay_buffers.Sampler", "reference/generated/torchrl.data.replay_buffers.SamplerWithoutReplacement", "reference/generated/torchrl.data.replay_buffers.SliceSampler", "reference/generated/torchrl.data.replay_buffers.SliceSamplerWithoutReplacement", "reference/generated/torchrl.data.replay_buffers.Storage", "reference/generated/torchrl.data.replay_buffers.TensorDictMaxValueWriter", "reference/generated/torchrl.data.replay_buffers.TensorDictRoundRobinWriter", "reference/generated/torchrl.data.replay_buffers.TensorStorage", "reference/generated/torchrl.data.replay_buffers.Writer", "reference/generated/torchrl.envs.BraxEnv", "reference/generated/torchrl.envs.BraxWrapper", "reference/generated/torchrl.envs.DMControlEnv", "reference/generated/torchrl.envs.DMControlWrapper", "reference/generated/torchrl.envs.EnvBase", "reference/generated/torchrl.envs.EnvCreator", "reference/generated/torchrl.envs.EnvMetaData", "reference/generated/torchrl.envs.GymEnv", "reference/generated/torchrl.envs.GymLikeEnv", "reference/generated/torchrl.envs.GymWrapper", "reference/generated/torchrl.envs.HabitatEnv", "reference/generated/torchrl.envs.IsaacGymEnv", "reference/generated/torchrl.envs.IsaacGymWrapper", "reference/generated/torchrl.envs.JumanjiEnv", "reference/generated/torchrl.envs.JumanjiWrapper", "reference/generated/torchrl.envs.MOGymEnv", "reference/generated/torchrl.envs.MOGymWrapper", "reference/generated/torchrl.envs.MarlGroupMapType", "reference/generated/torchrl.envs.ModelBasedEnvBase", "reference/generated/torchrl.envs.MultiThreadedEnv", "reference/generated/torchrl.envs.MultiThreadedEnvWrapper", "reference/generated/torchrl.envs.OpenMLEnv", "reference/generated/torchrl.envs.ParallelEnv", "reference/generated/torchrl.envs.PettingZooEnv", "reference/generated/torchrl.envs.PettingZooWrapper", "reference/generated/torchrl.envs.RoboHiveEnv", "reference/generated/torchrl.envs.SMACv2Env", "reference/generated/torchrl.envs.SMACv2Wrapper", "reference/generated/torchrl.envs.SerialEnv", "reference/generated/torchrl.envs.VmasEnv", "reference/generated/torchrl.envs.VmasWrapper", "reference/generated/torchrl.envs.check_marl_grouping", "reference/generated/torchrl.envs.gym_backend", "reference/generated/torchrl.envs.model_based.dreamer.DreamerEnv", "reference/generated/torchrl.envs.set_gym_backend", "reference/generated/torchrl.envs.transforms.ActionMask", "reference/generated/torchrl.envs.transforms.BinarizeReward", "reference/generated/torchrl.envs.transforms.CatFrames", "reference/generated/torchrl.envs.transforms.CatTensors", "reference/generated/torchrl.envs.transforms.CenterCrop", "reference/generated/torchrl.envs.transforms.ClipTransform", "reference/generated/torchrl.envs.transforms.Compose", "reference/generated/torchrl.envs.transforms.DTypeCastTransform", "reference/generated/torchrl.envs.transforms.DeviceCastTransform", "reference/generated/torchrl.envs.transforms.DiscreteActionProjection", "reference/generated/torchrl.envs.transforms.DoubleToFloat", "reference/generated/torchrl.envs.transforms.EndOfLifeTransform", "reference/generated/torchrl.envs.transforms.ExcludeTransform", "reference/generated/torchrl.envs.transforms.FiniteTensorDictCheck", "reference/generated/torchrl.envs.transforms.FlattenObservation", "reference/generated/torchrl.envs.transforms.FrameSkipTransform", "reference/generated/torchrl.envs.transforms.GrayScale", "reference/generated/torchrl.envs.transforms.InitTracker", "reference/generated/torchrl.envs.transforms.KLRewardTransform", "reference/generated/torchrl.envs.transforms.NoopResetEnv", "reference/generated/torchrl.envs.transforms.ObservationNorm", "reference/generated/torchrl.envs.transforms.ObservationTransform", "reference/generated/torchrl.envs.transforms.PermuteTransform", "reference/generated/torchrl.envs.transforms.PinMemoryTransform", "reference/generated/torchrl.envs.transforms.R3MTransform", "reference/generated/torchrl.envs.transforms.RandomCropTensorDict", "reference/generated/torchrl.envs.transforms.RenameTransform", "reference/generated/torchrl.envs.transforms.Resize", "reference/generated/torchrl.envs.transforms.Reward2GoTransform", "reference/generated/torchrl.envs.transforms.RewardClipping", "reference/generated/torchrl.envs.transforms.RewardScaling", "reference/generated/torchrl.envs.transforms.RewardSum", "reference/generated/torchrl.envs.transforms.SelectTransform", "reference/generated/torchrl.envs.transforms.SqueezeTransform", "reference/generated/torchrl.envs.transforms.StepCounter", "reference/generated/torchrl.envs.transforms.TargetReturn", "reference/generated/torchrl.envs.transforms.TensorDictPrimer", "reference/generated/torchrl.envs.transforms.TimeMaxPool", "reference/generated/torchrl.envs.transforms.ToTensorImage", "reference/generated/torchrl.envs.transforms.Transform", "reference/generated/torchrl.envs.transforms.TransformedEnv", "reference/generated/torchrl.envs.transforms.UnsqueezeTransform", "reference/generated/torchrl.envs.transforms.VC1Transform", "reference/generated/torchrl.envs.transforms.VIPRewardTransform", "reference/generated/torchrl.envs.transforms.VIPTransform", "reference/generated/torchrl.envs.transforms.VecGymEnvTransform", "reference/generated/torchrl.envs.transforms.VecNorm", "reference/generated/torchrl.envs.transforms.gSDENoise", "reference/generated/torchrl.envs.utils.check_env_specs", "reference/generated/torchrl.envs.utils.exploration_mode", "reference/generated/torchrl.envs.utils.exploration_type", "reference/generated/torchrl.envs.utils.get_available_libraries", "reference/generated/torchrl.envs.utils.make_composite_from_td", "reference/generated/torchrl.envs.utils.set_exploration_mode", "reference/generated/torchrl.envs.utils.set_exploration_type", "reference/generated/torchrl.envs.utils.step_mdp", "reference/generated/torchrl.envs.utils.terminated_or_truncated", "reference/generated/torchrl.modules.CEMPlanner", "reference/generated/torchrl.modules.Conv3dNet", "reference/generated/torchrl.modules.ConvNet", "reference/generated/torchrl.modules.DTActor", "reference/generated/torchrl.modules.DdpgCnnActor", "reference/generated/torchrl.modules.DdpgCnnQNet", "reference/generated/torchrl.modules.DdpgMlpActor", "reference/generated/torchrl.modules.DdpgMlpQNet", "reference/generated/torchrl.modules.DecisionTransformer", "reference/generated/torchrl.modules.Delta", "reference/generated/torchrl.modules.DistributionalDQNnet", "reference/generated/torchrl.modules.DistributionalQValueHook", "reference/generated/torchrl.modules.DreamerActor", "reference/generated/torchrl.modules.DuelingCnnDQNet", "reference/generated/torchrl.modules.GRU", "reference/generated/torchrl.modules.GRUCell", "reference/generated/torchrl.modules.GRUModule", "reference/generated/torchrl.modules.IndependentNormal", "reference/generated/torchrl.modules.LSTM", "reference/generated/torchrl.modules.LSTMCell", "reference/generated/torchrl.modules.LSTMModule", "reference/generated/torchrl.modules.LSTMNet", "reference/generated/torchrl.modules.MLP", "reference/generated/torchrl.modules.MPCPlannerBase", "reference/generated/torchrl.modules.MPPIPlanner", "reference/generated/torchrl.modules.MaskedCategorical", "reference/generated/torchrl.modules.MaskedOneHotCategorical", "reference/generated/torchrl.modules.MultiAgentConvNet", "reference/generated/torchrl.modules.MultiAgentMLP", "reference/generated/torchrl.modules.NoisyLazyLinear", "reference/generated/torchrl.modules.NoisyLinear", "reference/generated/torchrl.modules.NormalParamWrapper", "reference/generated/torchrl.modules.ObsDecoder", "reference/generated/torchrl.modules.ObsEncoder", "reference/generated/torchrl.modules.OneHotCategorical", "reference/generated/torchrl.modules.OnlineDTActor", "reference/generated/torchrl.modules.QMixer", "reference/generated/torchrl.modules.QValueHook", "reference/generated/torchrl.modules.RSSMPosterior", "reference/generated/torchrl.modules.RSSMPrior", "reference/generated/torchrl.modules.Squeeze2dLayer", "reference/generated/torchrl.modules.SqueezeLayer", "reference/generated/torchrl.modules.TanhDelta", "reference/generated/torchrl.modules.TanhNormal", "reference/generated/torchrl.modules.TruncatedNormal", "reference/generated/torchrl.modules.VDNMixer", "reference/generated/torchrl.modules.VmapModule", "reference/generated/torchrl.modules.reset_noise", "reference/generated/torchrl.modules.tensordict_module.Actor", "reference/generated/torchrl.modules.tensordict_module.ActorCriticOperator", "reference/generated/torchrl.modules.tensordict_module.ActorCriticWrapper", "reference/generated/torchrl.modules.tensordict_module.ActorValueOperator", "reference/generated/torchrl.modules.tensordict_module.AdditiveGaussianWrapper", "reference/generated/torchrl.modules.tensordict_module.DecisionTransformerInferenceWrapper", "reference/generated/torchrl.modules.tensordict_module.DistributionalQValueActor", "reference/generated/torchrl.modules.tensordict_module.DistributionalQValueModule", "reference/generated/torchrl.modules.tensordict_module.EGreedyModule", "reference/generated/torchrl.modules.tensordict_module.EGreedyWrapper", "reference/generated/torchrl.modules.tensordict_module.LMHeadActorValueOperator", "reference/generated/torchrl.modules.tensordict_module.OrnsteinUhlenbeckProcessWrapper", "reference/generated/torchrl.modules.tensordict_module.ProbabilisticActor", "reference/generated/torchrl.modules.tensordict_module.QValueActor", "reference/generated/torchrl.modules.tensordict_module.QValueModule", "reference/generated/torchrl.modules.tensordict_module.SafeModule", "reference/generated/torchrl.modules.tensordict_module.SafeProbabilisticModule", "reference/generated/torchrl.modules.tensordict_module.SafeProbabilisticTensorDictSequential", "reference/generated/torchrl.modules.tensordict_module.SafeSequential", "reference/generated/torchrl.modules.tensordict_module.TanhModule", "reference/generated/torchrl.modules.tensordict_module.ValueOperator", "reference/generated/torchrl.modules.tensordict_module.WorldModelWrapper", "reference/generated/torchrl.modules.utils.biased_softplus", "reference/generated/torchrl.modules.utils.inv_softplus", "reference/generated/torchrl.modules.utils.mappings", "reference/generated/torchrl.objectives.A2CLoss", "reference/generated/torchrl.objectives.CQLLoss", "reference/generated/torchrl.objectives.ClipPPOLoss", "reference/generated/torchrl.objectives.DDPGLoss", "reference/generated/torchrl.objectives.DQNLoss", "reference/generated/torchrl.objectives.DTLoss", "reference/generated/torchrl.objectives.DiscreteCQLLoss", "reference/generated/torchrl.objectives.DiscreteSACLoss", "reference/generated/torchrl.objectives.DistributionalDQNLoss", "reference/generated/torchrl.objectives.DreamerActorLoss", "reference/generated/torchrl.objectives.DreamerModelLoss", "reference/generated/torchrl.objectives.DreamerValueLoss", "reference/generated/torchrl.objectives.HardUpdate", "reference/generated/torchrl.objectives.IQLLoss", "reference/generated/torchrl.objectives.KLPENPPOLoss", "reference/generated/torchrl.objectives.LossModule", "reference/generated/torchrl.objectives.OnlineDTLoss", "reference/generated/torchrl.objectives.PPOLoss", "reference/generated/torchrl.objectives.REDQLoss", "reference/generated/torchrl.objectives.ReinforceLoss", "reference/generated/torchrl.objectives.SACLoss", "reference/generated/torchrl.objectives.SoftUpdate", "reference/generated/torchrl.objectives.TD3Loss", "reference/generated/torchrl.objectives.ValueEstimators", "reference/generated/torchrl.objectives.default_value_kwargs", "reference/generated/torchrl.objectives.distance_loss", "reference/generated/torchrl.objectives.hold_out_net", "reference/generated/torchrl.objectives.hold_out_params", "reference/generated/torchrl.objectives.multiagent.QMixerLoss", "reference/generated/torchrl.objectives.next_state_value", "reference/generated/torchrl.objectives.value.GAE", "reference/generated/torchrl.objectives.value.TD0Estimator", "reference/generated/torchrl.objectives.value.TD1Estimator", "reference/generated/torchrl.objectives.value.TDLambdaEstimator", "reference/generated/torchrl.objectives.value.ValueEstimatorBase", "reference/generated/torchrl.objectives.value.functional.generalized_advantage_estimate", "reference/generated/torchrl.objectives.value.functional.reward2go", "reference/generated/torchrl.objectives.value.functional.td0_advantage_estimate", "reference/generated/torchrl.objectives.value.functional.td0_return_estimate", "reference/generated/torchrl.objectives.value.functional.td1_advantage_estimate", "reference/generated/torchrl.objectives.value.functional.td1_return_estimate", "reference/generated/torchrl.objectives.value.functional.td_lambda_advantage_estimate", "reference/generated/torchrl.objectives.value.functional.td_lambda_return_estimate", "reference/generated/torchrl.objectives.value.functional.vec_generalized_advantage_estimate", "reference/generated/torchrl.objectives.value.functional.vec_td1_advantage_estimate", "reference/generated/torchrl.objectives.value.functional.vec_td1_return_estimate", "reference/generated/torchrl.objectives.value.functional.vec_td_lambda_advantage_estimate", "reference/generated/torchrl.objectives.value.functional.vec_td_lambda_return_estimate", "reference/generated/torchrl.record.TensorDictRecorder", "reference/generated/torchrl.record.VideoRecorder", "reference/generated/torchrl.record.loggers.Logger", "reference/generated/torchrl.record.loggers.csv.CSVLogger", "reference/generated/torchrl.record.loggers.generate_exp_name", "reference/generated/torchrl.record.loggers.get_logger", "reference/generated/torchrl.record.loggers.mlflow.MLFlowLogger", "reference/generated/torchrl.record.loggers.tensorboard.TensorboardLogger", "reference/generated/torchrl.record.loggers.wandb.WandbLogger", "reference/generated/torchrl.trainers.BatchSubSampler", "reference/generated/torchrl.trainers.ClearCudaCache", "reference/generated/torchrl.trainers.CountFramesLog", "reference/generated/torchrl.trainers.LogReward", "reference/generated/torchrl.trainers.OptimizerHook", "reference/generated/torchrl.trainers.Recorder", "reference/generated/torchrl.trainers.ReplayBufferTrainer", "reference/generated/torchrl.trainers.RewardNormalizer", "reference/generated/torchrl.trainers.SelectKeys", "reference/generated/torchrl.trainers.Trainer", "reference/generated/torchrl.trainers.TrainerHookBase", "reference/generated/torchrl.trainers.UpdateWeights", "reference/generated/torchrl.trainers.helpers.correct_for_frame_skip", "reference/generated/torchrl.trainers.helpers.get_stats_random_rollout", "reference/generated/torchrl.trainers.helpers.make_collector_offpolicy", "reference/generated/torchrl.trainers.helpers.make_collector_onpolicy", "reference/generated/torchrl.trainers.helpers.make_dqn_loss", "reference/generated/torchrl.trainers.helpers.make_redq_loss", "reference/generated/torchrl.trainers.helpers.make_redq_model", "reference/generated/torchrl.trainers.helpers.make_replay_buffer", "reference/generated/torchrl.trainers.helpers.make_target_updater", "reference/generated/torchrl.trainers.helpers.make_trainer", "reference/generated/torchrl.trainers.helpers.parallel_env_constructor", "reference/generated/torchrl.trainers.helpers.sync_async_collector", "reference/generated/torchrl.trainers.helpers.sync_sync_collector", "reference/generated/torchrl.trainers.helpers.transformed_env_constructor", "reference/generated/tutorials/README", "reference/index", "reference/knowledge_base", "reference/modules", "reference/objectives", "reference/trainers", "reference/utils", "sg_execution_times", "tutorials/coding_ddpg", "tutorials/coding_dqn", "tutorials/coding_ppo", "tutorials/dqn_with_rnn", "tutorials/index", "tutorials/multi_task", "tutorials/multiagent_ppo", "tutorials/pendulum", "tutorials/pretrained_models", "tutorials/rb_tutorial", "tutorials/sg_execution_times", "tutorials/torchrl_demo", "tutorials/torchrl_envs"], "filenames": ["index.rst", "reference/collectors.rst", "reference/data.rst", "reference/envs.rst", "reference/generated/knowledge_base/DEBUGGING_RL.rst", "reference/generated/knowledge_base/GYM.rst", "reference/generated/knowledge_base/HABITAT.rst", "reference/generated/knowledge_base/MUJOCO_INSTALLATION.rst", "reference/generated/knowledge_base/PRO-TIPS.rst", "reference/generated/knowledge_base/RESOURCES.rst", "reference/generated/knowledge_base/VERSIONING_ISSUES.rst", "reference/generated/torchrl._utils.implement_for.rst", "reference/generated/torchrl.collectors.collectors.DataCollectorBase.rst", "reference/generated/torchrl.collectors.collectors.MultiSyncDataCollector.rst", "reference/generated/torchrl.collectors.collectors.MultiaSyncDataCollector.rst", "reference/generated/torchrl.collectors.collectors.RandomPolicy.rst", "reference/generated/torchrl.collectors.collectors.SyncDataCollector.rst", "reference/generated/torchrl.collectors.collectors.aSyncDataCollector.rst", "reference/generated/torchrl.collectors.distributed.DistributedDataCollector.rst", "reference/generated/torchrl.collectors.distributed.DistributedSyncDataCollector.rst", "reference/generated/torchrl.collectors.distributed.RPCDataCollector.rst", "reference/generated/torchrl.collectors.distributed.RayCollector.rst", "reference/generated/torchrl.collectors.distributed.submitit_delayed_launcher.rst", "reference/generated/torchrl.collectors.utils.split_trajectories.rst", "reference/generated/torchrl.data.BinaryDiscreteTensorSpec.rst", "reference/generated/torchrl.data.BoundedTensorSpec.rst", "reference/generated/torchrl.data.CompositeSpec.rst", "reference/generated/torchrl.data.DiscreteTensorSpec.rst", "reference/generated/torchrl.data.LazyStackedCompositeSpec.rst", "reference/generated/torchrl.data.LazyStackedTensorSpec.rst", "reference/generated/torchrl.data.MultiDiscreteTensorSpec.rst", "reference/generated/torchrl.data.MultiOneHotDiscreteTensorSpec.rst", "reference/generated/torchrl.data.MultiStep.rst", "reference/generated/torchrl.data.OneHotDiscreteTensorSpec.rst", "reference/generated/torchrl.data.PairwiseDataset.rst", "reference/generated/torchrl.data.PrioritizedReplayBuffer.rst", "reference/generated/torchrl.data.PromptData.rst", "reference/generated/torchrl.data.PromptTensorDictTokenizer.rst", "reference/generated/torchrl.data.ReplayBuffer.rst", "reference/generated/torchrl.data.RewardData.rst", "reference/generated/torchrl.data.RolloutFromModel.rst", "reference/generated/torchrl.data.TensorDictPrioritizedReplayBuffer.rst", "reference/generated/torchrl.data.TensorDictReplayBuffer.rst", "reference/generated/torchrl.data.TensorDictTokenizer.rst", "reference/generated/torchrl.data.TensorSpec.rst", "reference/generated/torchrl.data.TokenizedDatasetLoader.rst", "reference/generated/torchrl.data.UnboundedContinuousTensorSpec.rst", "reference/generated/torchrl.data.UnboundedDiscreteTensorSpec.rst", "reference/generated/torchrl.data.check_no_exclusive_keys.rst", "reference/generated/torchrl.data.consolidate_spec.rst", "reference/generated/torchrl.data.contains_lazy_spec.rst", "reference/generated/torchrl.data.create_infinite_iterator.rst", "reference/generated/torchrl.data.datasets.D4RLExperienceReplay.rst", "reference/generated/torchrl.data.datasets.MinariExperienceReplay.rst", "reference/generated/torchrl.data.datasets.OpenMLExperienceReplay.rst", "reference/generated/torchrl.data.datasets.RobosetExperienceReplay.rst", "reference/generated/torchrl.data.datasets.VD4RLExperienceReplay.rst", "reference/generated/torchrl.data.get_dataloader.rst", "reference/generated/torchrl.data.replay_buffers.LazyMemmapStorage.rst", "reference/generated/torchrl.data.replay_buffers.LazyTensorStorage.rst", "reference/generated/torchrl.data.replay_buffers.ListStorage.rst", "reference/generated/torchrl.data.replay_buffers.PrioritizedSampler.rst", "reference/generated/torchrl.data.replay_buffers.RandomSampler.rst", "reference/generated/torchrl.data.replay_buffers.RoundRobinWriter.rst", "reference/generated/torchrl.data.replay_buffers.Sampler.rst", "reference/generated/torchrl.data.replay_buffers.SamplerWithoutReplacement.rst", "reference/generated/torchrl.data.replay_buffers.SliceSampler.rst", "reference/generated/torchrl.data.replay_buffers.SliceSamplerWithoutReplacement.rst", "reference/generated/torchrl.data.replay_buffers.Storage.rst", "reference/generated/torchrl.data.replay_buffers.TensorDictMaxValueWriter.rst", "reference/generated/torchrl.data.replay_buffers.TensorDictRoundRobinWriter.rst", "reference/generated/torchrl.data.replay_buffers.TensorStorage.rst", "reference/generated/torchrl.data.replay_buffers.Writer.rst", "reference/generated/torchrl.envs.BraxEnv.rst", "reference/generated/torchrl.envs.BraxWrapper.rst", "reference/generated/torchrl.envs.DMControlEnv.rst", "reference/generated/torchrl.envs.DMControlWrapper.rst", "reference/generated/torchrl.envs.EnvBase.rst", "reference/generated/torchrl.envs.EnvCreator.rst", "reference/generated/torchrl.envs.EnvMetaData.rst", "reference/generated/torchrl.envs.GymEnv.rst", "reference/generated/torchrl.envs.GymLikeEnv.rst", "reference/generated/torchrl.envs.GymWrapper.rst", "reference/generated/torchrl.envs.HabitatEnv.rst", "reference/generated/torchrl.envs.IsaacGymEnv.rst", "reference/generated/torchrl.envs.IsaacGymWrapper.rst", "reference/generated/torchrl.envs.JumanjiEnv.rst", "reference/generated/torchrl.envs.JumanjiWrapper.rst", "reference/generated/torchrl.envs.MOGymEnv.rst", "reference/generated/torchrl.envs.MOGymWrapper.rst", "reference/generated/torchrl.envs.MarlGroupMapType.rst", "reference/generated/torchrl.envs.ModelBasedEnvBase.rst", "reference/generated/torchrl.envs.MultiThreadedEnv.rst", "reference/generated/torchrl.envs.MultiThreadedEnvWrapper.rst", "reference/generated/torchrl.envs.OpenMLEnv.rst", "reference/generated/torchrl.envs.ParallelEnv.rst", "reference/generated/torchrl.envs.PettingZooEnv.rst", "reference/generated/torchrl.envs.PettingZooWrapper.rst", "reference/generated/torchrl.envs.RoboHiveEnv.rst", "reference/generated/torchrl.envs.SMACv2Env.rst", "reference/generated/torchrl.envs.SMACv2Wrapper.rst", "reference/generated/torchrl.envs.SerialEnv.rst", "reference/generated/torchrl.envs.VmasEnv.rst", "reference/generated/torchrl.envs.VmasWrapper.rst", "reference/generated/torchrl.envs.check_marl_grouping.rst", "reference/generated/torchrl.envs.gym_backend.rst", "reference/generated/torchrl.envs.model_based.dreamer.DreamerEnv.rst", "reference/generated/torchrl.envs.set_gym_backend.rst", "reference/generated/torchrl.envs.transforms.ActionMask.rst", "reference/generated/torchrl.envs.transforms.BinarizeReward.rst", "reference/generated/torchrl.envs.transforms.CatFrames.rst", "reference/generated/torchrl.envs.transforms.CatTensors.rst", "reference/generated/torchrl.envs.transforms.CenterCrop.rst", "reference/generated/torchrl.envs.transforms.ClipTransform.rst", "reference/generated/torchrl.envs.transforms.Compose.rst", "reference/generated/torchrl.envs.transforms.DTypeCastTransform.rst", "reference/generated/torchrl.envs.transforms.DeviceCastTransform.rst", "reference/generated/torchrl.envs.transforms.DiscreteActionProjection.rst", "reference/generated/torchrl.envs.transforms.DoubleToFloat.rst", "reference/generated/torchrl.envs.transforms.EndOfLifeTransform.rst", "reference/generated/torchrl.envs.transforms.ExcludeTransform.rst", "reference/generated/torchrl.envs.transforms.FiniteTensorDictCheck.rst", "reference/generated/torchrl.envs.transforms.FlattenObservation.rst", "reference/generated/torchrl.envs.transforms.FrameSkipTransform.rst", "reference/generated/torchrl.envs.transforms.GrayScale.rst", "reference/generated/torchrl.envs.transforms.InitTracker.rst", "reference/generated/torchrl.envs.transforms.KLRewardTransform.rst", "reference/generated/torchrl.envs.transforms.NoopResetEnv.rst", "reference/generated/torchrl.envs.transforms.ObservationNorm.rst", "reference/generated/torchrl.envs.transforms.ObservationTransform.rst", "reference/generated/torchrl.envs.transforms.PermuteTransform.rst", "reference/generated/torchrl.envs.transforms.PinMemoryTransform.rst", "reference/generated/torchrl.envs.transforms.R3MTransform.rst", "reference/generated/torchrl.envs.transforms.RandomCropTensorDict.rst", "reference/generated/torchrl.envs.transforms.RenameTransform.rst", "reference/generated/torchrl.envs.transforms.Resize.rst", "reference/generated/torchrl.envs.transforms.Reward2GoTransform.rst", "reference/generated/torchrl.envs.transforms.RewardClipping.rst", "reference/generated/torchrl.envs.transforms.RewardScaling.rst", "reference/generated/torchrl.envs.transforms.RewardSum.rst", "reference/generated/torchrl.envs.transforms.SelectTransform.rst", "reference/generated/torchrl.envs.transforms.SqueezeTransform.rst", "reference/generated/torchrl.envs.transforms.StepCounter.rst", "reference/generated/torchrl.envs.transforms.TargetReturn.rst", "reference/generated/torchrl.envs.transforms.TensorDictPrimer.rst", "reference/generated/torchrl.envs.transforms.TimeMaxPool.rst", "reference/generated/torchrl.envs.transforms.ToTensorImage.rst", "reference/generated/torchrl.envs.transforms.Transform.rst", "reference/generated/torchrl.envs.transforms.TransformedEnv.rst", "reference/generated/torchrl.envs.transforms.UnsqueezeTransform.rst", "reference/generated/torchrl.envs.transforms.VC1Transform.rst", "reference/generated/torchrl.envs.transforms.VIPRewardTransform.rst", "reference/generated/torchrl.envs.transforms.VIPTransform.rst", "reference/generated/torchrl.envs.transforms.VecGymEnvTransform.rst", "reference/generated/torchrl.envs.transforms.VecNorm.rst", "reference/generated/torchrl.envs.transforms.gSDENoise.rst", "reference/generated/torchrl.envs.utils.check_env_specs.rst", "reference/generated/torchrl.envs.utils.exploration_mode.rst", "reference/generated/torchrl.envs.utils.exploration_type.rst", "reference/generated/torchrl.envs.utils.get_available_libraries.rst", "reference/generated/torchrl.envs.utils.make_composite_from_td.rst", "reference/generated/torchrl.envs.utils.set_exploration_mode.rst", "reference/generated/torchrl.envs.utils.set_exploration_type.rst", "reference/generated/torchrl.envs.utils.step_mdp.rst", "reference/generated/torchrl.envs.utils.terminated_or_truncated.rst", "reference/generated/torchrl.modules.CEMPlanner.rst", "reference/generated/torchrl.modules.Conv3dNet.rst", "reference/generated/torchrl.modules.ConvNet.rst", "reference/generated/torchrl.modules.DTActor.rst", "reference/generated/torchrl.modules.DdpgCnnActor.rst", "reference/generated/torchrl.modules.DdpgCnnQNet.rst", "reference/generated/torchrl.modules.DdpgMlpActor.rst", "reference/generated/torchrl.modules.DdpgMlpQNet.rst", "reference/generated/torchrl.modules.DecisionTransformer.rst", "reference/generated/torchrl.modules.Delta.rst", "reference/generated/torchrl.modules.DistributionalDQNnet.rst", "reference/generated/torchrl.modules.DistributionalQValueHook.rst", "reference/generated/torchrl.modules.DreamerActor.rst", "reference/generated/torchrl.modules.DuelingCnnDQNet.rst", "reference/generated/torchrl.modules.GRU.rst", "reference/generated/torchrl.modules.GRUCell.rst", "reference/generated/torchrl.modules.GRUModule.rst", "reference/generated/torchrl.modules.IndependentNormal.rst", "reference/generated/torchrl.modules.LSTM.rst", "reference/generated/torchrl.modules.LSTMCell.rst", "reference/generated/torchrl.modules.LSTMModule.rst", "reference/generated/torchrl.modules.LSTMNet.rst", "reference/generated/torchrl.modules.MLP.rst", "reference/generated/torchrl.modules.MPCPlannerBase.rst", "reference/generated/torchrl.modules.MPPIPlanner.rst", "reference/generated/torchrl.modules.MaskedCategorical.rst", "reference/generated/torchrl.modules.MaskedOneHotCategorical.rst", "reference/generated/torchrl.modules.MultiAgentConvNet.rst", "reference/generated/torchrl.modules.MultiAgentMLP.rst", "reference/generated/torchrl.modules.NoisyLazyLinear.rst", "reference/generated/torchrl.modules.NoisyLinear.rst", "reference/generated/torchrl.modules.NormalParamWrapper.rst", "reference/generated/torchrl.modules.ObsDecoder.rst", "reference/generated/torchrl.modules.ObsEncoder.rst", "reference/generated/torchrl.modules.OneHotCategorical.rst", "reference/generated/torchrl.modules.OnlineDTActor.rst", "reference/generated/torchrl.modules.QMixer.rst", "reference/generated/torchrl.modules.QValueHook.rst", "reference/generated/torchrl.modules.RSSMPosterior.rst", "reference/generated/torchrl.modules.RSSMPrior.rst", "reference/generated/torchrl.modules.Squeeze2dLayer.rst", "reference/generated/torchrl.modules.SqueezeLayer.rst", "reference/generated/torchrl.modules.TanhDelta.rst", "reference/generated/torchrl.modules.TanhNormal.rst", "reference/generated/torchrl.modules.TruncatedNormal.rst", "reference/generated/torchrl.modules.VDNMixer.rst", "reference/generated/torchrl.modules.VmapModule.rst", "reference/generated/torchrl.modules.reset_noise.rst", "reference/generated/torchrl.modules.tensordict_module.Actor.rst", "reference/generated/torchrl.modules.tensordict_module.ActorCriticOperator.rst", "reference/generated/torchrl.modules.tensordict_module.ActorCriticWrapper.rst", "reference/generated/torchrl.modules.tensordict_module.ActorValueOperator.rst", "reference/generated/torchrl.modules.tensordict_module.AdditiveGaussianWrapper.rst", "reference/generated/torchrl.modules.tensordict_module.DecisionTransformerInferenceWrapper.rst", "reference/generated/torchrl.modules.tensordict_module.DistributionalQValueActor.rst", "reference/generated/torchrl.modules.tensordict_module.DistributionalQValueModule.rst", "reference/generated/torchrl.modules.tensordict_module.EGreedyModule.rst", "reference/generated/torchrl.modules.tensordict_module.EGreedyWrapper.rst", "reference/generated/torchrl.modules.tensordict_module.LMHeadActorValueOperator.rst", "reference/generated/torchrl.modules.tensordict_module.OrnsteinUhlenbeckProcessWrapper.rst", "reference/generated/torchrl.modules.tensordict_module.ProbabilisticActor.rst", "reference/generated/torchrl.modules.tensordict_module.QValueActor.rst", "reference/generated/torchrl.modules.tensordict_module.QValueModule.rst", "reference/generated/torchrl.modules.tensordict_module.SafeModule.rst", "reference/generated/torchrl.modules.tensordict_module.SafeProbabilisticModule.rst", "reference/generated/torchrl.modules.tensordict_module.SafeProbabilisticTensorDictSequential.rst", "reference/generated/torchrl.modules.tensordict_module.SafeSequential.rst", "reference/generated/torchrl.modules.tensordict_module.TanhModule.rst", "reference/generated/torchrl.modules.tensordict_module.ValueOperator.rst", "reference/generated/torchrl.modules.tensordict_module.WorldModelWrapper.rst", "reference/generated/torchrl.modules.utils.biased_softplus.rst", "reference/generated/torchrl.modules.utils.inv_softplus.rst", "reference/generated/torchrl.modules.utils.mappings.rst", "reference/generated/torchrl.objectives.A2CLoss.rst", "reference/generated/torchrl.objectives.CQLLoss.rst", "reference/generated/torchrl.objectives.ClipPPOLoss.rst", "reference/generated/torchrl.objectives.DDPGLoss.rst", "reference/generated/torchrl.objectives.DQNLoss.rst", "reference/generated/torchrl.objectives.DTLoss.rst", "reference/generated/torchrl.objectives.DiscreteCQLLoss.rst", "reference/generated/torchrl.objectives.DiscreteSACLoss.rst", "reference/generated/torchrl.objectives.DistributionalDQNLoss.rst", "reference/generated/torchrl.objectives.DreamerActorLoss.rst", "reference/generated/torchrl.objectives.DreamerModelLoss.rst", "reference/generated/torchrl.objectives.DreamerValueLoss.rst", "reference/generated/torchrl.objectives.HardUpdate.rst", "reference/generated/torchrl.objectives.IQLLoss.rst", "reference/generated/torchrl.objectives.KLPENPPOLoss.rst", "reference/generated/torchrl.objectives.LossModule.rst", "reference/generated/torchrl.objectives.OnlineDTLoss.rst", "reference/generated/torchrl.objectives.PPOLoss.rst", "reference/generated/torchrl.objectives.REDQLoss.rst", "reference/generated/torchrl.objectives.ReinforceLoss.rst", "reference/generated/torchrl.objectives.SACLoss.rst", "reference/generated/torchrl.objectives.SoftUpdate.rst", "reference/generated/torchrl.objectives.TD3Loss.rst", "reference/generated/torchrl.objectives.ValueEstimators.rst", "reference/generated/torchrl.objectives.default_value_kwargs.rst", "reference/generated/torchrl.objectives.distance_loss.rst", "reference/generated/torchrl.objectives.hold_out_net.rst", "reference/generated/torchrl.objectives.hold_out_params.rst", "reference/generated/torchrl.objectives.multiagent.QMixerLoss.rst", "reference/generated/torchrl.objectives.next_state_value.rst", "reference/generated/torchrl.objectives.value.GAE.rst", "reference/generated/torchrl.objectives.value.TD0Estimator.rst", "reference/generated/torchrl.objectives.value.TD1Estimator.rst", "reference/generated/torchrl.objectives.value.TDLambdaEstimator.rst", "reference/generated/torchrl.objectives.value.ValueEstimatorBase.rst", "reference/generated/torchrl.objectives.value.functional.generalized_advantage_estimate.rst", "reference/generated/torchrl.objectives.value.functional.reward2go.rst", "reference/generated/torchrl.objectives.value.functional.td0_advantage_estimate.rst", "reference/generated/torchrl.objectives.value.functional.td0_return_estimate.rst", "reference/generated/torchrl.objectives.value.functional.td1_advantage_estimate.rst", "reference/generated/torchrl.objectives.value.functional.td1_return_estimate.rst", "reference/generated/torchrl.objectives.value.functional.td_lambda_advantage_estimate.rst", "reference/generated/torchrl.objectives.value.functional.td_lambda_return_estimate.rst", "reference/generated/torchrl.objectives.value.functional.vec_generalized_advantage_estimate.rst", "reference/generated/torchrl.objectives.value.functional.vec_td1_advantage_estimate.rst", "reference/generated/torchrl.objectives.value.functional.vec_td1_return_estimate.rst", "reference/generated/torchrl.objectives.value.functional.vec_td_lambda_advantage_estimate.rst", "reference/generated/torchrl.objectives.value.functional.vec_td_lambda_return_estimate.rst", "reference/generated/torchrl.record.TensorDictRecorder.rst", "reference/generated/torchrl.record.VideoRecorder.rst", "reference/generated/torchrl.record.loggers.Logger.rst", "reference/generated/torchrl.record.loggers.csv.CSVLogger.rst", "reference/generated/torchrl.record.loggers.generate_exp_name.rst", "reference/generated/torchrl.record.loggers.get_logger.rst", "reference/generated/torchrl.record.loggers.mlflow.MLFlowLogger.rst", "reference/generated/torchrl.record.loggers.tensorboard.TensorboardLogger.rst", "reference/generated/torchrl.record.loggers.wandb.WandbLogger.rst", "reference/generated/torchrl.trainers.BatchSubSampler.rst", "reference/generated/torchrl.trainers.ClearCudaCache.rst", "reference/generated/torchrl.trainers.CountFramesLog.rst", "reference/generated/torchrl.trainers.LogReward.rst", "reference/generated/torchrl.trainers.OptimizerHook.rst", "reference/generated/torchrl.trainers.Recorder.rst", "reference/generated/torchrl.trainers.ReplayBufferTrainer.rst", "reference/generated/torchrl.trainers.RewardNormalizer.rst", "reference/generated/torchrl.trainers.SelectKeys.rst", "reference/generated/torchrl.trainers.Trainer.rst", "reference/generated/torchrl.trainers.TrainerHookBase.rst", "reference/generated/torchrl.trainers.UpdateWeights.rst", "reference/generated/torchrl.trainers.helpers.correct_for_frame_skip.rst", "reference/generated/torchrl.trainers.helpers.get_stats_random_rollout.rst", "reference/generated/torchrl.trainers.helpers.make_collector_offpolicy.rst", "reference/generated/torchrl.trainers.helpers.make_collector_onpolicy.rst", "reference/generated/torchrl.trainers.helpers.make_dqn_loss.rst", "reference/generated/torchrl.trainers.helpers.make_redq_loss.rst", "reference/generated/torchrl.trainers.helpers.make_redq_model.rst", "reference/generated/torchrl.trainers.helpers.make_replay_buffer.rst", "reference/generated/torchrl.trainers.helpers.make_target_updater.rst", "reference/generated/torchrl.trainers.helpers.make_trainer.rst", "reference/generated/torchrl.trainers.helpers.parallel_env_constructor.rst", "reference/generated/torchrl.trainers.helpers.sync_async_collector.rst", "reference/generated/torchrl.trainers.helpers.sync_sync_collector.rst", "reference/generated/torchrl.trainers.helpers.transformed_env_constructor.rst", "reference/generated/tutorials/README.rst", "reference/index.rst", "reference/knowledge_base.rst", "reference/modules.rst", "reference/objectives.rst", "reference/trainers.rst", "reference/utils.rst", "sg_execution_times.rst", "tutorials/coding_ddpg.rst", "tutorials/coding_dqn.rst", "tutorials/coding_ppo.rst", "tutorials/dqn_with_rnn.rst", "tutorials/index.rst", "tutorials/multi_task.rst", "tutorials/multiagent_ppo.rst", "tutorials/pendulum.rst", "tutorials/pretrained_models.rst", "tutorials/rb_tutorial.rst", "tutorials/sg_execution_times.rst", "tutorials/torchrl_demo.rst", "tutorials/torchrl_envs.rst"], "titles": ["TorchRL", "torchrl.collectors package", "torchrl.data package", "torchrl.envs package", "Things to consider when debugging RL", "Working with gym", "Working with <code class=\"docutils literal notranslate\"><span class=\"pre\">habitat-lab</span></code>", "Working with MuJoCo-based environments", "Common PyTorch errors and solutions", "Useful resources", "Versioning Issues", "implement_for", "DataCollectorBase", "MultiSyncDataCollector", "MultiaSyncDataCollector", "RandomPolicy", "SyncDataCollector", "aSyncDataCollector", "DistributedDataCollector", "DistributedSyncDataCollector", "RPCDataCollector", "RayCollector", "submitit_delayed_launcher", "split_trajectories", "BinaryDiscreteTensorSpec", "BoundedTensorSpec", "CompositeSpec", "DiscreteTensorSpec", "LazyStackedCompositeSpec", "LazyStackedTensorSpec", "MultiDiscreteTensorSpec", "MultiOneHotDiscreteTensorSpec", "MultiStep", "OneHotDiscreteTensorSpec", "PairwiseDataset", "PrioritizedReplayBuffer", "PromptData", "PromptTensorDictTokenizer", "ReplayBuffer", "RewardData", "RolloutFromModel", "TensorDictPrioritizedReplayBuffer", "TensorDictReplayBuffer", "TensorDictTokenizer", "TensorSpec", "TokenizedDatasetLoader", "UnboundedContinuousTensorSpec", "UnboundedDiscreteTensorSpec", "check_no_exclusive_keys", "consolidate_spec", "contains_lazy_spec", "create_infinite_iterator", "D4RLExperienceReplay", "MinariExperienceReplay", "OpenMLExperienceReplay", "RobosetExperienceReplay", "VD4RLExperienceReplay", "get_dataloader", "LazyMemmapStorage", "LazyTensorStorage", "ListStorage", "PrioritizedSampler", "RandomSampler", "RoundRobinWriter", "Sampler", "SamplerWithoutReplacement", "SliceSampler", "SliceSamplerWithoutReplacement", "Storage", "TensorDictMaxValueWriter", "TensorDictRoundRobinWriter", "TensorStorage", "Writer", "BraxEnv", "BraxWrapper", "DMControlEnv", "DMControlWrapper", "EnvBase", "EnvCreator", "EnvMetaData", "GymEnv", "GymLikeEnv", "GymWrapper", "HabitatEnv", "IsaacGymEnv", "IsaacGymWrapper", "JumanjiEnv", "JumanjiWrapper", "MOGymEnv", "MOGymWrapper", "MarlGroupMapType", "ModelBasedEnvBase", "MultiThreadedEnv", "MultiThreadedEnvWrapper", "OpenMLEnv", "ParallelEnv", "PettingZooEnv", "PettingZooWrapper", "RoboHiveEnv", "SMACv2Env", "SMACv2Wrapper", "SerialEnv", "VmasEnv", "VmasWrapper", "check_marl_grouping", "gym_backend", "DreamerEnv", "set_gym_backend", "ActionMask", "BinarizeReward", "CatFrames", "CatTensors", "CenterCrop", "ClipTransform", "Compose", "DTypeCastTransform", "DeviceCastTransform", "DiscreteActionProjection", "DoubleToFloat", "EndOfLifeTransform", "ExcludeTransform", "FiniteTensorDictCheck", "FlattenObservation", "FrameSkipTransform", "GrayScale", "InitTracker", "KLRewardTransform", "NoopResetEnv", "ObservationNorm", "ObservationTransform", "PermuteTransform", "PinMemoryTransform", "R3MTransform", "RandomCropTensorDict", "RenameTransform", "Resize", "Reward2GoTransform", "RewardClipping", "RewardScaling", "RewardSum", "SelectTransform", "SqueezeTransform", "StepCounter", "TargetReturn", "TensorDictPrimer", "TimeMaxPool", "ToTensorImage", "Transform", "TransformedEnv", "UnsqueezeTransform", "VC1Transform", "VIPRewardTransform", "VIPTransform", "VecGymEnvTransform", "VecNorm", "gSDENoise", "check_env_specs", "exploration_mode", "exploration_type", "get_available_libraries", "make_composite_from_td", "set_exploration_mode", "set_exploration_type", "step_mdp", "terminated_or_truncated", "CEMPlanner", "Conv3dNet", "ConvNet", "DTActor", "DdpgCnnActor", "DdpgCnnQNet", "DdpgMlpActor", "DdpgMlpQNet", "DecisionTransformer", "Delta", "DistributionalDQNnet", "DistributionalQValueHook", "DreamerActor", "DuelingCnnDQNet", "GRU", "GRUCell", "GRUModule", "IndependentNormal", "LSTM", "LSTMCell", "LSTMModule", "LSTMNet", "MLP", "MPCPlannerBase", "MPPIPlanner", "MaskedCategorical", "MaskedOneHotCategorical", "MultiAgentConvNet", "MultiAgentMLP", "NoisyLazyLinear", "NoisyLinear", "NormalParamWrapper", "ObsDecoder", "ObsEncoder", "OneHotCategorical", "OnlineDTActor", "QMixer", "QValueHook", "RSSMPosterior", "RSSMPrior", "Squeeze2dLayer", "SqueezeLayer", "TanhDelta", "TanhNormal", "TruncatedNormal", "VDNMixer", "VmapModule", "reset_noise", "Actor", "ActorCriticOperator", "ActorCriticWrapper", "ActorValueOperator", "AdditiveGaussianWrapper", "DecisionTransformerInferenceWrapper", "DistributionalQValueActor", "DistributionalQValueModule", "EGreedyModule", "EGreedyWrapper", "LMHeadActorValueOperator", "OrnsteinUhlenbeckProcessWrapper", "ProbabilisticActor", "QValueActor", "QValueModule", "SafeModule", "SafeProbabilisticModule", "SafeProbabilisticTensorDictSequential", "SafeSequential", "TanhModule", "ValueOperator", "WorldModelWrapper", "biased_softplus", "inv_softplus", "mappings", "A2CLoss", "CQLLoss", "ClipPPOLoss", "DDPGLoss", "DQNLoss", "DTLoss", "DiscreteCQLLoss", "DiscreteSACLoss", "DistributionalDQNLoss", "DreamerActorLoss", "DreamerModelLoss", "DreamerValueLoss", "HardUpdate", "IQLLoss", "KLPENPPOLoss", "LossModule", "OnlineDTLoss", "PPOLoss", "REDQLoss", "ReinforceLoss", "SACLoss", "SoftUpdate", "TD3Loss", "ValueEstimators", "default_value_kwargs", "distance_loss", "hold_out_net", "hold_out_params", "QMixerLoss", "next_state_value", "GAE", "TD0Estimator", "TD1Estimator", "TDLambdaEstimator", "ValueEstimatorBase", "generalized_advantage_estimate", "reward2go", "td0_advantage_estimate", "td0_return_estimate", "td1_advantage_estimate", "td1_return_estimate", "td_lambda_advantage_estimate", "td_lambda_return_estimate", "vec_generalized_advantage_estimate", "vec_td1_advantage_estimate", "vec_td1_return_estimate", "vec_td_lambda_advantage_estimate", "vec_td_lambda_return_estimate", "TensorDictRecorder", "VideoRecorder", "Logger", "CSVLogger", "generate_exp_name", "get_logger", "MLFlowLogger", "TensorboardLogger", "WandbLogger", "BatchSubSampler", "ClearCudaCache", "CountFramesLog", "LogReward", "OptimizerHook", "Recorder", "ReplayBufferTrainer", "RewardNormalizer", "SelectKeys", "Trainer", "TrainerHookBase", "UpdateWeights", "correct_for_frame_skip", "get_stats_random_rollout", "make_collector_offpolicy", "make_collector_onpolicy", "make_dqn_loss", "make_redq_loss", "make_redq_model", "make_replay_buffer", "make_target_updater", "make_trainer", "parallel_env_constructor", "sync_async_collector", "sync_sync_collector", "transformed_env_constructor", "README Tutos", "API Reference", "Knowledge Base", "torchrl.modules package", "torchrl.objectives package", "torchrl.trainers package", "torchrl._utils package", "Computation times", "TorchRL objectives: Coding a DDPG loss", "TorchRL trainer: A DQN example", "Reinforcement Learning (PPO) with TorchRL Tutorial", "Recurrent DQN: Training recurrent policies", "README Tutos", "Task-specific policy in multi-task environments", "Multi-Agent Reinforcement Learning (PPO) with TorchRL Tutorial", "Pendulum: Writing your environment and transforms with TorchRL", "Using pretrained models", "Using Replay Buffers", "Computation times", "Introduction to TorchRL", "TorchRL envs"], "terms": {"an": [0, 1, 2, 3, 5, 8, 9, 10, 13, 14, 16, 17, 18, 19, 20, 21, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 44, 46, 47, 51, 52, 53, 54, 55, 56, 58, 59, 60, 63, 68, 69, 70, 71, 72, 75, 77, 78, 81, 91, 92, 94, 95, 96, 97, 101, 104, 108, 110, 112, 115, 117, 118, 121, 127, 128, 132, 133, 134, 136, 143, 144, 145, 146, 147, 148, 150, 153, 154, 156, 166, 167, 169, 170, 171, 172, 179, 181, 183, 185, 186, 187, 188, 192, 193, 194, 198, 205, 206, 214, 215, 216, 217, 218, 219, 220, 221, 223, 224, 225, 226, 229, 230, 234, 237, 238, 239, 240, 242, 245, 246, 247, 248, 249, 251, 252, 253, 255, 256, 257, 258, 260, 266, 268, 269, 270, 271, 272, 287, 290, 299, 300, 304, 305, 308, 317, 318, 319, 320, 323, 324, 325, 329, 330, 334, 335, 337, 338, 340, 341], "open": [0, 5, 7, 11, 330, 335, 340], "sourc": [0, 1, 4, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 159, 160, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 340, 341], "reinforc": [0, 3, 9, 110, 169, 170, 171, 172, 176, 220, 224, 238, 239, 243, 244, 246, 250, 251, 257, 258, 259, 322, 328, 330, 333, 336, 339, 340], "learn": [0, 3, 7, 8, 9, 18, 32, 54, 55, 56, 110, 169, 170, 171, 172, 176, 189, 195, 220, 224, 238, 239, 243, 244, 246, 250, 251, 256, 257, 258, 259, 322, 324, 325, 328, 329, 330, 332, 333, 334, 336, 338, 339, 340, 341], "rl": [0, 1, 2, 3, 5, 8, 10, 13, 14, 16, 17, 91, 143, 195, 213, 225, 233, 238, 253, 255, 295, 323, 324, 325, 326, 329, 330, 331, 335, 337, 338, 341], "librari": [0, 1, 2, 5, 6, 7, 8, 9, 10, 18, 19, 20, 37, 43, 85, 92, 159, 322, 323, 324, 327, 329, 330, 331, 335, 336, 341], "pytorch": [0, 1, 2, 3, 53, 146, 179, 183, 194, 195, 304, 323, 326, 329, 331, 332, 335, 336, 337, 340, 341], "It": [0, 2, 3, 4, 7, 32, 37, 40, 41, 43, 45, 52, 53, 55, 56, 77, 81, 83, 91, 92, 95, 96, 97, 101, 119, 126, 128, 133, 143, 148, 153, 156, 169, 171, 177, 192, 193, 201, 203, 204, 210, 211, 220, 221, 224, 227, 229, 238, 239, 240, 245, 246, 247, 248, 249, 251, 252, 253, 255, 256, 257, 258, 259, 260, 266, 267, 268, 300, 313, 323, 324, 325, 329, 330, 332, 335, 336, 337, 338, 340, 341], "provid": [0, 1, 2, 3, 5, 8, 9, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 24, 30, 31, 32, 33, 35, 38, 41, 42, 45, 49, 52, 53, 54, 55, 56, 57, 58, 62, 66, 67, 69, 77, 81, 91, 95, 96, 97, 101, 110, 111, 112, 113, 115, 118, 122, 127, 128, 130, 132, 133, 135, 136, 139, 140, 143, 144, 145, 148, 150, 152, 153, 154, 164, 166, 167, 173, 176, 179, 180, 181, 183, 184, 185, 186, 187, 188, 190, 191, 192, 193, 211, 213, 217, 220, 221, 222, 224, 225, 226, 227, 232, 238, 239, 241, 242, 244, 245, 246, 247, 251, 253, 255, 256, 257, 258, 260, 266, 267, 268, 269, 270, 271, 272, 273, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 287, 291, 295, 301, 308, 313, 316, 323, 324, 325, 326, 329, 330, 331, 332, 334, 335, 336, 337, 338, 340, 341], "python": [0, 3, 5, 6, 7, 10, 21, 107, 179, 180, 181, 183, 184, 185, 190, 191, 326, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 340, 341], "first": [0, 1, 3, 4, 5, 7, 8, 18, 20, 21, 26, 28, 52, 53, 55, 56, 58, 59, 66, 67, 71, 81, 110, 111, 122, 128, 132, 133, 146, 148, 150, 179, 181, 183, 185, 187, 192, 193, 194, 198, 213, 218, 219, 220, 225, 226, 228, 229, 240, 248, 252, 253, 255, 286, 303, 324, 329, 330, 331, 332, 334, 335, 336, 337, 338, 340, 341], "low": [0, 25, 77, 81, 95, 101, 113, 117, 160, 220, 225, 232, 329, 330, 331, 335, 336, 340, 341], "high": [0, 9, 25, 41, 77, 81, 95, 101, 113, 117, 127, 160, 220, 225, 232, 268, 273, 281, 329, 330, 331, 335, 336, 338, 340, 341], "level": [0, 3, 4, 22, 26, 28, 110, 142, 252, 329, 330, 340], "abstract": [0, 3, 8, 24, 25, 26, 27, 28, 29, 30, 44, 46, 47, 72, 77, 129, 188, 272, 296, 305, 326, 331, 336, 340], "ar": [0, 1, 2, 3, 7, 8, 9, 10, 13, 14, 16, 17, 18, 19, 20, 21, 23, 28, 29, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 45, 48, 52, 53, 54, 55, 56, 57, 58, 59, 60, 67, 68, 71, 77, 78, 81, 90, 91, 94, 95, 96, 97, 98, 101, 103, 110, 113, 114, 115, 117, 118, 119, 121, 122, 126, 127, 130, 132, 136, 139, 144, 145, 146, 147, 148, 149, 150, 152, 153, 154, 160, 164, 165, 172, 174, 179, 180, 181, 183, 184, 185, 186, 188, 190, 191, 192, 195, 199, 201, 204, 218, 219, 221, 224, 225, 226, 228, 229, 230, 231, 232, 237, 238, 239, 240, 241, 242, 244, 245, 246, 247, 248, 249, 251, 252, 253, 255, 256, 257, 258, 260, 263, 266, 267, 268, 269, 270, 271, 272, 301, 316, 320, 324, 325, 326, 327, 329, 330, 331, 332, 334, 335, 336, 337, 338, 340, 341], "intend": [0, 7, 13, 14, 16, 17, 18, 19, 20, 21, 45, 117, 211, 253, 324, 340], "effici": [0, 1, 2, 4, 8, 179, 195, 324, 329, 330, 331, 332, 334, 335, 337, 338, 340], "modular": [0, 231, 338, 340], "document": [0, 5, 7, 18, 19, 21, 32, 77, 81, 95, 101, 148, 330, 332, 340], "properli": [0, 77, 81, 95, 101, 331, 335, 336, 340], "test": [0, 3, 5, 150, 156, 181, 185, 186, 300, 316, 331, 332, 340], "The": [0, 1, 2, 3, 4, 5, 7, 8, 13, 14, 16, 17, 18, 19, 20, 21, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 52, 53, 54, 55, 56, 57, 66, 67, 68, 69, 77, 81, 85, 95, 96, 97, 101, 110, 114, 115, 118, 119, 120, 128, 130, 132, 136, 138, 139, 140, 142, 143, 144, 147, 148, 150, 152, 153, 163, 164, 165, 169, 170, 171, 172, 173, 176, 179, 180, 181, 183, 184, 185, 186, 188, 189, 190, 191, 192, 195, 196, 202, 203, 204, 213, 214, 218, 219, 220, 224, 225, 226, 227, 228, 229, 231, 233, 234, 235, 238, 239, 240, 241, 242, 244, 245, 246, 247, 248, 249, 251, 252, 253, 255, 256, 257, 258, 260, 266, 267, 268, 269, 270, 271, 272, 274, 289, 292, 293, 294, 295, 299, 316, 318, 319, 324, 325, 326, 330, 331, 332, 335, 336, 337, 338, 340, 341], "code": [0, 3, 5, 7, 8, 77, 81, 95, 101, 132, 148, 150, 179, 180, 181, 183, 184, 185, 231, 328, 330, 331, 332, 333, 334, 335, 337, 338, 339, 340, 341], "aim": [0, 3, 7, 28, 29, 132, 150, 152, 187, 307, 323, 324, 325, 329, 330, 340], "support": [0, 1, 3, 18, 20, 26, 54, 56, 57, 58, 59, 68, 71, 92, 94, 96, 110, 119, 128, 144, 145, 147, 159, 176, 211, 219, 220, 225, 228, 231, 246, 268, 269, 270, 271, 292, 324, 326, 331, 332, 335, 336, 338, 340], "research": [0, 7, 9, 340], "most": [0, 3, 7, 8, 32, 66, 67, 117, 153, 329, 331, 336, 340, 341], "written": [0, 3, 34, 36, 39, 45, 52, 58, 66, 67, 77, 81, 95, 101, 110, 119, 126, 139, 142, 145, 153, 163, 164, 213, 224, 225, 228, 229, 233, 238, 240, 252, 255, 257, 267, 286, 287, 324, 325, 326, 329, 332, 334, 336, 340], "highli": [0, 2, 340, 341], "wai": [0, 2, 3, 4, 53, 85, 132, 134, 152, 153, 183, 255, 268, 269, 270, 271, 324, 329, 330, 331, 334, 335, 336, 337, 338, 340, 341], "can": [0, 1, 2, 3, 5, 6, 7, 8, 10, 11, 13, 14, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 44, 45, 46, 47, 52, 53, 55, 56, 61, 65, 66, 67, 77, 78, 81, 85, 90, 95, 96, 97, 99, 100, 101, 103, 107, 108, 110, 113, 114, 115, 117, 118, 119, 127, 128, 132, 133, 136, 139, 142, 143, 144, 147, 148, 150, 152, 154, 164, 165, 179, 181, 182, 183, 185, 188, 189, 192, 193, 195, 196, 209, 211, 213, 217, 219, 220, 221, 222, 225, 226, 227, 228, 229, 230, 231, 232, 237, 238, 239, 240, 241, 242, 244, 245, 246, 247, 248, 249, 251, 252, 253, 255, 256, 257, 258, 260, 266, 267, 268, 269, 270, 271, 272, 300, 313, 318, 319, 320, 323, 324, 325, 326, 329, 330, 331, 332, 334, 335, 336, 337, 338, 340, 341], "easili": [0, 3, 7, 77, 81, 95, 101, 313, 325, 329, 330, 331, 335, 340, 341], "swap": [0, 3, 153, 331, 337, 340], "compon": [0, 2, 3, 35, 38, 41, 42, 52, 53, 54, 55, 56, 58, 59, 60, 68, 71, 176, 202, 219, 220, 227, 238, 239, 240, 245, 246, 247, 248, 249, 251, 252, 253, 255, 256, 257, 258, 260, 266, 299, 304, 329, 330, 331, 332, 334, 335, 336, 337, 340], "transform": [0, 1, 2, 4, 8, 13, 14, 16, 18, 19, 20, 21, 32, 35, 37, 38, 40, 41, 42, 43, 52, 53, 54, 55, 56, 77, 78, 81, 95, 96, 97, 101, 103, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 148, 149, 150, 151, 152, 153, 154, 155, 168, 169, 173, 176, 177, 200, 201, 202, 210, 218, 223, 232, 235, 237, 243, 254, 287, 301, 313, 320, 322, 328, 330, 332, 333, 337, 339], "them": [0, 2, 3, 7, 9, 21, 32, 35, 37, 38, 41, 42, 52, 53, 54, 55, 56, 77, 78, 81, 85, 90, 95, 96, 97, 101, 103, 115, 118, 148, 166, 167, 168, 169, 170, 171, 172, 173, 175, 177, 178, 179, 180, 181, 183, 184, 185, 186, 187, 192, 193, 196, 197, 198, 200, 203, 204, 206, 210, 211, 217, 218, 220, 221, 222, 224, 227, 232, 235, 252, 258, 287, 329, 330, 332, 334, 335, 336, 337, 338, 340, 341], "write": [0, 3, 8, 23, 32, 34, 36, 37, 39, 45, 81, 113, 130, 131, 139, 142, 146, 164, 213, 228, 229, 231, 233, 241, 242, 244, 245, 251, 256, 258, 260, 267, 272, 287, 324, 326, 328, 329, 330, 331, 332, 333, 334, 335, 337, 338, 339, 340, 341], "new": [0, 2, 3, 4, 8, 13, 14, 16, 17, 21, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 39, 41, 44, 46, 47, 61, 65, 77, 81, 92, 95, 99, 100, 101, 139, 147, 154, 163, 164, 179, 181, 185, 224, 228, 229, 234, 238, 239, 240, 242, 245, 246, 247, 248, 249, 251, 252, 253, 255, 256, 257, 258, 260, 266, 329, 331, 332, 335, 336, 340, 341], "ones": [0, 2, 15, 26, 32, 35, 41, 42, 77, 81, 95, 101, 111, 114, 115, 116, 118, 128, 132, 136, 144, 147, 148, 150, 152, 190, 191, 211, 228, 238, 239, 241, 251, 255, 256, 258, 260, 274, 329, 331, 335, 336, 338, 340, 341], "littl": [0, 3, 43, 331, 332, 338, 340, 341], "effort": [0, 3, 336, 338, 340], "thi": [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 52, 53, 54, 55, 56, 58, 59, 60, 65, 66, 67, 68, 69, 71, 77, 81, 83, 90, 91, 95, 96, 97, 101, 103, 107, 108, 110, 111, 113, 114, 115, 116, 117, 118, 119, 120, 121, 123, 125, 126, 128, 132, 133, 134, 136, 139, 140, 142, 144, 145, 147, 148, 150, 151, 152, 153, 154, 156, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 192, 193, 194, 195, 196, 197, 198, 199, 200, 202, 203, 204, 206, 209, 211, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 231, 232, 234, 235, 238, 239, 240, 241, 242, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 255, 256, 257, 258, 259, 260, 266, 268, 269, 270, 271, 272, 286, 295, 297, 300, 301, 304, 306, 307, 308, 313, 316, 320, 323, 324, 325, 326, 329, 330, 331, 332, 334, 335, 336, 337, 338, 340, 341], "repo": [0, 6, 52, 110, 145, 150, 323, 335, 340], "attempt": [0, 66, 67, 217, 222, 224, 242, 251, 266, 340], "align": [0, 179, 183, 340], "exist": [0, 3, 4, 11, 18, 21, 32, 34, 36, 39, 45, 77, 81, 95, 101, 111, 116, 148, 258, 308, 320, 335, 340, 341], "ecosystem": [0, 340], "ha": [0, 2, 3, 4, 5, 7, 8, 10, 16, 17, 18, 20, 21, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 37, 40, 44, 46, 47, 66, 77, 78, 81, 85, 95, 101, 103, 110, 142, 143, 144, 145, 148, 179, 181, 183, 185, 192, 217, 220, 222, 224, 229, 252, 329, 330, 331, 332, 334, 335, 336, 337, 338, 340, 341], "dataset": [0, 34, 35, 36, 37, 38, 39, 40, 41, 42, 45, 52, 53, 54, 55, 56, 57, 66, 67, 94, 154, 322, 329, 330, 337, 338, 340, 341], "pillar": [0, 340], "environ": [0, 1, 2, 5, 8, 11, 13, 14, 16, 17, 18, 19, 20, 21, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 44, 46, 47, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 106, 108, 110, 111, 115, 116, 117, 118, 123, 127, 128, 132, 133, 139, 142, 143, 144, 145, 147, 148, 150, 153, 154, 156, 165, 181, 185, 186, 188, 189, 217, 224, 244, 247, 268, 269, 270, 271, 272, 273, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 287, 295, 297, 300, 307, 308, 309, 310, 313, 316, 317, 318, 319, 320, 322, 323, 324, 328, 333, 337, 338, 339], "model": [0, 1, 3, 8, 9, 13, 14, 16, 17, 18, 19, 20, 21, 32, 40, 45, 77, 81, 91, 95, 101, 115, 132, 144, 150, 152, 155, 166, 167, 168, 173, 181, 185, 187, 188, 189, 193, 200, 201, 210, 214, 215, 216, 223, 228, 234, 238, 239, 240, 242, 243, 244, 247, 248, 249, 251, 252, 253, 255, 256, 258, 266, 304, 309, 310, 311, 312, 313, 322, 323, 326, 328, 331, 333, 335, 336, 338, 339, 341], "data": [0, 3, 8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 77, 79, 81, 91, 94, 95, 96, 97, 101, 108, 110, 115, 116, 118, 120, 126, 128, 136, 142, 153, 156, 160, 164, 165, 176, 181, 185, 186, 189, 192, 193, 202, 211, 213, 219, 221, 222, 224, 225, 226, 228, 231, 232, 233, 238, 239, 241, 242, 244, 245, 251, 255, 256, 257, 258, 260, 266, 268, 269, 270, 271, 272, 295, 301, 304, 306, 309, 316, 318, 319, 320, 322, 324, 325, 326, 332, 336, 337, 338, 341], "util": [0, 3, 17, 23, 32, 40, 77, 81, 95, 96, 97, 101, 104, 132, 152, 156, 157, 158, 159, 160, 161, 162, 163, 164, 166, 167, 173, 179, 183, 235, 236, 237, 253, 316, 322, 327, 329, 331, 335, 336, 340, 341], "e": [0, 1, 3, 7, 8, 10, 11, 13, 14, 16, 17, 18, 19, 20, 21, 26, 28, 32, 33, 58, 59, 71, 77, 78, 81, 95, 101, 111, 114, 122, 128, 132, 139, 144, 147, 148, 150, 152, 156, 179, 181, 182, 183, 185, 189, 193, 196, 202, 208, 209, 218, 220, 225, 227, 228, 229, 258, 267, 268, 269, 270, 271, 295, 307, 319, 324, 329, 330, 331, 335, 337, 340, 341], "g": [0, 1, 3, 7, 8, 10, 11, 32, 33, 77, 78, 81, 95, 101, 111, 114, 122, 128, 132, 139, 144, 147, 148, 150, 152, 156, 179, 181, 182, 183, 184, 185, 189, 193, 208, 209, 218, 225, 228, 229, 258, 267, 277, 278, 279, 280, 282, 283, 284, 285, 319, 324, 329, 330, 331, 335, 336, 337, 340, 341], "collector": [0, 3, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 40, 66, 67, 110, 136, 142, 224, 301, 304, 306, 309, 310, 316, 318, 319, 322, 326, 338, 341], "contain": [0, 3, 7, 12, 13, 14, 16, 17, 19, 20, 26, 28, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 50, 52, 53, 54, 55, 56, 61, 63, 68, 70, 72, 77, 81, 91, 95, 101, 114, 115, 118, 132, 144, 147, 148, 150, 152, 153, 154, 163, 164, 165, 166, 167, 179, 180, 183, 184, 187, 189, 193, 213, 219, 220, 225, 227, 228, 233, 238, 239, 240, 241, 242, 244, 245, 246, 247, 248, 249, 251, 252, 253, 255, 256, 257, 258, 260, 266, 267, 268, 269, 270, 271, 272, 274, 291, 295, 307, 313, 316, 317, 318, 319, 320, 324, 325, 326, 329, 330, 331, 332, 335, 336, 337, 338, 340, 341], "etc": [0, 3, 7, 8, 11, 32, 46, 47, 77, 81, 95, 101, 126, 148, 187, 193, 329, 330, 331, 338, 340, 341], "have": [0, 1, 2, 3, 5, 6, 7, 8, 9, 13, 14, 17, 18, 20, 21, 26, 30, 32, 34, 35, 36, 38, 39, 40, 41, 42, 45, 52, 53, 54, 55, 56, 65, 68, 77, 81, 95, 96, 97, 101, 110, 115, 118, 119, 126, 127, 128, 142, 147, 148, 154, 156, 164, 166, 167, 186, 187, 192, 193, 211, 230, 231, 238, 240, 252, 255, 263, 266, 268, 269, 270, 271, 272, 273, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 295, 304, 324, 325, 326, 329, 330, 331, 332, 334, 335, 336, 337, 338, 340, 341], "few": [0, 2, 8, 295, 331, 332, 335, 338, 340, 341], "depend": [0, 1, 2, 3, 4, 7, 8, 34, 36, 115, 118, 233, 255, 324, 329, 331, 332, 335, 336, 340, 341], "possibl": [0, 2, 3, 4, 27, 29, 32, 33, 34, 36, 39, 56, 77, 81, 95, 101, 114, 132, 144, 147, 148, 150, 152, 166, 167, 179, 180, 183, 184, 228, 300, 304, 324, 329, 331, 332, 335, 336, 338, 340, 341], "standard": [0, 3, 128, 138, 154, 165, 177, 189, 194, 195, 217, 218, 260, 268, 269, 270, 271, 329, 330, 335, 338, 340], "numpi": [0, 11, 24, 25, 26, 27, 28, 29, 30, 31, 33, 44, 46, 47, 95, 101, 146, 304, 336, 338, 340, 341], "common": [0, 2, 3, 4, 21, 81, 108, 214, 215, 216, 223, 238, 239, 240, 245, 251, 252, 255, 256, 257, 258, 260, 316, 323, 324, 326, 329, 331, 334, 335, 336, 337, 340, 341], "openai": [0, 7, 80, 82, 98, 331, 336, 340, 341], "gym": [0, 1, 3, 4, 8, 11, 13, 14, 16, 17, 21, 22, 77, 78, 80, 81, 82, 85, 95, 98, 101, 105, 107, 110, 113, 119, 125, 126, 128, 130, 134, 136, 139, 144, 147, 153, 154, 313, 316, 323, 329, 330, 331, 332, 336, 337, 338, 340], "onli": [0, 1, 3, 4, 7, 13, 14, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 35, 38, 41, 44, 46, 47, 52, 58, 59, 66, 67, 71, 77, 81, 85, 92, 95, 96, 97, 101, 110, 111, 113, 114, 115, 117, 118, 122, 128, 132, 133, 136, 142, 143, 144, 145, 147, 148, 150, 152, 154, 183, 185, 186, 192, 193, 213, 218, 219, 225, 226, 228, 229, 230, 231, 238, 240, 241, 245, 251, 252, 253, 255, 256, 257, 258, 259, 260, 268, 269, 270, 271, 272, 308, 326, 329, 330, 331, 332, 334, 335, 336, 338, 340, 341], "option": [0, 1, 3, 4, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 65, 66, 67, 71, 75, 77, 78, 81, 91, 94, 95, 96, 97, 98, 101, 103, 108, 110, 111, 112, 113, 115, 117, 118, 119, 122, 123, 125, 126, 127, 128, 132, 133, 134, 135, 136, 138, 139, 140, 142, 143, 144, 145, 146, 147, 148, 149, 150, 152, 153, 154, 156, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 176, 177, 178, 180, 181, 182, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 202, 203, 204, 207, 208, 209, 211, 213, 217, 218, 219, 220, 221, 222, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 238, 239, 240, 241, 242, 244, 245, 246, 247, 248, 249, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 266, 267, 268, 269, 270, 271, 272, 274, 277, 278, 279, 280, 282, 283, 284, 285, 286, 287, 289, 292, 295, 297, 298, 299, 300, 301, 302, 304, 308, 309, 310, 311, 312, 313, 315, 316, 318, 319, 320, 324, 332, 335, 336, 338, 340], "On": [0, 3, 7, 18, 19, 20, 21, 180, 184, 324, 330, 335], "end": [0, 3, 13, 14, 32, 35, 38, 41, 42, 52, 53, 54, 55, 56, 65, 66, 67, 77, 81, 95, 101, 119, 130, 142, 143, 148, 166, 167, 179, 180, 183, 184, 188, 258, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 329, 330, 331, 332, 334, 335, 336, 337, 338, 340, 341], "come": [0, 1, 3, 8, 81, 90, 95, 101, 115, 118, 213, 214, 215, 216, 225, 233, 329, 330, 331, 332, 335, 338, 340, 341], "set": [0, 1, 2, 3, 7, 9, 11, 13, 14, 16, 17, 18, 19, 20, 21, 28, 29, 32, 33, 34, 35, 36, 38, 39, 41, 42, 52, 53, 54, 55, 56, 58, 59, 65, 68, 71, 77, 79, 81, 91, 95, 96, 97, 101, 107, 108, 110, 111, 114, 115, 118, 125, 126, 132, 136, 142, 143, 144, 145, 147, 148, 150, 152, 154, 156, 161, 162, 164, 179, 181, 183, 185, 188, 192, 193, 217, 218, 228, 253, 255, 258, 272, 295, 300, 301, 310, 320, 323, 324, 325, 327, 329, 330, 331, 332, 334, 335, 336, 337, 338, 340, 341], "re": [0, 3, 8, 32, 65, 77, 81, 95, 101, 185, 190, 191, 225, 229, 326, 329, 331, 332, 334, 336, 340, 341], "usabl": [0, 326, 332, 340], "function": [0, 3, 8, 11, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 39, 40, 43, 44, 45, 46, 47, 49, 58, 59, 60, 68, 71, 77, 78, 81, 95, 101, 107, 115, 118, 148, 154, 156, 164, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 181, 183, 184, 185, 186, 187, 190, 191, 192, 193, 196, 197, 198, 199, 200, 203, 204, 206, 209, 211, 214, 215, 216, 217, 218, 220, 221, 222, 224, 225, 227, 228, 229, 231, 232, 233, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 251, 252, 253, 255, 256, 257, 258, 260, 261, 262, 263, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 313, 316, 322, 324, 329, 332, 334, 336, 338, 341], "cost": [0, 2, 27, 329, 330, 335, 336, 338], "return": [0, 2, 3, 7, 8, 11, 13, 14, 16, 17, 18, 19, 20, 21, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 52, 53, 54, 55, 56, 57, 63, 66, 67, 69, 70, 72, 75, 77, 78, 81, 91, 94, 95, 96, 97, 101, 105, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 122, 124, 125, 126, 128, 130, 132, 133, 134, 135, 137, 138, 139, 140, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 157, 158, 159, 163, 164, 165, 168, 169, 170, 171, 172, 174, 176, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 193, 196, 199, 200, 201, 203, 204, 207, 208, 209, 210, 213, 214, 215, 216, 218, 225, 227, 228, 229, 233, 234, 235, 237, 238, 239, 240, 241, 242, 244, 245, 246, 247, 248, 249, 251, 252, 253, 255, 256, 257, 258, 260, 263, 266, 267, 268, 269, 270, 271, 272, 274, 275, 276, 277, 278, 279, 280, 282, 283, 284, 285, 291, 304, 307, 309, 313, 316, 317, 318, 319, 320, 322, 324, 326, 329, 330, 331, 332, 334, 335, 336, 337, 338, 340, 341], "process": [0, 1, 3, 4, 5, 8, 13, 14, 16, 17, 18, 19, 20, 21, 32, 34, 35, 36, 39, 43, 45, 55, 56, 77, 78, 81, 85, 90, 92, 95, 96, 97, 101, 115, 118, 146, 154, 192, 193, 220, 224, 227, 322, 326, 329, 330, 332, 335, 336, 337, 338, 340, 341], "good": [0, 1, 4, 9, 329, 331, 332, 335, 340, 341], "runtim": [0, 3, 32, 77, 81, 95, 101, 336], "perform": [0, 3, 4, 8, 13, 14, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 40, 44, 45, 46, 47, 77, 81, 95, 101, 104, 115, 118, 127, 148, 165, 166, 167, 168, 169, 170, 171, 172, 173, 175, 177, 178, 179, 180, 181, 183, 184, 185, 186, 187, 188, 189, 192, 193, 196, 197, 198, 200, 203, 204, 206, 211, 217, 218, 220, 221, 222, 224, 227, 232, 235, 248, 255, 258, 300, 304, 325, 329, 330, 331, 332, 334, 335, 336, 341], "To": [0, 3, 4, 6, 7, 8, 9, 18, 19, 20, 32, 35, 38, 40, 41, 42, 52, 53, 54, 55, 56, 66, 67, 77, 81, 90, 95, 96, 97, 99, 100, 101, 142, 154, 214, 215, 216, 224, 245, 253, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 324, 325, 329, 330, 331, 332, 335, 336, 337, 338, 340, 341], "read": [0, 2, 3, 7, 17, 23, 37, 40, 58, 59, 60, 68, 71, 77, 81, 95, 101, 108, 110, 111, 113, 114, 115, 116, 117, 119, 120, 121, 122, 123, 125, 126, 130, 131, 133, 134, 136, 139, 140, 142, 143, 144, 145, 147, 150, 151, 153, 154, 164, 199, 213, 214, 215, 216, 219, 225, 228, 229, 231, 233, 234, 238, 239, 240, 245, 246, 247, 248, 249, 251, 252, 253, 255, 256, 257, 258, 260, 266, 268, 269, 270, 271, 272, 287, 300, 304, 313, 324, 329, 330, 331, 334, 335, 336, 337, 341], "more": [0, 2, 3, 4, 6, 8, 9, 11, 13, 14, 16, 17, 18, 19, 20, 21, 32, 35, 38, 41, 42, 43, 52, 53, 54, 55, 56, 77, 81, 84, 85, 95, 96, 97, 101, 103, 146, 150, 155, 176, 183, 187, 194, 196, 213, 217, 219, 220, 228, 233, 238, 246, 253, 255, 268, 273, 281, 299, 323, 325, 326, 329, 330, 331, 332, 334, 335, 336, 337, 341], "about": [0, 2, 3, 5, 7, 9, 18, 19, 20, 43, 55, 56, 325, 329, 330, 331, 335, 336, 340, 341], "philosophi": [0, 9], "capabl": [0, 1, 7, 9, 326, 329, 334, 337, 341], "beyond": 0, "api": [0, 2, 3, 5, 96, 97, 98, 132, 152, 325, 326, 335, 336, 340, 341], "check": [0, 2, 3, 4, 5, 6, 7, 9, 11, 18, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 44, 46, 47, 48, 50, 66, 77, 78, 81, 91, 95, 101, 104, 110, 111, 121, 126, 133, 146, 156, 181, 185, 213, 219, 220, 225, 226, 227, 228, 229, 324, 325, 330, 331, 332, 334, 335, 336, 337, 338, 341], "paper": [0, 132, 150, 152, 179, 201, 210, 244, 250, 313, 329, 331, 335], "ppo": [0, 4, 8, 225, 229, 240, 252, 255, 322, 324, 328, 329, 330, 333, 339], "pendulum": [0, 3, 13, 14, 16, 17, 21, 22, 77, 78, 80, 81, 82, 92, 95, 101, 110, 113, 114, 120, 125, 126, 128, 134, 136, 142, 144, 145, 147, 148, 154, 181, 185, 316, 324, 328, 330, 331, 333, 339, 340, 341], "your": [0, 2, 3, 7, 8, 10, 18, 32, 77, 81, 85, 90, 95, 96, 97, 101, 154, 320, 323, 324, 325, 328, 330, 331, 332, 333, 335, 338, 339, 340], "introduct": [0, 325, 328, 333, 335, 339, 341], "multi": [0, 7, 9, 28, 29, 32, 77, 81, 95, 99, 100, 101, 179, 181, 183, 185, 186, 187, 192, 193, 266, 268, 269, 270, 271, 322, 328, 329, 330, 331, 332, 333, 336, 339, 340], "agent": [0, 9, 28, 29, 90, 96, 97, 99, 100, 102, 103, 104, 142, 143, 190, 191, 192, 193, 195, 201, 210, 266, 322, 328, 333, 336, 339], "env": [0, 1, 2, 5, 6, 7, 8, 13, 14, 16, 17, 18, 19, 20, 21, 22, 32, 40, 52, 53, 55, 56, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 181, 185, 188, 189, 228, 253, 286, 308, 309, 310, 313, 316, 318, 319, 320, 322, 324, 328, 329, 330, 331, 332, 333, 334, 335, 337, 338, 339], "us": [0, 1, 2, 3, 5, 7, 8, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 52, 53, 54, 55, 56, 57, 61, 62, 66, 67, 71, 75, 77, 78, 81, 91, 94, 95, 96, 97, 98, 99, 100, 101, 107, 108, 110, 111, 112, 114, 115, 116, 117, 118, 119, 120, 125, 126, 128, 132, 133, 134, 136, 139, 140, 142, 143, 144, 145, 146, 147, 148, 150, 152, 154, 156, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 173, 176, 177, 179, 180, 181, 182, 183, 184, 185, 187, 188, 189, 191, 192, 193, 195, 196, 199, 200, 201, 202, 208, 209, 210, 211, 213, 218, 219, 220, 221, 223, 224, 225, 226, 227, 228, 229, 232, 233, 234, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 251, 252, 253, 255, 256, 257, 258, 260, 263, 266, 267, 268, 269, 270, 271, 272, 273, 274, 276, 281, 290, 291, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 308, 309, 310, 314, 316, 320, 323, 324, 325, 326, 327, 328, 329, 330, 331, 333, 334, 335, 336, 339, 341], "pretrain": [0, 328, 333, 339], "recurr": [0, 179, 180, 181, 183, 185, 204, 328, 330, 333, 338, 339], "dqn": [0, 119, 176, 219, 220, 238, 239, 241, 242, 244, 245, 246, 247, 250, 251, 253, 255, 256, 257, 258, 259, 260, 266, 311, 322, 324, 328, 333, 339], "train": [0, 1, 3, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 32, 34, 36, 39, 40, 45, 57, 77, 81, 95, 96, 97, 101, 115, 123, 132, 143, 148, 150, 152, 156, 169, 171, 181, 185, 217, 221, 222, 224, 238, 239, 240, 241, 245, 246, 247, 248, 249, 251, 252, 253, 255, 256, 257, 258, 260, 266, 268, 304, 306, 316, 322, 326, 328, 330, 333, 337, 338, 339, 341], "polici": [0, 1, 2, 3, 8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 77, 81, 91, 95, 101, 117, 126, 143, 161, 162, 176, 181, 185, 192, 193, 195, 202, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 224, 225, 226, 227, 228, 229, 232, 238, 239, 240, 241, 245, 251, 252, 254, 255, 256, 257, 258, 260, 300, 306, 309, 310, 316, 318, 319, 324, 325, 326, 328, 330, 333, 337, 338, 339, 340, 341], "replai": [0, 8, 13, 14, 16, 35, 38, 41, 42, 52, 53, 54, 55, 56, 61, 62, 63, 64, 67, 68, 69, 70, 110, 117, 133, 136, 144, 241, 242, 244, 245, 251, 256, 258, 260, 301, 304, 314, 316, 322, 326, 328, 333, 336, 337, 339], "buffer": [0, 1, 3, 4, 8, 13, 14, 16, 32, 34, 35, 36, 38, 39, 41, 42, 52, 53, 54, 55, 56, 58, 59, 60, 61, 62, 63, 64, 67, 68, 69, 70, 71, 77, 81, 91, 95, 101, 110, 114, 117, 132, 133, 136, 144, 147, 148, 150, 152, 228, 231, 241, 242, 244, 245, 251, 256, 258, 260, 301, 304, 314, 316, 322, 326, 328, 333, 336, 337, 339, 341], "task": [0, 3, 9, 28, 29, 40, 45, 75, 81, 84, 95, 96, 97, 98, 101, 132, 142, 150, 152, 251, 328, 329, 330, 331, 332, 333, 335, 336, 339, 340, 341], "specif": [0, 2, 5, 8, 41, 42, 81, 173, 218, 304, 322, 325, 326, 328, 331, 332, 333, 335, 338, 339], "object": [0, 3, 4, 6, 13, 14, 15, 16, 17, 18, 19, 20, 21, 26, 32, 34, 36, 39, 45, 58, 59, 60, 68, 71, 77, 81, 95, 101, 115, 118, 119, 128, 132, 147, 148, 150, 154, 189, 201, 210, 213, 214, 225, 228, 229, 230, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 287, 308, 309, 310, 315, 316, 320, 322, 324, 326, 328, 330, 331, 332, 333, 335, 336, 338, 339, 341], "ddpg": [0, 169, 170, 171, 172, 241, 250, 259, 322, 324, 328, 330, 333, 339], "loss": [0, 3, 8, 36, 119, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 263, 266, 267, 268, 299, 304, 311, 312, 313, 316, 325, 326, 328, 333, 336, 338, 339, 340], "trainer": [0, 238, 239, 240, 245, 246, 247, 248, 249, 251, 252, 253, 255, 256, 257, 258, 260, 266, 295, 296, 297, 298, 299, 300, 301, 302, 303, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 322, 328, 329, 333, 339], "A": [0, 1, 2, 3, 8, 9, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 45, 52, 53, 54, 55, 56, 58, 59, 60, 62, 63, 64, 65, 68, 69, 70, 71, 72, 77, 79, 81, 83, 84, 95, 98, 101, 113, 117, 123, 126, 132, 133, 134, 144, 147, 148, 150, 151, 153, 154, 155, 156, 163, 165, 166, 167, 176, 179, 180, 181, 183, 184, 185, 187, 189, 190, 191, 193, 195, 196, 211, 217, 218, 219, 220, 221, 222, 225, 226, 229, 231, 232, 235, 238, 239, 240, 241, 242, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 255, 256, 257, 258, 259, 260, 263, 266, 268, 269, 270, 271, 272, 274, 288, 289, 292, 297, 304, 306, 313, 316, 325, 328, 329, 331, 333, 335, 336, 339, 341], "exampl": [0, 1, 2, 3, 4, 9, 10, 11, 13, 14, 15, 16, 17, 18, 21, 22, 24, 26, 27, 28, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 52, 53, 54, 55, 56, 57, 58, 59, 66, 67, 69, 71, 73, 74, 75, 76, 77, 78, 80, 81, 82, 84, 86, 87, 88, 89, 91, 94, 95, 96, 97, 99, 100, 101, 102, 103, 104, 105, 107, 108, 110, 111, 113, 114, 115, 116, 117, 118, 119, 120, 125, 126, 128, 130, 132, 134, 135, 136, 139, 142, 143, 144, 145, 146, 147, 148, 150, 152, 154, 160, 163, 164, 165, 166, 167, 168, 173, 176, 179, 180, 181, 183, 184, 185, 186, 187, 189, 192, 193, 196, 199, 200, 201, 202, 210, 211, 213, 214, 215, 216, 218, 219, 220, 221, 222, 224, 225, 226, 227, 228, 231, 232, 233, 238, 239, 241, 242, 244, 245, 246, 247, 251, 253, 255, 256, 257, 258, 260, 261, 262, 266, 268, 269, 270, 271, 274, 295, 296, 297, 298, 299, 301, 302, 303, 306, 313, 316, 324, 325, 326, 328, 329, 331, 332, 333, 334, 335, 336, 337, 339, 340, 341], "packag": [0, 6, 7, 10, 107, 322, 323, 341], "singl": [0, 3, 13, 14, 17, 18, 19, 20, 21, 32, 35, 38, 41, 42, 43, 52, 53, 54, 55, 56, 69, 77, 81, 95, 101, 110, 111, 132, 136, 152, 166, 167, 179, 180, 181, 183, 184, 185, 186, 187, 193, 227, 231, 240, 242, 244, 245, 246, 252, 255, 256, 260, 268, 269, 270, 271, 277, 278, 279, 280, 282, 283, 284, 285, 313, 320, 322, 329, 330, 331, 332, 334, 335, 336, 337, 338], "node": [0, 2, 18, 19, 20, 21, 22, 56, 313, 322], "distribut": [0, 2, 3, 4, 9, 10, 18, 19, 20, 21, 22, 96, 97, 126, 128, 165, 174, 175, 176, 177, 182, 189, 190, 191, 196, 199, 200, 203, 204, 207, 208, 209, 217, 218, 219, 220, 225, 229, 230, 238, 239, 240, 245, 246, 251, 252, 255, 256, 257, 258, 260, 322, 326, 330, 331, 335, 336, 340, 341], "helper": [0, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 322, 329, 330, 332, 336], "compos": [0, 3, 32, 35, 38, 41, 42, 52, 53, 54, 55, 56, 62, 63, 64, 69, 70, 77, 81, 95, 101, 110, 135, 147, 148, 154, 223, 248, 258, 313, 322, 329, 330, 331, 332, 334, 335, 338, 340, 341], "tensorspec": [0, 3, 15, 24, 25, 26, 27, 28, 29, 30, 31, 33, 46, 47, 48, 49, 50, 77, 81, 91, 95, 101, 103, 109, 110, 111, 112, 113, 114, 115, 116, 117, 119, 120, 122, 124, 125, 126, 128, 130, 134, 135, 137, 138, 139, 140, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 153, 164, 204, 213, 217, 218, 219, 220, 221, 222, 224, 225, 226, 227, 228, 229, 230, 232, 239, 242, 245, 256, 258, 260, 266, 322, 336], "from": [0, 1, 3, 4, 5, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 52, 53, 54, 55, 56, 57, 58, 59, 60, 65, 66, 67, 68, 69, 71, 77, 78, 81, 90, 91, 95, 96, 97, 99, 100, 101, 103, 104, 107, 108, 110, 111, 113, 115, 116, 117, 118, 119, 120, 125, 126, 128, 130, 132, 133, 134, 135, 136, 139, 140, 142, 143, 144, 145, 146, 147, 148, 149, 150, 152, 153, 154, 160, 163, 164, 165, 169, 170, 171, 172, 173, 176, 179, 180, 181, 182, 183, 184, 185, 187, 188, 189, 191, 192, 193, 194, 196, 199, 200, 201, 202, 208, 209, 210, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 238, 239, 240, 241, 242, 244, 245, 246, 247, 251, 252, 253, 255, 256, 257, 258, 260, 262, 266, 267, 268, 269, 270, 271, 274, 286, 287, 295, 301, 304, 307, 308, 313, 314, 316, 317, 320, 322, 323, 324, 325, 326, 328, 329, 330, 331, 332, 334, 335, 336, 337, 338, 339, 340, 341], "human": [0, 53, 322, 336], "feedback": [0, 322, 340], "rlhf": [0, 40, 45, 57, 126, 322, 324], "envbas": [0, 3, 13, 14, 16, 17, 18, 19, 20, 21, 78, 81, 95, 101, 108, 115, 118, 127, 134, 147, 148, 154, 156, 165, 188, 189, 300, 308, 309, 310, 313, 316, 318, 319, 320, 322], "gymlikeenv": [0, 322], "envmetadata": [0, 322], "vector": [0, 1, 8, 24, 27, 33, 90, 96, 97, 103, 117, 153, 169, 171, 179, 180, 183, 184, 187, 268, 271, 281, 282, 283, 284, 285, 322, 329, 330, 332, 334, 335, 336, 337, 341], "mask": [0, 1, 4, 23, 27, 30, 31, 33, 96, 97, 108, 133, 176, 190, 191, 202, 218, 219, 220, 221, 222, 226, 227, 301, 322, 330, 332, 341], "action": [0, 2, 8, 9, 13, 14, 15, 16, 17, 21, 27, 33, 40, 44, 53, 55, 56, 74, 77, 81, 87, 90, 91, 95, 96, 97, 99, 100, 101, 102, 103, 108, 113, 115, 117, 118, 119, 120, 123, 126, 127, 130, 134, 136, 140, 142, 148, 153, 160, 163, 165, 168, 169, 170, 171, 172, 173, 175, 176, 177, 181, 185, 187, 188, 189, 190, 191, 192, 200, 201, 202, 204, 207, 208, 210, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 224, 225, 226, 227, 229, 232, 233, 238, 239, 241, 242, 244, 245, 251, 253, 255, 256, 257, 258, 260, 266, 268, 269, 270, 271, 272, 273, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 313, 316, 320, 322, 324, 325, 326, 329, 330, 331, 334, 335, 337, 338, 340, 341], "record": [0, 32, 77, 81, 95, 101, 126, 255, 286, 287, 288, 289, 290, 291, 292, 293, 294, 316, 322, 330, 331], "domain": [0, 2, 8, 24, 25, 26, 27, 28, 29, 30, 31, 33, 44, 46, 47, 77, 81, 95, 101, 117, 144, 160, 213, 219, 220, 225, 226, 227, 228, 229, 230, 231, 322, 331, 332, 335, 336, 340, 341], "modul": [0, 2, 3, 4, 8, 11, 32, 40, 69, 77, 81, 90, 91, 95, 101, 107, 114, 117, 119, 126, 132, 133, 143, 144, 147, 148, 150, 152, 154, 155, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 244, 245, 246, 250, 251, 252, 253, 255, 256, 257, 258, 259, 260, 261, 264, 266, 268, 269, 270, 271, 272, 304, 311, 312, 316, 322, 325, 326, 330, 331, 334, 335, 336, 337, 338], "tensordict": [0, 1, 2, 3, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 52, 53, 54, 55, 56, 58, 59, 61, 66, 67, 69, 70, 71, 74, 77, 78, 79, 81, 87, 90, 91, 94, 95, 96, 97, 99, 100, 101, 102, 103, 108, 110, 111, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 125, 126, 128, 130, 131, 132, 133, 134, 136, 139, 140, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 160, 163, 164, 165, 175, 176, 181, 185, 186, 188, 189, 201, 202, 210, 211, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 251, 252, 253, 254, 255, 256, 257, 258, 260, 266, 267, 268, 269, 270, 271, 272, 286, 295, 299, 300, 301, 303, 304, 313, 322, 325, 326, 329, 330, 331, 332, 334, 335, 336, 337, 341], "actor": [0, 3, 4, 15, 21, 126, 165, 168, 169, 171, 176, 177, 189, 200, 202, 214, 215, 216, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 251, 252, 253, 254, 255, 256, 257, 258, 260, 261, 266, 313, 322, 325, 330, 331, 332, 335, 337, 340], "explor": [0, 1, 155, 195, 213, 217, 219, 220, 221, 222, 224, 225, 226, 227, 228, 229, 238, 300, 309, 310, 316, 322, 331, 332, 335, 336], "valu": [0, 1, 3, 8, 11, 13, 14, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 41, 42, 44, 45, 46, 47, 52, 57, 66, 67, 77, 81, 90, 95, 101, 107, 109, 110, 111, 113, 115, 117, 118, 119, 127, 128, 132, 133, 135, 136, 137, 139, 144, 145, 147, 148, 152, 154, 160, 164, 169, 170, 171, 172, 174, 176, 177, 178, 181, 182, 185, 187, 189, 190, 191, 192, 193, 194, 195, 196, 199, 201, 202, 207, 208, 209, 210, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 232, 233, 235, 236, 237, 238, 239, 240, 241, 242, 244, 245, 246, 247, 248, 249, 251, 252, 253, 254, 255, 256, 257, 258, 260, 261, 262, 263, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 287, 295, 297, 298, 299, 300, 301, 304, 313, 316, 322, 326, 330, 334, 335, 336, 338, 340, 341], "gener": [0, 1, 2, 3, 7, 8, 9, 16, 35, 38, 40, 64, 65, 77, 78, 81, 91, 95, 96, 97, 99, 100, 101, 114, 115, 116, 120, 126, 128, 134, 139, 140, 142, 147, 153, 164, 174, 190, 191, 199, 213, 225, 229, 233, 234, 256, 262, 268, 273, 281, 290, 304, 322, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 340, 341], "hook": [0, 32, 77, 81, 95, 101, 166, 167, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 179, 180, 181, 183, 184, 185, 186, 187, 192, 193, 196, 197, 198, 200, 202, 203, 204, 206, 211, 217, 218, 220, 221, 222, 224, 227, 232, 235, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 322], "planner": [0, 165, 189, 322], "sac": [0, 245, 256, 258, 322], "redq": [0, 256, 312, 313, 322], "iql": [0, 251, 322, 335], "cql": [0, 239, 244, 322], "dt": [0, 224, 322, 336], "td3": [0, 260, 322], "a2c": [0, 238, 322], "dreamer": [0, 106, 177, 247, 248, 249, 322, 324], "checkpoint": [0, 322, 337], "builder": [0, 322, 330, 341], "logger": [0, 287, 289, 290, 291, 292, 293, 294, 298, 304, 316, 320, 322, 330], "_util": [0, 3, 11, 322], "implement_for": [0, 3, 322], "contribut": 0, "thing": [0, 3, 7, 8, 323, 331, 332, 335, 338, 341], "consid": [0, 1, 3, 8, 20, 32, 34, 36, 39, 58, 59, 71, 77, 81, 95, 101, 117, 154, 174, 192, 207, 323, 329, 336, 338], "when": [0, 1, 2, 3, 5, 8, 13, 14, 16, 17, 18, 19, 20, 21, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 35, 38, 41, 42, 44, 45, 46, 47, 52, 53, 54, 55, 56, 58, 59, 60, 62, 65, 68, 71, 77, 78, 81, 90, 92, 94, 95, 96, 97, 101, 108, 110, 114, 115, 117, 118, 126, 127, 128, 132, 133, 139, 144, 147, 148, 150, 152, 153, 154, 161, 162, 165, 176, 179, 180, 183, 184, 187, 188, 189, 190, 191, 194, 202, 208, 225, 228, 229, 231, 235, 240, 242, 246, 252, 255, 258, 261, 266, 267, 268, 269, 270, 271, 286, 287, 301, 320, 323, 324, 326, 329, 330, 331, 332, 335, 336, 337, 338, 341], "debug": [0, 6, 8, 40, 323, 341], "work": [0, 2, 3, 4, 8, 11, 32, 34, 36, 38, 39, 66, 67, 77, 81, 85, 95, 101, 111, 126, 132, 150, 153, 154, 166, 167, 187, 220, 227, 232, 240, 252, 255, 304, 323, 324, 329, 330, 331, 332, 334, 335, 336, 337, 338, 340, 341], "habitat": [0, 3, 83, 323, 337], "lab": [0, 3, 75, 76, 323], "mujoco": [0, 6, 8, 98, 323, 331, 332], "error": [0, 1, 3, 7, 10, 11, 29, 32, 77, 81, 95, 101, 104, 133, 156, 323, 329, 331, 335, 341], "solut": [0, 3, 6, 7, 9, 21, 323, 324, 326, 340], "resourc": [0, 1, 21, 323, 329, 331, 335], "version": [0, 1, 3, 6, 11, 32, 34, 36, 40, 56, 66, 77, 81, 95, 96, 101, 103, 153, 216, 253, 258, 268, 271, 323, 324, 329, 331, 332, 335, 336, 337, 341], "issu": [0, 4, 5, 8, 53, 58, 59, 71, 85, 110, 133, 145, 213, 219, 220, 225, 226, 227, 228, 229, 323, 340], "index": [0, 3, 7, 8, 10, 16, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 52, 53, 54, 55, 56, 58, 59, 61, 63, 69, 70, 71, 72, 77, 81, 95, 101, 103, 110, 117, 163, 190, 191, 334, 335, 338, 340], "search": [0, 164, 330], "page": [0, 7], "somewhat": [1, 325, 341], "equival": [1, 3, 17, 24, 27, 30, 31, 32, 33, 34, 36, 39, 45, 52, 53, 55, 56, 57, 77, 81, 95, 101, 116, 119, 148, 176, 183, 202, 219, 220, 226, 227, 255, 301, 340, 341], "dataload": [1, 57, 65, 67, 330, 331, 338], "except": [1, 2, 3, 13, 14, 16, 18, 19, 20, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 39, 44, 46, 47, 77, 81, 95, 101, 110, 121, 136, 143, 144, 145, 179, 181, 183, 185, 199, 217, 221, 222, 224, 324, 330, 338, 340, 341], "1": [1, 2, 3, 4, 8, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 44, 45, 46, 47, 52, 53, 54, 55, 56, 57, 66, 67, 69, 74, 77, 78, 81, 87, 90, 91, 94, 95, 96, 97, 99, 100, 101, 102, 103, 108, 109, 110, 111, 113, 114, 115, 116, 117, 118, 119, 120, 123, 126, 128, 130, 132, 133, 134, 136, 139, 140, 142, 143, 144, 145, 146, 147, 148, 150, 152, 154, 160, 163, 165, 166, 167, 168, 169, 170, 172, 173, 176, 178, 179, 180, 181, 182, 183, 184, 185, 187, 189, 190, 191, 192, 193, 194, 195, 196, 199, 200, 201, 203, 204, 206, 207, 208, 209, 210, 213, 214, 215, 216, 217, 218, 220, 221, 222, 224, 225, 226, 227, 228, 231, 232, 233, 235, 238, 239, 240, 241, 242, 244, 245, 248, 251, 252, 254, 255, 256, 257, 258, 259, 260, 266, 267, 268, 269, 270, 271, 274, 276, 277, 278, 282, 283, 285, 295, 300, 301, 302, 313, 316, 320, 323, 324, 325, 326, 328, 329, 330, 331, 332, 334, 335, 336, 337, 338, 339, 340, 341], "thei": [1, 2, 3, 4, 8, 9, 18, 19, 20, 21, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 44, 46, 47, 77, 81, 90, 95, 96, 97, 101, 103, 121, 126, 132, 140, 147, 148, 152, 185, 186, 238, 239, 240, 245, 246, 247, 248, 249, 251, 252, 253, 255, 256, 257, 258, 260, 266, 301, 304, 324, 325, 326, 329, 330, 331, 332, 334, 335, 336, 337, 338, 340, 341], "collect": [1, 2, 3, 4, 8, 13, 14, 16, 17, 18, 19, 20, 21, 22, 32, 35, 38, 41, 42, 52, 53, 54, 55, 56, 95, 98, 101, 110, 128, 132, 152, 156, 224, 239, 241, 244, 245, 256, 258, 260, 295, 301, 304, 306, 307, 308, 316, 326, 329, 332, 335, 336, 337, 338, 340, 341], "over": [1, 2, 3, 4, 8, 13, 14, 16, 17, 18, 19, 20, 21, 32, 38, 42, 43, 45, 51, 69, 77, 81, 95, 101, 117, 128, 139, 145, 163, 211, 231, 246, 248, 253, 274, 307, 326, 329, 330, 331, 335, 336, 341], "non": [1, 3, 8, 21, 32, 34, 35, 36, 38, 39, 41, 42, 77, 81, 95, 96, 97, 101, 109, 114, 122, 132, 144, 147, 148, 149, 150, 152, 163, 179, 181, 183, 185, 192, 228, 229, 238, 239, 241, 242, 244, 245, 246, 247, 248, 251, 253, 255, 256, 257, 258, 260, 266, 268, 269, 270, 271, 324, 329, 332, 335, 336, 338, 341], "static": [1, 11, 40, 45, 66, 67, 154, 251, 336, 338], "2": [1, 3, 8, 9, 10, 11, 13, 14, 16, 21, 22, 26, 28, 30, 31, 32, 35, 36, 37, 38, 41, 42, 43, 45, 55, 57, 66, 67, 77, 78, 81, 90, 94, 95, 96, 97, 99, 100, 101, 102, 103, 111, 114, 115, 116, 117, 118, 126, 128, 130, 132, 136, 139, 142, 143, 144, 147, 148, 150, 152, 154, 160, 164, 166, 167, 168, 169, 170, 171, 173, 176, 178, 179, 180, 181, 183, 184, 185, 186, 187, 190, 191, 192, 193, 196, 200, 211, 218, 219, 220, 221, 222, 224, 228, 232, 233, 238, 239, 240, 241, 245, 251, 252, 255, 256, 257, 258, 260, 267, 268, 269, 270, 271, 273, 274, 277, 278, 279, 280, 281, 282, 283, 284, 285, 287, 295, 324, 325, 328, 329, 330, 331, 332, 334, 335, 336, 338, 339, 340, 341], "like": [1, 2, 3, 4, 7, 21, 26, 28, 32, 35, 38, 41, 42, 45, 67, 77, 81, 83, 90, 95, 96, 97, 101, 119, 146, 156, 179, 183, 193, 223, 256, 325, 329, 331, 332, 335, 336, 337, 338, 341], "being": [1, 2, 3, 7, 8, 17, 18, 20, 21, 32, 57, 77, 81, 95, 101, 115, 117, 118, 127, 134, 148, 161, 162, 181, 185, 221, 224, 240, 252, 255, 258, 287, 301, 306, 318, 319, 320, 324, 329, 330, 331, 332, 335, 336, 338], "s": [1, 2, 3, 6, 7, 8, 32, 34, 35, 36, 38, 39, 41, 42, 52, 53, 54, 55, 56, 66, 67, 77, 81, 85, 92, 95, 96, 97, 101, 110, 114, 132, 142, 144, 146, 147, 148, 150, 152, 154, 156, 166, 167, 181, 185, 191, 192, 193, 195, 201, 210, 214, 216, 217, 220, 221, 225, 228, 229, 232, 239, 251, 253, 258, 268, 269, 270, 271, 272, 313, 324, 329, 330, 331, 332, 334, 335, 336, 337, 338, 340, 341], "accept": [1, 13, 14, 16, 17, 18, 19, 20, 21, 32, 38, 53, 55, 56, 57, 77, 81, 91, 95, 101, 110, 114, 122, 132, 139, 144, 147, 148, 149, 150, 152, 211, 228, 229, 230, 258, 326, 331, 341], "two": [1, 2, 3, 4, 8, 10, 32, 40, 65, 67, 77, 81, 95, 101, 128, 132, 152, 172, 179, 181, 183, 185, 205, 229, 252, 263, 300, 304, 313, 325, 329, 330, 331, 332, 334, 335, 336, 338, 340, 341], "main": [1, 2, 3, 5, 20, 22, 56, 78, 229, 304, 324, 325, 329, 330, 334, 341], "argument": [1, 3, 13, 14, 16, 17, 18, 19, 20, 21, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 41, 42, 44, 46, 47, 53, 55, 56, 57, 65, 66, 67, 77, 81, 92, 95, 96, 101, 113, 114, 132, 140, 142, 144, 146, 147, 148, 150, 152, 163, 166, 167, 179, 181, 183, 185, 187, 190, 191, 192, 193, 194, 211, 213, 217, 218, 219, 220, 221, 222, 224, 225, 226, 227, 228, 229, 230, 232, 233, 238, 239, 240, 241, 242, 243, 244, 245, 250, 251, 252, 254, 255, 256, 257, 258, 260, 262, 266, 268, 269, 270, 271, 272, 276, 286, 297, 307, 313, 316, 317, 320, 329, 330, 331, 332, 335, 336, 338, 341], "list": [1, 6, 7, 8, 9, 13, 14, 18, 19, 20, 21, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 35, 38, 41, 42, 44, 45, 46, 47, 49, 52, 53, 54, 55, 56, 60, 65, 66, 67, 68, 77, 81, 91, 95, 96, 97, 101, 103, 104, 113, 115, 118, 126, 128, 130, 132, 139, 146, 148, 150, 152, 154, 163, 175, 181, 185, 187, 190, 191, 197, 202, 220, 226, 227, 229, 231, 232, 233, 253, 258, 265, 268, 271, 286, 300, 301, 318, 319, 324, 329, 331, 334, 336, 337, 338, 340, 341], "constructor": [1, 16, 18, 19, 20, 21, 38, 45, 147, 238, 239, 241, 242, 244, 245, 246, 247, 251, 253, 255, 256, 257, 258, 260, 266, 268, 269, 270, 271, 272, 313, 317, 320, 324, 329, 330, 331, 335, 338], "iter": [1, 11, 13, 14, 16, 20, 21, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 41, 42, 44, 46, 47, 51, 52, 53, 54, 55, 56, 57, 77, 81, 95, 101, 120, 128, 140, 166, 167, 187, 192, 193, 206, 213, 219, 225, 226, 228, 230, 231, 233, 253, 265, 300, 303, 304, 313, 325, 326, 329, 331, 332, 335, 336], "execut": [1, 3, 6, 7, 8, 13, 14, 16, 18, 19, 20, 21, 32, 35, 37, 38, 41, 42, 52, 53, 54, 55, 56, 77, 78, 81, 85, 91, 92, 95, 101, 108, 148, 179, 181, 183, 185, 221, 230, 231, 308, 320, 324, 326, 328, 330, 331, 332, 335, 338, 339, 341], "step": [1, 2, 3, 4, 8, 13, 14, 16, 17, 18, 19, 20, 21, 32, 40, 74, 77, 78, 81, 87, 91, 95, 96, 97, 101, 108, 122, 125, 128, 142, 143, 144, 145, 148, 153, 163, 164, 165, 177, 179, 181, 183, 185, 186, 188, 189, 217, 221, 222, 224, 225, 229, 238, 247, 255, 267, 268, 269, 270, 271, 274, 275, 276, 286, 295, 300, 304, 326, 329, 330, 332, 334, 336, 337, 338, 340], "queri": [1, 3, 13, 14, 16, 17, 32, 34, 36, 39, 77, 81, 95, 101, 132, 147, 150, 154, 231, 329, 336, 340], "defin": [1, 2, 11, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 44, 46, 47, 77, 81, 95, 101, 133, 143, 166, 167, 168, 169, 170, 171, 172, 173, 175, 177, 178, 179, 180, 181, 183, 184, 185, 186, 187, 192, 193, 196, 197, 198, 200, 203, 204, 206, 211, 217, 218, 220, 221, 222, 224, 227, 232, 235, 242, 244, 253, 268, 269, 270, 271, 272, 286, 317, 329, 330, 332, 336, 338, 341], "number": [1, 2, 3, 8, 13, 14, 16, 17, 18, 19, 20, 21, 22, 25, 27, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 45, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 66, 67, 71, 77, 81, 91, 92, 94, 95, 96, 97, 101, 110, 117, 123, 127, 128, 138, 142, 145, 154, 165, 166, 167, 174, 175, 177, 178, 179, 180, 181, 182, 183, 184, 185, 187, 189, 192, 193, 196, 197, 198, 201, 203, 204, 207, 208, 209, 210, 213, 217, 218, 221, 222, 224, 225, 228, 229, 233, 237, 239, 245, 247, 251, 252, 254, 256, 258, 260, 295, 297, 300, 304, 306, 307, 308, 318, 319, 320, 324, 329, 330, 331, 332, 335, 336, 337, 341], "befor": [1, 2, 3, 4, 6, 7, 10, 13, 14, 16, 17, 18, 19, 20, 21, 32, 40, 45, 54, 65, 77, 81, 95, 101, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 122, 124, 125, 126, 127, 128, 130, 134, 135, 137, 138, 139, 140, 142, 143, 144, 145, 146, 147, 149, 150, 151, 153, 179, 181, 185, 187, 194, 195, 238, 239, 240, 245, 246, 247, 248, 249, 251, 252, 253, 255, 256, 257, 258, 260, 266, 269, 270, 271, 301, 329, 331, 332, 335, 336, 338, 341], "deliv": [1, 16, 18, 19, 20, 329, 330, 340], "stack": [1, 3, 7, 8, 18, 20, 21, 28, 29, 50, 77, 81, 90, 95, 96, 97, 101, 154, 179, 181, 183, 184, 185, 230, 231, 286, 295, 324, 330, 334, 336, 340], "user": [1, 2, 3, 5, 8, 21, 32, 52, 53, 55, 56, 67, 77, 81, 95, 101, 143, 148, 173, 186, 255, 258, 317, 325, 326, 329, 330, 336, 340, 341], "reset": [1, 3, 8, 11, 13, 14, 16, 17, 18, 19, 20, 21, 32, 35, 38, 41, 42, 52, 53, 54, 55, 56, 67, 74, 77, 78, 81, 87, 90, 91, 92, 94, 95, 96, 97, 101, 110, 119, 122, 125, 127, 132, 139, 142, 143, 144, 145, 147, 150, 153, 154, 156, 164, 179, 181, 185, 212, 224, 286, 313, 329, 330, 331, 332, 334, 335, 340], "whenev": [1, 2, 3, 32, 35, 38, 41, 42, 107, 125, 148, 153, 253, 268, 269, 270, 271, 306, 324], "reach": [1, 13, 14, 16, 17, 18, 19, 20, 21, 22, 40, 65, 77, 81, 95, 101, 142, 217, 221, 222, 224, 329, 331, 335, 340, 341], "done": [1, 2, 3, 4, 7, 8, 13, 14, 16, 18, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 40, 44, 46, 47, 52, 53, 55, 56, 66, 67, 74, 77, 78, 81, 87, 90, 91, 94, 95, 96, 97, 99, 100, 101, 102, 103, 108, 110, 115, 116, 118, 119, 120, 127, 128, 130, 134, 136, 138, 140, 142, 144, 145, 147, 148, 154, 163, 164, 165, 179, 181, 185, 189, 238, 239, 241, 242, 244, 245, 251, 255, 256, 257, 258, 260, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 313, 325, 329, 331, 332, 334, 335, 336, 337, 338, 340, 341], "state": [1, 2, 3, 4, 13, 14, 16, 17, 32, 35, 38, 40, 41, 42, 52, 53, 54, 55, 56, 74, 77, 81, 87, 91, 95, 96, 97, 99, 100, 101, 110, 111, 113, 119, 128, 134, 142, 143, 147, 148, 154, 163, 164, 165, 168, 173, 177, 179, 180, 181, 183, 184, 185, 186, 187, 189, 197, 200, 201, 203, 204, 210, 214, 228, 234, 238, 240, 244, 252, 253, 255, 256, 257, 258, 266, 267, 268, 269, 270, 271, 272, 320, 324, 325, 329, 330, 331, 332, 335, 336, 341], "after": [1, 2, 3, 8, 13, 14, 18, 20, 21, 26, 32, 40, 77, 81, 85, 95, 101, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 119, 120, 122, 124, 125, 126, 127, 128, 130, 134, 135, 137, 138, 139, 140, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 153, 163, 179, 181, 185, 194, 217, 219, 221, 222, 226, 248, 258, 330, 331, 332, 335, 336, 337, 338, 341], "predefin": [1, 330, 331, 332, 338], "becaus": [1, 3, 4, 7, 34, 36, 39, 40, 77, 81, 95, 101, 119, 126, 142, 147, 153, 172, 186, 193, 213, 219, 220, 225, 226, 227, 228, 229, 329, 330, 332, 334, 335, 336, 338, 341], "potenti": [1, 2, 336, 338], "comput": [1, 3, 4, 8, 13, 16, 21, 27, 32, 40, 77, 81, 95, 101, 128, 148, 151, 164, 166, 167, 168, 169, 170, 171, 172, 173, 175, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 191, 192, 193, 196, 197, 198, 199, 200, 203, 204, 206, 208, 209, 211, 214, 217, 218, 220, 221, 222, 224, 225, 227, 229, 232, 235, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 251, 252, 253, 254, 255, 256, 257, 258, 260, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 274, 308, 325, 329, 331, 332, 334, 335, 337, 338], "heavi": [1, 8, 338], "crucial": [1, 217, 221, 222, 224, 251, 253, 329, 330, 331, 332, 335, 336, 341], "configur": [1, 8, 13, 14, 16, 17, 21, 22, 40, 126, 168, 173, 200, 253, 255, 313, 324, 329, 330, 331, 335, 336], "hyperparamet": [1, 238, 239, 241, 242, 244, 245, 246, 247, 251, 253, 255, 256, 257, 258, 260, 266, 329, 336, 338], "appropri": [1, 3, 4, 7, 13, 14, 16, 17, 63, 69, 70, 72, 95, 101, 119, 317, 320, 329, 338], "paramet": [1, 8, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 65, 68, 71, 75, 76, 77, 78, 81, 91, 92, 94, 95, 96, 97, 98, 101, 103, 104, 105, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 122, 123, 124, 125, 126, 127, 128, 130, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 156, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 206, 207, 208, 209, 210, 211, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 262, 263, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 289, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 313, 316, 317, 318, 319, 320, 324, 325, 329, 332, 335, 336, 337, 340], "take": [1, 3, 8, 23, 40, 77, 81, 95, 101, 113, 142, 145, 147, 166, 167, 168, 169, 170, 171, 172, 173, 175, 177, 178, 179, 180, 181, 183, 184, 185, 186, 187, 192, 193, 196, 197, 198, 200, 203, 204, 206, 211, 217, 218, 220, 221, 222, 223, 224, 225, 227, 232, 235, 237, 273, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 295, 306, 324, 326, 329, 330, 331, 335, 336, 338, 341], "consider": [1, 3, 8, 330, 335, 338], "whether": [1, 2, 3, 13, 14, 16, 17, 18, 19, 20, 21, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 35, 37, 38, 40, 41, 42, 43, 44, 46, 47, 52, 53, 54, 55, 56, 77, 81, 91, 95, 96, 97, 98, 101, 103, 115, 118, 143, 148, 164, 166, 167, 181, 185, 187, 233, 239, 240, 241, 242, 244, 245, 246, 252, 253, 255, 256, 258, 260, 266, 268, 271, 329, 330, 331, 335, 336, 341], "should": [1, 3, 4, 5, 7, 8, 11, 13, 14, 16, 17, 18, 19, 20, 21, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 35, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 52, 53, 54, 55, 56, 57, 66, 67, 68, 69, 77, 81, 90, 91, 95, 96, 97, 98, 101, 110, 113, 114, 115, 116, 119, 120, 122, 126, 128, 133, 134, 136, 139, 140, 142, 143, 145, 147, 148, 153, 154, 156, 163, 164, 166, 167, 168, 169, 170, 171, 172, 173, 175, 177, 178, 179, 180, 181, 183, 184, 185, 186, 187, 192, 193, 196, 197, 198, 200, 203, 204, 206, 211, 217, 218, 220, 221, 222, 224, 225, 227, 228, 229, 232, 235, 245, 250, 252, 253, 255, 256, 259, 267, 268, 269, 270, 271, 272, 287, 299, 300, 301, 304, 316, 318, 319, 320, 324, 326, 329, 330, 331, 332, 334, 335, 336, 337, 338, 340, 341], "occur": [1, 8, 14, 28, 29, 111, 128, 133, 153, 164, 213, 219, 220, 225, 226, 227, 228, 229, 248, 338, 341], "serial": [1, 2, 3, 32, 77, 81, 95, 101, 154], "optim": [1, 2, 8, 32, 40, 77, 81, 95, 101, 148, 165, 189, 194, 195, 239, 253, 254, 255, 258, 299, 304, 316, 325, 326, 331, 332, 335, 336], "parallel": [1, 3, 8, 17, 96, 97, 153, 156, 238, 317, 318, 319, 320, 330, 331, 335], "syncdatacollector": [1, 13, 14, 17, 18, 19, 20, 21, 110, 136, 316, 319, 322, 331, 332, 335, 338], "class": [1, 2, 3, 5, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 77, 78, 79, 81, 83, 90, 91, 95, 96, 97, 101, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 318, 319, 320, 324, 325, 326, 329, 330, 331, 332, 335, 338, 341], "worker": [1, 2, 13, 14, 16, 17, 18, 19, 20, 21, 22, 36, 45, 57, 78, 92, 95, 101, 154, 318, 319, 320, 329, 331, 340, 341], "multisyncdatacollector": [1, 18, 19, 20, 21, 319, 322, 331, 340], "split": [1, 13, 14, 16, 17, 18, 19, 20, 21, 34, 36, 45, 52, 53, 55, 56, 57, 66, 67, 90, 96, 97, 179, 183, 238, 239, 240, 245, 246, 247, 248, 249, 251, 252, 253, 255, 256, 257, 258, 260, 266, 324, 326, 331, 338, 340], "workload": 1, "across": [1, 3, 8, 18, 19, 20, 21, 35, 38, 41, 42, 66, 67, 85, 154, 192, 224, 306, 322, 324, 329, 335, 336], "aggreg": [1, 3, 164, 166, 167, 169, 170, 231], "result": [1, 3, 7, 13, 14, 16, 17, 18, 19, 20, 21, 32, 34, 35, 36, 37, 38, 39, 41, 42, 52, 53, 54, 55, 56, 65, 66, 67, 77, 78, 81, 95, 101, 109, 110, 111, 112, 113, 114, 115, 116, 117, 119, 120, 122, 124, 125, 126, 127, 128, 130, 134, 135, 137, 138, 139, 140, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 153, 154, 156, 163, 164, 179, 181, 183, 185, 187, 192, 202, 218, 220, 221, 227, 238, 239, 241, 242, 244, 245, 246, 247, 251, 253, 255, 256, 257, 258, 260, 266, 268, 273, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 306, 324, 330, 332, 336, 337, 340, 341], "final": [1, 3, 4, 21, 34, 36, 39, 40, 153, 179, 181, 183, 185, 192, 217, 221, 222, 223, 224, 230, 268, 300, 324, 329, 330, 331, 335, 336, 341], "multiasyncdatacollector": [1, 17, 18, 19, 20, 21, 318, 322, 329, 330, 331, 340], "sever": [1, 8, 30, 32, 45, 77, 81, 95, 101, 111, 113, 148, 255, 329, 331, 338, 341], "batch": [1, 3, 13, 14, 16, 17, 18, 19, 20, 21, 23, 27, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 52, 53, 54, 55, 56, 57, 58, 59, 62, 65, 66, 67, 69, 71, 77, 81, 91, 92, 94, 95, 101, 110, 122, 128, 130, 133, 136, 144, 148, 149, 153, 154, 164, 174, 175, 179, 180, 181, 183, 184, 185, 186, 190, 191, 192, 193, 194, 199, 201, 207, 211, 224, 228, 238, 239, 240, 241, 242, 244, 245, 246, 247, 248, 249, 251, 252, 253, 255, 256, 257, 258, 260, 266, 268, 269, 270, 271, 272, 273, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 287, 295, 298, 301, 302, 303, 304, 306, 318, 319, 320, 326, 330, 331, 332, 334, 335, 337, 340, 341], "gather": [1, 3, 18, 20, 21, 45, 57, 58, 59, 71, 133, 191, 199, 267, 308, 323, 329, 330, 331, 332, 335, 336, 338, 341], "continu": [1, 9, 25, 46, 67, 77, 81, 95, 96, 97, 101, 160, 169, 170, 171, 172, 224, 231, 238, 239, 245, 251, 255, 256, 257, 258, 259, 260, 268, 273, 281, 324, 329, 331, 332, 335, 336, 338, 340, 341], "concomitantli": 1, "network": [1, 4, 8, 32, 77, 81, 90, 95, 96, 97, 101, 166, 167, 169, 170, 171, 172, 175, 177, 178, 183, 187, 192, 193, 195, 197, 198, 201, 203, 204, 205, 210, 214, 215, 216, 218, 228, 232, 239, 240, 241, 242, 244, 245, 246, 250, 251, 252, 253, 255, 256, 257, 258, 259, 260, 264, 266, 268, 269, 270, 271, 272, 315, 316, 324, 325, 326, 334, 336, 341], "impli": [1, 341], "weight": [1, 4, 9, 12, 13, 14, 16, 17, 18, 19, 20, 21, 32, 35, 40, 77, 81, 95, 99, 100, 101, 114, 132, 144, 147, 148, 150, 152, 179, 180, 181, 183, 184, 185, 192, 195, 228, 238, 239, 240, 245, 248, 258, 306, 315, 324, 326, 329, 330, 331, 332, 334, 336, 338, 340], "mai": [1, 2, 3, 4, 5, 7, 8, 13, 14, 16, 17, 18, 20, 21, 28, 29, 32, 52, 53, 55, 56, 77, 81, 95, 101, 126, 128, 140, 148, 149, 154, 156, 187, 192, 325, 326, 329, 330, 331, 332, 335, 336, 337, 338, 340, 341], "slightli": [1, 324, 325, 332, 336, 337, 338, 341], "lag": [1, 13, 14, 16, 17, 329, 330, 331], "therefor": [1, 3, 7, 55, 56, 77, 81, 95, 101, 136, 255, 266, 341], "although": [1, 8, 77, 81, 95, 101, 166, 167, 168, 169, 170, 171, 172, 173, 175, 177, 178, 179, 180, 181, 183, 184, 185, 186, 187, 192, 193, 196, 197, 198, 200, 203, 204, 206, 211, 217, 218, 220, 221, 222, 224, 227, 232, 235, 326, 329, 330, 338], "fastest": 1, "price": 1, "suitabl": [1, 2], "where": [1, 3, 4, 7, 8, 13, 14, 16, 17, 18, 19, 20, 21, 28, 29, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 52, 53, 54, 55, 56, 57, 58, 59, 66, 67, 69, 71, 77, 81, 90, 91, 94, 95, 96, 97, 101, 108, 110, 119, 126, 132, 136, 139, 142, 143, 145, 147, 149, 152, 153, 163, 164, 179, 180, 183, 184, 190, 191, 192, 217, 221, 222, 224, 225, 228, 229, 237, 238, 239, 240, 245, 246, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 267, 268, 269, 270, 271, 272, 273, 274, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 325, 326, 329, 330, 331, 334, 335, 336, 338, 341], "asynchron": [1, 9, 14, 21, 32, 77, 81, 95, 101, 114, 132, 144, 147, 148, 150, 152, 228, 238, 318, 330, 331], "off": [1, 2, 4, 182, 209, 219, 258, 300, 309, 324, 326, 329, 330, 331, 335, 337, 341], "curriculum": [1, 4], "For": [1, 2, 3, 4, 7, 8, 9, 10, 13, 14, 16, 17, 18, 20, 21, 32, 52, 53, 55, 56, 66, 77, 81, 95, 96, 97, 101, 115, 118, 122, 128, 143, 148, 153, 176, 179, 181, 183, 185, 193, 194, 214, 216, 218, 220, 226, 238, 246, 251, 255, 300, 324, 326, 329, 330, 331, 332, 335, 336, 337, 338, 341], "remot": [1, 2, 18, 19, 20, 21, 95, 101, 341], "rollout": [1, 2, 3, 13, 14, 16, 21, 23, 40, 77, 81, 84, 91, 92, 95, 96, 97, 99, 100, 101, 102, 103, 108, 110, 113, 115, 118, 119, 120, 126, 130, 134, 139, 140, 142, 143, 145, 156, 165, 181, 185, 189, 224, 238, 308, 324, 329, 331, 332, 337, 338, 340], "necessari": [1, 4, 6, 8, 13, 14, 16, 17, 53, 55, 56, 140, 256, 268, 269, 270, 271, 272, 325, 329, 331], "synchronis": [1, 78, 335], "either": [1, 5, 22, 32, 40, 57, 77, 81, 95, 101, 142, 143, 234, 260, 291, 326, 329, 330, 332, 337, 338, 340, 341], "update_policy_weights_": [1, 12, 13, 14, 16, 17, 18, 19, 20, 21, 329, 335, 340], "update_at_each_batch": [1, 13, 14, 17, 329], "true": [1, 3, 4, 8, 13, 14, 16, 17, 18, 19, 20, 21, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 65, 66, 67, 75, 76, 77, 78, 79, 81, 91, 95, 96, 97, 98, 99, 100, 101, 102, 103, 108, 110, 111, 114, 117, 122, 125, 126, 127, 128, 132, 133, 134, 135, 138, 140, 142, 144, 146, 147, 148, 149, 150, 152, 154, 156, 160, 163, 164, 165, 166, 167, 169, 170, 171, 172, 178, 179, 180, 181, 183, 184, 185, 187, 189, 190, 191, 192, 193, 194, 195, 208, 209, 213, 214, 215, 216, 217, 219, 220, 224, 225, 226, 227, 228, 229, 230, 231, 232, 238, 239, 240, 241, 244, 245, 247, 248, 249, 251, 252, 253, 254, 255, 256, 257, 258, 260, 263, 268, 269, 270, 271, 274, 277, 278, 279, 280, 282, 283, 284, 285, 286, 287, 297, 298, 300, 301, 304, 320, 324, 325, 326, 329, 330, 331, 332, 334, 335, 336, 337, 338, 340, 341], "second": [1, 3, 8, 179, 181, 183, 185, 220, 240, 252, 255, 258, 303, 329, 330, 331, 332, 334, 335, 336, 337, 338, 340, 341], "devic": [1, 2, 3, 7, 8, 12, 13, 14, 16, 17, 18, 19, 20, 21, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 53, 55, 56, 57, 58, 59, 71, 74, 77, 79, 81, 84, 85, 87, 90, 91, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 114, 115, 116, 118, 119, 120, 126, 130, 131, 132, 134, 136, 140, 142, 144, 146, 147, 148, 150, 152, 160, 163, 165, 166, 167, 168, 169, 170, 171, 172, 176, 178, 179, 180, 181, 183, 184, 185, 186, 187, 189, 192, 193, 194, 195, 200, 201, 202, 210, 213, 214, 215, 216, 218, 219, 220, 224, 225, 226, 227, 228, 231, 233, 238, 239, 241, 242, 244, 245, 251, 255, 256, 257, 258, 260, 266, 268, 269, 270, 271, 301, 306, 313, 314, 324, 329, 330, 331, 332, 334, 335, 336, 337, 338, 340], "oper": [1, 3, 4, 7, 8, 13, 14, 17, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 39, 44, 45, 46, 47, 77, 81, 95, 101, 122, 126, 147, 175, 176, 180, 184, 196, 214, 215, 216, 219, 220, 223, 228, 234, 238, 240, 241, 242, 246, 252, 255, 257, 266, 267, 268, 269, 270, 271, 304, 313, 322, 326, 329, 330, 331, 332, 334, 335, 336, 341], "instanc": [1, 2, 3, 4, 7, 8, 13, 14, 16, 17, 18, 19, 20, 21, 32, 34, 36, 37, 39, 43, 44, 45, 52, 66, 67, 76, 77, 78, 81, 91, 95, 101, 110, 128, 144, 147, 154, 160, 164, 166, 167, 168, 169, 170, 171, 172, 173, 175, 177, 178, 179, 180, 181, 183, 184, 185, 186, 187, 188, 192, 193, 196, 197, 198, 200, 203, 204, 206, 211, 217, 218, 219, 220, 221, 222, 224, 225, 226, 227, 229, 230, 231, 232, 235, 242, 245, 253, 266, 268, 269, 270, 271, 287, 291, 300, 308, 309, 310, 313, 316, 318, 319, 324, 325, 326, 329, 331, 332, 336, 338, 341], "cpu": [1, 3, 8, 10, 13, 14, 16, 18, 19, 20, 21, 24, 26, 28, 32, 34, 36, 37, 39, 40, 41, 42, 43, 44, 45, 53, 55, 56, 57, 58, 59, 71, 74, 77, 81, 87, 90, 91, 94, 95, 96, 97, 99, 100, 101, 102, 103, 114, 115, 116, 118, 119, 120, 130, 132, 134, 136, 140, 142, 144, 147, 148, 150, 152, 160, 163, 165, 179, 180, 181, 183, 184, 185, 189, 194, 195, 201, 202, 210, 213, 214, 215, 216, 218, 219, 220, 225, 226, 227, 228, 231, 233, 238, 239, 241, 242, 244, 245, 251, 255, 256, 257, 258, 260, 266, 301, 313, 324, 329, 330, 331, 332, 334, 335, 336, 337, 338, 340, 341], "slower": 1, "than": [1, 2, 3, 4, 8, 13, 14, 16, 17, 52, 66, 67, 77, 81, 85, 95, 101, 134, 172, 181, 183, 185, 187, 196, 211, 213, 217, 219, 228, 233, 253, 295, 296, 297, 298, 299, 300, 301, 302, 303, 305, 306, 323, 325, 329, 330, 331, 335, 336, 338, 340, 341], "one": [1, 2, 3, 4, 5, 7, 8, 11, 13, 14, 16, 17, 18, 19, 20, 21, 22, 24, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 52, 53, 54, 55, 56, 61, 63, 66, 67, 68, 70, 72, 77, 78, 81, 85, 90, 94, 95, 96, 97, 101, 103, 108, 110, 113, 115, 116, 117, 118, 127, 128, 132, 136, 139, 141, 143, 144, 145, 147, 148, 149, 152, 154, 166, 167, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 179, 180, 181, 183, 184, 185, 186, 187, 192, 193, 196, 197, 198, 199, 200, 202, 203, 204, 206, 211, 213, 217, 218, 219, 220, 221, 222, 224, 225, 226, 227, 228, 229, 232, 233, 235, 237, 238, 239, 240, 241, 242, 244, 245, 246, 247, 251, 252, 253, 255, 256, 257, 258, 259, 260, 266, 268, 269, 270, 271, 275, 276, 297, 299, 300, 304, 308, 313, 320, 323, 324, 325, 326, 329, 330, 331, 332, 334, 335, 336, 337, 338, 341], "cuda": [1, 3, 7, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 44, 46, 47, 77, 81, 84, 85, 95, 101, 114, 126, 131, 132, 144, 147, 148, 150, 152, 179, 180, 183, 184, 228, 244, 296, 329, 330, 331, 332, 335, 337, 341], "multipl": [1, 2, 3, 5, 8, 13, 14, 16, 17, 18, 19, 20, 21, 27, 43, 95, 101, 111, 113, 117, 127, 136, 139, 142, 147, 154, 179, 183, 185, 186, 192, 194, 195, 213, 219, 225, 226, 228, 229, 232, 240, 245, 252, 255, 256, 260, 274, 313, 320, 324, 326, 329, 330, 331, 335, 336, 338, 340], "infer": [1, 95, 101, 110, 154, 181, 185, 194, 218, 244, 329, 331, 338], "run": [1, 3, 4, 5, 6, 7, 8, 10, 13, 14, 17, 21, 32, 75, 76, 77, 81, 91, 95, 101, 127, 128, 148, 154, 166, 167, 168, 169, 170, 171, 172, 173, 175, 177, 178, 179, 180, 181, 183, 184, 185, 186, 187, 192, 193, 196, 197, 198, 200, 203, 204, 206, 211, 217, 218, 220, 221, 222, 224, 227, 230, 231, 232, 235, 258, 300, 318, 319, 320, 323, 326, 329, 330, 331, 332, 334, 335, 336, 337, 338, 340], "dispatch": [1, 18, 19, 20, 21, 211], "avail": [1, 3, 4, 6, 21, 56, 65, 85, 95, 96, 97, 126, 176, 202, 225, 229, 253, 318, 319, 324, 329, 330, 331, 332, 335, 336, 338, 341], "speed": [1, 2, 4, 8, 27, 95, 101, 325, 329, 330, 331, 332, 335, 336, 338], "up": [1, 2, 3, 8, 9, 13, 14, 16, 27, 40, 52, 53, 55, 56, 95, 101, 145, 147, 255, 323, 324, 325, 329, 330, 331, 332, 335, 336, 338, 341], "avoid": [1, 32, 58, 59, 71, 77, 81, 95, 101, 107, 148, 154, 213, 228, 233, 240, 252, 255, 258, 307, 331, 335], "oom": [1, 58, 59, 71], "choic": [1, 2, 52, 53, 55, 56, 95, 196, 324, 325, 329, 330, 335], "size": [1, 2, 3, 13, 14, 16, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 52, 53, 54, 55, 56, 57, 58, 59, 62, 65, 66, 67, 68, 69, 71, 74, 77, 79, 81, 87, 90, 91, 92, 94, 95, 96, 97, 99, 100, 101, 102, 103, 111, 115, 118, 119, 120, 122, 130, 132, 134, 136, 140, 141, 142, 144, 146, 147, 148, 149, 152, 154, 160, 163, 165, 166, 167, 168, 173, 174, 176, 179, 180, 181, 183, 184, 185, 186, 187, 189, 190, 191, 192, 193, 196, 199, 200, 201, 202, 203, 204, 207, 210, 211, 213, 214, 215, 216, 218, 219, 220, 221, 222, 224, 225, 226, 227, 228, 231, 233, 238, 239, 241, 242, 244, 245, 251, 253, 255, 256, 257, 258, 260, 266, 267, 268, 269, 270, 271, 272, 287, 295, 301, 313, 324, 330, 331, 332, 334, 335, 336, 337, 340, 341], "pass": [1, 3, 4, 13, 14, 16, 18, 19, 20, 21, 22, 26, 32, 35, 38, 40, 41, 42, 45, 53, 55, 56, 58, 59, 69, 71, 77, 78, 79, 81, 90, 92, 95, 96, 97, 101, 115, 118, 134, 147, 149, 154, 166, 167, 168, 169, 170, 171, 172, 173, 175, 177, 178, 179, 180, 181, 183, 184, 185, 186, 187, 192, 193, 194, 196, 197, 198, 200, 201, 203, 204, 206, 210, 211, 213, 217, 218, 219, 220, 221, 222, 224, 225, 226, 227, 228, 229, 231, 232, 233, 235, 240, 252, 253, 255, 268, 269, 270, 271, 272, 301, 318, 319, 320, 324, 329, 330, 331, 332, 334, 335, 336, 338, 341], "ie": [1, 3, 18, 20, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 39, 41, 44, 45, 46, 47, 61, 67, 77, 81, 85, 94, 95, 101, 110, 122, 149, 154, 164, 181, 185, 218, 238, 240, 241, 245, 251, 252, 255, 256, 257, 258, 260, 268, 269, 270, 271, 324, 325, 330, 331, 335, 338], "store": [1, 3, 8, 13, 14, 16, 17, 20, 26, 32, 34, 36, 37, 39, 41, 42, 43, 45, 55, 57, 58, 59, 60, 61, 71, 77, 81, 95, 101, 153, 154, 165, 186, 189, 238, 239, 241, 242, 244, 245, 246, 247, 251, 253, 255, 256, 257, 258, 260, 266, 313, 322, 326, 329, 331, 332, 335, 337, 338, 341], "while": [1, 3, 7, 8, 32, 77, 81, 95, 101, 136, 148, 166, 167, 168, 169, 170, 171, 172, 173, 175, 177, 178, 179, 180, 181, 183, 184, 185, 186, 187, 192, 193, 196, 197, 198, 200, 203, 204, 206, 211, 217, 218, 220, 221, 222, 224, 227, 232, 235, 251, 252, 255, 258, 324, 329, 331, 332, 335, 336, 337, 338, 340], "wait": [1, 20, 21, 22, 332, 336], "also": [1, 2, 3, 8, 9, 11, 32, 34, 36, 39, 41, 53, 55, 56, 57, 58, 59, 71, 77, 81, 95, 96, 97, 101, 107, 110, 117, 128, 134, 136, 139, 140, 142, 144, 148, 179, 183, 204, 225, 230, 231, 232, 238, 239, 241, 242, 244, 245, 251, 255, 258, 268, 275, 276, 324, 326, 329, 330, 331, 332, 334, 335, 336, 338, 341], "impact": [1, 115, 118, 330, 332, 335], "memori": [1, 2, 3, 8, 21, 27, 32, 34, 36, 39, 45, 52, 53, 55, 56, 58, 77, 78, 81, 85, 95, 101, 110, 114, 132, 144, 147, 148, 150, 152, 154, 183, 184, 228, 320, 326, 329, 330, 331, 332, 334, 335, 336, 337, 338, 340, 341], "manag": [1, 8, 264, 265, 268, 269, 270, 271, 300], "kei": [1, 2, 3, 7, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 52, 66, 67, 69, 77, 81, 95, 101, 108, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 125, 126, 128, 131, 132, 133, 134, 136, 139, 140, 142, 143, 144, 145, 146, 147, 148, 150, 151, 152, 153, 154, 163, 164, 165, 175, 176, 181, 185, 188, 189, 202, 213, 217, 218, 219, 220, 221, 222, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 237, 238, 239, 240, 241, 242, 244, 245, 246, 247, 248, 249, 251, 252, 253, 255, 256, 257, 258, 260, 266, 267, 268, 269, 270, 271, 272, 287, 298, 299, 300, 302, 303, 304, 308, 313, 325, 326, 329, 331, 332, 334, 335, 336, 338, 340, 341], "control": [1, 3, 5, 8, 16, 75, 76, 90, 96, 97, 117, 163, 169, 170, 171, 172, 181, 185, 188, 189, 204, 211, 224, 228, 229, 230, 238, 240, 252, 255, 259, 268, 273, 281, 324, 326, 329, 330, 331, 335, 336, 338], "which": [1, 2, 3, 4, 7, 8, 11, 13, 14, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 39, 40, 41, 42, 44, 45, 46, 47, 52, 53, 55, 56, 57, 65, 77, 81, 85, 92, 95, 98, 101, 110, 111, 115, 118, 123, 126, 127, 128, 132, 133, 142, 144, 145, 147, 148, 150, 156, 179, 180, 182, 183, 184, 185, 190, 191, 192, 209, 214, 215, 216, 218, 225, 228, 229, 231, 238, 239, 240, 242, 245, 246, 247, 248, 249, 251, 252, 253, 255, 256, 257, 258, 260, 263, 266, 268, 269, 270, 271, 295, 299, 313, 324, 325, 326, 329, 330, 331, 332, 334, 335, 336, 337, 338, 341], "storing_devic": [1, 13, 14, 16, 17, 18, 19, 20, 21, 329, 330, 335, 340], "dure": [1, 3, 13, 14, 16, 17, 18, 19, 20, 36, 40, 45, 52, 53, 54, 55, 56, 57, 77, 81, 95, 96, 97, 101, 110, 113, 115, 118, 123, 130, 148, 181, 185, 300, 304, 325, 329, 330, 331, 332, 335, 336, 338, 341], "heurist": [1, 4, 24, 25, 26, 27, 28, 29, 30, 31, 33, 44, 46, 47, 224, 329, 341], "usual": [1, 3, 4, 6, 7, 8, 52, 77, 81, 95, 101, 195, 255, 268, 269, 270, 271, 272, 286, 313, 323, 324, 326, 329, 330, 331, 332, 335, 338, 341], "same": [1, 2, 3, 4, 11, 13, 14, 16, 18, 19, 20, 21, 28, 29, 32, 34, 36, 39, 43, 45, 52, 65, 77, 78, 81, 90, 95, 96, 97, 101, 110, 115, 117, 118, 123, 127, 128, 147, 148, 154, 166, 167, 180, 181, 184, 185, 187, 190, 191, 192, 193, 218, 224, 232, 258, 329, 330, 331, 334, 335, 337, 338, 341], "storag": [1, 2, 8, 32, 34, 35, 36, 38, 39, 41, 42, 52, 53, 54, 55, 56, 58, 59, 60, 65, 66, 67, 69, 71, 77, 79, 81, 95, 101, 110, 115, 118, 136, 322, 326, 330, 331, 332, 335, 337], "default": [1, 2, 3, 10, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 52, 53, 54, 55, 56, 57, 58, 59, 61, 65, 66, 67, 71, 75, 77, 81, 94, 95, 96, 97, 98, 101, 103, 108, 110, 111, 115, 117, 118, 119, 122, 126, 127, 128, 130, 132, 133, 136, 138, 140, 142, 143, 144, 145, 146, 148, 149, 150, 152, 153, 154, 156, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 187, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 200, 202, 203, 204, 206, 207, 208, 209, 213, 217, 218, 219, 220, 221, 222, 224, 225, 226, 227, 228, 229, 232, 233, 235, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 260, 262, 263, 266, 267, 268, 269, 270, 271, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 313, 316, 320, 326, 329, 330, 331, 332, 337, 338, 340, 341], "behaviour": [1, 3, 21, 81, 111, 115, 118, 128, 133, 143, 163, 181, 182, 185, 209, 300, 324, 330, 338], "besid": 1, "those": [1, 2, 3, 5, 7, 26, 28, 95, 101, 110, 115, 118, 128, 144, 145, 185, 225, 229, 230, 231, 306, 318, 319, 324, 329, 330, 335, 336, 341], "choos": [1, 90, 181, 185, 255, 324, 325, 329, 330, 331, 335, 338], "follow": [1, 2, 3, 6, 7, 8, 32, 34, 36, 37, 39, 40, 52, 54, 77, 81, 91, 94, 95, 96, 97, 99, 100, 101, 103, 126, 132, 150, 166, 167, 179, 181, 183, 185, 187, 220, 226, 227, 237, 238, 239, 240, 241, 245, 251, 252, 255, 256, 257, 258, 260, 304, 313, 324, 325, 326, 329, 330, 331, 332, 334, 335, 336, 338, 340, 341], "max_frames_per_traj": [1, 13, 14, 16, 17, 18, 19, 20, 21, 307, 329, 331, 340], "frame": [1, 2, 13, 14, 16, 17, 18, 19, 20, 21, 32, 110, 123, 217, 221, 222, 224, 286, 287, 297, 300, 304, 307, 308, 329, 330, 331, 332, 335, 338, 340, 341], "call": [1, 2, 3, 7, 8, 11, 13, 14, 16, 17, 18, 19, 20, 21, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 44, 45, 46, 47, 49, 52, 53, 54, 55, 56, 57, 58, 59, 60, 62, 65, 68, 71, 77, 81, 94, 95, 101, 110, 113, 114, 117, 122, 125, 126, 128, 130, 131, 132, 139, 144, 147, 148, 150, 152, 153, 154, 156, 161, 162, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 175, 177, 178, 179, 180, 181, 183, 184, 185, 186, 187, 189, 192, 193, 194, 196, 197, 198, 200, 203, 204, 206, 211, 217, 218, 220, 221, 222, 224, 227, 228, 229, 231, 232, 235, 240, 252, 255, 258, 267, 268, 269, 270, 271, 286, 300, 326, 330, 331, 332, 335, 336, 338, 341], "frames_per_batch": [1, 13, 14, 16, 17, 18, 19, 20, 21, 110, 136, 307, 329, 330, 331, 332, 335, 338, 340], "each": [1, 2, 3, 4, 7, 8, 11, 13, 14, 16, 17, 18, 19, 20, 21, 23, 30, 31, 32, 40, 41, 52, 66, 67, 77, 78, 81, 95, 96, 97, 101, 103, 132, 136, 139, 142, 143, 144, 145, 152, 154, 176, 179, 180, 181, 183, 185, 192, 193, 197, 201, 202, 210, 217, 219, 220, 221, 227, 231, 274, 277, 278, 279, 280, 282, 283, 284, 285, 300, 301, 318, 319, 324, 329, 330, 331, 332, 335, 336, 337, 338, 340, 341], "init_random_fram": [1, 13, 14, 16, 17, 18, 19, 20, 21, 307, 329, 330], "random": [1, 3, 13, 14, 15, 16, 17, 18, 19, 20, 21, 24, 25, 26, 27, 28, 29, 30, 31, 33, 40, 44, 46, 47, 56, 62, 77, 81, 91, 95, 101, 117, 127, 128, 144, 156, 179, 181, 183, 185, 221, 225, 228, 229, 239, 256, 300, 308, 324, 329, 330, 331, 332, 336, 337, 338, 340, 341], "rand_step": [1, 3, 73, 75, 76, 77, 78, 80, 81, 82, 86, 88, 89, 91, 92, 95, 101, 125, 144, 154, 336, 340, 341], "reset_at_each_it": [1, 13, 14, 16, 17, 18, 19, 20, 21, 329], "split_traj": [1, 13, 14, 16, 17, 18, 19, 20, 21, 52, 53, 55, 56, 329, 330, 331], "trajectori": [1, 3, 13, 14, 16, 17, 18, 19, 20, 21, 23, 32, 41, 52, 53, 55, 56, 61, 66, 67, 69, 77, 81, 95, 101, 133, 142, 147, 165, 185, 189, 224, 255, 268, 271, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 295, 322, 325, 329, 330, 331, 332, 336, 338, 340, 341], "pad": [1, 2, 3, 23, 37, 43, 52, 53, 55, 56, 110, 166, 167, 169, 170, 185, 186, 190, 191, 192, 301], "along": [1, 2, 3, 23, 28, 29, 34, 36, 39, 40, 45, 52, 53, 55, 56, 59, 66, 67, 71, 110, 111, 128, 130, 133, 139, 146, 185, 187, 190, 191, 195, 219, 225, 228, 229, 253, 324, 329, 330, 332, 335, 336, 338], "point": [1, 2, 3, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 44, 46, 47, 54, 61, 63, 69, 70, 72, 77, 81, 95, 101, 110, 114, 132, 143, 144, 146, 147, 148, 150, 152, 188, 228, 237, 246, 304, 323, 330, 331, 334, 335, 336, 338, 341], "boolean": [1, 13, 14, 16, 17, 18, 19, 20, 21, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 40, 44, 46, 47, 81, 133, 142, 164, 190, 191, 217, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 326, 332], "repres": [1, 3, 13, 14, 16, 17, 18, 19, 20, 21, 26, 28, 41, 53, 77, 81, 95, 101, 103, 123, 133, 154, 176, 190, 191, 202, 219, 220, 226, 227, 229, 263, 268, 301, 329, 331, 332, 335], "valid": [1, 3, 23, 34, 36, 37, 45, 57, 104, 133, 148, 166, 167, 187, 190, 191, 217, 224, 252, 268, 269, 270, 271, 301, 326, 341], "exploration_typ": [1, 13, 14, 16, 18, 19, 20, 21, 300, 322, 329, 330], "strategi": [1, 2, 16, 90, 191, 199, 221, 324, 326, 329, 330, 335, 338], "reset_when_don": [1, 13, 14, 16, 18, 19, 20, 21], "These": [1, 2, 7, 32, 40, 56, 77, 81, 95, 101, 132, 152, 324, 325, 329, 331, 335, 336, 338, 341], "tool": [1, 2, 3, 5, 332, 336, 338, 341], "backend": [1, 3, 7, 11, 18, 19, 21, 22, 95, 105, 107, 326, 329, 331, 332, 336], "gloo": [1, 18, 19, 22], "nccl": [1, 18, 19], "mpi": [1, 18, 19], "distributeddatacollector": [1, 22, 322], "rpc": [1, 20, 22], "rpcdatacollector": [1, 22, 322], "launcher": [1, 18, 19, 20, 22], "rai": [1, 21], "submitit": [1, 18, 19, 20, 22], "torch": [1, 2, 3, 8, 9, 10, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 52, 53, 54, 55, 56, 57, 58, 59, 61, 65, 66, 67, 69, 71, 74, 77, 78, 81, 87, 90, 91, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 108, 111, 114, 115, 116, 117, 118, 119, 120, 126, 128, 130, 132, 134, 136, 138, 139, 140, 142, 143, 144, 145, 146, 147, 148, 150, 152, 154, 160, 163, 164, 165, 166, 167, 168, 173, 174, 176, 177, 179, 180, 181, 182, 183, 184, 185, 186, 187, 189, 190, 191, 192, 193, 194, 195, 196, 199, 200, 201, 202, 207, 208, 209, 210, 211, 213, 214, 215, 216, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 231, 232, 233, 236, 238, 239, 241, 242, 244, 245, 246, 247, 251, 253, 255, 256, 257, 258, 260, 266, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 295, 302, 303, 313, 316, 324, 325, 326, 329, 330, 331, 332, 334, 335, 336, 337, 338, 340, 341], "multiprocess": [1, 2, 3, 18, 19, 20, 78, 79, 154, 330, 331, 336, 341], "synchron": [1, 13, 19, 21, 92, 318, 319, 330, 331], "mode": [1, 6, 13, 14, 16, 18, 19, 20, 21, 32, 77, 81, 92, 95, 101, 115, 118, 143, 148, 154, 157, 161, 162, 174, 181, 182, 185, 199, 207, 208, 209, 225, 229, 253, 300, 329, 330, 332, 335, 340, 341], "find": [1, 4, 6, 7, 18, 19, 20, 35, 37, 43, 66, 67, 183, 217, 224, 298, 302, 329, 330, 335], "dedic": [1, 2, 3, 18, 19, 20, 21, 214, 215, 216, 324, 329, 334, 335], "folder": [1, 2, 330], "sub": [1, 2, 3, 13, 14, 18, 19, 20, 21, 66, 77, 81, 95, 101, 133, 230, 231, 295, 304, 324, 329, 330, 331, 334, 340, 341], "all": [1, 2, 3, 4, 8, 13, 14, 16, 17, 18, 19, 20, 21, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 44, 46, 47, 49, 56, 77, 78, 81, 91, 95, 96, 97, 101, 103, 104, 110, 113, 114, 115, 116, 118, 121, 126, 127, 128, 132, 139, 144, 145, 147, 148, 150, 152, 154, 159, 160, 161, 162, 163, 166, 167, 168, 169, 170, 171, 172, 173, 175, 177, 178, 179, 180, 181, 183, 184, 185, 186, 187, 192, 193, 196, 197, 198, 200, 203, 204, 206, 211, 217, 218, 220, 221, 222, 224, 227, 228, 229, 231, 232, 235, 248, 253, 273, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 299, 304, 307, 318, 319, 320, 323, 324, 325, 326, 328, 329, 330, 331, 332, 333, 334, 335, 336, 338, 340, 341], "variou": [1, 3, 13, 14, 16, 17, 181, 185, 238, 239, 240, 245, 246, 247, 248, 249, 251, 252, 253, 255, 256, 257, 258, 260, 261, 266, 318, 319, 329, 330, 331, 335, 341], "machin": [1, 7, 18, 19, 20, 32, 54, 85, 335], "One": [1, 2, 4, 8, 31, 33, 45, 110, 136, 150, 199, 217, 228, 232, 259, 263, 291, 329, 330, 338, 341], "wonder": 1, "why": [1, 3, 336, 341], "parallelenv": [1, 2, 3, 13, 14, 16, 17, 20, 77, 81, 92, 96, 97, 101, 317, 322, 329, 330, 331, 334, 340, 341], "instead": [1, 4, 7, 8, 11, 27, 32, 77, 81, 95, 101, 122, 144, 148, 166, 167, 168, 169, 170, 171, 172, 173, 175, 177, 178, 179, 180, 181, 183, 184, 185, 186, 187, 192, 193, 196, 197, 198, 200, 203, 204, 206, 211, 217, 218, 220, 221, 222, 224, 227, 232, 235, 238, 240, 242, 245, 246, 251, 252, 255, 256, 257, 258, 266, 268, 272, 276, 320, 324, 336, 338, 341], "In": [1, 3, 4, 5, 7, 8, 10, 11, 17, 21, 22, 32, 52, 53, 55, 56, 77, 81, 95, 96, 97, 101, 114, 115, 116, 118, 132, 136, 140, 143, 144, 146, 147, 148, 150, 152, 153, 179, 182, 183, 187, 192, 204, 208, 209, 228, 231, 237, 238, 239, 241, 242, 244, 245, 251, 253, 255, 256, 257, 258, 260, 306, 318, 319, 320, 324, 325, 329, 330, 331, 332, 334, 335, 336, 337, 338, 341], "lower": [1, 2, 3, 17, 21, 25, 113, 154, 203, 204, 232, 331, 336], "io": [1, 92, 183, 184], "footprint": [1, 2, 338], "need": [1, 2, 3, 4, 7, 8, 10, 11, 18, 19, 20, 21, 32, 34, 36, 68, 77, 81, 85, 90, 95, 96, 97, 101, 110, 113, 122, 132, 134, 145, 148, 152, 154, 166, 167, 168, 169, 170, 171, 172, 173, 175, 177, 178, 179, 180, 181, 183, 184, 185, 186, 187, 192, 193, 194, 196, 197, 198, 200, 203, 204, 206, 211, 217, 218, 220, 221, 222, 224, 226, 227, 228, 232, 235, 237, 245, 256, 257, 258, 260, 267, 272, 287, 304, 320, 324, 325, 329, 330, 331, 332, 335, 336, 338, 340, 341], "commun": [1, 2, 3, 323, 331, 341], "yet": [1, 337], "spec": [1, 2, 3, 15, 21, 24, 25, 26, 27, 28, 29, 30, 31, 33, 44, 46, 47, 48, 49, 50, 52, 77, 79, 81, 91, 95, 101, 103, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 122, 124, 125, 126, 128, 130, 132, 134, 135, 137, 138, 139, 140, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 153, 156, 160, 164, 176, 202, 204, 213, 217, 218, 219, 220, 221, 222, 224, 225, 226, 227, 228, 229, 231, 232, 238, 239, 241, 242, 244, 245, 251, 255, 256, 257, 258, 260, 266, 313, 324, 329, 330, 331, 332, 334, 335, 340], "plai": [1, 3, 96, 97, 110, 330, 331, 338, 341], "role": [1, 3, 330, 341], "opposit": 1, "direct": [1, 32, 77, 81, 95, 101, 179, 183, 253, 330], "sinc": [1, 2, 3, 4, 5, 7, 32, 35, 38, 41, 42, 56, 67, 77, 81, 95, 96, 97, 101, 163, 166, 167, 168, 169, 170, 171, 172, 173, 175, 177, 178, 179, 180, 181, 183, 184, 185, 186, 187, 192, 193, 196, 197, 198, 200, 203, 204, 206, 211, 217, 218, 219, 220, 221, 222, 224, 226, 227, 232, 235, 329, 330, 331, 332, 336, 337, 338, 340, 341], "faster": [1, 4, 24, 25, 26, 27, 28, 29, 30, 31, 33, 44, 46, 47, 55, 56, 92, 268, 269, 270, 271, 332, 335], "share": [1, 3, 6, 8, 34, 36, 39, 58, 59, 60, 68, 71, 78, 95, 101, 154, 181, 185, 192, 193, 214, 215, 216, 238, 240, 241, 245, 251, 252, 255, 256, 257, 258, 260, 320, 322, 324, 331, 332, 334, 335, 340, 341], "among": [1, 3, 96, 97, 335], "achiev": [1, 3, 4, 32, 77, 81, 85, 95, 101, 143, 164, 301, 326, 329, 330, 331, 332, 335, 336, 341], "via": [1, 4, 7, 8, 35, 38, 41, 42, 52, 53, 54, 55, 56, 95, 132, 147, 152, 243, 253, 325, 326, 329, 330, 331, 332, 338, 341], "prohibit": [1, 3], "slow": [1, 3, 4, 34, 36, 39], "compar": [1, 3, 300, 325, 329, 331, 335, 338, 341], "gpu": [1, 7, 8, 32, 58, 59, 71, 77, 81, 85, 95, 101, 329, 331, 332, 335, 341], "nativ": [1, 7, 9, 53, 77, 81, 95, 101, 110, 332, 338], "driver": [1, 7], "practic": [1, 3, 4, 5, 8, 182, 208, 209, 237, 323, 329, 330, 331, 332, 335, 337, 341], "mean": [1, 2, 3, 4, 7, 13, 14, 16, 18, 19, 20, 21, 34, 36, 39, 41, 61, 81, 128, 154, 165, 174, 177, 179, 181, 183, 185, 186, 189, 207, 217, 225, 229, 268, 269, 270, 271, 273, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 324, 325, 329, 330, 331, 335, 336, 338, 340, 341], "keyword": [1, 3, 13, 14, 16, 18, 19, 20, 21, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 41, 42, 44, 46, 47, 53, 55, 56, 57, 66, 67, 77, 81, 95, 101, 113, 114, 132, 140, 144, 146, 147, 148, 150, 152, 181, 185, 190, 191, 213, 217, 218, 219, 221, 222, 224, 225, 226, 228, 229, 232, 238, 239, 240, 241, 242, 243, 244, 245, 250, 251, 252, 254, 255, 256, 257, 258, 260, 262, 266, 268, 269, 270, 271, 272, 276, 317, 329, 330, 331, 335, 338, 341], "build": [1, 3, 7, 23, 26, 32, 35, 38, 41, 42, 52, 53, 54, 55, 56, 77, 81, 95, 98, 101, 136, 154, 165, 181, 185, 189, 223, 225, 229, 304, 311, 312, 314, 315, 324, 326, 331, 332, 335, 336, 337, 340, 341], "given": [1, 2, 3, 13, 14, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 35, 38, 40, 41, 42, 44, 46, 47, 48, 49, 52, 53, 54, 55, 56, 66, 67, 77, 81, 91, 95, 101, 114, 117, 128, 132, 144, 147, 148, 150, 152, 163, 165, 176, 177, 179, 183, 189, 202, 206, 213, 219, 220, 221, 224, 227, 228, 229, 230, 231, 233, 237, 241, 242, 244, 267, 268, 269, 270, 271, 272, 274, 296, 300, 316, 324, 326, 329, 330, 331, 335, 336, 341], "mani": [1, 3, 4, 38, 77, 238, 240, 245, 252, 255, 256, 260, 324, 329, 330, 331, 335, 336, 338, 341], "eg": [1, 2, 3, 11, 34, 36, 39, 58, 59, 60, 68, 71, 77, 81, 85, 95, 101, 117, 142, 148, 192, 218], "gymnasium": [1, 3, 5, 11, 77, 81, 88, 89, 95, 101, 105, 107, 120, 140, 142, 153, 330, 331, 336, 340], "other": [1, 2, 3, 4, 7, 8, 21, 22, 32, 35, 38, 41, 42, 45, 52, 53, 55, 56, 58, 59, 60, 65, 66, 67, 68, 71, 77, 81, 91, 95, 101, 113, 116, 117, 140, 146, 150, 154, 179, 181, 185, 195, 196, 218, 220, 221, 227, 229, 238, 239, 240, 245, 246, 247, 248, 249, 251, 252, 253, 255, 256, 257, 258, 260, 266, 268, 301, 313, 318, 319, 324, 326, 329, 330, 331, 332, 335, 336, 337, 338, 340, 341], "warn": [1, 3, 217, 221, 222, 224, 330], "quickli": [1, 3, 330, 335, 341], "becom": [1, 3, 4, 21, 179, 183, 335, 341], "quit": [1, 3, 324, 329, 330, 331, 335, 341], "annoi": [1, 3], "By": [1, 2, 3, 33, 77, 81, 95, 96, 97, 101, 103, 211, 229, 253, 300, 320, 329, 337, 338, 341], "filter": [1, 3, 4, 45, 238, 239, 241, 245, 251, 255, 256, 258], "out": [1, 3, 4, 5, 9, 21, 32, 34, 36, 39, 45, 52, 77, 81, 95, 96, 97, 101, 144, 156, 179, 180, 183, 190, 191, 194, 195, 213, 218, 219, 220, 224, 225, 226, 227, 228, 229, 264, 265, 326, 329, 330, 331, 332, 335, 336, 338, 340, 341], "If": [1, 3, 4, 5, 6, 7, 8, 10, 11, 13, 14, 16, 17, 18, 19, 20, 21, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 41, 42, 44, 45, 46, 47, 52, 53, 54, 55, 56, 57, 58, 59, 65, 66, 67, 69, 71, 77, 78, 81, 85, 91, 95, 96, 97, 101, 103, 105, 110, 111, 112, 113, 115, 116, 117, 118, 120, 122, 126, 127, 128, 132, 133, 135, 136, 139, 140, 143, 144, 145, 146, 147, 148, 150, 152, 154, 163, 164, 166, 167, 179, 180, 181, 183, 184, 185, 186, 187, 190, 191, 192, 193, 211, 213, 217, 218, 219, 220, 221, 222, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 235, 237, 238, 239, 240, 241, 242, 244, 245, 246, 247, 248, 251, 252, 253, 255, 256, 257, 258, 260, 266, 267, 268, 269, 270, 271, 272, 282, 283, 284, 285, 291, 299, 301, 304, 306, 308, 313, 316, 320, 323, 329, 330, 331, 332, 334, 335, 336, 338, 340, 341], "still": [1, 2, 3, 9, 217, 252, 253, 329, 330, 332, 334, 336, 338, 341], "wish": [1, 3, 107, 338], "see": [1, 3, 6, 7, 8, 9, 13, 14, 16, 17, 18, 19, 20, 21, 32, 35, 38, 41, 42, 43, 52, 53, 54, 55, 56, 57, 66, 77, 81, 84, 92, 95, 96, 97, 101, 103, 114, 132, 144, 146, 147, 148, 150, 152, 155, 166, 167, 179, 182, 183, 187, 193, 194, 201, 209, 210, 214, 216, 228, 229, 301, 329, 330, 331, 332, 335, 336, 338, 341], "displai": [1, 3, 7, 304, 326, 329, 330, 335, 336], "filter_warnings_subprocess": [1, 3], "fals": [1, 3, 13, 14, 16, 17, 18, 19, 20, 21, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 52, 53, 54, 55, 56, 57, 58, 59, 65, 66, 67, 71, 74, 75, 77, 78, 81, 87, 90, 91, 94, 95, 96, 97, 99, 100, 101, 102, 103, 108, 110, 111, 114, 115, 118, 119, 120, 122, 125, 126, 127, 128, 130, 132, 133, 134, 136, 138, 140, 142, 144, 146, 147, 148, 149, 150, 152, 154, 156, 163, 164, 165, 166, 167, 169, 176, 179, 180, 181, 182, 183, 184, 185, 187, 189, 190, 191, 192, 193, 201, 202, 208, 209, 210, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 224, 225, 226, 227, 228, 229, 231, 232, 233, 238, 239, 240, 241, 242, 244, 245, 247, 248, 249, 251, 252, 253, 254, 255, 256, 257, 258, 260, 263, 266, 268, 269, 270, 271, 277, 278, 279, 280, 282, 283, 284, 285, 297, 298, 300, 301, 302, 304, 313, 320, 324, 326, 329, 330, 331, 332, 334, 335, 336, 337, 338, 340, 341], "central": [2, 192, 329, 330, 335, 338], "part": [2, 4, 8, 32, 40, 53, 55, 56, 77, 81, 95, 101, 128, 136, 139, 181, 185, 233, 295, 320, 329, 331, 332, 336, 341], "algorithm": [2, 3, 8, 9, 13, 14, 91, 123, 238, 255, 256, 257, 258, 295, 309, 322, 325, 326, 329, 330, 331, 332, 335, 337, 338, 340], "implement": [2, 3, 9, 11, 16, 32, 68, 77, 81, 92, 95, 101, 114, 115, 116, 120, 126, 134, 140, 142, 147, 154, 166, 179, 180, 181, 182, 183, 184, 185, 207, 208, 209, 238, 239, 243, 244, 251, 253, 254, 255, 258, 313, 324, 326, 329, 330, 331, 332, 336, 340], "wide": [2, 3, 5], "we": [2, 3, 5, 7, 9, 11, 26, 32, 34, 36, 39, 40, 42, 52, 56, 65, 67, 77, 78, 81, 85, 95, 101, 110, 126, 132, 134, 150, 153, 154, 165, 185, 186, 192, 193, 238, 239, 241, 242, 244, 245, 246, 247, 251, 253, 255, 256, 257, 258, 260, 266, 323, 324, 325, 326, 329, 330, 331, 332, 334, 335, 336, 337, 338, 340, 341], "give": [2, 3, 7, 41, 77, 81, 91, 95, 101, 110, 323, 325, 329, 330, 335, 336, 337, 340], "abil": [2, 253, 336, 338], "veri": [2, 3, 330, 336, 338, 340, 341], "influenti": 2, "sampl": [2, 4, 8, 9, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 38, 40, 41, 42, 44, 46, 47, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 65, 66, 67, 69, 71, 77, 81, 91, 94, 95, 101, 110, 133, 136, 157, 158, 161, 162, 165, 174, 182, 189, 190, 191, 199, 200, 203, 208, 209, 213, 217, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 238, 239, 240, 241, 242, 244, 252, 254, 255, 260, 295, 301, 304, 307, 324, 329, 330, 331, 332, 335, 337, 340, 341], "latenc": 2, "especi": [2, 3, 7, 8, 111], "larger": [2, 4, 251], "volum": 2, "lazymemmapstorag": [2, 35, 38, 41, 42, 52, 53, 54, 55, 56, 66, 67, 110, 322, 329, 330, 332, 337, 338], "advis": [2, 341], "due": [2, 3, 5, 337, 338, 341], "serialis": [2, 34, 36, 39], "memmaptensor": 2, "well": [2, 3, 8, 17, 21, 32, 35, 37, 38, 41, 42, 68, 77, 81, 95, 101, 183, 203, 204, 253, 272, 329, 330, 332, 337, 338, 340, 341], "specifi": [2, 11, 13, 14, 21, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 41, 42, 44, 46, 47, 52, 53, 54, 55, 56, 77, 81, 95, 96, 97, 101, 103, 115, 116, 118, 139, 141, 143, 149, 165, 183, 228, 229, 253, 259, 324, 329, 331, 332], "file": [2, 6, 7, 8, 34, 36, 39, 52, 53, 55, 56, 286, 326, 328, 330, 338, 339], "locat": [2, 7, 34, 36, 39, 45, 56, 77, 81, 95, 101, 119, 128, 138, 182, 196, 208, 209, 295, 296, 297, 298, 299, 300, 301, 302, 303, 305, 306, 329, 330, 331, 335, 338], "improv": [2, 4, 123, 238, 325, 335, 338], "failur": [2, 4], "recoveri": 2, "liststorag": [2, 35, 38, 41, 42, 322, 338], "were": [2, 7, 95, 101, 331, 338], "found": [2, 3, 6, 7, 10, 21, 26, 32, 34, 36, 39, 45, 52, 53, 55, 56, 66, 67, 77, 81, 85, 95, 101, 108, 110, 136, 139, 145, 154, 164, 221, 222, 225, 229, 252, 253, 255, 329, 330, 332], "rough": 2, "benchmark": [2, 3, 9], "http": [2, 5, 6, 7, 10, 18, 19, 20, 35, 43, 54, 55, 56, 61, 85, 92, 96, 97, 98, 110, 132, 150, 168, 169, 170, 171, 172, 173, 176, 177, 178, 183, 189, 190, 191, 195, 197, 198, 200, 201, 203, 204, 210, 220, 224, 238, 239, 242, 243, 244, 246, 247, 248, 249, 250, 251, 254, 255, 256, 257, 258, 259, 268, 273, 281, 313, 337, 340], "github": [2, 5, 6, 7, 10, 18, 19, 20, 53, 96, 97, 98, 150, 340], "com": [2, 5, 6, 7, 10, 18, 19, 20, 55, 85, 96, 97, 98, 337, 340], "tree": [2, 34, 36, 39, 77, 81, 95, 101], "type": [2, 3, 14, 18, 19, 20, 21, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 56, 57, 77, 81, 90, 91, 95, 96, 97, 101, 114, 115, 116, 119, 120, 126, 132, 134, 140, 142, 144, 147, 148, 150, 152, 154, 158, 162, 166, 167, 187, 192, 193, 195, 201, 210, 217, 219, 225, 228, 229, 238, 239, 241, 242, 244, 245, 246, 247, 251, 253, 255, 256, 257, 258, 260, 262, 266, 274, 313, 318, 324, 329, 330, 331, 335, 336, 338, 341], "1x": 2, "lazytensorstorag": [2, 41, 42, 69, 136, 322, 331, 335, 338], "83x": 2, "3": [2, 3, 6, 7, 10, 11, 13, 14, 15, 16, 17, 21, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 38, 39, 41, 42, 52, 53, 54, 55, 56, 66, 67, 77, 81, 84, 90, 92, 94, 95, 96, 97, 99, 100, 101, 108, 110, 114, 117, 119, 120, 126, 128, 130, 132, 134, 136, 139, 140, 142, 143, 144, 146, 147, 148, 150, 152, 160, 165, 166, 167, 169, 170, 173, 176, 178, 179, 180, 181, 183, 184, 185, 186, 187, 189, 192, 193, 196, 199, 201, 211, 213, 214, 215, 216, 219, 220, 225, 227, 228, 231, 232, 233, 238, 239, 241, 242, 244, 245, 246, 247, 248, 251, 253, 255, 256, 257, 258, 260, 266, 268, 269, 270, 271, 274, 277, 278, 279, 280, 282, 283, 284, 285, 287, 303, 324, 326, 329, 330, 331, 332, 335, 336, 337, 338, 340, 341], "44x": 2, "between": [2, 3, 4, 5, 13, 14, 16, 17, 21, 32, 40, 65, 67, 77, 81, 95, 101, 117, 127, 137, 148, 156, 166, 167, 179, 181, 185, 187, 192, 193, 220, 225, 229, 238, 240, 241, 244, 245, 248, 249, 251, 252, 253, 255, 256, 257, 258, 260, 263, 268, 300, 304, 325, 329, 330, 332, 335, 336, 341], "long": [2, 3, 13, 14, 16, 17, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 36, 37, 39, 44, 46, 47, 117, 183, 184, 332, 338], "sharabl": 2, "featur": [2, 3, 4, 13, 14, 16, 17, 18, 19, 20, 21, 33, 45, 53, 66, 67, 77, 81, 90, 95, 96, 97, 99, 100, 101, 110, 122, 126, 130, 144, 145, 149, 154, 166, 167, 177, 178, 179, 180, 181, 183, 184, 185, 187, 194, 195, 229, 268, 269, 270, 271, 272, 273, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 320, 324, 329, 330, 331, 332, 336, 338, 341], "allow": [2, 3, 13, 14, 16, 17, 18, 19, 20, 21, 26, 28, 29, 32, 33, 66, 67, 77, 81, 95, 101, 134, 163, 187, 238, 239, 241, 242, 244, 245, 246, 247, 251, 253, 255, 256, 257, 258, 260, 261, 263, 266, 324, 326, 329, 331, 332, 335, 336, 338, 341], "popul": [2, 3, 35, 38, 41, 42, 52, 53, 54, 55, 56, 125, 144, 329, 331, 332, 336, 338], "collabor": 2, "rather": [2, 4, 134, 329, 330, 331, 335], "incur": 2, "some": [2, 3, 4, 7, 8, 9, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 38, 44, 45, 46, 47, 52, 53, 55, 56, 58, 59, 69, 71, 77, 81, 95, 96, 97, 101, 103, 132, 148, 150, 156, 169, 181, 185, 206, 229, 230, 231, 295, 307, 324, 326, 329, 330, 331, 332, 335, 336, 338, 340, 341], "transmiss": 2, "overhead": [2, 95, 101], "includ": [2, 3, 4, 7, 9, 21, 32, 56, 58, 59, 60, 68, 71, 77, 81, 91, 95, 101, 143, 148, 154, 253, 258, 307, 324, 326, 329, 330, 331, 332, 335, 336, 338, 341], "ani": [2, 3, 5, 8, 26, 28, 32, 34, 35, 36, 38, 39, 41, 42, 52, 53, 54, 55, 56, 58, 59, 60, 63, 65, 67, 68, 69, 70, 71, 72, 77, 78, 81, 95, 96, 97, 101, 103, 108, 122, 132, 133, 136, 148, 150, 154, 156, 164, 166, 167, 173, 187, 195, 218, 228, 229, 230, 231, 238, 239, 241, 242, 244, 245, 251, 253, 255, 256, 257, 258, 260, 268, 292, 304, 323, 329, 330, 331, 335, 336, 338, 340, 341], "subclass": [2, 3, 77, 81, 95, 101, 147, 153, 156, 166, 167, 168, 169, 170, 171, 172, 173, 175, 177, 178, 179, 180, 181, 183, 184, 185, 186, 187, 192, 193, 196, 197, 198, 200, 203, 204, 206, 211, 217, 218, 220, 221, 222, 224, 227, 228, 229, 230, 232, 235, 253, 255, 330, 332, 336, 338], "tensorstorag": [2, 322], "instanti": [2, 3, 21, 34, 36, 39, 85, 147, 193, 329, 330, 335, 336, 338, 341], "content": [2, 8, 13, 14, 16, 26, 28, 34, 35, 36, 38, 39, 41, 42, 65, 92, 166, 167, 187, 192, 193, 225, 253, 331, 336, 340], "map": [2, 3, 8, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 41, 42, 44, 45, 46, 47, 52, 53, 54, 55, 56, 57, 58, 77, 81, 90, 95, 96, 97, 99, 100, 101, 103, 104, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 122, 124, 125, 126, 128, 130, 134, 135, 137, 138, 139, 140, 142, 143, 144, 145, 146, 147, 149, 150, 151, 153, 154, 160, 176, 196, 213, 214, 215, 216, 219, 225, 226, 228, 229, 231, 232, 233, 234, 258, 266, 300, 322, 324, 325, 329, 330, 331, 332, 337], "tensor": [2, 3, 8, 13, 14, 16, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 52, 53, 54, 55, 56, 57, 58, 59, 61, 63, 66, 67, 69, 70, 71, 72, 74, 77, 78, 81, 87, 90, 91, 94, 95, 96, 97, 99, 100, 101, 102, 103, 108, 110, 111, 114, 115, 117, 118, 119, 120, 122, 125, 128, 130, 132, 133, 134, 136, 138, 139, 140, 142, 143, 144, 145, 146, 147, 148, 149, 150, 152, 154, 160, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 176, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 196, 199, 200, 201, 202, 205, 206, 207, 208, 209, 210, 213, 214, 215, 216, 218, 219, 220, 221, 222, 224, 225, 226, 227, 228, 229, 231, 232, 233, 235, 236, 238, 239, 241, 242, 244, 245, 248, 249, 251, 253, 255, 256, 257, 258, 260, 263, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 287, 313, 324, 326, 329, 330, 331, 332, 334, 335, 336, 337, 338, 340, 341], "writer": [2, 38, 42, 52, 53, 54, 55, 56, 63, 69, 70, 322, 331], "tensordictroundrobinwrit": [2, 322], "current": [2, 3, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 40, 44, 46, 47, 67, 77, 81, 83, 92, 95, 101, 110, 133, 143, 144, 145, 147, 148, 157, 158, 163, 177, 186, 204, 224, 246, 258, 290, 326, 329, 330, 331, 332, 335, 336, 340, 341], "goe": [2, 4, 96, 97, 329, 331, 335, 341], "sampler": [2, 35, 38, 41, 42, 52, 53, 54, 55, 56, 58, 59, 60, 61, 62, 65, 66, 67, 68, 69, 71, 133, 242, 246, 266, 322, 329, 331, 335, 338], "prioritizedsampl": [2, 35, 38, 41, 42, 52, 53, 54, 55, 56, 242, 246, 266, 322, 329, 338], "extend": [2, 8, 24, 25, 26, 27, 28, 29, 30, 31, 33, 35, 38, 41, 42, 44, 46, 47, 52, 53, 54, 55, 56, 63, 66, 67, 69, 70, 72, 136, 301, 326, 329, 330, 331, 332, 335, 337, 338, 340], "access": [2, 3, 7, 8, 32, 35, 54, 77, 81, 95, 101, 132, 150, 320, 323, 329, 335, 336, 338], "show": [2, 32, 77, 81, 95, 101, 193, 324, 329, 331, 332, 335, 336, 338, 340], "import": [2, 3, 4, 6, 10, 11, 13, 14, 15, 16, 17, 21, 22, 35, 37, 38, 40, 41, 42, 43, 45, 52, 53, 54, 55, 56, 57, 58, 59, 61, 66, 67, 69, 71, 77, 78, 81, 89, 91, 95, 96, 97, 99, 100, 101, 104, 105, 107, 108, 110, 113, 119, 120, 125, 126, 128, 130, 132, 134, 135, 136, 139, 140, 142, 143, 144, 145, 147, 152, 154, 160, 163, 164, 165, 176, 179, 180, 181, 183, 184, 185, 187, 189, 192, 193, 196, 201, 202, 210, 213, 214, 215, 216, 218, 219, 220, 221, 222, 224, 225, 226, 227, 228, 231, 232, 233, 238, 239, 240, 241, 242, 244, 245, 246, 247, 251, 253, 255, 256, 257, 258, 260, 266, 268, 269, 270, 271, 297, 300, 313, 316, 324, 325, 330, 331, 332, 334, 335, 336, 337, 338, 340, 341], "tensordictreplaybuff": [2, 35, 38, 41, 52, 53, 54, 55, 56, 66, 67, 69, 110, 301, 316, 322, 329, 330, 332, 338], "mp": [2, 18, 19, 20, 78, 154], "def": [2, 3, 11, 22, 32, 77, 78, 81, 91, 95, 101, 107, 108, 115, 118, 165, 176, 179, 180, 183, 184, 189, 225, 233, 239, 241, 245, 251, 253, 256, 258, 260, 326, 329, 330, 334, 335, 336, 340, 341], "rb": [2, 35, 38, 41, 42, 52, 53, 54, 55, 56, 66, 67, 69, 110, 136, 330, 332, 335, 337, 338, 340], "updat": [2, 3, 4, 8, 12, 13, 14, 16, 17, 18, 19, 20, 21, 32, 34, 35, 36, 39, 40, 41, 61, 77, 81, 91, 95, 96, 97, 101, 108, 115, 117, 118, 142, 143, 148, 151, 154, 164, 165, 179, 181, 185, 189, 217, 221, 222, 224, 225, 226, 227, 228, 229, 238, 239, 241, 242, 244, 245, 246, 247, 250, 251, 253, 255, 256, 257, 258, 259, 260, 266, 268, 269, 270, 271, 272, 300, 304, 306, 309, 310, 315, 316, 326, 330, 331, 332, 335, 336, 338, 340, 341], "td": [2, 3, 15, 26, 34, 35, 36, 38, 39, 41, 42, 52, 53, 54, 55, 56, 69, 73, 74, 75, 76, 80, 82, 86, 87, 88, 89, 108, 111, 115, 116, 117, 118, 125, 126, 128, 136, 139, 144, 146, 148, 154, 163, 165, 176, 181, 185, 188, 189, 201, 202, 210, 213, 214, 215, 216, 218, 219, 221, 222, 224, 225, 226, 228, 231, 233, 266, 269, 270, 271, 275, 276, 277, 278, 279, 280, 282, 283, 284, 285, 286, 295, 303, 313, 324, 325, 329, 332, 335, 336, 340, 341], "10": [2, 7, 22, 26, 35, 38, 40, 41, 42, 43, 45, 58, 59, 66, 67, 69, 71, 78, 91, 96, 97, 99, 100, 102, 103, 108, 110, 143, 145, 146, 165, 168, 173, 179, 180, 183, 184, 186, 189, 200, 211, 221, 222, 224, 225, 232, 239, 242, 244, 245, 255, 256, 257, 260, 266, 268, 269, 270, 271, 274, 295, 326, 328, 329, 330, 331, 332, 335, 336, 338, 339, 340, 341], "__name__": [2, 22, 78, 330], "__main__": [2, 22, 78], "21": [2, 55, 67, 96, 97, 329, 330, 331, 334, 336], "zero": [2, 3, 4, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 39, 41, 42, 44, 45, 46, 47, 52, 59, 66, 67, 71, 77, 81, 95, 101, 111, 115, 117, 118, 128, 136, 160, 163, 165, 179, 180, 181, 183, 184, 185, 186, 190, 191, 193, 201, 210, 221, 222, 224, 227, 235, 238, 239, 241, 242, 244, 245, 251, 255, 256, 257, 258, 260, 266, 268, 269, 270, 271, 274, 332, 340], "proc": 2, "target": [2, 4, 8, 21, 32, 77, 78, 81, 95, 101, 143, 147, 228, 229, 238, 239, 240, 241, 242, 244, 245, 246, 249, 250, 252, 253, 254, 255, 256, 257, 258, 259, 260, 266, 267, 268, 269, 270, 271, 272, 307, 315, 316, 325, 326, 332, 336], "arg": [2, 12, 14, 26, 28, 32, 58, 59, 71, 73, 74, 75, 76, 77, 78, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 106, 108, 114, 132, 141, 144, 147, 148, 149, 151, 152, 165, 166, 167, 175, 181, 185, 187, 188, 189, 211, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 251, 252, 253, 254, 255, 256, 257, 258, 260, 266, 268, 269, 270, 271, 272, 294, 297, 301, 304, 320, 330], "start": [2, 3, 4, 5, 13, 21, 45, 56, 66, 67, 78, 90, 163, 299, 329, 330, 335, 336, 338, 341], "join": [2, 78, 322, 330, 331], "now": [2, 3, 7, 35, 110, 193, 329, 330, 331, 332, 334, 335, 337, 338, 341], "length": [2, 17, 20, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 36, 37, 40, 43, 44, 45, 46, 47, 57, 66, 67, 77, 81, 95, 101, 133, 154, 165, 166, 167, 169, 171, 173, 175, 179, 183, 187, 189, 192, 193, 213, 228, 233, 295, 301, 329, 331, 332, 336, 338, 341], "20": [2, 45, 55, 66, 67, 69, 77, 81, 85, 95, 101, 143, 179, 180, 183, 184, 218, 295, 329, 330, 331, 332, 335, 336, 340, 341], "assert": [2, 3, 6, 16, 24, 25, 26, 27, 28, 29, 30, 31, 33, 35, 38, 41, 42, 44, 46, 47, 52, 53, 54, 55, 56, 81, 84, 107, 110, 113, 115, 118, 126, 134, 154, 156, 160, 193, 196, 211, 268, 269, 270, 271, 295, 303, 334, 338, 341], "len": [2, 35, 38, 41, 42, 52, 53, 54, 55, 56, 58, 59, 71, 130, 166, 167, 187, 193, 329, 336, 337, 338, 340], "_data": [2, 336], "0": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 21, 22, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 49, 52, 53, 54, 55, 56, 57, 58, 59, 61, 66, 67, 71, 74, 77, 81, 84, 87, 91, 95, 98, 99, 100, 101, 108, 109, 110, 111, 113, 114, 116, 117, 126, 127, 128, 132, 136, 139, 143, 144, 145, 146, 147, 148, 150, 152, 153, 154, 156, 165, 166, 167, 169, 170, 172, 173, 177, 179, 181, 182, 183, 184, 185, 187, 189, 191, 192, 193, 194, 195, 196, 199, 203, 204, 207, 208, 209, 211, 213, 217, 218, 220, 221, 222, 224, 227, 228, 231, 232, 235, 238, 239, 240, 241, 242, 244, 245, 246, 247, 248, 249, 251, 252, 253, 254, 255, 256, 257, 258, 260, 261, 262, 266, 267, 268, 269, 270, 271, 274, 275, 276, 295, 302, 316, 320, 325, 326, 328, 329, 330, 331, 332, 334, 335, 336, 337, 338, 339, 340, 341], "too": [2, 7, 13, 14, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 36, 37, 39, 40, 44, 46, 47, 95, 101, 127, 144, 182, 208, 209, 238, 239, 240, 241, 242, 244, 245, 246, 247, 248, 249, 251, 252, 253, 255, 256, 257, 258, 260, 266, 268, 269, 270, 271, 330, 331, 336, 338, 341], "difficult": [2, 4], "element": [2, 13, 14, 16, 18, 19, 20, 21, 30, 31, 33, 35, 38, 41, 42, 52, 53, 54, 55, 56, 58, 59, 60, 61, 67, 69, 71, 94, 110, 133, 143, 166, 167, 179, 180, 183, 213, 217, 219, 228, 229, 233, 295, 329, 331, 338, 341], "pai": [2, 8, 329, 332], "attent": [2, 8, 329, 332, 341], "alwai": [2, 3, 20, 26, 28, 32, 57, 77, 81, 95, 101, 126, 127, 246, 253, 324, 325, 330, 331, 332, 335, 336, 338], "lead": [2, 3, 4, 8, 10, 11, 26, 28, 32, 34, 35, 36, 38, 39, 41, 42, 52, 65, 144, 182, 201, 208, 209, 329, 332, 335, 336, 338, 340], "dimens": [2, 3, 16, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 39, 40, 44, 45, 46, 47, 52, 53, 55, 56, 58, 59, 66, 67, 69, 71, 77, 81, 95, 101, 103, 110, 111, 122, 128, 130, 133, 139, 141, 146, 149, 154, 166, 167, 168, 173, 181, 183, 185, 187, 190, 191, 192, 194, 195, 200, 201, 205, 206, 207, 208, 211, 219, 238, 239, 240, 245, 246, 247, 248, 249, 251, 252, 253, 255, 256, 257, 258, 260, 266, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 320, 324, 329, 330, 331, 332, 335, 336, 338], "word": [2, 3, 40, 52, 53, 55, 56, 253, 329, 336, 341], "creat": [2, 3, 4, 5, 6, 7, 10, 13, 14, 16, 17, 18, 19, 20, 21, 26, 28, 32, 34, 35, 36, 38, 39, 41, 42, 45, 56, 57, 77, 78, 81, 85, 92, 95, 96, 101, 110, 132, 147, 148, 150, 153, 154, 160, 163, 166, 167, 169, 170, 171, 172, 173, 178, 181, 185, 187, 188, 192, 193, 218, 229, 242, 246, 256, 258, 266, 287, 301, 308, 309, 310, 316, 318, 319, 324, 329, 330, 331, 332, 335, 336, 337, 338, 340, 341], "1m": [2, 307, 329, 331, 332, 337], "multidimension": [2, 41, 61, 338], "doe": [2, 3, 18, 34, 35, 36, 39, 41, 45, 52, 61, 68, 173, 179, 180, 181, 183, 184, 185, 194, 211, 218, 230, 231, 238, 240, 246, 252, 255, 267, 304, 324, 326, 329, 330, 331, 332, 336, 338, 341], "howev": [2, 3, 5, 7, 32, 77, 81, 95, 101, 110, 139, 143, 148, 258, 324, 329, 330, 331, 332, 336, 338, 341], "episod": [2, 52, 55, 56, 66, 67, 81, 136, 139, 143, 165, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 330, 335], "flatten": [2, 34, 36, 39, 122, 301, 332, 335], "capac": [2, 331], "desir": [2, 3, 32, 77, 81, 95, 101, 114, 128, 130, 132, 133, 144, 147, 148, 150, 152, 161, 162, 166, 167, 187, 193, 213, 219, 220, 225, 226, 227, 228, 229, 324, 329, 335, 336], "diversifi": 2, "make": [2, 3, 4, 7, 32, 34, 36, 39, 40, 52, 53, 54, 55, 56, 68, 77, 81, 82, 85, 87, 89, 92, 95, 101, 120, 128, 132, 133, 136, 142, 150, 156, 179, 180, 183, 184, 192, 193, 194, 219, 229, 255, 268, 269, 270, 271, 301, 310, 320, 324, 325, 329, 330, 331, 332, 334, 335, 336, 337, 338, 340, 341], "offer": [2, 3, 7, 324, 330, 336, 341], "distinct": [2, 3, 334], "accomplish": 2, "slicesampl": [2, 322], "slice": [2, 3, 24, 25, 26, 27, 28, 29, 30, 31, 33, 44, 46, 47, 52, 66, 67], "anoth": [2, 3, 8, 34, 36, 39, 77, 81, 85, 95, 101, 115, 116, 118, 144, 147, 187, 238, 239, 240, 245, 246, 247, 248, 249, 251, 252, 253, 255, 256, 257, 258, 260, 266, 295, 296, 297, 298, 299, 300, 301, 302, 303, 305, 306, 324, 325, 329, 331, 332, 334, 335, 336, 341], "recommend": [2, 4, 7, 34, 36, 39, 85, 335], "__especially__": 2, "offlin": [2, 8, 13, 14, 16, 17, 18, 19, 20, 21, 110, 156, 239, 244, 251, 326, 337, 338, 340], "convent": [2, 3, 103, 325, 329, 332, 335, 336], "requir": [2, 3, 4, 7, 8, 16, 18, 19, 20, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 41, 42, 44, 45, 46, 47, 52, 53, 77, 81, 85, 92, 95, 98, 101, 114, 132, 144, 147, 148, 150, 152, 187, 211, 228, 230, 231, 238, 239, 240, 245, 246, 247, 248, 249, 251, 252, 253, 255, 256, 257, 258, 260, 266, 324, 326, 329, 330, 331, 332, 335, 336, 338, 341], "reshap": [2, 32, 66, 181, 185, 187, 331, 335], "extens": [2, 67, 326, 338], "detail": [2, 3, 5, 6, 7, 32, 77, 81, 95, 96, 97, 101, 146, 148, 176, 179, 183, 220, 238, 246, 255, 323, 330, 334, 338], "independ": [2, 13, 14, 16, 17, 18, 19, 20, 21, 147, 149, 193, 325, 326, 329, 330, 335, 338, 340], "differ": [2, 3, 4, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 39, 40, 44, 45, 46, 47, 52, 77, 81, 90, 95, 96, 97, 101, 110, 117, 128, 134, 148, 149, 176, 179, 180, 181, 183, 184, 185, 187, 189, 192, 193, 202, 251, 255, 263, 268, 269, 270, 274, 275, 276, 300, 304, 306, 318, 319, 324, 325, 326, 329, 330, 331, 334, 335, 336, 337, 338, 341], "congruent": 2, "shape": [2, 3, 13, 14, 16, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 52, 53, 55, 56, 57, 58, 59, 71, 77, 81, 90, 94, 95, 96, 97, 99, 100, 101, 102, 103, 111, 115, 118, 119, 120, 126, 128, 130, 134, 136, 140, 142, 144, 146, 154, 155, 156, 160, 163, 165, 168, 173, 174, 175, 179, 180, 181, 183, 184, 185, 187, 189, 190, 191, 192, 193, 194, 196, 199, 200, 201, 202, 207, 210, 213, 214, 215, 216, 218, 219, 220, 225, 226, 227, 228, 231, 232, 233, 238, 239, 241, 242, 244, 245, 251, 255, 256, 257, 258, 260, 263, 266, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 287, 295, 301, 304, 316, 324, 329, 330, 331, 332, 334, 335, 337, 338, 340, 341], "custom": [2, 3, 5, 32, 77, 81, 95, 101, 150, 192, 193, 232, 246, 255, 261, 320, 324, 329, 330, 331, 332, 335], "name": [2, 3, 6, 7, 11, 16, 32, 34, 36, 39, 45, 52, 54, 56, 57, 75, 77, 81, 90, 92, 95, 96, 97, 98, 101, 103, 104, 117, 120, 134, 139, 140, 142, 148, 150, 153, 164, 181, 185, 219, 226, 238, 239, 240, 245, 246, 247, 248, 249, 251, 252, 253, 255, 256, 257, 258, 260, 266, 272, 289, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 305, 306, 313, 326, 329, 330, 331, 332, 335, 336, 341], "randomcroptensordict": [2, 329], "note": [2, 3, 4, 13, 14, 16, 17, 18, 19, 20, 21, 32, 34, 35, 36, 38, 39, 41, 42, 77, 81, 95, 101, 115, 118, 154, 164, 179, 181, 183, 185, 224, 225, 229, 246, 329, 330, 334, 335, 341], "unlik": [2, 65, 246, 255, 330, 340], "base": [2, 3, 4, 8, 9, 12, 13, 14, 16, 17, 18, 19, 20, 21, 35, 38, 41, 42, 45, 64, 69, 70, 72, 85, 91, 92, 93, 95, 101, 136, 144, 150, 151, 192, 214, 223, 238, 239, 241, 242, 244, 245, 247, 251, 255, 256, 257, 258, 260, 304, 313, 324, 325, 326, 329, 330, 332, 335, 336, 338, 341], "here": [2, 3, 4, 7, 8, 9, 10, 55, 56, 77, 81, 85, 95, 96, 97, 101, 110, 324, 325, 329, 330, 331, 332, 335, 336, 338, 340, 341], "stop": [2, 3, 16, 21, 40, 56, 66, 67, 77, 81, 95, 101, 331, 335, 340, 341], "signal": [2, 3, 17, 52, 53, 55, 56, 66, 67, 81, 110, 119, 142, 145, 164, 325, 329, 331, 335, 338, 341], "isn": [2, 3, 8, 34, 36, 39, 119, 219, 228, 335], "t": [2, 3, 4, 6, 7, 8, 11, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 39, 44, 46, 47, 61, 65, 69, 77, 78, 81, 92, 95, 101, 110, 115, 118, 119, 132, 135, 136, 143, 145, 152, 154, 163, 179, 183, 219, 224, 228, 259, 268, 269, 270, 271, 272, 274, 304, 306, 320, 323, 329, 330, 331, 332, 334, 335, 336, 337, 338, 340, 341], "how": [2, 3, 18, 19, 20, 32, 35, 41, 61, 77, 81, 95, 96, 97, 101, 103, 238, 240, 250, 252, 255, 304, 323, 324, 329, 330, 331, 332, 334, 335, 336, 337, 338, 340, 341], "our": [2, 3, 7, 8, 18, 110, 324, 329, 330, 331, 332, 334, 335, 337, 338, 340], "enjoi": [2, 3], "separ": [2, 4, 8, 13, 14, 17, 18, 20, 21, 23, 132, 152, 239, 241, 244, 245, 256, 258, 260, 329, 330, 335, 338, 341], "save": [2, 8, 32, 34, 35, 36, 38, 39, 41, 42, 52, 53, 54, 55, 56, 77, 81, 95, 101, 153, 286, 304, 326, 335], "disk": [2, 34, 35, 36, 38, 39, 41, 42, 52, 53, 54, 55, 56, 304, 326, 329, 330, 332, 338], "dump": [2, 35, 38, 41, 42, 52, 53, 54, 55, 56, 286], "load": [2, 6, 7, 13, 14, 16, 17, 32, 34, 35, 36, 38, 39, 40, 41, 42, 45, 52, 53, 54, 55, 56, 76, 77, 81, 95, 101, 107, 154, 320, 326, 329, 338], "json": 2, "metadata": [2, 52, 331, 335, 341], "cannot": [2, 3, 4, 7, 22, 26, 27, 28, 31, 33, 66, 67, 77, 81, 85, 95, 101, 115, 118, 133, 139, 226, 330, 331, 332, 335, 336], "anticip": [2, 115, 118], "compli": [2, 24, 25, 26, 27, 28, 29, 30, 31, 33, 44, 46, 47], "structur": [2, 3, 7, 34, 35, 36, 38, 39, 40, 41, 42, 45, 69, 77, 81, 95, 101, 115, 118, 164, 192, 224, 268, 269, 270, 271, 272, 325, 329, 331, 332, 335, 336, 337, 338], "guarante": [2, 32, 34, 36, 39, 58, 59, 60, 68, 71, 77, 81, 95, 101, 154, 340], "back": [2, 24, 25, 26, 27, 28, 29, 30, 31, 33, 35, 44, 46, 47, 52, 153, 213, 219, 220, 225, 226, 227, 228, 229, 331, 335, 336, 338], "exact": [2, 3, 95, 183], "look": [2, 3, 5, 7, 8, 32, 77, 81, 90, 95, 96, 97, 101, 132, 133, 150, 225, 229, 230, 231, 325, 331, 332, 335, 336, 337, 338, 340, 341], "statu": [2, 3], "its": [2, 3, 4, 5, 7, 9, 11, 13, 14, 16, 17, 18, 19, 20, 21, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 39, 41, 44, 46, 47, 49, 77, 81, 91, 95, 96, 97, 101, 104, 110, 119, 126, 142, 143, 147, 148, 153, 154, 166, 167, 190, 191, 192, 193, 217, 219, 225, 226, 229, 232, 238, 239, 240, 245, 246, 247, 248, 249, 251, 252, 253, 254, 255, 256, 257, 258, 260, 266, 304, 316, 326, 329, 330, 331, 332, 335, 336, 337, 338, 341], "prioriti": [2, 4, 35, 41, 42, 58, 59, 60, 61, 68, 71, 241, 242, 244, 245, 246, 251, 256, 258, 260, 266, 326, 329, 330, 338], "max": [2, 23, 33, 36, 41, 45, 57, 61, 117, 145, 207, 208, 209, 218, 224, 239, 240, 245, 254, 256, 258, 329, 331, 332, 335], "heap": 2, "under": [2, 3, 4, 21, 32, 40, 52, 53, 55, 56, 77, 81, 95, 101, 213, 219, 220, 225, 226, 227, 228, 229, 253, 268, 269, 270, 271, 272, 325, 329, 330, 336, 341], "hood": [2, 21, 336], "just": [2, 3, 4, 11, 77, 81, 90, 95, 96, 97, 101, 113, 164, 193, 295, 324, 326, 329, 330, 331, 332, 335, 336, 338, 340, 341], "public": [2, 54, 132, 152], "method": [2, 3, 4, 11, 13, 14, 15, 16, 17, 21, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 45, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 66, 67, 68, 71, 77, 81, 95, 101, 110, 114, 115, 116, 119, 120, 122, 126, 128, 132, 134, 135, 136, 140, 142, 144, 147, 148, 150, 152, 165, 186, 213, 214, 215, 216, 218, 219, 220, 221, 223, 225, 226, 227, 228, 229, 230, 238, 239, 241, 242, 244, 245, 246, 247, 251, 253, 255, 256, 257, 258, 260, 266, 272, 286, 317, 325, 326, 327, 330, 331, 332, 336, 338, 341], "don": [2, 3, 4, 6, 7, 24, 25, 26, 27, 28, 29, 30, 31, 33, 44, 46, 47, 110, 330, 331, 338, 340, 341], "assum": [2, 3, 6, 26, 33, 40, 41, 42, 52, 53, 55, 56, 81, 95, 101, 112, 122, 132, 133, 139, 144, 150, 152, 160, 181, 185, 186, 211, 232, 242, 246, 258, 266, 277, 278, 279, 280, 282, 283, 284, 285, 287, 329, 331, 332, 334, 336], "serializ": 2, "altern": [2, 4, 27, 92, 173, 190, 191, 192, 237, 329, 331, 335], "state_dict": [2, 13, 14, 16, 17, 21, 32, 34, 36, 39, 77, 81, 95, 101, 148, 154, 258, 320, 326, 329, 330, 341], "load_state_dict": [2, 13, 14, 16, 17, 21, 32, 34, 36, 39, 77, 81, 95, 101, 148, 154, 258, 326, 329], "drawback": 2, "struggl": 2, "big": [2, 331, 338, 341], "wrapper": [2, 3, 11, 15, 17, 34, 36, 39, 40, 41, 42, 73, 74, 75, 76, 80, 82, 83, 85, 86, 87, 88, 89, 91, 93, 96, 97, 98, 99, 100, 102, 103, 105, 153, 196, 211, 217, 218, 222, 224, 229, 234, 268, 292, 293, 294, 320, 322, 331, 332, 335, 337, 341], "around": [2, 5, 7, 15, 17, 41, 42, 91, 229, 268, 329, 330, 335, 341], "present": [2, 3, 32, 34, 35, 36, 38, 39, 41, 42, 52, 53, 54, 55, 56, 61, 65, 77, 81, 95, 101, 120, 136, 140, 163, 164, 168, 169, 170, 171, 172, 178, 183, 195, 200, 224, 228, 229, 230, 231, 238, 239, 240, 243, 244, 245, 246, 247, 248, 249, 251, 252, 253, 254, 255, 256, 257, 258, 260, 266, 268, 269, 270, 271, 272, 320, 326, 329, 334, 335, 338, 340], "replaybuff": [2, 41, 42, 72, 110, 133, 136, 242, 246, 266, 314, 316, 322, 331, 335, 337, 338, 340], "promptli": 2, "virtual": [2, 3], "instal": [2, 3, 5, 10, 18, 19, 20, 52, 54, 96, 97, 99, 100, 304, 323, 331, 332, 335, 341], "respons": [2, 3, 8, 304, 341], "d4rl": [2, 52, 53, 55, 56], "clone": [2, 4, 8, 26, 28, 126, 214, 215, 216, 228, 251, 313, 322, 329, 336, 340], "repositori": [2, 7, 53, 54, 56], "latest": [2, 3, 10, 92, 96, 97, 301, 331, 335, 336, 340], "wheel": [2, 331], "publish": 2, "pypi": [2, 340], "openml": [2, 54, 94], "scikit": [2, 54], "panda": [2, 54], "parent": [2, 3, 21, 26, 28, 44, 77, 110, 111, 114, 116, 119, 122, 123, 128, 132, 139, 142, 143, 144, 145, 147, 149, 150, 214, 253, 255, 272, 329, 336, 340, 341], "basic": [2, 91, 324, 331, 341], "properti": [2, 3, 32, 34, 36, 39, 77, 81, 91, 95, 101, 147, 148, 174, 182, 194, 199, 207, 208, 209, 253, 258, 336, 338], "observ": [2, 3, 8, 13, 14, 16, 17, 21, 32, 44, 52, 53, 55, 56, 74, 75, 76, 77, 78, 81, 87, 90, 91, 94, 95, 96, 97, 99, 100, 101, 102, 103, 110, 111, 112, 113, 114, 115, 116, 119, 120, 122, 124, 125, 126, 128, 129, 130, 134, 135, 136, 139, 140, 142, 143, 144, 145, 146, 147, 148, 149, 150, 153, 154, 163, 168, 169, 170, 171, 172, 173, 176, 181, 185, 186, 192, 197, 198, 200, 202, 203, 213, 214, 215, 216, 218, 219, 221, 222, 224, 225, 226, 233, 234, 238, 239, 240, 241, 242, 244, 245, 248, 251, 252, 255, 256, 257, 258, 260, 266, 268, 269, 270, 271, 272, 287, 313, 316, 324, 326, 330, 331, 332, 334, 335, 336, 338, 340, 341], "dtype": [2, 3, 13, 14, 16, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 53, 55, 56, 57, 58, 59, 61, 66, 67, 71, 74, 77, 81, 87, 90, 91, 94, 95, 96, 97, 99, 100, 101, 102, 103, 108, 114, 115, 116, 117, 118, 119, 120, 126, 128, 130, 132, 134, 136, 140, 142, 144, 146, 147, 148, 150, 152, 156, 160, 163, 164, 165, 176, 179, 180, 181, 183, 184, 185, 189, 194, 195, 201, 202, 210, 213, 214, 215, 216, 218, 219, 220, 224, 225, 226, 227, 228, 231, 233, 238, 239, 241, 242, 244, 245, 251, 255, 256, 257, 258, 260, 266, 268, 269, 270, 271, 274, 313, 324, 331, 332, 334, 335, 336, 337, 338, 340, 341], "match": [2, 3, 6, 8, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 44, 46, 47, 52, 53, 54, 55, 56, 77, 78, 81, 95, 101, 109, 110, 111, 112, 113, 114, 115, 116, 117, 119, 120, 122, 124, 125, 126, 128, 130, 134, 135, 137, 138, 139, 140, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 153, 154, 166, 167, 174, 181, 185, 187, 192, 193, 207, 213, 218, 219, 225, 226, 228, 229, 232, 233, 239, 245, 252, 254, 256, 258, 301, 306, 324, 329, 331, 334, 335, 336, 338, 340, 341], "input": [2, 3, 4, 13, 14, 16, 17, 18, 19, 20, 21, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 39, 40, 43, 44, 46, 47, 77, 81, 91, 94, 95, 96, 97, 98, 101, 103, 108, 110, 111, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 125, 126, 128, 130, 131, 132, 133, 134, 136, 139, 140, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 156, 163, 164, 166, 167, 169, 170, 171, 172, 175, 176, 179, 180, 181, 183, 184, 185, 186, 187, 192, 193, 194, 195, 202, 203, 204, 205, 206, 211, 213, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 237, 238, 239, 240, 245, 246, 247, 248, 249, 251, 252, 253, 255, 256, 257, 258, 260, 266, 267, 268, 269, 270, 271, 273, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 298, 302, 307, 316, 324, 325, 326, 329, 330, 331, 332, 335, 336, 340, 341], "output": [2, 3, 4, 13, 14, 16, 17, 32, 35, 38, 41, 42, 52, 53, 54, 55, 56, 66, 67, 77, 81, 91, 94, 95, 96, 97, 98, 101, 103, 110, 113, 114, 115, 116, 118, 120, 126, 128, 132, 134, 139, 140, 142, 145, 147, 150, 152, 153, 156, 164, 166, 167, 168, 169, 170, 173, 175, 176, 177, 179, 180, 181, 183, 184, 185, 186, 187, 192, 193, 196, 202, 211, 213, 214, 217, 218, 219, 220, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 238, 239, 240, 241, 245, 246, 247, 248, 249, 251, 252, 253, 255, 256, 257, 258, 260, 266, 268, 269, 270, 271, 272, 287, 295, 324, 325, 329, 330, 331, 332, 334, 335, 336, 337, 340, 341], "send": [2, 3, 8, 340], "receiv": [2, 3, 32, 40, 77, 81, 95, 101, 147, 187, 274, 325, 329, 331, 334, 336], "spawn": [2, 3, 4, 18, 22, 85, 92, 335], "check_env_spec": [2, 3, 322, 331, 335, 336], "saniti": [2, 3, 7, 156, 331], "utmost": 2, "techniqu": [2, 8, 330, 338], "commonli": [2, 66, 67, 341], "emploi": [2, 195], "realm": 2, "languag": [2, 40], "scarc": 2, "address": [2, 338], "subdomain": 2, "within": [2, 13, 14, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 41, 42, 44, 46, 47, 77, 81, 95, 101, 110, 115, 118, 119, 142, 153, 154, 164, 166, 167, 168, 169, 170, 171, 172, 173, 175, 177, 178, 179, 180, 181, 183, 184, 185, 186, 187, 192, 193, 196, 197, 198, 200, 203, 204, 206, 211, 217, 218, 220, 221, 222, 224, 227, 232, 235, 242, 246, 266, 324, 336, 340], "facilit": [2, 3, 7, 131, 132, 150, 152, 214, 215, 216, 324, 329, 332, 336], "interact": [2, 4, 5, 7, 8, 13, 14, 16, 18, 19, 20, 21, 225, 229, 329, 331, 335, 336, 341], "extern": [2, 3, 115, 118, 341], "consist": [2, 3, 32, 35, 38, 41, 42, 77, 81, 95, 101, 126, 153, 167, 187, 329, 330, 331, 336, 337, 341], "token": [2, 36, 37, 40, 43, 45, 57], "format": [2, 17, 31, 32, 33, 55, 56, 77, 81, 95, 101, 114, 132, 144, 147, 148, 150, 152, 228, 329, 330, 341], "manner": [2, 81, 132, 150, 324, 329, 330, 331, 334, 336, 338], "handl": [3, 21, 32, 77, 81, 95, 101, 153, 154, 185, 187, 304, 318, 319, 329, 330, 331, 335, 338], "dm": [3, 329, 341], "goal": [3, 4, 143, 329, 330, 331, 332, 335, 336], "abl": [3, 90, 96, 97, 329, 331, 332, 334, 335, 336, 338, 340], "experi": [3, 35, 38, 41, 42, 52, 53, 54, 55, 56, 61, 156, 289, 290, 291, 292, 293, 294, 323, 330, 331, 335, 338], "even": [3, 4, 8, 14, 18, 20, 21, 58, 59, 60, 68, 71, 77, 78, 81, 85, 95, 101, 164, 329, 331, 335, 336, 341], "simul": [3, 5, 7, 8, 98, 103, 106, 165, 189, 324, 329, 331, 335], "box": [3, 24, 25, 26, 27, 28, 29, 30, 31, 33, 44, 46, 47], "lib": [3, 5, 6, 7, 9, 10, 13, 14, 16, 17, 21, 22, 77, 78, 81, 95, 96, 97, 99, 100, 101, 110, 113, 119, 125, 126, 128, 130, 134, 136, 139, 144, 147, 153, 154, 313, 316, 329, 330, 331, 332, 334, 335, 337, 338, 340, 341], "hope": 3, "imit": 3, "nn": [3, 13, 14, 16, 17, 21, 32, 40, 77, 81, 91, 95, 101, 114, 117, 119, 126, 132, 144, 147, 148, 150, 152, 165, 166, 167, 169, 170, 171, 172, 175, 176, 177, 178, 179, 180, 181, 183, 184, 185, 187, 189, 191, 192, 193, 196, 201, 202, 210, 213, 214, 215, 216, 218, 219, 221, 222, 224, 225, 226, 228, 229, 230, 231, 233, 238, 239, 241, 242, 244, 245, 246, 247, 251, 253, 255, 256, 257, 258, 260, 266, 268, 269, 270, 271, 313, 316, 324, 325, 329, 330, 331, 332, 334, 335, 336, 337, 340], "typic": [3, 4, 8, 32, 77, 81, 95, 101, 119, 143, 225, 239, 253, 255, 258, 324, 325, 326, 331, 335, 336], "organis": [3, 55, 330], "arbitrari": [3, 33, 95, 101, 324, 329, 330, 336], "nest": [3, 26, 28, 32, 34, 36, 39, 48, 58, 59, 71, 77, 81, 95, 101, 110, 142, 145, 164, 268, 269, 270, 271, 272, 326, 330, 331, 335, 336, 338, 340], "attribut": [3, 4, 32, 34, 36, 39, 45, 77, 81, 95, 101, 119, 132, 150, 181, 185, 229, 238, 239, 241, 242, 244, 245, 246, 247, 251, 253, 255, 256, 257, 258, 260, 266, 329, 332, 336], "batch_siz": [3, 8, 13, 14, 15, 16, 26, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 52, 53, 54, 55, 56, 57, 58, 59, 62, 66, 67, 69, 71, 74, 77, 79, 81, 84, 87, 90, 91, 94, 95, 96, 97, 99, 100, 101, 102, 103, 110, 115, 118, 119, 120, 130, 134, 136, 140, 142, 144, 147, 163, 164, 165, 173, 176, 181, 185, 189, 201, 202, 210, 211, 213, 214, 215, 216, 218, 219, 220, 221, 222, 224, 225, 226, 227, 228, 231, 232, 233, 238, 239, 241, 242, 244, 245, 251, 255, 256, 257, 258, 260, 266, 295, 301, 313, 324, 329, 330, 331, 332, 334, 335, 336, 337, 338, 340, 341], "togeth": [3, 13, 14, 16, 17, 18, 19, 20, 21, 28, 29, 40, 77, 81, 90, 95, 96, 97, 101, 110, 133, 179, 181, 183, 185, 210, 214, 215, 216, 234, 324, 330, 331, 332], "expect": [3, 4, 7, 26, 32, 38, 44, 45, 65, 77, 81, 91, 94, 95, 98, 101, 109, 110, 111, 112, 113, 114, 115, 116, 117, 119, 120, 122, 124, 125, 126, 128, 130, 132, 134, 135, 137, 138, 139, 140, 142, 143, 144, 145, 146, 147, 149, 150, 151, 153, 156, 179, 180, 181, 183, 184, 185, 192, 193, 220, 224, 228, 231, 238, 239, 240, 241, 242, 244, 245, 251, 252, 253, 255, 256, 257, 258, 260, 266, 308, 323, 324, 325, 326, 329, 331, 332, 335, 336, 338, 341], "live": [3, 12, 13, 14, 16, 17, 19, 20, 32, 35, 38, 41, 42, 52, 53, 54, 55, 56, 77, 81, 91, 95, 101, 119], "actual": [3, 4, 7, 17, 52, 53, 55, 56, 77, 81, 95, 101, 153, 307, 325, 329, 331, 335, 336], "do": [3, 4, 7, 56, 81, 103, 133, 153, 154, 163, 193, 194, 215, 268, 326, 329, 330, 331, 332, 334, 335, 336, 338, 340, 341], "retriev": [3, 34, 35, 36, 38, 39, 41, 42, 52, 53, 54, 55, 56, 77, 81, 95, 101, 111, 116, 119, 128, 163, 165, 166, 189, 225, 229, 232, 238, 239, 240, 242, 252, 255, 256, 258, 260, 266, 268, 269, 270, 271, 313, 320, 326, 330, 331, 336, 341], "care": [3, 8, 77, 81, 95, 101, 147, 166, 167, 168, 169, 170, 171, 172, 173, 175, 177, 178, 179, 180, 181, 183, 184, 185, 186, 187, 192, 193, 196, 197, 198, 200, 203, 204, 206, 211, 217, 218, 220, 221, 222, 224, 227, 232, 235, 329, 331, 335, 336, 338], "below": [3, 7, 13, 14, 16, 17, 18, 19, 20, 21, 32, 57, 77, 81, 95, 101, 114, 132, 144, 147, 148, 150, 152, 166, 167, 179, 182, 183, 187, 193, 209, 228, 301, 329, 330, 331, 332, 336], "parametr": [3, 195, 229, 239, 251, 258, 329, 331], "hardwar": 3, "observation_spec": [3, 77, 81, 91, 95, 101, 108, 110, 111, 112, 113, 114, 115, 116, 118, 119, 122, 124, 125, 126, 128, 130, 132, 135, 139, 142, 143, 144, 145, 146, 147, 149, 150, 153, 165, 181, 185, 189, 308, 316, 329, 331, 334, 335, 336, 341], "compositespec": [3, 28, 49, 77, 79, 81, 91, 95, 101, 108, 115, 116, 117, 118, 120, 126, 134, 140, 142, 144, 147, 160, 164, 165, 189, 213, 217, 225, 231, 232, 322, 329, 331, 332, 335, 336, 341], "pair": [3, 32, 34, 36, 39, 52, 77, 81, 95, 101, 136, 144, 181, 214, 225, 229, 253, 268, 269, 270, 271, 272, 324, 325, 329, 330, 331, 334, 336, 341], "state_spec": [3, 77, 81, 91, 95, 101, 108, 165, 189, 331, 336, 341], "empti": [3, 26, 28, 35, 38, 41, 42, 52, 53, 54, 55, 56, 77, 81, 94, 95, 101, 132, 145, 148, 150, 152, 291, 329, 336], "action_spec": [3, 13, 14, 15, 16, 18, 19, 20, 74, 77, 81, 87, 91, 95, 96, 97, 101, 108, 110, 115, 118, 126, 136, 165, 176, 189, 202, 204, 213, 219, 225, 226, 239, 242, 244, 256, 258, 260, 316, 324, 329, 330, 331, 332, 334, 335, 336, 337, 338, 340, 341], "reward_spec": [3, 77, 81, 91, 95, 101, 108, 109, 113, 114, 115, 116, 118, 137, 138, 139, 147, 149, 165, 189, 331, 335, 336, 341], "reward": [3, 13, 14, 16, 32, 34, 39, 40, 44, 45, 53, 55, 56, 57, 69, 74, 77, 81, 87, 91, 94, 95, 99, 100, 101, 102, 103, 108, 109, 113, 114, 115, 116, 118, 119, 120, 126, 130, 134, 136, 137, 138, 139, 140, 142, 143, 147, 148, 149, 151, 152, 154, 160, 163, 165, 181, 189, 218, 234, 238, 239, 241, 242, 244, 245, 248, 251, 253, 255, 256, 257, 258, 260, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 297, 298, 300, 302, 320, 325, 326, 329, 330, 331, 332, 334, 335, 336, 337, 338, 340, 341], "done_spec": [3, 77, 81, 95, 101, 115, 116, 118, 119, 147, 164, 331, 335, 336, 341], "flag": [3, 8, 35, 38, 41, 42, 52, 53, 54, 55, 56, 103, 224, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 324, 335, 336, 337], "section": [3, 4, 179, 183, 330, 335], "termin": [3, 7, 32, 40, 52, 53, 55, 56, 77, 81, 95, 96, 97, 99, 100, 101, 102, 103, 119, 164, 165, 181, 185, 189, 230, 238, 239, 241, 242, 244, 245, 251, 255, 256, 257, 258, 260, 266, 268, 269, 270, 271, 272, 273, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 329, 330, 331, 332, 334, 335, 336, 337, 338, 340, 341], "input_spec": [3, 77, 81, 91, 95, 101, 114, 115, 116, 117, 128, 130, 134, 139, 140, 142, 143, 144, 147, 148, 149, 151, 336], "full_action_spec": [3, 77, 81, 95, 101, 165, 189, 335], "full_state_spec": [3, 77, 81, 95, 101, 165, 189], "lock": [3, 26, 28, 34, 36, 39, 77, 81, 95, 101, 144, 154, 336], "modifi": [3, 7, 8, 26, 28, 32, 45, 77, 81, 95, 101, 114, 122, 126, 132, 144, 147, 148, 150, 152, 218, 224, 228, 307, 313, 329, 330, 331, 335, 336], "directli": [3, 4, 8, 77, 81, 91, 95, 101, 136, 153, 253, 320, 324, 331, 335, 336, 338], "output_spec": [3, 77, 81, 95, 101, 114, 115, 116, 120, 126, 134, 140, 142, 147, 148, 336], "full_observation_spec": [3, 77, 81, 95, 101, 165, 189], "full_reward_spec": [3, 77, 81, 95, 101, 335], "full_done_spec": [3, 77, 81, 95, 101, 164, 335], "importantli": [3, 225, 229], "4": [3, 7, 24, 26, 27, 28, 33, 34, 35, 36, 38, 39, 40, 41, 42, 52, 53, 54, 55, 56, 66, 67, 75, 76, 77, 80, 81, 86, 88, 89, 90, 91, 95, 99, 100, 101, 108, 110, 119, 136, 142, 143, 154, 165, 166, 167, 168, 169, 170, 173, 176, 177, 178, 179, 180, 183, 184, 186, 187, 189, 192, 193, 196, 197, 198, 199, 200, 201, 202, 210, 213, 214, 215, 216, 218, 219, 220, 221, 222, 224, 225, 226, 227, 228, 231, 233, 238, 239, 241, 242, 244, 245, 246, 247, 251, 253, 255, 256, 257, 258, 260, 266, 286, 324, 329, 330, 331, 332, 335, 336, 337, 338, 340, 341], "action_s": 3, "help": [3, 4, 32, 77, 81, 95, 101, 119, 323, 325, 329, 330, 331, 332, 335], "prealloc": [3, 336], "With": [3, 90, 143, 326, 329, 330, 335, 338, 341], "necessarili": [3, 341], "0s": [3, 144, 332], "stateless": [3, 147, 253, 329, 336, 341], "step_and_maybe_reset": [3, 77, 81, 95, 101], "partial": [3, 77, 81, 95, 101, 110, 143, 144, 145, 304, 332], "next": [3, 4, 8, 13, 14, 16, 26, 28, 32, 35, 38, 40, 41, 42, 52, 53, 54, 55, 56, 57, 66, 67, 69, 74, 77, 78, 81, 87, 91, 95, 99, 100, 101, 102, 103, 110, 115, 118, 119, 120, 125, 126, 130, 134, 136, 139, 140, 142, 144, 153, 154, 160, 163, 165, 180, 181, 184, 185, 189, 204, 234, 238, 239, 241, 242, 244, 245, 246, 251, 255, 256, 257, 258, 260, 266, 267, 268, 269, 270, 271, 272, 298, 300, 302, 329, 330, 332, 334, 336, 337, 338, 340, 341], "step_mdp": [3, 181, 185, 322, 332, 336, 340, 341], "done_kei": [3, 77, 81, 95, 101, 119, 136, 142, 163, 335], "assign": [3, 4, 13, 14, 32, 34, 36, 39, 77, 81, 95, 101, 148, 241, 242, 244, 258, 331, 335, 338], "_reset": [3, 77, 81, 91, 95, 101, 108, 110, 115, 118, 164, 165, 189], "data_": [3, 77, 81, 95, 101], "i": [3, 13, 14, 16, 17, 18, 19, 20, 21, 26, 28, 32, 35, 38, 42, 43, 58, 59, 61, 67, 71, 77, 81, 95, 101, 132, 136, 139, 148, 152, 180, 184, 196, 202, 220, 225, 227, 228, 229, 268, 269, 270, 271, 295, 307, 329, 330, 331, 332, 335, 336, 338, 340, 341], "rang": [3, 4, 8, 11, 27, 35, 38, 40, 41, 42, 52, 53, 54, 55, 56, 58, 59, 69, 77, 78, 81, 95, 101, 136, 146, 154, 180, 184, 252, 260, 325, 326, 329, 331, 332, 335, 336, 338, 340], "n": [3, 6, 7, 24, 27, 32, 33, 40, 77, 81, 95, 101, 110, 117, 122, 149, 179, 180, 183, 189, 224, 229, 238, 245, 253, 267, 301, 324, 326, 330, 331, 332, 335, 338, 341], "append": [3, 8, 35, 38, 41, 42, 52, 53, 54, 55, 56, 77, 78, 81, 95, 101, 113, 136, 144, 153, 180, 181, 184, 185, 219, 226, 329, 330, 331, 332, 335, 336, 337, 338, 340], "set_se": [3, 13, 14, 16, 17, 21, 74, 77, 81, 87, 91, 95, 101, 128, 134, 139, 143, 145, 148, 336, 340, 341], "seed": [3, 13, 14, 16, 17, 21, 55, 75, 77, 81, 91, 95, 96, 97, 101, 102, 103, 108, 115, 118, 148, 156, 304], "determinist": [3, 32, 77, 81, 95, 101, 114, 132, 144, 147, 148, 150, 152, 168, 177, 197, 204, 213, 222, 228, 229, 232, 239, 324, 329, 330, 332, 336, 341], "preced": [3, 186, 332], "without": [3, 7, 9, 32, 40, 52, 66, 67, 77, 81, 95, 101, 103, 108, 115, 118, 146, 179, 180, 183, 184, 215, 216, 238, 239, 241, 242, 244, 245, 251, 255, 256, 257, 258, 260, 267, 268, 269, 270, 271, 272, 316, 323, 324, 329, 330, 331, 335, 336, 338, 341], "risk": [3, 133], "overlap": [3, 41], "consecut": [3, 65, 85, 185, 224, 332, 335, 341], "reproduc": [3, 110, 156, 329, 331, 335], "maximum": [3, 4, 13, 14, 16, 17, 18, 19, 20, 21, 32, 34, 36, 37, 39, 40, 43, 45, 57, 58, 59, 60, 71, 77, 81, 95, 101, 117, 137, 142, 143, 145, 207, 208, 209, 232, 239, 245, 251, 253, 254, 258, 301, 329, 330, 331, 332, 335, 338], "max_step": [3, 13, 77, 81, 91, 95, 101, 102, 103, 142, 335, 340, 341], "tensordictmodul": [3, 13, 14, 16, 17, 20, 21, 40, 91, 126, 176, 181, 185, 189, 201, 202, 210, 211, 214, 215, 216, 217, 218, 219, 222, 224, 225, 226, 227, 228, 230, 231, 232, 234, 239, 241, 245, 247, 248, 249, 251, 253, 256, 258, 260, 266, 267, 268, 269, 270, 271, 300, 316, 324, 329, 331, 332, 334, 335, 336, 337], "compat": [3, 7, 11, 18, 19, 32, 34, 36, 39, 52, 66, 67, 68, 77, 81, 83, 94, 95, 101, 110, 142, 150, 154, 179, 180, 181, 183, 184, 185, 226, 238, 239, 241, 242, 244, 245, 251, 253, 255, 256, 257, 258, 260, 263, 329, 332, 338, 340], "mark": [3, 16, 56, 77, 81, 95, 101, 181, 185], "trail": [3, 154], "time": [3, 4, 7, 8, 13, 14, 16, 17, 18, 20, 21, 32, 35, 38, 40, 41, 42, 55, 69, 77, 78, 81, 90, 94, 95, 96, 97, 101, 107, 111, 133, 139, 144, 145, 154, 163, 177, 179, 183, 185, 186, 224, 240, 245, 248, 252, 253, 255, 256, 260, 268, 269, 270, 271, 272, 273, 274, 277, 278, 279, 280, 281, 282, 283, 284, 285, 304, 324, 325, 330, 331, 332, 334, 335, 336, 337, 338, 340, 341], "treat": 3, "figur": [3, 329, 331, 332, 335, 336, 341], "summar": [3, 336], "brief": [3, 331], "entri": [3, 13, 14, 18, 19, 20, 21, 23, 26, 28, 32, 34, 36, 37, 39, 45, 49, 52, 53, 54, 55, 56, 66, 67, 77, 81, 95, 101, 110, 112, 113, 115, 118, 119, 122, 125, 128, 130, 132, 134, 136, 139, 142, 143, 144, 152, 154, 163, 164, 181, 190, 191, 218, 219, 226, 227, 239, 258, 268, 269, 270, 271, 324, 329, 331, 332, 335, 336, 337, 338, 341], "deliveri": 3, "design": [3, 13, 14, 32, 33, 77, 81, 95, 101, 110, 133, 148, 218, 238, 239, 240, 245, 246, 247, 248, 249, 251, 252, 253, 255, 256, 257, 258, 260, 266, 329, 330, 331, 332, 334, 335, 336, 338, 341], "metaclass": 3, "ensur": [3, 32, 35, 41, 61, 65, 77, 81, 95, 101, 110, 132, 142, 150, 154, 219, 324, 330, 331, 336, 338], "everi": [3, 8, 17, 26, 28, 32, 33, 68, 77, 81, 95, 101, 142, 143, 154, 166, 167, 168, 169, 170, 171, 172, 173, 175, 177, 178, 179, 180, 181, 183, 184, 185, 186, 187, 192, 193, 196, 197, 198, 200, 203, 204, 206, 211, 217, 218, 220, 221, 222, 224, 227, 232, 235, 304, 326, 329, 330, 331, 332, 335, 336], "flank": [3, 332], "dual": 3, "strictli": [3, 8, 32, 77, 81, 95, 101, 148, 258, 329, 331], "refer": [3, 7, 8, 9, 21, 32, 40, 77, 81, 95, 101, 148, 154, 165, 176, 177, 189, 190, 191, 192, 197, 198, 203, 204, 220, 238, 246, 247, 248, 249, 255, 258, 268, 273, 281, 328, 329, 331, 335], "union": [3, 11, 13, 15, 16, 17, 20, 21, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 39, 44, 46, 47, 61, 77, 81, 95, 101, 108, 117, 119, 125, 128, 132, 133, 136, 138, 150, 152, 154, 163, 166, 167, 169, 170, 171, 172, 174, 176, 178, 186, 187, 190, 191, 192, 193, 194, 195, 199, 201, 202, 207, 208, 209, 210, 228, 244, 245, 250, 256, 259, 281, 287, 298, 300, 301, 309, 310, 313, 314, 316, 317, 318, 319, 320], "interpret": [3, 330], "last": [3, 4, 11, 13, 14, 16, 17, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 37, 44, 46, 47, 52, 65, 67, 77, 81, 95, 101, 122, 128, 133, 143, 145, 146, 166, 167, 179, 181, 183, 185, 186, 187, 190, 191, 197, 205, 211, 217, 218, 221, 222, 229, 330, 331, 332, 335, 336, 337, 338, 340, 341], "indic": [3, 8, 11, 13, 14, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 44, 45, 46, 47, 52, 53, 54, 55, 56, 57, 63, 65, 66, 67, 69, 70, 72, 77, 81, 95, 101, 110, 111, 142, 143, 144, 145, 148, 164, 166, 167, 187, 190, 191, 193, 224, 226, 227, 235, 238, 239, 241, 242, 244, 245, 246, 247, 251, 253, 255, 256, 257, 258, 260, 266, 308, 320, 323, 326, 331, 332, 336, 338, 341], "truncat": [3, 13, 14, 16, 18, 19, 20, 21, 37, 43, 45, 52, 53, 55, 56, 66, 67, 77, 81, 95, 96, 97, 101, 119, 120, 127, 136, 142, 164, 181, 185, 209, 274, 329, 331, 332, 334, 337, 338, 340, 341], "carri": [3, 21, 45, 77, 81, 95, 101, 144, 253, 330, 332, 335, 336, 338], "assess": [3, 104, 329], "split_trajectori": [3, 13, 14, 16, 17, 18, 19, 20, 21, 66, 67, 322], "adjac": [3, 23, 122], "reli": [3, 179, 180, 183, 184, 238, 325, 329, 331, 336, 341], "traj_id": [3, 13, 14, 16, 23, 136, 332, 338, 340], "junction": 3, "miss": [3, 4, 6, 7, 11, 26, 32, 77, 81, 95, 101, 148, 163, 230, 231, 258, 323, 329, 332], "context": [3, 5, 8, 32, 77, 78, 81, 94, 95, 101, 144, 149, 193, 194, 218, 264, 265, 268, 269, 270, 271, 273, 281, 300, 324, 325, 329, 330, 331, 335, 336, 337, 338], "through": [3, 4, 5, 8, 11, 16, 18, 20, 21, 26, 28, 85, 90, 95, 96, 97, 101, 115, 118, 133, 187, 201, 225, 229, 230, 231, 235, 268, 269, 270, 271, 324, 329, 330, 331, 334, 335, 336, 337, 338, 341], "inittrack": [3, 181, 185, 329, 332], "tutori": [3, 328, 329, 330, 332, 333, 334, 336, 337, 338, 339, 341], "inform": [3, 4, 13, 14, 16, 17, 18, 19, 20, 21, 32, 34, 36, 39, 43, 77, 78, 81, 84, 95, 101, 166, 167, 187, 193, 325, 326, 329, 330, 331, 332, 335, 336, 338], "scratch": [3, 8, 330, 336], "better": [3, 8, 9, 181, 185, 325, 331, 336], "intens": [3, 8], "gym3": 3, "envpool": [3, 92, 93], "interfac": [3, 84, 94, 187, 194, 324, 329, 331, 336, 338], "simultan": [3, 20, 95, 101, 336], "often": [3, 8, 250, 304, 329, 330, 336, 338, 341], "competit": [3, 335], "advantag": [3, 8, 178, 238, 240, 252, 255, 257, 268, 269, 270, 271, 272, 273, 275, 277, 279, 281, 282, 284, 325, 326, 329, 330, 331, 332, 335, 336, 341], "scale": [3, 4, 52, 110, 126, 128, 138, 143, 146, 177, 182, 196, 203, 204, 208, 209, 214, 215, 216, 225, 229, 231, 238, 239, 251, 255, 256, 257, 258, 302, 308, 313, 320, 324, 329, 330, 331, 332, 335, 340], "varieti": 3, "own": [3, 13, 14, 17, 22, 32, 77, 81, 95, 96, 97, 101, 330, 331, 335, 336], "As": [3, 4, 77, 81, 90, 95, 96, 97, 101, 136, 229, 268, 324, 329, 330, 331, 332, 335, 336, 337, 338, 340, 341], "inherit": [3, 188, 253, 326, 331, 335], "serialenv": [3, 77, 81, 95, 144, 322, 341], "Of": [3, 7, 323, 336, 341], "cours": [3, 4, 323, 331, 336, 341], "correspond": [3, 4, 13, 14, 18, 19, 20, 21, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 39, 41, 44, 46, 47, 56, 61, 77, 81, 91, 92, 95, 101, 132, 144, 148, 152, 154, 181, 183, 185, 190, 191, 221, 222, 224, 225, 229, 242, 245, 258, 266, 268, 269, 270, 271, 272, 329, 330, 331, 335, 336, 337], "count": [3, 78, 142, 224, 300, 304, 307, 329, 330, 331, 332, 338, 341], "make_env": [3, 103, 154, 309, 310, 329, 330, 341], "gymenv": [3, 5, 13, 14, 16, 17, 21, 22, 77, 78, 81, 83, 95, 101, 110, 113, 114, 119, 125, 126, 128, 130, 134, 135, 136, 139, 143, 144, 145, 147, 148, 154, 181, 185, 313, 316, 322, 324, 329, 330, 331, 332, 337, 338, 340, 341], "v1": [3, 13, 14, 16, 17, 21, 22, 52, 53, 77, 78, 81, 92, 95, 101, 110, 113, 120, 125, 126, 128, 134, 136, 139, 142, 143, 144, 145, 147, 181, 185, 263, 277, 278, 279, 280, 282, 283, 284, 285, 324, 330, 332, 336, 338, 340, 341], "from_pixel": [3, 75, 76, 110, 135, 313, 329, 330, 332, 337, 338, 340, 341], "9": [3, 7, 32, 35, 38, 41, 55, 56, 67, 69, 90, 96, 97, 143, 154, 238, 239, 241, 242, 244, 245, 246, 247, 251, 253, 255, 256, 257, 258, 260, 261, 266, 325, 328, 329, 330, 331, 335, 336, 338, 339], "81": [3, 330, 336, 337], "must": [3, 7, 13, 14, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 40, 44, 45, 46, 47, 53, 55, 56, 57, 58, 59, 60, 66, 67, 68, 71, 77, 78, 81, 95, 96, 97, 101, 110, 113, 119, 123, 126, 128, 130, 140, 143, 144, 145, 148, 149, 154, 166, 167, 176, 181, 185, 187, 190, 191, 192, 193, 202, 213, 219, 220, 225, 226, 227, 228, 229, 232, 233, 238, 239, 241, 242, 244, 245, 246, 247, 251, 253, 255, 256, 257, 258, 259, 260, 266, 268, 269, 270, 271, 272, 273, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 313, 329, 330, 331, 332, 334, 336, 338, 340], "print": [3, 6, 7, 13, 14, 16, 21, 22, 24, 26, 27, 28, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 45, 53, 55, 56, 57, 66, 67, 69, 73, 74, 75, 76, 77, 78, 80, 81, 82, 86, 87, 88, 89, 90, 91, 94, 95, 96, 97, 99, 100, 101, 102, 103, 105, 107, 110, 111, 115, 116, 117, 118, 125, 128, 134, 136, 139, 142, 144, 145, 146, 154, 160, 163, 164, 166, 167, 173, 176, 181, 187, 190, 191, 192, 193, 196, 199, 202, 213, 214, 215, 216, 218, 219, 221, 222, 224, 226, 228, 231, 233, 253, 313, 316, 324, 326, 330, 331, 332, 334, 335, 336, 337, 338, 340, 341], "simpli": [3, 6, 34, 36, 39, 45, 120, 140, 153, 253, 324, 325, 329, 331, 335, 341], "b": [3, 7, 8, 23, 26, 28, 34, 36, 39, 40, 41, 42, 69, 179, 180, 183, 184, 192, 193, 194, 195, 201, 210, 232, 268, 269, 270, 271, 272, 274, 287, 324, 330, 337, 338], "c": [3, 6, 7, 26, 34, 36, 39, 41, 42, 54, 128, 146, 183, 184, 330, 338], "d": [3, 35, 54, 55, 56, 57, 61, 179, 183, 225, 229, 340], "get": [3, 4, 6, 7, 8, 9, 34, 35, 36, 38, 39, 52, 58, 59, 66, 67, 68, 69, 71, 78, 95, 101, 108, 111, 115, 117, 118, 126, 128, 133, 143, 144, 146, 154, 213, 221, 222, 225, 226, 229, 268, 269, 270, 271, 272, 291, 324, 329, 330, 331, 332, 335, 336, 338, 340, 341], "forc": [3, 6, 7, 13, 14, 18, 20, 21, 53, 55, 56, 330, 335, 336], "privat": [3, 77, 81, 95, 101, 153, 336, 341], "absenc": 3, "total": [3, 13, 14, 16, 17, 18, 19, 20, 21, 24, 30, 31, 33, 67, 240, 252, 255, 295, 297, 300, 304, 307, 308, 328, 329, 330, 331, 332, 334, 335, 336, 337, 338, 339, 340, 341], "unless": [3, 13, 14, 16, 17, 18, 19, 20, 21, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 44, 46, 47, 65, 77, 81, 95, 101, 331], "wa": [3, 5, 7, 35, 38, 41, 42, 52, 53, 54, 55, 56, 77, 81, 95, 101, 148, 164, 183, 250, 259, 274, 325, 330, 331, 334, 338, 340], "abov": [3, 7, 32, 77, 81, 95, 101, 182, 208, 209, 237, 325, 326, 329, 331, 335, 336, 341], "deal": [3, 329, 331, 335, 338], "proper": [3, 4, 6, 7, 268, 269, 270, 271, 330, 331, 335, 338], "behav": [3, 83, 91, 179, 183, 199, 251, 337], "accord": [3, 13, 14, 16, 17, 18, 19, 20, 21, 34, 36, 39, 40, 128, 138, 182, 194, 203, 208, 209, 266, 324, 336, 338], "develop": [3, 4, 7, 85, 329, 340], "inner": [3, 77, 81, 95, 101, 117, 326, 330, 331, 335, 341], "logic": 3, "nevertheless": [3, 331, 338], "kept": [3, 13, 14, 16, 17, 65, 67, 117, 140, 147, 156, 163, 182, 208, 209], "mind": [3, 66, 67, 335], "desig": 3, "previou": [3, 4, 10, 32, 40, 41, 144, 164, 179, 183, 204, 218, 331, 332, 336, 341], "wherev": 3, "expos": [3, 98, 115, 118, 230, 330], "modif": [3, 5, 26, 28, 32, 77, 81, 95, 101, 122, 164, 253, 331, 336], "lost": [3, 8, 153], "eras": [3, 77, 81, 95, 101, 148], "intern": [3, 327], "face": [3, 5, 8, 9, 341], "NOT": [3, 133], "outsid": [3, 16, 335, 336], "keep": [3, 4, 7, 8, 14, 42, 65, 69, 95, 101, 128, 132, 152, 154, 163, 224, 297, 304, 329, 330, 331, 332, 335, 336, 338, 340, 341], "right": [3, 6, 7, 40, 186, 330, 331, 335, 336, 341], "preliminari": 3, "warranti": 3, "affect": [3, 8, 32, 77, 81, 95, 101, 147, 148, 156, 268, 269, 270, 271], "assumpt": [3, 336, 338], "made": [3, 32, 58, 59, 60, 68, 71, 77, 81, 95, 101, 224, 242, 266, 329, 330, 332, 335, 337], "preclud": 3, "presenc": 3, "annihil": 3, "effect": [3, 26, 32, 66, 67, 77, 81, 95, 101, 110, 148, 304, 329, 338, 341], "reason": [3, 4, 8, 32, 77, 81, 95, 96, 97, 101, 132, 150, 185, 325, 329, 330, 331, 336, 338], "root": [3, 26, 28, 52, 53, 55, 56, 110, 145, 163, 182, 208, 209, 332, 335, 336, 337, 338, 341], "known": [3, 5, 7, 8, 275, 276, 329, 330], "advanc": [3, 21, 35, 38, 41, 42, 338], "explicitli": [3, 4, 330, 332, 335, 338], "place": [3, 13, 14, 16, 17, 26, 28, 32, 34, 36, 39, 58, 59, 71, 77, 78, 81, 95, 101, 114, 119, 132, 144, 147, 148, 150, 152, 153, 154, 164, 218, 228, 301, 306, 307, 330, 331, 335, 336, 338], "superse": 3, "pettingzoowrapp": [3, 322], "group": [3, 24, 25, 26, 27, 28, 29, 30, 31, 33, 44, 46, 47, 77, 81, 90, 95, 96, 97, 101, 103, 104, 324, 330, 331, 335], "associ": [3, 32, 34, 36, 39, 77, 81, 95, 101, 203, 320, 329, 338], "environemtn": 3, "__not__": 3, "constrain": [3, 126, 181, 185, 255], "li": 3, "fact": [3, 7, 8, 329, 331, 335, 336, 337, 338, 341], "predict": [3, 32, 40, 177, 188, 189, 218, 234, 244, 246, 248, 249, 267, 324, 329, 330], "know": [3, 4, 9, 35, 38, 41, 42, 217, 256, 300, 329, 330, 331, 332, 335, 338], "meaning": 3, "could": [3, 4, 6, 330, 331, 335, 337, 341], "perfectli": [3, 326, 329, 336], "case": [3, 4, 5, 7, 8, 11, 13, 14, 16, 17, 18, 19, 20, 21, 22, 26, 32, 35, 41, 53, 55, 56, 61, 77, 81, 95, 101, 115, 116, 118, 146, 148, 156, 185, 187, 193, 225, 228, 229, 231, 232, 237, 238, 239, 241, 242, 244, 245, 251, 255, 256, 257, 258, 260, 268, 269, 270, 271, 295, 306, 318, 319, 320, 324, 326, 329, 330, 331, 332, 335, 336, 338, 341], "meaningless": 3, "discard": [3, 45, 52, 53, 81, 150, 163, 286, 338, 341], "val": [3, 24, 25, 26, 27, 28, 29, 30, 31, 33, 44, 46, 47, 340], "agent0": 3, "agent1": 3, "overridden": [3, 53, 55, 56, 77, 81, 95, 101, 166, 167, 168, 169, 170, 171, 172, 173, 175, 177, 178, 179, 180, 181, 183, 184, 185, 186, 187, 192, 193, 196, 197, 198, 200, 203, 204, 206, 211, 217, 218, 220, 221, 222, 224, 227, 232, 235, 332], "overrid": [3, 24, 25, 26, 27, 28, 29, 30, 31, 33, 38, 44, 46, 47, 77, 81, 95, 101, 320, 324], "elimin": 3, "field": [3, 13, 14, 16, 17, 26, 32, 34, 36, 37, 39, 40, 41, 42, 43, 45, 53, 55, 56, 58, 59, 71, 74, 77, 81, 87, 90, 91, 94, 95, 96, 97, 99, 100, 101, 102, 103, 115, 118, 119, 120, 130, 134, 136, 140, 142, 144, 148, 163, 165, 176, 181, 185, 189, 201, 202, 210, 213, 214, 215, 216, 218, 219, 220, 224, 225, 226, 227, 228, 231, 233, 238, 239, 241, 242, 244, 245, 251, 255, 256, 257, 258, 260, 266, 308, 313, 323, 324, 330, 331, 332, 334, 335, 336, 337, 338, 340, 341], "bool": [3, 13, 14, 16, 17, 18, 19, 20, 21, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 52, 53, 54, 55, 56, 57, 65, 66, 67, 74, 75, 76, 77, 78, 79, 81, 87, 90, 91, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 108, 110, 111, 115, 117, 118, 119, 120, 122, 126, 127, 128, 130, 132, 134, 136, 138, 140, 142, 144, 146, 148, 149, 150, 152, 154, 156, 163, 164, 165, 166, 167, 169, 170, 179, 180, 181, 182, 183, 184, 185, 187, 189, 192, 193, 194, 195, 208, 209, 213, 219, 220, 224, 225, 226, 227, 228, 229, 230, 231, 232, 238, 239, 240, 241, 242, 244, 245, 246, 247, 248, 249, 251, 252, 253, 254, 255, 256, 257, 258, 260, 263, 266, 268, 269, 270, 271, 274, 277, 278, 279, 280, 282, 283, 284, 285, 286, 287, 297, 298, 300, 301, 302, 304, 313, 320, 330, 331, 332, 334, 335, 336, 337, 338, 340, 341], "pixel": [3, 7, 26, 56, 110, 112, 119, 122, 124, 128, 130, 132, 135, 146, 150, 152, 169, 197, 198, 287, 313, 324, 329, 330, 332, 337, 338, 340, 341], "500": [3, 329, 330, 336, 340, 341], "uint8": [3, 34, 36, 39, 47, 119, 130, 146, 330, 337, 338, 340, 341], "none": [3, 8, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 66, 67, 68, 69, 71, 77, 78, 81, 90, 91, 95, 96, 97, 101, 102, 103, 105, 109, 110, 111, 112, 113, 114, 115, 116, 118, 122, 124, 126, 128, 129, 130, 132, 133, 134, 135, 136, 137, 138, 139, 142, 143, 144, 145, 146, 147, 148, 150, 152, 154, 155, 157, 158, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 176, 178, 179, 180, 183, 184, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 197, 198, 199, 200, 201, 202, 210, 211, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 224, 225, 226, 227, 228, 229, 231, 232, 233, 238, 239, 241, 242, 244, 245, 246, 247, 251, 253, 254, 255, 256, 257, 258, 259, 260, 266, 267, 268, 269, 270, 271, 272, 273, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 291, 292, 293, 298, 299, 300, 301, 302, 303, 304, 308, 309, 310, 313, 316, 318, 319, 320, 324, 326, 329, 330, 331, 332, 335, 336, 338, 340, 341], "is_shar": [3, 13, 14, 16, 26, 34, 36, 37, 39, 40, 41, 42, 43, 45, 53, 55, 56, 57, 58, 59, 71, 74, 77, 81, 87, 90, 91, 94, 95, 96, 97, 99, 100, 101, 102, 103, 115, 118, 119, 120, 130, 134, 136, 140, 142, 144, 154, 163, 165, 176, 181, 185, 189, 201, 202, 210, 213, 214, 215, 216, 218, 219, 220, 224, 225, 226, 227, 228, 231, 233, 238, 239, 241, 242, 244, 245, 251, 255, 256, 257, 258, 260, 266, 313, 324, 331, 332, 334, 335, 336, 337, 338, 340, 341], "launch": [3, 13, 14, 18, 19, 20, 22, 95, 101], "bottleneck": [3, 8], "so": [3, 4, 6, 7, 10, 32, 34, 36, 39, 40, 77, 81, 95, 101, 144, 154, 230, 231, 331, 332, 335, 336, 341], "onc": [3, 7, 13, 14, 16, 17, 18, 19, 20, 21, 32, 34, 36, 39, 77, 81, 95, 101, 136, 148, 217, 222, 224, 302, 326, 330, 331, 332, 336, 338, 341], "great": [3, 7, 8, 340], "speedup": [3, 8, 341], "precis": [3, 115, 118, 163, 180, 184, 329, 331], "misspecifi": 3, "caus": [3, 7, 8, 58, 59, 71, 77, 81, 85, 95, 101, 133, 341], "breakag": 3, "rais": [3, 13, 14, 16, 18, 19, 20, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 39, 44, 46, 47, 77, 81, 95, 101, 104, 110, 121, 127, 136, 143, 144, 145, 148, 156, 217, 221, 222, 224, 258, 329, 331, 335, 338], "mismatch": [3, 330], "mostli": [3, 17, 325, 338, 341], "purpos": [3, 7, 110, 179, 316, 329, 331, 332, 335, 337, 341], "want": [3, 6, 7, 8, 67, 128, 238, 239, 241, 242, 244, 245, 246, 247, 251, 253, 255, 256, 257, 258, 260, 266, 324, 329, 330, 331, 332, 335, 336, 337, 338, 340, 341], "subprocess": [3, 13, 14, 78, 95, 101], "addit": [3, 4, 32, 52, 77, 81, 92, 95, 101, 114, 132, 144, 147, 148, 150, 152, 179, 217, 218, 228, 237, 253, 268, 325, 329, 330, 335, 338], "multithread": [3, 35, 38, 41, 42, 52, 53, 54, 55, 56, 57, 92, 93, 338], "multithreadedenv": [3, 322], "underneath": 3, "higher": [3, 4, 113, 232, 329, 330, 331, 338, 341], "restrict": [3, 330, 337, 338, 341], "flexibl": [3, 9, 92, 261, 325, 326, 338, 341], "cover": [3, 323, 331, 336, 340], "popular": [3, 324, 332, 335], "atari": [3, 4, 110, 341], "classic": [3, 91, 97, 330], "benchmark_batched_env": 3, "py": [3, 107, 201, 210, 326, 328, 329, 330, 331, 332, 334, 335, 336, 337, 338, 339, 340, 341], "pipelin": [3, 7, 324, 331], "seamlessli": [3, 336], "infrastructur": [3, 335], "view": [3, 8, 27, 32, 33, 55, 77, 81, 95, 101, 108, 176, 179, 183, 187, 336, 338, 340, 341], "core": [3, 8, 313, 326, 332, 340], "decis": [3, 168, 200, 218, 243, 254, 332, 335, 338, 341], "act": [3, 4, 66, 67, 96, 97, 193, 239, 241, 251, 256, 258, 260, 332, 335], "world": [3, 5, 91, 234, 248, 335, 336, 341], "paradigm": [3, 17, 335], "decpodp": 3, "markov": [3, 341], "game": [3, 4, 5], "per": [3, 4, 13, 14, 16, 17, 18, 19, 20, 21, 85, 95, 96, 97, 113, 139, 177, 192, 193, 221, 304, 318, 319, 329, 330, 331, 332, 335, 338, 340], "accommod": [3, 13, 14, 16, 17], "thank": [3, 329], "carrier": [3, 331, 332, 338], "particular": [3, 32, 45, 52, 77, 81, 95, 101, 148, 325, 326, 330, 332, 334, 335, 338], "thu": [3, 252, 335], "hand": [3, 7, 21, 335, 336], "let": [3, 6, 7, 32, 43, 77, 81, 95, 96, 97, 101, 110, 181, 185, 192, 193, 219, 300, 325, 329, 330, 331, 332, 334, 335, 336, 337, 338, 340, 341], "understand": [3, 8, 329, 330, 335], "go": [3, 7, 90, 133, 136, 218, 274, 329, 330, 331, 332, 334, 335, 336, 337, 338, 340, 341], "vma": [3, 102, 103, 335], "robot": [3, 5, 7, 132, 150, 152, 335], "what": [3, 8, 35, 44, 77, 81, 95, 101, 119, 144, 163, 226, 323, 324, 325, 330, 331, 332, 335, 336, 337, 338, 340, 341], "vmasenv": [3, 322, 335], "balanc": [3, 329, 330], "num_env": [3, 21, 84, 102, 103, 335], "n_agent": [3, 102, 103, 192, 193, 201, 210, 266, 335], "5": [3, 24, 26, 28, 35, 38, 41, 42, 66, 67, 78, 87, 92, 99, 100, 102, 103, 136, 142, 143, 165, 166, 167, 176, 177, 179, 182, 183, 186, 187, 189, 192, 193, 197, 202, 208, 209, 218, 219, 226, 232, 252, 255, 257, 260, 324, 329, 330, 335, 336, 338, 340, 341], "info": [3, 35, 38, 41, 42, 52, 53, 54, 55, 56, 66, 67, 77, 81, 95, 96, 97, 98, 99, 100, 101, 102, 103, 150, 153, 155, 335, 338], "ground_rew": 3, "pos_rew": [3, 335], "16": [3, 32, 55, 67, 77, 81, 95, 101, 110, 328, 329, 330, 332, 335, 336, 338, 339, 340], "style": [3, 35, 38, 41, 42, 52, 53, 54, 55, 56], "relat": [3, 4, 10, 35, 122, 238, 239, 241, 242, 244, 245, 251, 255, 256, 257, 258, 260, 330, 336], "vari": [3, 96, 97, 133, 335], "creation": [3, 95, 101, 329, 341], "info_spec": 3, "agent_i_action_spec": 3, "agent_i_reward_spec": 3, "agent_i_observation_spec": 3, "discretetensorspec": [3, 33, 77, 81, 95, 101, 108, 164, 242, 245, 266, 322, 331, 335, 341], "you": [3, 5, 6, 7, 8, 9, 10, 32, 43, 77, 81, 85, 90, 95, 96, 97, 99, 100, 101, 107, 154, 183, 323, 324, 329, 330, 331, 332, 334, 335, 336, 337, 338, 340, 341], "simpl": [3, 9, 32, 33, 77, 81, 95, 101, 169, 229, 242, 244, 253, 257, 268, 324, 325, 329, 330, 331, 335, 341], "composit": [3, 26, 28, 77, 81, 95, 101, 331, 336], "prefix": [3, 23, 32, 34, 36, 39, 45, 77, 81, 95, 101, 148, 253, 258, 286, 332, 341], "exactli": [3, 32, 77, 81, 83, 95, 101, 148, 179, 183, 258, 329, 332, 335], "action_kei": [3, 15, 77, 81, 95, 101, 108, 117, 163, 165, 188, 189, 217, 221, 222, 224, 335], "reward_kei": [3, 77, 81, 95, 101, 163, 165, 189, 298, 302, 335], "automat": [3, 5, 56, 58, 59, 71, 77, 81, 95, 96, 97, 101, 115, 118, 128, 153, 166, 213, 225, 324, 329, 331, 335, 336, 338, 340], "sure": [3, 4, 7, 54, 68, 85, 136, 219, 320, 324, 329, 331, 332, 335, 336, 338, 340, 341], "set_kei": [3, 119, 238, 240, 242, 245, 246, 251, 252, 253, 255, 256, 257, 258, 266, 272, 335], "awai": [3, 331, 335], "eas": [3, 335], "leaf": [3, 26, 28, 77, 81, 95, 101, 142, 229], "would": [3, 32, 40, 77, 81, 95, 101, 179, 181, 183, 185, 187, 192, 326, 330, 331, 332, 336, 338, 341], "full": [3, 77, 81, 95, 101, 181, 185, 220, 295, 329, 330, 331, 332, 334, 335, 336, 337, 338, 340, 341], "raw": [3, 4, 40, 182, 208, 209, 330, 336], "torchvis": [3, 132, 152, 340, 341], "transformedenv": [3, 13, 77, 78, 81, 95, 101, 108, 110, 113, 114, 115, 118, 119, 120, 122, 125, 126, 127, 128, 130, 134, 135, 136, 139, 140, 142, 143, 144, 145, 147, 154, 181, 185, 313, 329, 330, 331, 332, 334, 335, 336, 337, 338, 340, 341], "primit": [3, 4, 238, 239, 241, 242, 244, 245, 251, 255, 256, 257, 258, 260], "built": [3, 5, 7, 238, 239, 241, 242, 244, 245, 246, 247, 251, 253, 255, 256, 257, 258, 260, 261, 266, 314, 316, 317, 320, 329, 330, 331, 332, 338, 341], "base_env": [3, 77, 81, 95, 101, 108, 113, 115, 117, 118, 126, 130, 135, 142, 144, 145, 329, 330, 331, 337, 340, 341], "totensorimag": [3, 56, 110, 135, 330, 332, 338, 340, 341], "in_kei": [3, 13, 14, 16, 17, 21, 52, 91, 109, 110, 111, 112, 113, 115, 117, 118, 122, 124, 126, 128, 129, 130, 132, 134, 135, 136, 137, 138, 139, 143, 145, 146, 147, 148, 150, 152, 154, 165, 175, 181, 185, 189, 201, 210, 211, 213, 214, 215, 216, 218, 219, 225, 226, 228, 229, 231, 232, 233, 238, 239, 240, 241, 242, 244, 245, 251, 252, 255, 256, 257, 258, 260, 266, 268, 269, 270, 271, 286, 287, 313, 316, 324, 329, 330, 331, 332, 334, 335, 336, 337, 338, 340, 341], "resiz": [3, 56, 110, 330, 332, 338, 341], "64": [3, 34, 36, 39, 110, 135, 169, 170, 178, 181, 185, 193, 201, 266, 329, 330, 331, 332, 334, 336, 337, 338, 340, 341], "appar": [3, 297], "bring": [3, 331, 341], "signific": [3, 5, 8, 331, 341], "kind": [3, 38, 44, 163, 338], "consult": 3, "interest": [3, 225, 229, 324, 330, 331, 335, 336, 341], "resize_par": 3, "out_kei": [3, 13, 14, 16, 17, 21, 91, 109, 110, 111, 112, 113, 115, 118, 122, 124, 126, 128, 129, 130, 132, 134, 135, 136, 137, 138, 139, 143, 145, 146, 147, 150, 152, 154, 165, 175, 176, 181, 185, 189, 201, 202, 210, 211, 213, 214, 215, 216, 218, 220, 225, 226, 227, 228, 229, 231, 232, 233, 238, 239, 240, 245, 251, 252, 255, 256, 257, 258, 266, 268, 269, 270, 271, 287, 300, 316, 324, 329, 330, 331, 332, 334, 335, 336, 337, 338, 340, 341], "easi": [3, 5, 54, 217, 221, 222, 224, 324, 325, 329, 330, 331, 335, 337, 338, 341], "graph": [3, 4, 8, 264, 265, 329, 336], "inv": [3, 113, 117, 130, 136, 336], "appli": [3, 4, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 35, 38, 41, 42, 43, 44, 46, 47, 52, 53, 54, 55, 56, 77, 81, 95, 101, 108, 110, 111, 114, 115, 116, 117, 119, 120, 121, 122, 123, 125, 126, 127, 131, 133, 134, 136, 139, 140, 142, 143, 144, 145, 147, 148, 150, 151, 153, 154, 179, 183, 208, 219, 268, 299, 326, 329, 330, 331, 336, 340, 341], "revers": [3, 183], "order": [3, 16, 32, 33, 35, 38, 41, 42, 52, 53, 54, 55, 56, 65, 77, 81, 95, 101, 115, 118, 130, 148, 213, 219, 228, 230, 231, 233, 238, 239, 241, 245, 251, 255, 256, 257, 258, 260, 330, 335], "chain": [3, 34, 35, 36, 38, 39, 41, 42, 52, 53, 54, 55, 56, 114, 117, 166, 167, 231, 341], "taken": [3, 77, 81, 95, 101, 135, 190, 191, 222, 325, 329, 331, 332, 335, 336], "invers": [3, 4, 35, 38, 41, 42, 52, 53, 54, 55, 56, 110, 115, 118, 128, 136, 236, 251, 336], "in_keys_inv": [3, 113, 115, 118, 128, 129, 130, 134, 136, 147, 329, 334, 336, 341], "append_transform": [3, 35, 38, 41, 42, 52, 53, 54, 55, 56, 132, 144, 150, 329, 332, 336, 340, 341], "doubletofloat": [3, 313, 329, 331, 334], "float32": [3, 13, 14, 16, 26, 34, 35, 36, 39, 40, 41, 42, 44, 45, 53, 56, 58, 59, 61, 71, 74, 77, 81, 87, 91, 94, 95, 99, 100, 101, 102, 103, 115, 118, 119, 120, 128, 130, 134, 136, 140, 142, 144, 146, 160, 163, 165, 176, 181, 185, 189, 201, 202, 210, 213, 214, 215, 216, 218, 219, 224, 225, 226, 227, 228, 231, 233, 238, 239, 241, 242, 244, 245, 251, 255, 256, 257, 258, 260, 266, 313, 324, 331, 332, 334, 335, 336, 337, 338, 340, 341], "float64": [3, 32, 53, 55, 77, 81, 95, 101, 114, 115, 118, 132, 144, 147, 148, 150, 152, 228, 334, 341], "regist": [3, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 44, 46, 47, 77, 81, 95, 101, 115, 118, 119, 148, 166, 167, 168, 169, 170, 171, 172, 173, 175, 177, 178, 179, 180, 181, 183, 184, 185, 186, 187, 192, 193, 196, 197, 198, 200, 203, 204, 206, 211, 217, 218, 220, 221, 222, 224, 227, 232, 235, 238, 239, 241, 242, 244, 245, 246, 247, 251, 253, 255, 256, 257, 258, 260, 266, 295, 296, 297, 298, 299, 300, 301, 302, 303, 305, 306, 326, 329, 331, 338], "manipul": [3, 4, 8, 132, 150], "third_transform": 3, "replac": [3, 6, 7, 26, 28, 32, 66, 67, 117, 119, 163, 221, 324, 338], "unexpect": [3, 32, 77, 81, 95, 101, 148, 258, 341], "behviour": 3, "fortun": [3, 332], "ident": [3, 13, 14, 16, 32, 34, 36, 39, 95, 101, 119, 192, 193, 268, 269, 270, 271, 318, 319, 330, 335], "alreadi": [3, 8, 11, 32, 34, 36, 39, 45, 77, 81, 95, 101, 144, 164, 229, 268, 269, 270, 271, 329, 331, 335], "chang": [3, 5, 7, 32, 35, 38, 41, 42, 58, 59, 60, 65, 68, 71, 77, 81, 95, 101, 114, 115, 116, 118, 120, 126, 134, 140, 142, 147, 148, 154, 183, 238, 239, 241, 242, 244, 245, 246, 247, 251, 253, 255, 256, 257, 258, 260, 266, 325, 329, 331, 332, 335, 336, 337, 338, 341], "happen": [3, 77, 81, 95, 101, 217, 330, 337, 341], "catfram": [3, 330], "hold": [3, 264, 265, 336, 338], "notic": [3, 110, 331, 336], "parenthood": 3, "henc": [3, 35, 133, 164, 192, 324, 329, 331, 335, 336], "transform1": 3, "transform2": 3, "transform3": 3, "last_two": 3, "isinst": [3, 336], "discret": [3, 24, 27, 30, 31, 33, 47, 77, 81, 95, 96, 97, 101, 103, 117, 199, 202, 244, 245, 246, 324, 330, 331, 335, 341], "might": [3, 34, 36, 37, 39, 291, 323, 329, 341], "throughout": [3, 238, 239, 240, 245, 246, 247, 248, 249, 251, 252, 253, 255, 256, 257, 258, 260, 266, 331, 341], "action_mask": [3, 96, 97, 99, 100, 108], "unavail": [3, 96, 97], "probabl": [3, 4, 8, 40, 174, 176, 179, 181, 183, 185, 187, 190, 191, 199, 209, 221, 225, 229, 324, 330, 340], "categor": [3, 27, 31, 33, 96, 97, 103, 108, 119, 176, 199, 202, 219, 220, 225, 226, 227, 242, 245, 266, 332], "probabilistictensordictmodul": [3, 126, 229, 230, 340], "tensordictsequenti": [3, 181, 185, 219, 221, 230, 324, 329, 332, 334, 337, 340], "maskedcategor": [3, 191, 322], "linear": [3, 13, 14, 16, 17, 21, 32, 77, 81, 91, 95, 101, 114, 126, 132, 144, 147, 148, 150, 152, 165, 166, 167, 176, 187, 189, 192, 193, 194, 195, 196, 202, 203, 204, 213, 214, 215, 216, 221, 222, 223, 224, 225, 226, 228, 231, 233, 238, 239, 241, 242, 244, 245, 246, 247, 251, 253, 255, 256, 257, 258, 260, 266, 268, 269, 270, 271, 316, 324, 330, 334, 337, 340], "in_feat": 3, "out_feat": 3, "logit": [3, 36, 40, 190, 191, 199, 220, 225, 245, 324], "dist": [3, 10, 190, 191, 199], "distribution_class": [3, 126, 214, 215, 216, 218, 225, 229, 231, 238, 239, 245, 251, 255, 256, 257, 258, 324, 329, 331, 335, 340], "wrap": [3, 5, 13, 14, 16, 17, 18, 19, 20, 21, 32, 40, 53, 77, 81, 95, 96, 97, 101, 103, 156, 181, 185, 211, 214, 215, 216, 217, 222, 224, 226, 234, 266, 324, 329, 330, 331, 332, 335, 341], "actionmask": 3, "your_base_env": 3, "mask_kei": [3, 108, 133], "add": [3, 4, 6, 21, 32, 35, 38, 41, 42, 52, 53, 54, 55, 56, 63, 69, 70, 72, 77, 81, 95, 101, 110, 126, 181, 185, 194, 223, 238, 299, 331, 332, 335, 336, 338, 340], "enviorn": [3, 96, 97, 103, 335], "itself": [3, 32, 77, 81, 95, 101, 105, 253, 331], "log": [3, 4, 8, 40, 174, 175, 176, 190, 191, 199, 209, 219, 220, 225, 229, 238, 239, 240, 245, 246, 247, 248, 249, 251, 252, 253, 255, 256, 257, 258, 260, 266, 297, 298, 300, 304, 316, 324, 325, 326, 329, 330, 331, 335, 336, 340], "mission": 3, "irrespect": [3, 228, 229], "dmcontrol": [3, 329], "jumanji": [3, 86, 87], "natur": [3, 329, 332], "special": [3, 324, 329, 332, 341], "framework": [3, 4, 9, 22, 91, 179, 340, 341], "Its": [3, 32, 77, 81, 95, 101, 114, 132, 144, 147, 148, 150, 152, 154, 228, 272], "success": [3, 53, 110, 147, 221, 330, 336, 338, 340], "been": [3, 5, 7, 8, 17, 18, 20, 21, 40, 65, 77, 81, 85, 95, 101, 126, 142, 143, 147, 179, 183, 217, 222, 224, 329, 330, 331, 332, 334, 335, 336, 338, 341], "foundat": [3, 5, 96, 97, 331, 335], "inspir": [3, 336], "gone": [3, 4, 5], "sometim": [3, 332, 341], "hard": [3, 7, 250, 330, 341], "adopt": [3, 5, 329, 341], "prefer": [3, 17, 20, 35, 38, 41, 42, 133, 140, 255, 301, 324, 331, 335, 338], "moreov": 3, "maintain": [3, 5, 9, 336], "both": [3, 7, 32, 77, 78, 81, 95, 96, 97, 101, 110, 134, 148, 164, 166, 167, 181, 184, 185, 187, 192, 193, 214, 215, 216, 220, 227, 238, 240, 241, 245, 251, 252, 253, 255, 256, 257, 258, 260, 300, 324, 329, 331, 335, 336, 337, 338, 341], "concomittantli": 3, "problem": [3, 7, 8, 9, 16, 330, 331, 332, 335, 336, 338, 341], "decor": [3, 8, 11, 107, 253, 268, 269, 270, 271], "set_gym_backend": [3, 105, 322], "relev": [3, 40, 268, 269, 270, 271, 272, 336], "gym_backend": [3, 107, 322], "env1": [3, 334], "path": [3, 6, 7, 32, 34, 35, 36, 38, 39, 41, 42, 45, 52, 53, 54, 55, 56, 57, 58, 77, 81, 95, 101, 107, 132, 152, 189, 304, 326, 330], "venv": 3, "python3": [3, 6, 7, 10], "site": [3, 6, 7, 55, 107], "__init__": [3, 7, 91, 107, 108, 115, 118, 165, 176, 179, 183, 189, 233, 239, 241, 245, 251, 256, 258, 260, 326, 336, 341], "env2": [3, 334], "_env": [3, 6, 341], "classic_control": 3, "pendulumenv": [3, 336], "0x15147e190": 3, "0x1629916a0": 3, "further": [3, 5, 331], "tell": [3, 4, 7, 96, 97, 329, 332, 335], "mo_gymnasium": [3, 89, 105], "handi": 3, "side": [3, 4, 341], "v0": [3, 80, 81, 82, 86, 87, 88, 89, 114, 148, 154, 316], "26": [3, 330, 331, 334, 336, 337, 338], "fun": [3, 11, 107, 331, 335], "reveal": 4, "bug": [4, 340], "curv": 4, "won": [4, 32, 77, 78, 81, 95, 101, 132, 152, 304, 320, 330, 331], "exploit": 4, "video": [4, 9, 287, 300, 320, 335], "cv": 4, "flip": 4, "imag": [4, 7, 75, 112, 132, 146, 152, 187, 329, 330, 335, 337, 341], "correspondingli": 4, "prescript": 4, "tune": [4, 126, 335, 337], "coeffici": [4, 40, 126, 335], "bonu": [4, 238, 240, 252, 255], "beta": [4, 35, 41, 61, 251, 252, 329, 330, 338, 340], "reduc": [4, 6, 27, 143, 330, 331], "downstream": [4, 329], "formul": [4, 335], "ob": [4, 8, 26, 28, 35, 38, 41, 42, 52, 53, 54, 55, 56, 66, 67, 69, 108, 115, 116, 118, 128, 146, 160, 163, 192, 193, 226, 233, 239, 241, 245, 251, 256, 258, 260, 268, 269, 270, 271, 330, 334, 336, 340, 341], "rate": [4, 154, 267, 330, 331, 335], "gradient": [4, 32, 77, 81, 95, 101, 148, 182, 191, 195, 199, 208, 209, 238, 240, 241, 245, 251, 252, 253, 255, 256, 257, 258, 260, 267, 268, 269, 270, 271, 304, 329, 331, 335, 336], "norm": [4, 8, 304, 329, 330, 331, 335, 336], "easier": [4, 324, 329], "behavior": [4, 32, 77, 81, 95, 101, 148, 251, 331, 332, 335, 336], "local": [4, 7, 10, 16, 21, 32, 77, 81, 95, 101, 148, 192, 193, 201, 210, 266, 292, 335], "optima": 4, "sens": [4, 336], "product": [4, 9, 179, 180, 183, 184, 318, 319], "sum": [4, 21, 31, 33, 69, 139, 190, 191, 210, 248, 267, 274, 325, 329, 330, 331, 332, 335, 336, 341], "track": [4, 13, 14, 16, 17, 18, 19, 20, 21, 42, 65, 139, 154, 224, 292, 297, 330, 332, 335, 336, 338], "stat": [4, 128, 308, 320, 330, 331], "w": [4, 110, 112, 135, 146, 179, 224, 287, 330, 332, 338], "r": [4, 32, 108, 113, 128, 180, 229, 237, 267, 324, 330, 336, 341], "yield": [4, 16, 21, 32, 77, 81, 95, 101, 253, 329], "insight": 4, "auxiliari": 4, "credit": 4, "futur": [4, 32, 34, 36, 39, 77, 81, 95, 101, 132, 148, 152, 187, 238, 239, 241, 242, 244, 245, 246, 247, 251, 253, 255, 256, 257, 258, 260, 266, 323, 340], "past": [4, 330, 338], "spars": [4, 332], "ineffici": 4, "ad": [4, 13, 14, 16, 32, 35, 38, 41, 42, 49, 52, 53, 54, 55, 56, 61, 77, 81, 95, 101, 139, 148, 194, 195, 224, 238, 240, 242, 246, 252, 255, 258, 266, 330, 332, 338, 341], "intermedi": [4, 181, 185, 220, 329, 337], "instrument": 4, "greatli": 4, "soccer": 4, "kick": 4, "ball": 4, "likelihood": [4, 329], "discov": 4, "score": [4, 40], "undesir": 4, "though": [4, 77, 81, 95, 101, 187, 331, 335], "unintention": 4, "valuabl": 4, "idiosyncrat": 4, "subtask": 4, "hierarch": [4, 340], "individu": [4, 18, 19, 20, 21, 32, 45, 77, 81, 95, 101, 329, 335], "select": [4, 15, 35, 38, 41, 42, 52, 53, 54, 55, 56, 96, 97, 103, 108, 110, 111, 114, 115, 116, 118, 119, 120, 121, 122, 123, 125, 126, 127, 131, 133, 134, 136, 139, 140, 142, 143, 144, 145, 147, 150, 151, 153, 154, 165, 181, 185, 219, 226, 303, 329, 338], "fall": [4, 52], "explicit": [4, 11, 45, 186, 338], "mechan": [4, 32, 77, 81, 95, 101, 148, 330, 336], "curios": 4, "magnitudin": 4, "domin": 4, "smaller": [4, 34, 36, 39, 77, 81, 95, 101, 183, 251, 331, 335], "addition": 4, "timestep": [4, 40, 52, 136, 273, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 335], "realli": 4, "larg": [4, 27, 34, 36, 39, 115, 118, 150, 330, 331, 335, 338], "huge": [4, 193, 332], "std": [4, 128, 154, 196, 200, 217, 329, 341], "torchrl": [4, 5, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 322, 328, 332, 333, 334, 337, 338, 339], "initi": [4, 7, 13, 14, 16, 17, 18, 19, 20, 21, 32, 34, 36, 39, 40, 77, 81, 95, 101, 128, 132, 144, 147, 148, 150, 155, 165, 179, 180, 183, 184, 189, 194, 195, 217, 221, 222, 224, 238, 239, 241, 242, 244, 245, 246, 247, 251, 252, 253, 254, 255, 256, 257, 258, 260, 266, 313, 320, 330, 332, 336, 341], "estim": [4, 66, 67, 119, 126, 214, 215, 216, 238, 239, 240, 241, 242, 244, 245, 246, 247, 251, 252, 253, 254, 255, 256, 257, 258, 260, 261, 266, 268, 269, 270, 271, 272, 273, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 325, 330, 331, 332, 334, 335, 336, 337, 338, 340, 341], "encount": [4, 323, 330, 336], "unseen": 4, "extrins": 4, "wrong": 4, "bonus": 4, "denser": 4, "prior": [4, 204, 248, 335], "freshli": 4, "doesn": [4, 11, 92, 115, 118], "drop": [4, 65, 67, 163], "meant": [4, 91], "encourag": [4, 329, 330, 338], "measur": [4, 331], "novelti": 4, "revisit": 4, "previous": [4, 331, 341], "diminish": 4, "decreas": 4, "ideal": [4, 128, 336], "down": [4, 13, 14, 16, 17, 332], "anyth": 4, "try": [4, 7, 8, 9, 26, 28, 34, 36, 39, 330, 331, 332, 335, 336, 340, 341], "distil": 4, "nois": [4, 155, 195, 212, 224, 256, 260, 300, 320, 329], "exploratori": [4, 238, 240, 252, 255], "misalign": 4, "trade": 4, "unavoid": 4, "schedul": [4, 7, 40, 300, 331, 336], "divers": [4, 95, 101], "bootstrap": [4, 246, 269, 275, 276, 329, 332], "noisi": [4, 194, 195, 212, 324], "unstabl": [4, 182, 208, 209], "inher": 4, "stochast": [4, 126, 177, 195, 197, 204, 239, 243, 245, 251, 254, 256, 258, 324, 331, 335], "enemi": 4, "variabl": [4, 7, 8, 24, 25, 26, 27, 28, 29, 30, 31, 33, 44, 46, 47, 53, 55, 56, 103, 179, 180, 181, 183, 184, 185, 189, 214, 215, 216, 253, 256, 326, 330], "pomdp": [4, 338], "loos": [4, 324, 330, 331], "nonexist": 4, "architectur": [4, 173, 335], "sequenc": [4, 13, 14, 16, 17, 26, 28, 30, 31, 35, 37, 38, 40, 43, 45, 57, 63, 69, 70, 72, 109, 110, 111, 112, 115, 117, 118, 122, 124, 128, 129, 133, 134, 135, 136, 137, 138, 139, 143, 145, 146, 147, 154, 166, 167, 174, 176, 179, 183, 187, 190, 191, 192, 193, 199, 202, 206, 218, 230, 231, 243, 286, 287, 299, 300, 301, 303, 304, 313, 324, 329, 331, 332, 334, 335, 341], "lstm": [4, 184, 185, 186, 196], "rel": [4, 144, 174, 207, 329, 330, 335, 338], "tend": 4, "stabl": [4, 9, 10], "compens": 4, "descent": [4, 195], "1000": [4, 38, 66, 67, 77, 81, 95, 101, 110, 154, 221, 224, 225, 229, 250, 329, 330, 331, 332, 337, 338], "minimum": [4, 95, 101, 137, 177, 196, 207, 208, 209, 232, 235, 237, 239, 245, 253, 254, 258, 295, 329, 331, 335], "manual": [4, 18, 20, 21, 329, 332, 338], "deviat": [4, 128, 154, 165, 177, 189, 194, 195, 217, 255, 260, 329, 335], "radic": 4, "begin": [4, 13, 14, 16, 18, 19, 20, 21, 179, 180, 183, 184], "stabil": [4, 123], "stage": [4, 329, 336], "never": 4, "prevent": [4, 26, 28, 182, 208, 209, 252, 255, 302, 338], "solv": [4, 9, 10, 323, 329, 330, 331, 335, 336, 338], "entir": [4, 192, 331, 336, 338], "submit": [4, 323, 340], "suffici": [4, 329], "system": [4, 5, 331, 335, 336], "adequ": [4, 156, 331, 335], "infeas": 4, "allevi": [4, 324], "prune": 4, "fire": [4, 32, 77, 81, 95, 101], "certain": [4, 18, 20, 21, 32, 45, 77, 81, 95, 101, 107, 123, 142, 148, 180, 184, 221, 252, 324, 329, 330, 331, 335, 341], "illeg": 4, "move": [4, 21, 32, 56, 77, 81, 95, 101, 114, 116, 132, 144, 147, 148, 150, 152, 154, 163, 187, 228, 302, 329, 330, 332, 340, 341], "chess": 4, "combin": [4, 147, 330, 338], "grasp": 4, "releas": [4, 7, 10, 32, 77, 81, 95, 101, 148, 258, 340], "top": [4, 69, 165, 189], "p": [4, 78, 99, 100], "wherein": 4, "cumul": [4, 139, 143, 165, 274, 331], "q": [4, 9, 77, 81, 95, 101, 169, 170, 171, 172, 175, 176, 178, 201, 202, 210, 216, 220, 226, 227, 239, 241, 242, 244, 245, 246, 250, 251, 256, 258, 260, 266, 313, 322, 329], "flow": [4, 329, 331, 335, 336, 338], "reparameter": [4, 174, 191, 199], "soft": [4, 250, 258, 259], "critic": [4, 8, 214, 223, 238, 240, 241, 245, 251, 252, 255, 256, 257, 258, 260, 329, 331], "clip": [4, 40, 113, 137, 240, 260, 304, 331, 335, 336], "oppos": [4, 45], "incorrect": 4, "thought": [4, 77, 81, 95, 101], "bound": [4, 17, 21, 25, 26, 32, 77, 81, 95, 101, 113, 127, 154, 203, 204, 213, 219, 220, 224, 225, 226, 227, 228, 229, 232, 260, 324, 329, 330, 331, 341], "region": 4, "squash": [4, 332, 340], "tanh": [4, 166, 167, 179, 180, 182, 183, 184, 187, 193, 207, 208, 209, 232, 331, 335, 336, 337, 340], "correct": [4, 34, 36, 39, 126, 307, 331, 332], "prob": [4, 190, 191, 199, 331, 335], "rememb": 4, "remap": 4, "origin": [4, 8, 13, 14, 16, 17, 34, 36, 39, 40, 85, 116, 117, 126, 132, 148, 152, 179, 225, 228, 229, 250, 253, 255, 313, 329, 334, 336, 341], "real": [5, 229, 325, 332, 336], "histor": 5, "ceas": 5, "fork": 5, "farama": [5, 88, 89, 96, 97, 331, 336], "usag": [5, 7, 52, 53, 55, 56, 110, 119, 181, 185, 251, 258, 261, 324, 329, 330, 331, 332, 334, 335, 336, 337, 338, 340, 341], "bc": [5, 340], "break": [5, 13, 14, 16, 21, 32, 38, 42, 53, 55, 56, 57, 66, 67, 77, 81, 95, 101, 110, 136, 154, 330, 338, 340], "against": [5, 7, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 44, 46, 47, 77, 81, 95, 101, 156, 213, 219, 220, 225, 226, 227, 228, 229, 331, 335], "13": [5, 10, 11, 66, 67, 98, 153, 328, 329, 330, 331, 332, 335, 336, 339], "construct": [5, 32, 35, 38, 41, 42, 77, 81, 95, 96, 101, 115, 118, 156, 181, 185, 204, 229, 304, 324, 330, 331, 332, 336, 338, 341], "best": [5, 9, 85, 181, 185, 335, 338, 340], "gymwrapp": [5, 77, 81, 95, 101, 120, 140, 142, 153, 322, 331, 340], "feel": [5, 323, 340], "free": [5, 7, 115, 118, 238, 248, 255, 326, 331, 335, 340], "gladli": 5, "instruct": [6, 7, 10, 22, 52, 117, 119, 329, 330, 331, 332, 335, 338], "prepar": [6, 331], "conda": [6, 7, 323], "7": [6, 10, 27, 33, 35, 38, 41, 67, 143, 165, 166, 167, 186, 187, 189, 192, 274, 328, 329, 330, 335, 336, 338, 339, 340], "cmake": 6, "14": [6, 11, 56, 66, 67, 128, 329, 330, 331, 335, 336, 337, 338], "activ": [6, 7, 9, 166, 167, 173, 177, 187, 192, 193, 240, 252, 255, 324, 336, 340], "sim": 6, "bullet": 6, "physic": [6, 7, 95, 98, 326, 329, 335, 336], "headless": [6, 7], "cluster": [6, 7, 8, 18, 21, 323], "withbullet": 6, "forg": [6, 7], "aihabitat": 6, "nightli": 6, "y": [6, 7, 94, 186, 192, 211, 329, 331, 335], "git": [6, 7, 10], "facebookresearch": 6, "subdirectori": 6, "verbos": 6, "export": [6, 7], "magnum_log": 6, "quiet": 6, "habitat_sim_log": 6, "remov": [6, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 39, 44, 46, 47, 49, 77, 81, 95, 101, 141, 253, 335, 341], "command": [6, 7, 10, 331, 335, 336, 341], "readm": [6, 7], "md": [6, 7], "habitatenv": [6, 322], "_has_habitat": 6, "available_env": [6, 73, 74, 75, 76, 77, 80, 81, 82, 86, 87, 88, 89, 95, 99, 100, 101, 341], "startswith": [6, 325, 329], "oserror": 6, "libllvmlit": 6, "ionstal": 6, "pointer": [6, 78, 253, 329], "env_nam": [6, 73, 75, 80, 86, 88, 92, 98, 329, 331, 341], "llvmlite": 6, "config": [6, 7, 132, 152, 168, 173, 200, 308, 309, 310, 313, 314, 317], "var": [6, 7, 32, 77, 81, 95, 101, 148, 253, 258], "ld_preload": [6, 7], "8": [6, 7, 38, 55, 61, 66, 67, 74, 77, 81, 95, 101, 143, 166, 167, 169, 170, 178, 187, 214, 215, 216, 225, 228, 231, 251, 328, 329, 330, 335, 336, 337, 338, 339, 340], "bind": 6, "deactiv": [6, 7, 219], "importerror": [6, 7, 10], "usr": [6, 7, 10], "x86_64": [6, 7], "linux": [6, 7], "gnu": [6, 7], "libopengl": [6, 7], "undefin": [6, 7, 10, 32, 77, 81, 95, 101, 148, 253, 258, 338], "symbol": [6, 7, 10], "_glapi_tls_curr": [6, 7], "link": [6, 7, 330], "mujoco_env": [6, 7], "libglvnd": [6, 7], "glx": [6, 7], "cos7": [6, 7], "reinstal": [6, 7], "xvfbwrapper": [6, 7], "sysroot": [6, 7], "lib64": [6, 7], "libgldispatch": [6, 7], "offici": [7, 52], "stand": [7, 334, 336], "joint": [7, 330], "dynam": [7, 56, 251, 331, 336], "contact": [7, 37], "engin": [7, 98, 336], "biomechan": 7, "graphic": 7, "anim": [7, 335], "area": 7, "demand": [7, 341], "fast": [7, 9, 74, 134, 256, 329, 330, 331], "accur": [7, 52, 53, 55, 56, 330, 336, 338], "articul": 7, "recent": [7, 11, 153, 341], "acquir": [7, 331], "deepmind": [7, 8, 9, 75, 76, 119, 331], "whomev": 7, "licenc": 7, "incorpor": [7, 217, 221, 222, 224, 332, 336], "relianc": 7, "obsolet": 7, "seri": [7, 8, 33, 63, 69, 70, 72, 101, 127, 147, 287, 324, 325, 329, 330, 331, 335, 338, 341], "legaci": 7, "pro": [7, 323], "tip": [7, 323], "glfw": 7, "osmesa": 7, "egl": 7, "advic": [7, 341], "sudo": [7, 323], "enabl": [7, 8, 52, 58, 59, 71, 181, 185, 224, 300, 331, 335, 336, 338], "apt": [7, 335], "libglfw3": 7, "libglew2": 7, "libgl1": 7, "mesa": 7, "libosmesa6": 7, "awar": [7, 58, 59, 60, 68, 71, 330, 332], "workflow": [7, 214, 215, 216], "glew": 7, "mesalib": 7, "anaconda": 7, "libgl": 7, "cos6": 7, "menpo": 7, "glfw3": 7, "mujoco_gl": 7, "pyopengl_platform": 7, "pre": [7, 22, 32, 45, 59, 77, 81, 95, 101, 132, 150, 152, 341], "binari": [7, 24, 27, 33, 109, 176, 202, 219, 220, 226, 227, 242, 245, 266], "setup": [7, 85], "mkdir": 7, "cd": 7, "tag": [7, 287, 292, 320], "earlier": [7, 329, 331, 332, 335, 338], "roboti": 7, "download": [7, 10, 52, 53, 55, 56, 85, 132, 152, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 340, 341], "html": [7, 92], "wget": 7, "mujoco210": 7, "tar": 7, "gz": 7, "xf": 7, "charg": [7, 13, 14, 95, 101], "obtain": [7, 40, 77, 81, 95, 101, 132, 143, 152, 165, 201, 301, 329, 331, 335], "mjkei": 7, "txt": 7, "mjlib_path": 7, "home": [7, 34, 36, 45, 57], "bin": [7, 176, 220, 324], "libmujoco210": 7, "ld_library_path": 7, "mujoco_py_mujoco_path": 7, "mujoco_py_mjkey_path": 7, "reload": 7, "later": [7, 172, 225, 229, 329, 331, 338], "nvidia": [7, 85], "older": [7, 11], "hack": [7, 329], "line": [7, 32, 77, 81, 95, 101, 330, 335], "adatp": 7, "script": [7, 156, 313, 316, 320, 324, 325, 326, 329, 330, 331, 332, 334, 335, 336, 337, 338, 340, 341], "unnot": [7, 133], "until": [7, 21, 145, 147, 331, 332, 335], "complet": [7, 9, 65, 81, 110, 142, 323, 325, 329, 331, 334], "mujoco_pi": 7, "trigger": 7, "cymj": 7, "linuxgpuextensionbuild": 7, "filenam": [7, 330, 338], "troubleshoot": 7, "gl": 7, "h": [7, 110, 112, 135, 146, 179, 180, 181, 183, 184, 185, 189, 287, 330, 332, 338], "eglshim": 7, "fatal": 7, "No": 7, "directori": [7, 34, 36, 39, 45, 52, 53, 55, 56, 58, 292, 326], "devel": 7, "ubuntu": [7, 85], "libglew": 7, "dev": 7, "cento": 7, "yum": 7, "glu": 7, "38": [7, 330, 332, 335, 336, 338], "disappear": [7, 330, 332, 334], "libstdc": 7, "6": [7, 13, 14, 16, 17, 38, 55, 56, 67, 87, 99, 100, 128, 130, 143, 166, 167, 174, 180, 186, 187, 192, 193, 197, 207, 225, 233, 313, 328, 329, 330, 332, 335, 336, 338, 339, 340, 341], "glibcxx_3": 7, "29": [7, 329, 330, 331, 335, 336], "compil": [7, 32, 77, 81, 95, 101, 179, 180, 183, 184], "libosmesa": 7, "libgcc": 7, "Then": [7, 153, 331, 334], "filenotfounderror": 7, "errno": 7, "patchelf": 7, "fatalerror": 7, "gladloadgl": 7, "mj_env": 7, "912": 7, "glfwerror": 7, "65537": 7, "sovl": 7, "myscript": 7, "runtimeerror": [7, 8, 26, 28, 32, 77, 81, 95, 101, 127, 148, 258, 341], "job": [7, 18, 19, 20, 22], "slurm": 7, "mjrendercontext": 7, "pyx": 7, "46": [7, 330, 332, 336, 337], "114": [7, 336, 338], "_setup_opengl_context": 7, "opengl_context": 7, "130": [7, 336], "offscreenopenglcontext": 7, "fail": [7, 22, 26, 28, 108, 156], "opengl": [7, 335], "global": [7, 32, 77, 81, 95, 96, 97, 101, 201, 210, 225, 229, 266, 326, 329, 335], "cuda_visible_devic": 7, "id": [7, 23, 40, 224, 256, 290, 313], "slurm_step_gpu": 7, "enviro": [7, 10], "black": 7, "onscreen": 7, "101": [7, 336], "correctli": [7, 32, 77, 81, 95, 101], "lgl": 7, "libegl": 7, "x11": [7, 335], "xlib": 7, "libx11": 7, "xorg": 7, "loop": [8, 13, 14, 16, 17, 34, 36, 39, 81, 163, 217, 221, 222, 224, 255, 304, 326, 329, 330, 334, 338], "sketch": [8, 326], "_": [8, 35, 38, 41, 42, 52, 53, 54, 55, 56, 78, 85, 103, 111, 115, 117, 118, 126, 128, 134, 146, 154, 213, 228, 233, 237, 238, 239, 241, 245, 251, 255, 256, 258, 260, 268, 269, 270, 271, 329, 330, 331, 332, 335, 336, 338, 340], "n_training_step": 8, "datapoint": [8, 45, 338], "onlin": [8, 13, 17, 110, 173, 200, 238, 243, 254, 255, 295, 320, 331, 332, 335, 338], "n_data_per_train": 8, "no_grad": [8, 32, 77, 81, 95, 101, 126, 179, 180, 183, 184, 268, 269, 270, 271, 331, 332, 335], "replay_buff": [8, 35, 38, 41, 42, 52, 53, 54, 55, 56, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 301, 316, 329, 330, 331, 335, 338], "loss_fn": [8, 332, 340], "backward": [8, 32, 77, 81, 95, 101, 154, 179, 180, 183, 184, 238, 239, 241, 245, 251, 255, 256, 257, 258, 260, 329, 331, 332, 335, 336], "zero_grad": [8, 32, 77, 81, 95, 101, 326, 329, 331, 332, 335, 336], "backpropag": [8, 238, 239, 240, 245, 246, 247, 248, 249, 251, 252, 253, 255, 256, 257, 258, 260, 266, 335, 336], "differenti": [8, 45, 126, 268, 269, 270, 271, 332, 335, 336], "denomin": 8, "artifact": 8, "numer": [8, 38, 154, 182, 208, 209, 213, 219, 220, 225, 226, 227, 228, 229, 302, 331, 338, 341], "misconcept": 8, "freed": 8, "appear": [8, 33, 66, 67, 336, 338], "compuat": 8, "twice": 8, "fix": [8, 144, 239, 254, 258, 330, 336, 341], "retain_graph": 8, "discuss": [8, 9, 335], "inplac": [8, 32, 34, 36, 39, 77, 81, 95, 101, 148, 258, 329], "accumul": 8, "onto": [8, 33, 34, 36, 39, 160, 213, 217, 219, 220, 224, 225, 226, 227, 228, 229, 332, 336], "exclud": [8, 52, 55, 110, 120, 163, 201, 335, 338], "forward": [8, 32, 77, 81, 95, 101, 108, 110, 111, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 125, 126, 128, 131, 132, 133, 134, 136, 139, 140, 142, 143, 144, 145, 147, 150, 151, 153, 154, 166, 167, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 179, 180, 181, 183, 184, 185, 186, 187, 188, 192, 193, 194, 196, 197, 198, 200, 201, 203, 204, 206, 210, 211, 217, 218, 220, 221, 222, 224, 225, 227, 228, 229, 232, 233, 235, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 251, 252, 253, 254, 255, 256, 257, 258, 260, 266, 268, 269, 270, 271, 272, 325, 336, 340], "submodul": [8, 32, 77, 81, 95, 101, 105, 253], "param": [8, 32, 40, 77, 81, 91, 95, 101, 114, 115, 116, 120, 126, 134, 140, 142, 147, 174, 176, 207, 218, 225, 228, 231, 233, 253, 262, 265, 268, 269, 270, 271, 272, 329, 335, 336, 337, 340], "grad": [8, 32, 77, 81, 95, 101, 329, 331], "whose": [8, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 40, 44, 46, 47, 77, 81, 95, 96, 97, 101, 114, 132, 144, 147, 148, 150, 152, 196, 201, 228], "neg": [8, 13, 14, 16, 17, 18, 19, 20, 21, 35, 41, 61, 110, 122, 133, 149, 247, 325, 331, 335, 336], "ask": [8, 66, 67, 329, 331, 332, 335, 337, 341], "much": [8, 13, 14, 35, 41, 61, 95, 101, 252, 255, 331, 335, 336, 338, 341], "render": [8, 300, 329, 330, 331], "upon": [8, 336], "factor": [8, 32, 136, 182, 195, 208, 209, 217, 221, 222, 224, 239, 244, 246, 247, 249, 259, 274, 329, 330, 335, 338, 341], "fit": [8, 11, 128, 325, 326, 329], "bottlneck": 8, "brax": [8, 73, 74, 134, 341], "jax": [8, 11], "improperli": 8, "item": [8, 13, 26, 28, 32, 38, 45, 57, 69, 77, 81, 95, 101, 121, 148, 190, 191, 241, 242, 244, 258, 295, 325, 326, 329, 331, 332, 335, 336, 338], "underli": [8, 77, 81, 95, 101, 253, 336], "tedeiou": 8, "priorit": [8, 35, 41, 61, 241, 242, 244, 245, 251, 256, 258, 260, 329, 330], "amount": [8, 224, 330, 338], "contigu": [8, 55, 77, 81, 95, 101, 160, 331, 335, 336, 338, 340, 341], "costli": [8, 336], "concaten": [8, 21, 30, 31, 110, 111, 128, 147, 183, 187, 231, 329, 330, 335, 336, 338, 341], "constitut": [8, 330, 335, 336], "plain": 8, "profil": 8, "fulli": [8, 32, 77, 81, 95, 101, 180, 184, 330, 336, 338], "frequent": [8, 338], "program": [8, 251, 341], "functorch": [8, 10], "incl": 8, "suit": [8, 76, 331, 341], "mujoco_instal": 8, "valueerror": 8, "bad": 8, "fds_to_keep": 8, "expand": [8, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 36, 39, 44, 46, 47, 66, 67, 228, 231, 253, 335, 336, 340], "new_shap": 8, "permut": [8, 65, 130, 340, 341], "idea": [9, 256, 326, 332, 335], "introductori": 9, "intro": [9, 331, 332], "dai": [9, 340], "2022": [9, 10, 336, 340], "spin": 9, "deep": [9, 110, 169, 170, 171, 172, 175, 224, 238, 250, 258, 259, 329], "hug": 9, "syllabu": 9, "lectur": 9, "awesom": 9, "curat": 9, "succinct": 9, "summari": [9, 128, 154, 329, 330, 331, 332], "reddit": 9, "reagent": 9, "orient": [9, 56, 341], "baselines3": 9, "tf": 9, "bandit": [9, 94], "tensorflow": [9, 190, 191], "kera": 9, "acm": 9, "dopamin": 9, "prototyp": 9, "salina": 9, "sequenti": [9, 32, 77, 81, 95, 101, 126, 230, 231, 255, 324, 331, 332, 335, 336, 337, 341], "tianshou": 9, "eleg": 9, "rlpyt": 9, "rllib": 9, "industri": [9, 340], "grade": 9, "factori": [9, 43], "throughput": [9, 329], "cherri": 9, "jaxrl": 9, "space": [9, 33, 44, 77, 81, 95, 101, 113, 117, 160, 173, 176, 192, 198, 202, 213, 217, 219, 220, 222, 224, 225, 226, 227, 228, 229, 231, 232, 233, 242, 244, 245, 260, 266, 324, 330, 331, 332, 335, 336, 340, 341], "mbrl": [9, 91, 324], "rlmeta": 9, "light": 9, "elegantrl": 9, "cloud": 9, "mtrl": 9, "baselin": 9, "689": [10, 336], "_torchrl": 10, "_zn8pybind116detail11type_casterin2at6tensoreve4loadens_6handleeb": 10, "colab": [10, 331, 332, 335], "notebook": [10, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 340, 341], "24": [10, 55, 67, 330, 331, 336], "11": [10, 27, 33, 45, 58, 59, 67, 71, 78, 146, 165, 189, 328, 329, 330, 331, 332, 335, 336, 337, 339], "12": [10, 55, 58, 59, 67, 71, 99, 100, 328, 330, 331, 332, 335, 336, 338, 339], "pip": [10, 54, 335, 340, 341], "pip3": [10, 331, 332, 335], "extra": [10, 32, 77, 81, 95, 101, 110, 154, 163, 324, 331, 332, 338], "url": 10, "org": [10, 35, 56, 61, 110, 132, 150, 168, 169, 170, 171, 172, 173, 176, 177, 178, 183, 189, 190, 191, 195, 197, 198, 200, 201, 203, 204, 210, 220, 224, 238, 239, 242, 243, 244, 246, 247, 248, 249, 250, 251, 254, 255, 257, 258, 259, 268, 273, 281, 337], "whl": 10, "u": [10, 54, 179, 180, 183, 184, 336], "There": [10, 181, 185, 324, 326, 331, 332, 335, 336, 338, 341], "upgrad": 10, "relas": 10, "lib_version_her": 10, "module_nam": [11, 253], "str": [11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 52, 53, 54, 55, 56, 57, 58, 61, 75, 77, 79, 81, 94, 95, 96, 97, 98, 101, 103, 104, 105, 108, 110, 117, 119, 125, 126, 128, 132, 133, 135, 142, 143, 148, 150, 152, 153, 154, 157, 161, 163, 164, 165, 166, 167, 169, 170, 171, 172, 175, 176, 178, 181, 185, 186, 187, 188, 189, 192, 193, 194, 195, 196, 201, 202, 210, 213, 219, 220, 225, 226, 227, 228, 229, 232, 233, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 248, 249, 251, 252, 253, 254, 255, 256, 257, 258, 260, 263, 266, 267, 268, 269, 270, 271, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 305, 306, 308, 313, 314, 320, 330, 331], "callabl": [11, 13, 14, 16, 17, 18, 19, 20, 21, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 35, 38, 41, 42, 44, 45, 46, 47, 52, 53, 54, 55, 56, 77, 78, 81, 91, 95, 101, 107, 119, 237, 309, 310, 318, 319, 320, 330], "from_vers": 11, "to_vers": 11, "intersect": [11, 142], "vs": [11, 181, 185, 186, 340], "longer": [11, 330, 335, 338], "self": [11, 26, 28, 32, 34, 36, 39, 77, 81, 91, 95, 101, 108, 114, 115, 118, 132, 144, 147, 148, 150, 152, 165, 176, 189, 201, 210, 217, 221, 222, 225, 228, 233, 238, 239, 241, 242, 244, 245, 246, 247, 251, 253, 255, 256, 257, 258, 260, 266, 268, 269, 270, 271, 272, 326, 329, 330, 336, 340], "x": [11, 23, 26, 32, 38, 40, 67, 126, 146, 167, 176, 178, 179, 180, 181, 183, 184, 185, 186, 187, 189, 192, 193, 211, 219, 225, 226, 235, 237, 273, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 287, 304, 329, 331, 336, 338, 340], "23": [11, 55, 67, 330, 331, 336], "lambda": [11, 13, 14, 16, 17, 21, 22, 38, 77, 78, 81, 95, 101, 107, 126, 144, 211, 219, 226, 247, 249, 268, 271, 279, 280, 284, 285, 316, 325, 329, 330, 335, 338, 340, 341], "import_modul": 11, "27": [11, 330, 331, 336, 338], "get_class_that_defined_method": 11, "f": [11, 81, 184, 237, 268, 269, 270, 271, 272, 273, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 329, 330, 331, 332, 335, 336, 338, 341], "otherwis": [11, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 39, 43, 44, 45, 46, 47, 52, 57, 66, 67, 77, 81, 90, 95, 96, 97, 101, 103, 110, 117, 128, 143, 144, 145, 148, 154, 179, 182, 183, 192, 193, 208, 209, 219, 226, 232, 239, 248, 253, 254, 258, 300, 301, 326, 329, 330, 331, 332, 336, 341], "classmethod": [11, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 36, 39, 44, 46, 47, 150, 168, 200], "module_set": 11, "setters_dict": 11, "dict": [11, 13, 14, 16, 17, 18, 19, 20, 21, 22, 24, 26, 27, 28, 29, 30, 32, 34, 36, 39, 55, 77, 78, 81, 95, 96, 97, 101, 103, 104, 126, 144, 148, 153, 154, 166, 167, 168, 169, 170, 171, 172, 173, 178, 186, 187, 200, 225, 229, 258, 291, 292, 300, 309, 310, 313, 318, 319, 320, 329, 330, 331, 341], "setter": 11, "setter_dict": 11, "copi": [11, 18, 19, 20, 21, 32, 34, 36, 39, 40, 45, 77, 81, 95, 101, 134, 143, 148, 163, 181, 185, 218, 253, 258, 325, 329, 330, 332, 338], "kwd": 12, "policy_weight": [12, 13, 14, 16, 17, 19, 20], "tensordictbas": [12, 13, 14, 16, 17, 18, 19, 20, 21, 23, 26, 28, 29, 32, 41, 42, 52, 53, 54, 55, 56, 77, 79, 81, 95, 101, 108, 110, 111, 114, 115, 116, 119, 120, 121, 122, 125, 126, 131, 133, 134, 136, 139, 140, 142, 143, 144, 145, 147, 153, 154, 163, 164, 165, 181, 185, 188, 189, 217, 218, 220, 221, 222, 224, 227, 228, 229, 238, 239, 240, 241, 242, 243, 244, 245, 246, 251, 252, 253, 254, 255, 256, 257, 258, 260, 266, 267, 268, 269, 270, 271, 272, 304, 329, 336], "udpdat": [12, 13, 14, 16, 17, 19, 20], "create_env_fn": [13, 14, 16, 17, 18, 19, 20, 21, 78, 95, 101, 329, 340], "int": [13, 14, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 66, 67, 68, 69, 70, 71, 72, 75, 77, 81, 91, 95, 96, 97, 101, 103, 110, 111, 112, 117, 122, 123, 127, 128, 130, 132, 133, 135, 141, 142, 145, 148, 149, 150, 152, 156, 160, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 176, 177, 178, 179, 180, 182, 183, 184, 186, 187, 189, 190, 191, 192, 193, 194, 195, 197, 198, 200, 201, 202, 203, 204, 206, 207, 208, 210, 211, 217, 218, 219, 220, 221, 222, 224, 225, 227, 228, 229, 238, 239, 240, 245, 247, 248, 252, 253, 254, 255, 256, 260, 273, 274, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 295, 296, 297, 300, 301, 304, 306, 313, 314, 318, 319, 320, 336], "200": [13, 14, 16, 17, 21, 32, 77, 81, 95, 101, 102, 103, 136, 169, 170, 177, 203, 204, 329, 332, 336], "total_fram": [13, 14, 16, 17, 18, 19, 20, 21, 110, 136, 304, 307, 316, 326, 329, 330, 331, 332, 335, 338, 340], "device_typ": [13, 16, 27, 30, 33, 166, 167, 168, 169, 170, 171, 172, 178, 187, 194, 195, 200], "create_env_kwarg": [13, 14, 16, 17, 78, 92, 95, 101, 329], "postproc": [13, 14, 16, 17, 18, 19, 20, 21, 136, 330, 338], "explorationtyp": [13, 14, 16, 20, 21, 253, 300, 329, 330, 331, 332, 340], "interactiontyp": [13, 16, 18, 19, 20, 21, 158, 162, 225, 229, 300], "exploration_mod": [13, 16, 18, 19, 20, 322, 324], "preemptive_threshold": [13, 14], "float": [13, 14, 25, 27, 32, 33, 35, 40, 41, 46, 61, 77, 81, 95, 101, 110, 114, 115, 118, 126, 128, 132, 136, 137, 138, 143, 144, 146, 147, 148, 150, 152, 154, 174, 177, 179, 182, 183, 187, 190, 191, 194, 195, 203, 204, 207, 209, 217, 228, 232, 235, 236, 237, 238, 239, 244, 245, 248, 249, 250, 251, 254, 256, 258, 259, 260, 267, 273, 274, 275, 276, 277, 278, 279, 280, 281, 302, 329, 330, 338, 341], "num_thread": [13, 14, 34, 36, 39, 95, 101], "num_sub_thread": [13, 14, 95, 101], "datacollector": [13, 14, 16, 17, 225, 229, 255, 331], "recept": 13, "safe": [13, 14, 24, 25, 26, 27, 28, 29, 30, 31, 33, 44, 46, 47, 213, 217, 219, 220, 224, 225, 226, 227, 228, 229, 231, 324, 340], "stepcount": [13, 77, 81, 95, 101, 147, 329, 330, 331, 332, 335, 340], "env_mak": [13, 14, 16, 21, 316, 341], "50": [13, 14, 16, 21, 37, 40, 56, 66, 67, 328, 330, 331, 332, 334, 335, 336, 337, 338, 339], "2000": [13, 14, 16, 45, 84, 331, 338], "enumer": [13, 14, 16, 21, 32, 38, 42, 67, 77, 81, 95, 101, 261, 325, 329, 330, 331, 332, 338, 340], "int64": [13, 14, 16, 24, 27, 30, 34, 36, 37, 39, 40, 41, 43, 45, 53, 55, 56, 57, 77, 81, 90, 94, 95, 96, 97, 99, 100, 101, 119, 130, 136, 142, 176, 202, 219, 220, 224, 225, 226, 227, 324, 331, 332, 336, 338, 340, 341], "step_count": [13, 14, 16, 77, 81, 95, 101, 142, 331, 332, 340], "shutdown": [13, 14, 16, 17, 21, 329, 340], "del": [13, 14, 16, 329, 331, 334, 340, 341], "randompolici": [13, 14, 16, 18, 19, 20, 22, 110, 136, 322, 338], "lifespan": [13, 14, 16, 18, 19, 20, 330], "divis": [13, 14, 16, 18, 19, 20, 66, 67, 335], "endless": [13, 14, 16, 18, 19, 20], "dictionari": [13, 14, 16, 17, 18, 19, 20, 21, 26, 32, 34, 36, 39, 45, 66, 67, 77, 81, 95, 101, 103, 144, 148, 225, 229, 258, 300, 318, 319, 320, 326, 330, 331, 336, 341], "span": [13, 14, 16, 17, 18, 19, 20, 21], "n_step": [13, 14, 16, 17, 18, 19, 20, 21, 32, 330, 331, 335], "ignor": [13, 14, 16, 17, 18, 19, 20, 21, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 37, 43, 44, 46, 47, 77, 81, 95, 101, 117, 120, 140, 146, 166, 167, 168, 169, 170, 171, 172, 173, 175, 177, 178, 179, 180, 181, 183, 184, 185, 186, 187, 190, 191, 192, 193, 196, 197, 198, 200, 203, 204, 206, 211, 217, 218, 220, 221, 222, 224, 227, 232, 235, 268, 338], "mainli": [13, 14, 16, 17, 18, 19, 20, 21, 40, 324, 335, 336], "round": [13, 14, 16], "closest": [13, 14, 16], "post": [13, 14, 16, 18, 19, 20, 21, 32, 53, 77, 81, 95, 101], "multistep": [13, 14, 16, 18, 19, 20, 21, 322, 330], "return_same_td": [13, 14, 16], "cautious": [13, 14, 16, 255], "whole": [13, 14, 16, 26, 28, 32, 45, 77, 81, 95, 101, 148, 225, 258, 295, 329, 331], "boolm": [13, 14], "update_policy_weight_": [13, 14], "sync": [13, 14, 18, 19, 20, 21, 306, 316, 326, 329, 340], "async": [13, 14, 18, 19, 20, 21, 153, 329, 340], "ratio": [13, 14, 40, 329, 331], "finish": [13, 14, 21, 81, 136, 341], "rest": [13, 14, 324, 331, 332, 336, 340], "earli": [13, 14, 81, 142, 340], "thread": [13, 14, 34, 36, 39, 92, 95, 101], "equal": [13, 14, 66, 67, 92, 95, 101, 127, 128, 166, 167, 175, 179, 181, 183, 185, 187, 193, 259, 263, 295, 318, 319, 329, 331, 337], "plu": [13, 14, 40, 95, 101, 336], "safeti": [13, 14, 91, 95, 101], "harm": [13, 14, 95, 101], "ordereddict": [13, 14, 16, 17, 21, 32, 77, 81, 95, 101, 148, 154, 258, 330], "form": [13, 14, 17, 32, 35, 38, 41, 42, 52, 53, 54, 55, 56, 77, 81, 95, 101, 154, 179, 181, 183, 185, 237, 238, 240, 252, 255, 304, 324, 335], "worker0": [13, 14, 17], "state_dict0": [13, 14, 17], "worker1": [13, 14, 17], "state_dict1": [13, 14, 17], "reset_idx": [13, 14, 17], "static_se": [13, 14, 16, 17, 21, 77, 81, 95, 101, 148], "integ": [13, 14, 16, 17, 23, 30, 31, 32, 33, 40, 47, 68, 77, 81, 95, 101, 119, 123, 128, 142, 166, 167, 187, 192, 193, 251, 258, 338], "increment": [13, 14, 16, 17, 77, 81, 95, 101, 252], "env_fn": [13, 14, 16, 17, 78, 318, 319], "env_fn_parallel": [13, 14, 16, 17], "100": [13, 14, 16, 17, 32, 35, 38, 41, 42, 43, 52, 53, 54, 55, 56, 58, 59, 77, 81, 95, 101, 113, 119, 128, 136, 142, 192, 220, 296, 316, 328, 330, 331, 332, 334, 335, 336, 337, 338, 339, 340, 341], "300": [13, 14, 16, 17, 66, 67, 171, 172, 336], "out_se": [13, 14, 16, 17, 341], "shut": [13, 14, 16, 17], "irrevers": [13, 14, 17], "kwarg": [14, 16, 17, 21, 25, 26, 32, 52, 58, 59, 69, 71, 73, 74, 75, 76, 77, 78, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 106, 108, 114, 132, 141, 144, 147, 148, 149, 151, 152, 155, 165, 166, 167, 169, 170, 171, 172, 175, 178, 181, 182, 185, 187, 188, 189, 192, 193, 199, 207, 209, 211, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 251, 252, 253, 254, 255, 256, 257, 258, 260, 262, 266, 267, 268, 269, 270, 271, 272, 287, 291, 292, 294, 297, 304, 309, 310, 313, 317, 318, 319, 325, 331, 335], "tupl": [15, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 41, 42, 44, 46, 47, 52, 53, 54, 55, 56, 77, 81, 95, 101, 108, 117, 119, 125, 126, 128, 133, 163, 169, 175, 176, 181, 184, 185, 186, 187, 193, 196, 200, 201, 202, 219, 220, 226, 227, 232, 238, 239, 241, 245, 247, 251, 253, 255, 256, 257, 258, 260, 268, 269, 270, 271, 287, 298, 300, 302, 311, 312, 329], "rand": [15, 24, 25, 26, 27, 28, 29, 30, 31, 33, 35, 38, 41, 42, 44, 46, 47, 52, 53, 54, 55, 56, 74, 87, 91, 108, 115, 118, 165, 189, 225, 238, 239, 241, 242, 244, 245, 251, 255, 256, 258, 260, 336, 340, 341], "describ": [15, 44, 111, 147, 207, 208, 242, 290, 325, 329, 331, 335, 336, 341], "tensor_spec": [15, 108, 164, 245, 255, 257], "boundedtensorspec": [15, 22, 26, 77, 81, 95, 101, 221, 222, 224, 225, 232, 238, 239, 241, 251, 255, 256, 258, 260, 322, 331, 335, 336, 340, 341], "cube": 15, "envcreat": [16, 22, 316, 317, 320, 322, 329, 330, 340, 341], "interruptor": 16, "_interruptor": 16, "start_collect": 16, "stop_collect": 16, "preeptiv": 16, "chunk": 16, "policy_state_dict": 16, "env_state_dict": 16, "close": [16, 17, 81, 92, 126, 238, 240, 252, 255, 329, 334, 336, 340], "pin_memori": [17, 35, 38, 41, 42, 52, 53, 54, 55, 56, 131, 329, 340], "regular": [17, 34, 36, 39, 77, 81, 95, 101, 148, 202, 220, 226, 227, 228, 229, 246, 306, 322, 326, 329, 330, 338, 341], "mere": 17, "greater": [17, 66, 67, 181, 185, 329, 330, 340], "sent": [17, 58, 59, 71, 154], "server": 17, "postprocessor": 17, "collector_class": [18, 19, 20, 21], "collector_kwarg": [18, 19, 20, 21], "num_workers_per_collector": [18, 19, 20, 21], "slurm_kwarg": [18, 19, 20], "update_after_each_batch": [18, 20, 21], "max_weight_update_interv": [18, 19, 20, 21], "tcp_port": [18, 19, 20, 22], "deriv": [18, 19, 20, 21, 304], "string": [18, 19, 20, 32, 37, 45, 57, 77, 81, 95, 101, 107, 132, 142, 152, 181, 185, 219, 225, 226, 237, 286, 303, 313, 325, 329, 331, 332], "respect": [18, 19, 20, 32, 77, 81, 95, 101, 109, 114, 115, 118, 132, 133, 144, 147, 148, 150, 152, 179, 183, 192, 204, 228, 233, 299, 331, 332, 335], "subnod": [18, 19, 20, 21], "readi": [18, 20, 21, 323, 330, 331, 334, 338], "serv": [18, 20, 21, 83, 338, 341], "fashion": [18, 20, 21, 34, 36, 39, 67], "executor": [18, 19, 20], "distributed_back": [18, 19], "ucc": [18, 19], "overwritten": [18, 20, 21, 53, 55, 56, 77, 81, 95, 101, 122], "seen": [18, 20, 21, 325, 329, 330, 332, 335, 338], "turn": [18, 20, 21, 34, 36, 39, 124, 149, 153, 219, 300, 325, 329, 330, 332, 336, 337], "submitit_delai": [18, 22], "former": [18, 19, 20, 35, 38, 41, 42, 52, 77, 81, 95, 101, 166, 167, 168, 169, 170, 171, 172, 173, 175, 177, 178, 179, 180, 181, 183, 184, 185, 186, 187, 192, 193, 196, 197, 198, 200, 203, 204, 206, 211, 217, 218, 220, 221, 222, 224, 227, 232, 235, 329], "whilst": [18, 19, 20], "latter": [18, 19, 20, 32, 52, 77, 81, 95, 101, 166, 167, 168, 169, 170, 171, 172, 173, 175, 177, 178, 179, 180, 181, 183, 184, 185, 186, 187, 192, 193, 196, 197, 198, 200, 203, 204, 206, 211, 217, 218, 220, 221, 222, 224, 227, 232, 235, 255, 318, 319], "homonym": [18, 19, 20, 336], "visit": [18, 19, 20], "facebookincub": [18, 19, 20], "tcp": [18, 19, 20, 22], "port": [18, 19, 20, 22], "10003": [18, 19, 20, 22], "worker_rank": [18, 19, 21], "update_interv": 19, "frequenc": [19, 329], "visible_devic": 20, "tensorpipe_opt": 20, "experiment": [20, 33, 225, 229], "tensorpiperpcbackendopt": 20, "_td": [21, 78], "ray_init_config": 21, "remote_config": 21, "num_collector": [21, 318, 319, 329, 330], "coordin": 21, "init": [21, 32, 77, 81, 95, 101, 329, 330, 331], "autodetect": 21, "similarli": [21, 32, 65, 77, 81, 95, 101, 192, 230, 231, 251, 341], "num_cpu": 21, "num_gpu": 21, "1024": [21, 173, 330, 338], "equat": [21, 81, 224, 237, 240, 259, 331, 336], "exce": [21, 331, 338], "indefinit": [21, 51], "raydistributedcollector": 21, "distributed_collector": 21, "10000": [21, 304, 329, 331, 332], "add_collector": 21, "local_polici": 21, "remote_collector": 21, "stop_remote_collector": 21, "num_job": 22, "tcpport": 22, "submitit_main_conf": 22, "slurm_cpus_per_task": 22, "32": [22, 26, 35, 38, 41, 42, 52, 53, 54, 55, 56, 67, 99, 100, 102, 103, 166, 167, 168, 169, 170, 173, 178, 187, 192, 193, 197, 198, 200, 201, 210, 266, 329, 330, 331, 332, 336, 337, 338, 340, 341], "slurm_gpus_per_nod": 22, "slurm_partit": 22, "timeout_min": 22, "submitit_collection_conf": 22, "delai": 22, "jump": 22, "host": [22, 32, 77, 81, 95, 101, 114, 132, 144, 147, 148, 150, 152, 228], "wherea": [22, 117, 253, 326], "satellit": 22, "rendezv": 22, "hang": 22, "forev": 22, "default_config": [22, 168, 173, 200, 218], "default_slurm_conf_main": 22, "default_slurm_conf": 22, "rollout_tensordict": 23, "durat": [23, 335], "meta": [23, 44, 52, 79, 326, 331, 335, 338], "aren": [23, 143, 332], "assert_is_in": [24, 25, 26, 27, 28, 29, 30, 31, 33, 44, 46, 47], "belong": [24, 25, 26, 27, 28, 29, 30, 31, 33, 44, 46, 47, 153, 154, 324, 329, 335], "encod": [24, 25, 26, 27, 28, 29, 30, 31, 33, 35, 38, 41, 42, 44, 46, 47, 117, 198, 199, 203, 237, 324, 330, 331, 332, 336, 338], "ndarrai": [24, 25, 26, 27, 28, 29, 30, 31, 33, 44, 46, 47, 81, 224, 232], "ignore_devic": [24, 25, 26, 27, 28, 29, 30, 31, 33, 44, 46, 47], "np": [24, 25, 26, 27, 28, 29, 30, 31, 33, 44, 46, 47, 81, 232, 336], "cast": [24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 44, 46, 47, 57, 77, 81, 95, 101, 114, 115, 118, 126, 132, 144, 147, 148, 150, 152, 154, 228, 313, 341], "least": [24, 25, 26, 27, 28, 29, 30, 31, 33, 44, 46, 47, 113, 341], "complient": [24, 25, 26, 27, 28, 29, 30, 31, 33, 44, 46, 47], "singleton": [24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 44, 46, 47, 166, 167, 187, 205, 206], "implements_for_spec": [24, 25, 26, 27, 28, 29, 30, 31, 33, 44, 46, 47], "torch_funct": [24, 25, 26, 27, 28, 29, 30, 31, 33, 44, 46, 47], "tensor_to_index": [24, 25, 26, 27, 28, 29, 30, 31, 33, 44, 46, 47], "is_in": [24, 25, 26, 27, 28, 29, 30, 31, 33, 44, 46, 47, 341], "project": [24, 25, 26, 27, 28, 29, 30, 31, 33, 44, 46, 47, 117, 181, 183, 213, 217, 219, 220, 224, 225, 226, 227, 228, 229, 324, 340, 341], "uniform": [24, 25, 26, 27, 28, 29, 30, 31, 33, 35, 41, 44, 46, 47, 61], "unbound": [24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 36, 39, 44, 46, 47, 144, 160, 336, 338], "squeez": [24, 25, 26, 27, 28, 29, 30, 31, 33, 44, 46, 47, 110, 141, 143, 166, 167, 205, 206, 329, 336, 338], "dim": [24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 36, 39, 44, 46, 47, 66, 110, 111, 130, 144, 149, 154, 184, 186, 206, 211, 320, 330, 331, 336, 338], "to_numpi": [24, 25, 26, 27, 28, 29, 30, 31, 33, 44, 46, 47], "transformed_in": [24, 25, 26, 27, 28, 29, 30, 31, 33, 44, 46, 47, 147, 148, 196, 207, 320], "check_spec_encod": [24, 25, 26, 27, 28, 29, 30, 31, 33, 44, 46, 47], "to_one_hot": [24, 27, 30], "hot": [24, 27, 30, 31, 33, 96, 97, 103, 108, 117, 176, 199, 202, 219, 220, 226, 227, 238, 239, 241, 242, 244, 245, 246, 247, 251, 253, 255, 256, 257, 258, 260, 266, 332], "to_one_hot_spec": [24, 27, 30], "onehotdiscretetensorspec": [24, 27, 176, 202, 219, 226, 242, 244, 245, 266, 322, 324], "convert": [24, 27, 30, 31, 32, 33, 34, 36, 39, 45, 77, 81, 95, 101, 114, 115, 118, 132, 144, 147, 148, 150, 152, 154, 228, 237, 253, 329, 330, 331, 336, 338], "type_check": [24, 25, 26, 27, 28, 29, 30, 31, 33, 44, 46, 47], "fill": [24, 25, 26, 27, 28, 29, 30, 31, 33, 44, 46, 47, 144, 153, 185, 332, 336, 337], "upper": [25, 127], "unnam": 26, "pixels_spec": 26, "observation_vector_spec": 26, "33": [26, 32, 77, 81, 95, 101, 166, 167, 187, 328, 330, 336, 339], "composite_spec": 26, "observation_vector": [26, 111, 313, 329], "randn": [26, 34, 35, 36, 38, 39, 41, 42, 52, 53, 54, 55, 56, 58, 59, 66, 67, 71, 128, 160, 168, 173, 176, 179, 180, 183, 184, 186, 190, 191, 192, 196, 199, 200, 202, 213, 214, 215, 216, 218, 219, 225, 226, 228, 231, 232, 233, 238, 239, 241, 242, 244, 245, 251, 255, 256, 257, 258, 260, 268, 269, 270, 271, 303, 324, 340, 341], "td_project": 26, "is_empti": [26, 28, 336], "include_nest": [26, 28], "leaves_onli": [26, 28], "itemsview": 26, "immedi": [26, 28, 32, 77, 81, 95, 101, 267, 335], "children": [26, 28, 32, 77, 81, 95, 101], "keysview": [26, 28], "reflect": [26, 28, 96, 97, 153, 163, 253, 307, 330, 331, 332, 335], "lock_": [26, 28], "recurs": [26, 28, 32, 48, 49, 77, 81, 95, 101, 253], "succeed": [26, 28, 331, 335, 336], "selected_kei": [26, 28, 140, 329], "unlock_": [26, 28], "unlock": [26, 28, 34, 36, 39], "valuesview": 26, "onehottensorspec": 27, "action_valu": [27, 33, 175, 176, 202, 219, 220, 226, 227, 245, 253, 266, 324, 332], "arang": [27, 33, 176, 191, 219, 295, 324, 338], "argmax": [27, 176, 202, 220, 227], "chosen_action_valu": [27, 33, 201, 202, 210, 226, 227, 266, 324, 332], "outcom": [27, 33, 174, 207], "lazi": [28, 29, 49, 50, 77, 81, 95, 101, 103, 132, 150, 166, 194, 230, 231, 329, 330, 334, 338, 341], "represent": [28, 29, 32, 77, 81, 95, 101, 132, 150, 152, 329, 336, 337, 341], "drawn": [28, 29, 144, 221, 225, 229, 331, 335], "lazystackedtensordict": [28, 77, 81, 91, 95, 101, 334, 340], "heterogen": [28, 29, 90, 96, 97, 156, 192, 193, 329, 330], "semant": [28, 29, 324], "thrown": [29, 32, 77, 81, 95, 101, 338], "nvec": [30, 31], "cardin": [30, 31, 176, 202, 219, 220, 227, 331], "ax": [30, 194, 195], "m": [30, 32, 77, 81, 95, 101, 117, 229, 324, 330, 336], "ts": [30, 31], "multionehotdiscretetensorspec": [30, 242, 245, 266, 322], "use_regist": [31, 33], "to_categor": [31, 33], "to_categorical_spec": [31, 33], "multidiscretetensorspec": [31, 322], "gamma": [32, 136, 189, 238, 239, 241, 242, 244, 245, 246, 247, 249, 251, 253, 255, 256, 257, 258, 260, 261, 262, 266, 267, 268, 269, 270, 271, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 316, 325, 329, 330, 331, 335, 340], "sutton": [32, 325, 335], "1988": 32, "tempor": [32, 181, 185, 189, 269, 270, 275, 276], "44": [32, 328, 330, 332, 336, 338, 339], "discount": [32, 78, 136, 239, 244, 246, 247, 249, 267, 268, 269, 270, 271, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 325, 330, 331, 335], "ahead": [32, 341], "add_modul": [32, 77, 81, 95, 101], "child": [32, 77, 81, 95, 101], "fn": [32, 37, 77, 81, 95, 101, 196, 318, 319], "init_weight": [32, 77, 81, 95, 101], "fill_": [32, 77, 81, 95, 101, 330, 332, 341], "net": [32, 77, 81, 95, 101, 186, 193, 238, 239, 245, 251, 255, 256, 257, 258, 313, 316, 330, 336, 337, 340], "in_featur": [32, 77, 81, 95, 101, 114, 132, 144, 147, 148, 150, 152, 166, 167, 169, 170, 171, 172, 186, 187, 193, 194, 195, 214, 228, 242, 244, 340], "out_featur": [32, 77, 81, 91, 95, 101, 114, 132, 144, 147, 148, 150, 152, 165, 166, 167, 169, 170, 171, 172, 177, 178, 181, 185, 186, 187, 189, 192, 193, 194, 195, 214, 219, 228, 242, 244, 324, 329, 332, 340], "bia": [32, 77, 81, 95, 101, 114, 132, 144, 147, 148, 150, 152, 166, 167, 177, 179, 180, 181, 183, 184, 185, 187, 193, 194, 195, 196, 221, 222, 224, 228, 235, 236, 237, 253, 258, 325, 329, 330, 331, 332, 335, 340], "requires_grad": [32, 77, 81, 95, 101, 126], "bfloat16": [32, 77, 81, 95, 101], "datatyp": [32, 77, 81, 95, 101, 338], "member": [32, 77, 81, 95, 101, 253], "xdoctest": [32, 77, 81, 95, 101, 114, 132, 144, 147, 148, 150, 152, 228, 253, 258], "skip": [32, 77, 81, 95, 101, 123, 148, 156, 225, 229, 253, 258, 268, 269, 270, 271, 286, 287, 297, 300, 329, 330, 331, 336], "buf": [32, 77, 81, 95, 101], "20l": [32, 77, 81, 95, 101, 253], "1l": [32, 77, 81, 95, 101, 253], "5l": [32, 77, 81, 95, 101, 253], "__call__": [32, 37, 77, 81, 95, 101, 229, 326], "doubl": [32, 46, 77, 81, 95, 101, 114, 115, 116, 118, 132, 144, 147, 148, 150, 152, 228, 242, 246, 250, 256, 259, 266, 329, 330, 331, 332, 341], "eval": [32, 77, 81, 95, 101, 148, 154, 329, 330, 331], "evalu": [32, 77, 81, 95, 101, 148, 174, 190, 191, 199, 209, 256, 309, 310, 330, 331], "dropout": [32, 77, 81, 95, 101, 148, 179, 181, 183, 185, 187, 332], "batchnorm": [32, 77, 81, 95, 101, 148], "disabl": [32, 77, 81, 95, 101, 148, 182, 209, 329], "comparison": [32, 77, 81, 95, 101, 148, 253, 329, 330], "similar": [32, 77, 81, 95, 96, 97, 101, 114, 132, 144, 147, 148, 150, 151, 152, 154, 214, 216, 225, 228, 229, 325, 329, 330, 331, 332, 336, 341], "confus": [32, 77, 81, 95, 101, 148], "extra_repr": [32, 77, 81, 95, 101], "shift": [32, 235, 268, 269, 270, 271, 331], "nontermin": 32, "original_reward": 32, "newli": [32, 77, 81, 95, 101], "OR": 32, "get_buff": [32, 77, 81, 95, 101], "throw": [32, 34, 36, 39, 77, 81, 95, 101, 341], "docstr": [32, 77, 81, 95, 101], "get_submodul": [32, 77, 81, 95, 101], "explan": [32, 77, 81, 95, 101], "qualifi": [32, 77, 81, 95, 101], "referenc": [32, 77, 81, 95, 101], "attributeerror": [32, 77, 81, 95, 101], "invalid": [32, 77, 81, 95, 101, 104, 190, 191], "resolv": [32, 77, 81, 95, 101], "someth": [32, 77, 81, 90, 95, 101, 323, 330, 331, 336, 341], "get_extra_st": [32, 77, 81, 95, 101, 154], "set_extra_st": [32, 77, 81, 95, 101, 154], "picklabl": [32, 77, 81, 95, 101, 154], "pickl": [32, 77, 81, 95, 101, 154], "get_paramet": [32, 77, 81, 95, 101], "sai": [32, 77, 81, 95, 101, 192, 337, 341], "net_b": [32, 77, 81, 95, 101], "net_c": [32, 77, 81, 95, 101], "conv": [32, 77, 81, 95, 101, 166, 167, 330], "conv2d": [32, 77, 81, 95, 101, 167, 192, 340], "kernel_s": [32, 77, 81, 95, 101, 166, 167, 169, 170, 192, 197, 330, 340], "stride": [32, 77, 81, 95, 101, 166, 167, 169, 170, 178, 192, 330, 340], "diagram": [32, 77, 81, 95, 101], "degre": [32, 77, 81, 95, 101], "named_modul": [32, 77, 81, 95, 101], "o": [32, 77, 81, 95, 101, 184], "transit": [32, 52, 67, 77, 81, 95, 101, 234, 329, 332, 336, 338], "half": [32, 77, 81, 95, 101, 114, 132, 144, 147, 148, 150, 152, 228, 329], "ipu": [32, 77, 81, 95, 101], "strict": [32, 34, 36, 39, 77, 81, 95, 101, 148, 258], "descend": [32, 77, 81, 95, 101, 148, 258], "persist": [32, 77, 81, 95, 101, 148, 163, 258], "enforc": [32, 65, 77, 81, 95, 101, 148, 230, 258, 336], "preserv": [32, 77, 81, 95, 101, 148, 258], "missing_kei": [32, 77, 81, 95, 101, 148, 258], "unexpected_kei": [32, 77, 81, 95, 101, 148, 258], "namedtupl": [32, 77, 81, 95, 101, 148, 258], "duplic": [32, 65, 77, 81, 95, 101, 242, 246, 253, 266], "l": [32, 77, 81, 95, 101, 179, 183, 267, 331, 336], "idx": [32, 77, 81, 95, 101], "named_buff": [32, 77, 81, 95, 101], "remove_dupl": [32, 77, 81, 95, 101, 253], "prepend": [32, 77, 81, 95, 101, 253], "running_var": [32, 77, 81, 95, 101], "named_children": [32, 77, 81, 95, 101], "conv4": [32, 77, 81, 95, 101], "conv5": [32, 77, 81, 95, 101], "memo": [32, 77, 81, 95, 101], "named_paramet": [32, 77, 81, 95, 101, 126, 253], "register_backward_hook": [32, 77, 81, 95, 101], "removablehandl": [32, 77, 81, 95, 101], "deprec": [32, 77, 81, 95, 101, 148, 157, 161, 175, 222, 238, 240, 242, 245, 246, 251, 252, 255, 256, 257, 258, 266, 268, 269, 270, 271, 276, 341], "favor": [32, 77, 81, 95, 101, 331], "register_full_backward_hook": [32, 77, 81, 95, 101], "register_buff": [32, 77, 81, 95, 101], "running_mean": [32, 77, 81, 95, 101], "alongsid": [32, 77, 81, 95, 101, 335], "num_featur": [32, 77, 81, 95, 101], "register_forward_hook": [32, 77, 81, 95, 101, 176, 202], "with_kwarg": [32, 77, 81, 95, 101], "always_cal": [32, 77, 81, 95, 101], "posit": [32, 35, 38, 41, 42, 52, 53, 54, 55, 56, 77, 81, 95, 101, 122, 123, 141, 142, 145, 148, 149, 196, 258, 325, 331, 335, 336, 338], "signatur": [32, 77, 81, 95, 101, 114, 132, 144, 147, 148, 150, 152, 228, 325, 329, 336], "register_module_forward_hook": [32, 77, 81, 95, 101], "regardless": [32, 77, 81, 95, 101, 240, 252, 255], "register_forward_pre_hook": [32, 77, 81, 95, 101], "invok": [32, 77, 81, 95, 101], "And": [32, 77, 81, 95, 101], "forward_pr": [32, 77, 81, 95, 101], "register_module_forward_pre_hook": [32, 77, 81, 95, 101], "grad_input": [32, 77, 81, 95, 101], "grad_output": [32, 77, 81, 95, 101], "subsequ": [32, 77, 81, 95, 101, 332], "technic": [32, 77, 81, 95, 101, 330, 332], "caller": [32, 77, 81, 95, 101], "register_module_full_backward_hook": [32, 77, 81, 95, 101], "register_full_backward_pre_hook": [32, 77, 81, 95, 101], "backward_pr": [32, 77, 81, 95, 101], "register_module_full_backward_pre_hook": [32, 77, 81, 95, 101], "register_load_state_dict_post_hook": [32, 77, 81, 95, 101], "incompatible_kei": [32, 77, 81, 95, 101], "clear": [32, 77, 81, 85, 95, 101, 296], "register_modul": [32, 77, 81, 95, 101, 326], "alia": [32, 77, 81, 95, 101], "register_paramet": [32, 77, 81, 95, 101], "register_state_dict_pre_hook": [32, 77, 81, 95, 101], "keep_var": [32, 34, 36, 39, 77, 81, 95, 101, 148, 258], "requires_grad_": [32, 77, 81, 95, 101], "autograd": [32, 77, 81, 95, 101, 148, 258], "freez": [32, 77, 81, 95, 101], "finetun": [32, 77, 81, 95, 101], "gan": [32, 77, 81, 95, 101], "share_memori": [32, 77, 78, 81, 95, 101, 329], "share_memory_": [32, 77, 81, 95, 101, 340], "destin": [32, 34, 36, 39, 77, 81, 95, 101, 115, 116, 118, 148, 150, 154, 163, 258, 287], "averag": [32, 77, 81, 95, 101, 148, 154, 224, 247, 248, 258, 302, 329, 331], "shallow": [32, 77, 81, 95, 101, 148, 258, 332], "pleas": [32, 53, 77, 81, 95, 96, 97, 101, 110, 145, 148, 258, 323], "detach": [32, 77, 81, 95, 101, 148, 253, 258, 268, 269, 270, 271, 329], "non_block": [32, 77, 81, 95, 101, 114, 132, 144, 147, 148, 150, 152, 228, 332], "memory_format": [32, 77, 81, 95, 101, 114, 132, 144, 147, 148, 150, 152, 228], "channels_last": [32, 77, 81, 95, 101, 114, 132, 144, 147, 148, 150, 152, 228], "complex": [32, 77, 81, 95, 101, 114, 132, 144, 147, 148, 150, 152, 228, 329, 330], "integr": [32, 77, 81, 95, 101, 114, 132, 144, 147, 148, 150, 152, 172, 181, 185, 189, 228, 324, 335, 336, 337], "unchang": [32, 77, 81, 95, 101, 114, 117, 132, 144, 147, 148, 150, 152, 221, 228, 301, 329, 338], "tri": [32, 77, 81, 95, 101, 114, 132, 144, 147, 148, 150, 152, 228], "pin": [32, 77, 81, 95, 101, 114, 132, 144, 147, 148, 150, 152, 228], "4d": [32, 77, 81, 95, 101, 114, 132, 144, 147, 148, 150, 152, 228], "ignore_w": [32, 77, 81, 95, 101, 114, 132, 144, 147, 148, 150, 152, 228], "1913": [32, 77, 81, 95, 101, 114, 132, 144, 147, 148, 150, 152, 228], "3420": [32, 77, 81, 95, 101, 114, 132, 144, 147, 148, 150, 152, 228], "5113": [32, 77, 81, 95, 101, 114, 132, 144, 147, 148, 150, 152, 228], "2325": [32, 77, 81, 95, 101, 114, 132, 144, 147, 148, 150, 152, 228], "torch_doctest_cuda1": [32, 77, 81, 95, 101, 114, 132, 144, 147, 148, 150, 152, 228], "gpu1": [32, 77, 81, 95, 101, 114, 132, 144, 147, 148, 150, 152, 228], "1914": [32, 77, 81, 95, 101, 114, 132, 144, 147, 148, 150, 152, 228], "5112": [32, 77, 81, 95, 101, 114, 132, 144, 147, 148, 150, 152, 228, 336], "2324": [32, 77, 81, 95, 101, 114, 132, 144, 147, 148, 150, 152, 228], "float16": [32, 77, 81, 95, 101, 114, 132, 144, 147, 148, 150, 152, 180, 184, 228], "cdoubl": [32, 77, 81, 95, 101, 114, 132, 144, 147, 148, 150, 152, 228], "3741": [32, 77, 81, 95, 101, 114, 132, 144, 147, 148, 150, 152, 228], "j": [32, 35, 61, 77, 81, 95, 101, 114, 132, 144, 147, 148, 150, 152, 228, 326], "2382": [32, 77, 81, 95, 101, 114, 132, 144, 147, 148, 150, 152, 228], "5593": [32, 77, 81, 95, 101, 114, 132, 144, 147, 148, 150, 152, 228, 336], "4443": [32, 77, 81, 95, 101, 114, 132, 144, 147, 148, 150, 152, 228], "complex128": [32, 77, 81, 95, 101, 114, 132, 144, 147, 148, 150, 152, 228], "6122": [32, 77, 81, 95, 101, 114, 132, 144, 147, 148, 150, 152, 228], "1150": [32, 77, 81, 95, 101, 114, 132, 144, 147, 148, 150, 152, 228], "to_empti": [32, 77, 81, 95, 101], "dst_type": [32, 77, 81, 95, 101], "xpu": [32, 77, 81, 95, 101], "set_to_non": [32, 77, 81, 95, 101], "unidimension": 33, "keepdim": 33, "user_regist": 33, "priori": 33, "definit": [33, 68, 192], "uniqu": [33, 66, 67, 110, 119, 143, 144, 145, 338], "discretebox": [33, 77, 81, 95, 101, 331, 335, 341], "chosen_data": [34, 57], "rewarddata": [34, 57, 322], "rejected_data": [34, 57], "from_dataset": [34, 36, 57], "dataset_nam": [34, 36, 40, 45, 57, 94], "max_length": [34, 36, 37, 43, 45, 57], "550": [34, 36, 40, 45, 57, 66, 67, 336], "root_dir": [34, 36, 45, 57], "from_disk": [34, 36, 45, 57], "num_work": [34, 36, 45, 57, 92, 95, 101, 329, 330], "carperai": [34, 36, 40, 45], "openai_summarize_comparison": [34, 36, 45], "sequen": [34, 36], "cach": [34, 36, 45, 52, 53, 55, 56, 57, 66, 77, 81, 95, 101, 115, 118, 132, 148, 152, 296, 337], "load_from_disk": [34, 36, 45, 57], "load_dataset": [34, 36, 45, 57], "attention_mask": [34, 36, 37, 39, 40, 43, 45, 57], "memorymappedtensor": [34, 36, 45, 58, 337], "92534": 34, "input_id": [34, 36, 37, 39, 40, 43, 45, 57], "end_scor": [34, 39, 40, 57], "sub_data": [34, 36], "from_dict": [34, 36, 39, 45], "batch_dim": [34, 36, 39, 45, 320], "determin": [34, 35, 36, 39, 41, 52, 61, 77, 81, 95, 101, 132, 152, 192, 224, 330, 335], "input_dict": [34, 36, 39], "exclusinv": [34, 36, 39], "__maximum__": [34, 36, 39], "toler": [34, 36, 39, 174, 207], "sie": [34, 36, 39], "input_td": [34, 36, 39], "from_tensordict": [34, 36, 39], "non_tensordict": [34, 36, 39], "_no_default_": [34, 36, 39], "getattr": [34, 36, 39], "tensorclass": [34, 36, 39, 57, 58, 59, 71], "from_flatten": [34, 36, 39], "attemptedli": [34, 36, 39], "memmap": [34, 36, 39, 58, 95, 101, 154, 301, 338], "copy_exist": [34, 36, 39], "return_earli": [34, 36, 39], "mimic": [34, 36, 39, 77, 81, 95, 101], "renam": [34, 36, 39, 134, 136, 163, 329], "cross": [34, 36, 39, 165], "anymor": [34, 36, 39, 148, 228], "tensordictfutur": [34, 36, 39], "deepli": [34, 36, 39], "insid": [34, 36, 39, 341], "memmap_": [34, 36, 39, 154], "memmap_lik": [34, 36, 39], "contentless": [34, 36, 39], "1_000_000": [34, 35, 36, 38, 39, 41, 42, 52, 53, 54, 55, 56, 66, 329, 332], "alloc": [34, 36, 39, 59, 190, 191, 329], "setattr": [34, 36, 39], "tent": [34, 36, 39, 45], "to_tensordict": [34, 36, 39, 332], "unbind": [34, 36, 39, 181, 185], "alpha": [35, 41, 61, 166, 167, 192, 239, 245, 254, 256, 258, 329, 338, 340], "ep": [35, 41, 61, 154, 224, 240, 259, 302, 329, 330, 332], "1e": [35, 41, 61, 154, 174, 177, 196, 207, 329, 330, 331, 335], "08": [35, 41, 61, 329, 330, 336], "collate_fn": [35, 38, 41, 42, 52, 53, 54, 55, 56, 338, 340], "prefetch": [35, 38, 41, 42, 52, 53, 54, 55, 56, 57, 329, 330, 332, 338], "schaul": [35, 61], "quan": [35, 61], "antonogl": [35, 61], "silver": [35, 61], "2015": [35, 61], "arxiv": [35, 56, 61, 110, 132, 150, 168, 169, 170, 171, 172, 173, 176, 177, 178, 183, 189, 195, 197, 198, 200, 201, 203, 204, 210, 220, 224, 238, 239, 242, 243, 244, 246, 247, 248, 249, 250, 251, 254, 255, 258, 259, 268, 273, 281, 337], "ab": [35, 56, 61, 132, 150, 154, 168, 173, 177, 178, 183, 189, 195, 197, 198, 200, 201, 203, 204, 210, 238, 239, 242, 243, 244, 247, 248, 249, 250, 251, 254, 255, 258, 337], "1511": [35, 61, 178], "05952": [35, 61], "expon": [35, 41, 61], "\u03b1": [35, 41, 61], "delta": [35, 41, 61, 179, 183, 207, 225, 229, 322, 325], "null": [35, 41, 61, 109], "max_siz": [35, 38, 41, 42, 58, 59, 60, 68, 71], "1_000": [35, 38, 41, 42, 338], "merg": [35, 38, 41, 42, 52, 53, 54, 55, 56, 336], "mini": [35, 38, 41, 42, 52, 53, 54, 55, 56, 335], "decid": [35, 38, 41, 42, 340], "meth": [35, 38, 41, 42, 253, 336], "incompat": [35, 38, 41, 42, 338], "drop_last": [35, 38, 41, 42, 65, 67], "return_info": [35, 38, 41, 42, 52, 53, 54, 55, 56, 338], "tensordictprioritizedreplaybuff": [35, 322, 340], "simplifi": [35, 336, 338], "manual_se": [35, 38, 41, 42, 55, 56, 66, 67, 108, 117, 128, 136, 139, 143, 145, 190, 191, 199, 213, 220, 221, 222, 224, 232, 238, 239, 241, 251, 258, 335, 336, 340, 341], "_weight": [35, 41, 338, 340], "arrai": [35, 40, 119, 179, 180, 183, 184, 329, 338], "update_prior": [35, 61, 301, 326, 330, 338, 340], "36278465": 35, "tempfil": [35, 38, 41, 42, 45, 52, 53, 54, 55, 56, 316, 329, 330, 338], "tqdm": [35, 38, 41, 42, 52, 53, 54, 55, 56, 304, 329, 331, 332, 335, 336], "randomsampl": [35, 38, 41, 42, 52, 53, 54, 55, 56, 322, 329], "td_error": [35, 38, 41, 42, 52, 53, 54, 55, 56, 241, 242, 244, 245, 246, 251, 253, 256, 258, 260, 266, 329, 338, 340], "update_tensordict_prior": [35, 38, 41, 42, 52, 53, 54, 55, 56, 329, 338, 340], "temporarydirectori": [35, 38, 41, 42, 45, 52, 53, 54, 55, 56, 329, 330, 338], "tmpdir": [35, 38, 41, 42, 45, 52, 53, 54, 55, 56, 329, 330], "rb_load": [35, 38, 41, 42, 52, 53, 54, 55, 56], "cursor": [35, 38, 41, 42, 52, 53, 54, 55, 56], "insert_transform": [35, 38, 41, 42, 52, 53, 54, 55, 56], "insert": [35, 38, 41, 42, 52, 53, 54, 55, 56, 63, 69, 70, 72, 149], "prompt_rindex": [36, 37, 40], "label": [36, 37, 40, 45, 329, 338], "os": [36, 45, 57, 330], "cpu_count": [36, 45, 57], "promptdatatldr": 36, "116722": 36, "prompt": [37, 40], "return_tensordict": [37, 43], "recip": [37, 77, 81, 95, 101, 166, 167, 168, 169, 170, 171, 172, 173, 175, 177, 178, 179, 180, 181, 183, 184, 185, 186, 187, 192, 193, 196, 197, 198, 200, 203, 204, 206, 211, 217, 218, 220, 221, 222, 224, 227, 232, 235], "text": [37, 40, 43, 53, 179, 180, 183, 184, 224, 331], "tensodict": [37, 43], "orign": [37, 43], "valid_sampl": 37, "identifi": 37, "eough": 37, "toknen": 37, "meet": 37, "criterion": 37, "autotoken": [37, 43, 45], "from_pretrain": [37, 40, 43], "gpt2": [37, 40, 43, 45, 168, 173, 200], "pad_token": [37, 43], "eos_token": 37, "enough": [37, 338], "inde": [37, 117, 331, 336], "roundrobinwrit": [38, 42, 52, 53, 54, 55, 56, 322], "Not": 38, "ref_model": 40, "reward_model": [40, 234], "kl_coef": 40, "max_new_token": 40, "score_clip": 40, "kl_schedul": 40, "klcontrollerbas": 40, "num_step": 40, "causal": 40, "sentenc": 40, "frozen": [40, 126], "kl": [40, 126, 248, 252], "penalti": [40, 252], "strai": 40, "far": [40, 182, 208, 209, 336, 341], "calcul": [40, 136, 179, 244], "gpt2rewardmodel": 40, "get_dataload": [40, 322], "promptdata": [40, 322], "gpt2lmheadmodel": 40, "dl": 40, "block_siz": [40, 57], "tensorclass_typ": [40, 57], "openai_summarize_tldr": 40, "config_class": 40, "model_path": 40, "rollout_from_model": 40, "rollout_from_data": 40, "600": [40, 336, 338], "reward_kl": [40, 126], "reward_raw": 40, "sample_log_prob": [40, 214, 215, 216, 225, 229, 231, 255, 313, 331, 335, 340], "create_rollout_td": 40, "log_prob": [40, 174, 190, 191, 199, 209, 229], "log_ratio": 40, "replic": 40, "rindex": 40, "multipli": [40, 179, 183, 239, 240, 245, 252, 254, 255, 256, 258, 302, 329], "term": [40, 126, 183, 184, 194, 195, 237, 238, 245, 306, 330, 331, 335], "subtract": [40, 143], "ve": [40, 329, 332], "eo": 40, "limit": [40, 91, 110, 126, 329, 330, 332, 335, 336], "generation_config": 40, "generationconfig": 40, "ti": [40, 277, 278, 279, 280, 282, 283, 284, 285, 330], "log_probs_gen": 40, "logprobs_of_label": 40, "priority_kei": [41, 42, 242, 245, 246, 251, 253, 256, 258, 260, 266, 338, 340], "reduct": [41, 61], "prioritizedreplaybuff": [41, 322, 340], "min": [41, 61, 207, 208, 209, 218, 224, 239, 240, 245, 254, 256, 258, 330, 331, 335], "median": [41, 61, 225, 229], "include_info": [41, 42, 52, 53, 54, 55, 56], "kw": [42, 63, 70], "int32": [42, 66, 87, 160], "huggingfac": [43, 56, 223], "co": [43, 119, 336], "doc": [43, 330, 335], "pad_trunc": 43, "am": 43, "worri": 43, "me": 43, "reassur": 43, "ok": 43, "tokenizer_fn": 45, "tensordicttoken": [45, 322], "pre_tokenization_hook": 45, "valid_s": 45, "tokenizer_class": 45, "tokenizer_model_nam": 45, "tokein": 45, "condit": [45, 143, 219, 220, 226, 227, 237, 329, 336, 338], "elementwis": 45, "vocabulari": 45, "loader": [45, 331], "185068": 45, "dataset_to_tensordict": 45, "data_dir": 45, "nestedkei": [45, 66, 67, 108, 109, 110, 111, 112, 113, 115, 117, 118, 119, 120, 122, 124, 125, 128, 129, 130, 133, 134, 135, 136, 137, 138, 139, 140, 143, 144, 145, 146, 147, 150, 154, 163, 164, 217, 218, 221, 222, 224, 229, 242, 266, 287], "valid_mask_kei": 45, "conver": 45, "undergon": 45, "preprocess": [45, 330], "batch_dimens": 45, "filder": 45, "randint": [45, 146, 338], "data_memmap": 45, "exclus": [48, 49, 66, 67, 122, 179, 181, 183, 185, 190, 191, 219, 220, 226, 227, 259, 260, 268, 269, 270, 271, 272, 320, 324], "recurse_through_entri": 49, "recurse_through_stack": 49, "consolid": 49, "from_env": 52, "use_truncated_as_don": 52, "direct_download": 52, "terminate_on_end": 52, "env_kwarg": [52, 53, 55, 56, 318, 319, 329], "reconstruct": [52, 66, 67, 248, 329, 341], "recov": [52, 53, 55, 56, 66, 67, 217, 222, 224, 230, 251, 334], "regard": [52, 53, 55, 56, 176, 220, 238, 246, 255, 329, 331, 336], "get_dataset": 52, "qlearning_dataset": 52, "fewer": 52, "left": [52, 114, 115, 116, 120, 126, 132, 134, 140, 142, 145, 147, 150, 152, 221, 330, 331], "possess": 52, "unexpectedli": 52, "absent": [52, 77, 81, 95, 101], "traj_split": 52, "dataset_id": [52, 53, 55, 56], "observationnorm": [52, 154, 320, 329, 330, 331, 332, 340], "maze2d": 52, "umaz": 52, "128": [52, 67, 170, 173, 330, 332, 336, 337, 338], "loc": [52, 126, 128, 138, 182, 196, 208, 209, 214, 215, 216, 225, 229, 231, 238, 239, 251, 255, 256, 257, 258, 308, 313, 320, 324, 329, 330, 331, 332, 335, 340], "minari": 53, "available_dataset": [53, 55, 56, 66, 67], "currenrtli": 53, "minari_data": 53, "door": 53, "28": [53, 192, 328, 330, 331, 332, 336, 337, 339], "39": [53, 328, 330, 331, 336, 337, 339], "door_body_po": 53, "qpo": 53, "30": [53, 127, 203, 204, 329, 330, 331, 332, 335, 336], "qvel": 53, "dua": 54, "graff": 54, "2017": 54, "uci": 54, "archiv": 54, "ic": 54, "edu": 54, "ml": 54, "sklearn": 54, "adult_num": [54, 94], "adult_onehot": [54, 94], "mushroom_num": [54, 94], "mushroom_onehot": [54, 94], "covertyp": [54, 94], "shuttl": [54, 94], "magic": [54, 94], "roboset": 55, "h5": [55, 56], "mmap": [55, 56], "googl": [55, 73, 74, 331, 332, 335], "roboh": [55, 98], "excludetransform": [55, 140, 338], "fk1": 55, "v4": [55, 135, 277, 278, 279, 280, 282, 283, 284, 285, 329, 331, 337], "expert": 55, "fk1_microopenrandom_v2d": 55, "concis": 55, "17": [55, 67, 313, 329, 330, 331, 336, 337], "18": [55, 67, 99, 100, 102, 103, 193, 329, 330, 335, 336, 341], "15": [55, 67, 77, 81, 95, 101, 218, 224, 247, 329, 330, 331, 332, 336, 338], "19": [55, 66, 67, 69, 329, 330, 332, 336, 337], "75": [55, 330, 336, 337], "totensor": 56, "image_s": 56, "v": [56, 154, 179, 180, 183, 184, 214, 251, 258, 324, 329, 330], "npz": 56, "2206": 56, "04779": [56, 239, 244], "vd4rl": 56, "detect": 56, "squar": [56, 112, 182, 208, 209, 287], "rectangular": [56, 166, 167], "internet": 56, "connect": 56, "walker_walk": 56, "64px": 56, "is_init": [56, 125, 181, 185, 224, 332], "height": [56, 112, 135], "veloc": [56, 110, 335, 336, 341], "infinit": [57, 338], "three": [57, 324, 326, 331, 335, 336, 338, 341], "block": [57, 324, 332], "pairwisedataset": [57, 322], "256": [57, 173, 330, 331, 335, 336], "scratch_dir": [58, 329, 338], "mistak": [58, 59, 71], "myclass": [58, 59, 71], "foo": [58, 59, 71, 218, 338, 341], "bar": [58, 59, 71, 218, 297, 298, 300, 304, 326, 330], "attach": [58, 59, 60, 68, 71, 330], "entiti": [58, 59, 60, 68, 71], "auto": [59, 71, 153, 224, 239, 245, 254, 256, 258, 260, 325, 335], "zero_": [59, 71, 160], "max_capac": [61, 329, 338], "uniformli": [62, 253, 341], "roundrobin": [63, 70], "piec": [63, 70, 72, 329, 330, 331, 335, 336, 338], "consum": [65, 67, 330, 331, 335, 338], "incomplet": [65, 67], "fresh": 65, "caution": [65, 156, 341], "shuffl": [65, 335], "haven": [65, 337], "remain": [65, 116, 117, 126, 143, 195], "draw": [65, 221], "num_slic": [66, 67], "slice_len": [66, 67], "end_kei": [66, 67], "traj_kei": [66, 67], "cache_valu": 66, "truncated_kei": [66, 67, 136, 142], "strict_length": [66, 67], "slicesamplerwithoutreplac": [66, 322], "Will": [66, 287], "shorter": [66, 67], "Be": [66, 67], "320": [66, 67, 330, 336, 341], "700": [66, 67], "robosetexperiencereplai": [66, 67, 322], "dataid": [66, 67], "22": [66, 67, 153, 329, 330, 336, 337], "__len__": 68, "rank_kei": 69, "rank": [69, 165], "samplerwithoutreplac": [69, 322, 331, 335, 338], "get_insert_index": 69, "ant": [73, 74, 84, 337], "get_environ": 74, "87": [74, 329, 330, 335, 336, 337], "acrobot": [74, 341], "fetch": [74, 126, 337, 338], "task_nam": 75, "cheetah": [75, 76, 329], "frame_skip": [75, 76, 80, 81, 86, 88, 89, 123, 297, 300, 307, 326, 329, 330, 331, 340], "dm_control": [76, 329, 334, 341], "continuousbox": [77, 81, 95, 101, 160, 331, 335, 336, 340, 341], "unboundedcontinuoustensorspec": [77, 81, 91, 95, 101, 108, 115, 118, 144, 160, 165, 189, 213, 228, 231, 233, 257, 322, 331, 332, 335, 336, 341], "sort": [77, 81, 95, 101, 224], "depth": [77, 81, 91, 95, 101, 165, 166, 167, 169, 170, 171, 172, 177, 178, 187, 189, 192, 193, 197, 198, 219, 324, 330, 334, 335], "another_act": [77, 81, 95, 101], "mutabl": [77, 81, 95, 101], "batch_lock": [77, 79, 81, 95, 101, 144, 148, 336], "immut": [77, 81, 95, 101, 134, 148], "done_keys_group": [77, 81, 95, 101], "outer": [77, 81, 95, 101, 326, 329, 330, 341], "another_don": [77, 81, 95, 101], "empty_cach": [77, 81, 95, 101, 148], "fake_tensordict": [77, 81, 95, 101, 330], "fake": [77, 81, 95, 101, 329, 330], "afterward": [77, 81, 95, 101, 166, 167, 168, 169, 170, 171, 172, 173, 175, 177, 178, 179, 180, 181, 183, 184, 185, 186, 187, 192, 193, 196, 197, 198, 200, 203, 204, 206, 211, 217, 218, 220, 221, 222, 224, 227, 232, 235, 341], "silent": [77, 81, 95, 101, 166, 167, 168, 169, 170, 171, 172, 173, 175, 177, 178, 179, 180, 181, 183, 184, 185, 186, 187, 192, 193, 196, 197, 198, 200, 203, 204, 206, 211, 217, 218, 220, 221, 222, 224, 227, 232, 235], "braxenv": [77, 81, 95, 101, 134, 322], "envnam": [77, 81, 95, 101], "renametransform": [77, 81, 95, 101], "pipeline_st": [77, 81, 95, 101], "attibut": [77, 81, 95, 101], "speak": [77, 81, 95, 101, 329], "rand_act": [77, 81, 90, 95, 96, 97, 101], "_step": [77, 81, 95, 101, 108, 115, 118, 122, 134], "reset_kei": [77, 81, 95, 101, 110, 139, 143, 144, 145], "multitask": [77, 81, 95, 101], "multiag": [77, 81, 90, 95, 96, 97, 101, 164, 193, 201, 210, 266], "another_reward": [77, 81, 95, 101], "callback": [77, 81, 95, 101, 335], "auto_reset": [77, 81, 95, 101, 336], "auto_cast_to_devic": [77, 81, 95, 101, 335], "break_when_any_don": [77, 81, 95, 101, 335], "return_contigu": [77, 81, 95, 101, 156, 334], "soon": [77, 81, 95, 96, 97, 101], "ndim": [77, 81, 95, 101], "concomitt": [77, 81, 95, 101], "workspac": [77, 81, 95, 101], "prevail": [77, 81, 95, 101, 139, 164], "cartpol": [77, 81, 95, 101, 110, 139, 143, 330, 332, 338, 341], "creator": [78, 309, 310, 318, 319, 320], "substitut": [78, 143, 154], "vecnorm": [78, 320], "env_creat": [78, 329], "test_env1": 78, "observation_count": [78, 341], "test_env2": 78, "sleep": [78, 341], "ps": 78, "p1": 78, "p2": 78, "9934": 78, "env_str": 79, "info_dict_read": 81, "set_info_dict_read": 81, "put": [81, 103, 154, 320, 324, 330, 331, 332, 336], "read_act": 81, "read_don": 81, "reader": [81, 330], "interrupt": [81, 274], "nonsens": 81, "fallback": 81, "broken": [81, 156], "read_ob": 81, "dictat": [81, 225, 229, 255, 329, 336], "read_reward": 81, "baseinfodictread": 81, "info_dict": 81, "hoc": 81, "dict_read": 81, "default_info_dict_read": 81, "my_info_kei": 81, "some_env": 81, "placehold": [83, 119, 148], "secur": 83, "isaacgym": [84, 85], "isaacgymwrapp": [84, 322], "isaacgymenv": [85, 322], "webpag": 85, "isaac": 85, "essenc": 85, "04": [85, 328, 329, 330, 336, 337, 339], "snake": [86, 87], "6x6": [86, 87], "td1": [87, 238, 239, 241, 242, 244, 245, 246, 247, 251, 253, 255, 256, 257, 258, 260, 266, 329], "12x12": 87, "tsp50": 87, "tsp100": 87, "mo": [88, 89], "minecart": [88, 89], "mo_gym": 89, "qualnam": 90, "marl": [90, 104, 110, 145, 192, 335], "leverag": [90, 96, 97, 329, 335, 341], "neural": [90, 96, 97, 166, 167, 205, 228, 324, 330, 331, 332, 335, 336, 341], "group_map": [90, 96, 97, 103, 104], "constructiuon": [90, 96, 97], "premad": [90, 96, 97, 103, 266], "all_in_one_group": [90, 104], "agent_0": [90, 96, 97, 104], "agent_1": [90, 96, 97, 104], "agent_2": [90, 96, 97, 104], "agent_3": 90, "int8": [90, 96, 97], "one_group_per_ag": [90, 96, 97], "environn": 91, "constraint": [91, 331, 335], "mymbenv": [91, 165, 189], "world_model": [91, 165, 189, 248], "super": [91, 108, 115, 118, 165, 176, 189, 233, 239, 241, 245, 251, 256, 258, 260, 329, 336, 340], "hidden_observ": [91, 165, 189], "mlp": [91, 165, 166, 167, 169, 170, 171, 172, 181, 185, 186, 189, 193, 214, 219, 242, 244, 313, 324, 330, 334, 337, 340], "worldmodelwrapp": [91, 165, 189], "activation_class": [91, 165, 166, 167, 169, 170, 171, 172, 177, 178, 187, 189, 192, 193, 330, 335, 340], "relu": [91, 165, 173, 189, 196, 237], "activate_last_lay": [91, 165, 172, 187, 189], "run_type_check": 91, "less": [92, 211, 318, 319, 325, 331, 332, 338, 340], "readthedoc": 92, "en": 92, "python_interfac": 92, "task_id": 92, "106": [94, 336], "my_env_fun": [95, 101], "custom_attribute_list": [95, 101], "custom_attribut": [95, 101], "custom_method_list": [95, 101], "custom_method": [95, 101], "deploi": [95, 101], "slight": [95, 101, 330], "share_individual_td": [95, 101], "shared_memori": [95, 101], "policy_proof": [95, 101], "ll": [95, 101, 179, 180, 183, 184, 329, 330, 331, 332, 335, 341], "hidden": [95, 101, 177, 179, 180, 181, 183, 184, 185, 186, 197, 198, 203, 204, 214, 215, 216, 218, 228, 231, 240, 252, 255, 324, 332, 334, 340], "introduc": [95, 101, 179, 181, 183, 185, 224, 329], "drastic": [95, 338], "influenc": 95, "rule": [95, 115, 118, 229, 324, 331], "thumb": [95, 331], "suppos": [95, 300, 326, 341], "scenario": [95, 102, 103, 329, 335, 336], "myenv": [95, 115, 118], "update_kwarg": [95, 101], "pettingzoo": [96, 97], "pet": [96, 97], "zoo": [96, 97], "guid": [96, 97, 99, 100, 143, 323, 329, 335], "__": [96, 97], "aecenv": [96, 97], "use_mask": [96, 97], "dead": [96, 97], "compulsori": [96, 97], "adversary_0": [96, 97], "adversari": [96, 97], "marlgroupmaptyp": [96, 97, 103, 104, 322], "vectoris": [96, 97, 179, 180, 183, 184], "multiwalker_v9": 96, "return_st": [96, 97], "categorical_act": [96, 97, 99, 100, 103], "n_piston": [96, 97], "pistonball_v6": [96, 97], "piston": [96, 97], "piston_0": [96, 97], "piston_1": [96, 97], "piston_20": [96, 97], "aec": [96, 97], "tictactoe_v3": [96, 97], "player": [96, 97], "player_1": [96, 97], "player_2": [96, 97], "butterfli": 97, "parallel_env": [97, 329, 340, 341], "vikashplu": 98, "read_info": 98, "pars": [98, 338], "smacv2": [99, 100], "starcraft": [99, 100], "challeng": [99, 100, 336, 337], "v2": [99, 100, 263, 277, 278, 279, 280, 282, 283, 284, 285, 313, 332], "10gen_terran": [99, 100], "10gen_zerg": [99, 100], "10gen_protoss": [99, 100], "3m": [99, 100], "8m": [99, 100, 337], "25m": [99, 100], "5m_vs_6m": [99, 100], "8m_vs_9m": [99, 100], "10m_vs_11m": [99, 100], "27m_vs_30m": [99, 100], "mmm": [99, 100], "mmm2": [99, 100], "2s3z": [99, 100], "3s5z": [99, 100], "3s5z_vs_3s6z": [99, 100], "3s_vs_3z": [99, 100], "3s_vs_4z": [99, 100], "3s_vs_5z": [99, 100], "1c3s5z": [99, 100], "2m_vs_1z": [99, 100], "corridor": [99, 100], "6h_vs_8z": [99, 100], "2s_vs_1sc": [99, 100], "so_many_banel": [99, 100], "bane_vs_ban": [99, 100], "2c_vs_64zg": [99, 100], "old": [99, 100, 252, 341], "smac": [99, 100], "map_nam": [99, 100], "176": [99, 100, 336], "battle_won": [99, 100], "dead_al": [99, 100], "dead_enemi": [99, 100], "episode_limit": [99, 100], "322": [99, 100, 336], "Or": [99, 100, 192], "procedur": [99, 100], "distribution_config": [99, 100], "n_unit": [99, 100], "n_enemi": [99, 100], "team_gen": [99, 100], "dist_typ": [99, 100], "weighted_team": [99, 100], "unit_typ": [99, 100], "marin": [99, 100], "maraud": [99, 100], "medivac": [99, 100], "exception_unit_typ": [99, 100], "start_posit": [99, 100], "surrounded_and_reflect": [99, 100], "map_x": [99, 100], "map_i": [99, 100], "capability_config": [99, 100], "88": [99, 100, 329, 330, 336, 337, 338], "131": [99, 100, 336, 338], "starcraft2env": 100, "flock": [102, 103], "continuous_act": [102, 103, 335], "agent_collision_rew": [102, 103], "agent_distance_rew": [102, 103], "agent_nam": [103, 104], "agent_names_to_indices_map": 103, "unbatched_action_spec": [103, 335], "unbatched_observation_spec": 103, "unbatched_reward_spec": 103, "het_spec": 103, "het_specs_map": 103, "ca": 104, "environment4": 104, "get_group_map": 104, "sumbodul": 105, "model_bas": [106, 165, 189], "adapt": [108, 252, 329, 336], "masker": 108, "binarydiscretetensorspec": [108, 242, 245, 266, 322], "maskedenv": 108, "ones_lik": 108, "scatter": 108, "unsqueez": [108, 110, 111, 146, 149, 186, 329, 332, 335, 336], "_set_se": [108, 115, 118, 336], "transform_reward_spec": [109, 113, 114, 115, 116, 120, 126, 134, 137, 138, 140, 142, 147, 149], "padding_valu": [110, 190, 191], "as_invers": 110, "account": [110, 190, 191, 324, 330, 332, 338, 341], "movement": 110, "propos": [110, 119, 188, 250, 259, 313, 324, 332, 338], "pdf": [110, 168, 169, 170, 171, 172, 176, 200, 220, 224, 246, 256, 259, 268, 273, 281, 313], "1312": [110, 330], "5602": 110, "constant": [110, 128, 143, 326, 329, 331, 332, 341], "unsqueezetransform": [110, 336, 338], "consumpt": 110, "followin": 110, "pictur": 110, "pixels_trsf": [110, 338], "grayscal": [110, 330, 332, 338, 341], "data_exclud": [110, 338], "transform_observation_spec": [110, 111, 112, 113, 114, 115, 116, 119, 120, 122, 124, 125, 126, 128, 130, 134, 135, 139, 140, 142, 143, 144, 145, 146, 147, 149, 150, 153, 336], "del_kei": [111, 150, 334, 336], "unsqueeze_if_oor": 111, "observation_posit": 111, "observation_veloc": 111, "delet": 111, "key1": [111, 295, 303], "key2": [111, 295, 303], "crop": [112, 133, 287], "center": [112, 287], "width": [112, 135], "out_keys_inv": [113, 115, 118, 128, 129, 130, 134, 147, 336], "scalar": [113, 137, 170, 172, 194, 195, 217, 221, 222, 224, 235, 238, 239, 240, 245, 246, 247, 248, 249, 250, 251, 252, 253, 255, 256, 257, 258, 259, 260, 266, 268, 269, 270, 271, 273, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 324, 330, 336], "permit": [113, 122, 149], "rewardsc": [114, 148, 329, 330, 332], "rewardclip": 114, "transformed_env": [114, 147, 148], "transform_env_devic": [114, 116, 147], "transform_input_spec": [114, 115, 116, 117, 128, 130, 134, 139, 142, 143, 144, 147, 149, 151], "transform_output_spec": [114, 115, 116, 120, 126, 134, 140, 142, 147], "untouch": [114, 115, 116, 120, 126, 134, 140, 142, 147], "transformfull_done_spec": [114, 115, 116, 120, 126, 134, 140, 142, 147], "dtype_in": 115, "dtype_out": 115, "scan": [115, 118, 230, 231], "resp": [115, 118], "not_transform": [115, 118], "constructedw": [115, 118], "orig_devic": 116, "unspecifi": 116, "transform_done_spec": [116, 147], "num_actions_effect": 117, "max_act": 117, "include_forward": 117, "dimension": [117, 181, 185, 268, 273, 281, 335], "num_act": [117, 245], "action_out": 117, "_call": [117, 122, 336], "eol_kei": 119, "life": 119, "lives_kei": 119, "eol_attribut": 119, "unwrap": 119, "al": [119, 130, 165, 341], "breakout": 119, "v5": [119, 130, 341], "210": [119, 130, 336, 341], "160": [119, 130, 330, 336, 341], "eol_transform": 119, "eol": 119, "dqnloss": [119, 238, 239, 241, 244, 245, 246, 247, 250, 251, 253, 255, 256, 257, 258, 259, 260, 261, 266, 311, 322, 325, 330, 332], "action_spac": [119, 176, 202, 219, 220, 226, 227, 238, 239, 241, 242, 244, 245, 246, 247, 251, 253, 255, 256, 257, 258, 260, 266, 332], "register_kei": 119, "loss_or_advantag": 119, "lossmodul": [119, 304, 315, 316, 322], "valueestimatorbas": [119, 253, 322], "excluded_kei": 120, "finit": [121, 338], "first_dim": 122, "last_dim": 122, "allow_positive_dim": [122, 149], "th": [122, 149, 179, 183, 336], "frameskip": 122, "repeatedli": [123, 331, 335], "init_kei": 125, "tracker": 125, "coef": 126, "pi_curr": 126, "pi_0": 126, "overfit": 126, "fine": [126, 337], "probabilist": [126, 225, 322, 331, 340], "get_dist": [126, 229, 230], "mod": [126, 181, 185, 232, 332], "normalparamextractor": [126, 324, 331, 335], "probabilisticactor": [126, 214, 215, 216, 218, 238, 239, 243, 245, 251, 254, 255, 256, 257, 258, 260, 324, 329, 331, 335], "tanhnorm": [126, 214, 215, 216, 225, 231, 238, 239, 251, 255, 256, 257, 258, 260, 322, 331, 335, 340], "n_ob": [126, 238, 239, 241, 242, 244, 245, 251, 255, 256, 257, 258, 260], "n_act": [126, 238, 239, 241, 242, 244, 245, 251, 255, 256, 257, 258, 260], "return_log_prob": [126, 214, 215, 216, 225, 229, 231, 257, 324, 331, 335, 340], "apply_": 126, "copy_": [126, 329], "formulat": 126, "diverg": [126, 181, 185, 225, 229, 248, 252], "noop": [127, 340], "trial": 127, "op": [127, 153, 217, 221, 222, 306], "randomli": [127, 128, 144, 221, 225, 229, 335, 336, 338], "standard_norm": [128, 138, 329, 330, 332], "affin": [128, 138], "layer": [128, 154, 166, 167, 169, 170, 177, 179, 180, 181, 183, 184, 185, 187, 192, 193, 194, 195, 197, 198, 205, 206, 212, 223, 232, 324, 330, 331, 332, 337], "normal": [128, 154, 166, 167, 182, 187, 190, 191, 196, 208, 209, 217, 225, 229, 240, 252, 255, 300, 302, 320, 324, 326, 332, 335, 341], "set_default_tensor_typ": 128, "doubletensor": 128, "isclos": 128, "next_ob": [128, 268, 269, 270, 271, 340], "rubric": [128, 231], "init_stat": [128, 329, 330, 331, 332], "3752e": 128, "01": [128, 224, 235, 240, 252, 255, 328, 329, 330, 332, 335, 336, 337, 339], "5087e": 128, "03": [128, 328, 329, 330, 331, 335, 336, 337, 339], "9294e": 128, "9636": 128, "5608": 128, "6408": 128, "num_it": [128, 330, 331], "reduce_dim": [128, 329, 330, 331, 332], "cat_dim": [128, 329, 330, 331, 332], "keep_dim": [128, 330, 332], "statist": [128, 154, 257, 320, 329, 330, 331, 341], "approach": [128, 329, 331, 341], "gaussian": [128, 144, 165, 189, 194, 195, 200, 217, 331], "empir": [128, 165, 189, 225, 229, 329, 331, 335], "3d": [128, 166], "third": [128, 220, 335], "reorder": 130, "in_keys_in": 130, "pong": [130, 341], "channel": [130, 146, 192, 197, 198, 330], "r3m": [132, 337], "resnet": [132, 150, 152], "visual": [132, 150, 152, 331, 336], "embed": [132, 150, 151, 152, 201, 213, 214, 215, 216, 228, 233, 337], "ego4d": [132, 150, 152], "univers": [132, 150, 152], "suraj": [132, 150], "nair": [132, 150], "aravind": [132, 150], "rajeswaran": [132, 150], "vikash": [132, 150, 152], "kumar": [132, 150, 152], "chelsea": [132, 150], "finn": [132, 150], "abhinav": [132, 150], "gupta": [132, 150], "2203": [132, 150, 189, 337], "12601": [132, 150, 337], "_init": [132, 150, 329], "snippet": [132, 150, 329], "resnet50": [132, 152, 337], "model_nam": [132, 150, 152, 290], "resnet34": 132, "resnet18": 132, "r3m_vec": [132, 337], "feed": [132, 152, 253, 324, 329, 335, 338], "244": [132, 152, 336], "stack_imag": [132, 152], "tread": [132, 152], "separet": [132, 152], "hub": [132, 152, 337], "resnet50_weight": [132, 152], "imagenet1k_v1": [132, 152], "download_path": [132, 152], "tensor_pixels_kei": [132, 152], "dest": [132, 150, 152, 228], "sub_seq_len": 133, "sample_dim": [133, 329], "primarili": 133, "hesit": 133, "request": 133, "robust": 133, "mix": [133, 201, 210, 266, 329, 335], "improp": 133, "create_copi": 134, "stuff": 134, "newnam": 134, "interpol": [135, 330, 332], "bilinear": [135, 332], "84": [135, 330, 332, 336, 337], "halfcheetah": [135, 313, 329], "r2g": 136, "99": [136, 154, 189, 249, 262, 267, 274, 316, 329, 330, 331, 335, 336, 340], "reward_to_go": 136, "bernoulli_": 136, "9010": 136, "9404": [136, 274], "9701": [136, 274], "9900": [136, 274], "0000": [136, 145, 221, 222, 232, 274, 331, 332, 336, 340], "crash": 136, "clamp_min": 137, "clamp_max": 137, "clip_min": 137, "clip_max": 137, "episode_": 139, "reward1": 139, "reward2": 139, "episode_reward": [139, 335], "keep_reward": 140, "keep_don": 140, "squeeze_dim": 141, "step_count_kei": 142, "update_don": 142, "adaptec": 142, "accordingli": [142, 143, 183, 226, 332], "completet": 142, "recognis": 142, "accompani": 142, "target_return": 143, "chosen": [143, 144, 201, 202, 210, 227, 313, 324], "primer": [144, 332], "default_valu": [144, 332], "unit": [144, 165, 177, 179, 180, 197, 198, 203, 204, 331], "transfomedenv": 144, "mykei": 144, "__unless": 144, "exists__": 144, "pool": 145, "increas": [145, 224, 335], "10th": 145, "0216": 145, "1149": 145, "1990": 145, "2749": 145, "3281": 145, "9290": 145, "3702": 145, "8978": 145, "from_int": 146, "shape_toler": 146, "255": [146, 336, 338], "permuat": 146, "ri": 146, "principl": 147, "cattransform": 147, "notabl": 147, "rewardsum": [147, 335], "cache_spec": 148, "set_missing_toler": 148, "keyerror": 148, "unsqueeze_dim": [149, 336], "danger": 149, "vc1": 150, "vc1_vec": 150, "small": [150, 329, 331, 335, 341], "untrain": 150, "make_noload_model": 150, "naiv": 150, "vip": [151, 152, 337], "toward": 152, "implicit": [152, 251, 338], "jason": 152, "ma": 152, "shagun": 152, "sodhani": 152, "dinesh": 152, "jayaraman": 152, "osbert": 152, "bastani": 152, "ami": 152, "zhang": 152, "vip_vec": 152, "final_nam": 153, "sb3": 153, "terminal_obs_read": 153, "truli": [153, 340], "till": 153, "did": [153, 274, 330, 331, 338, 341], "nan": 153, "shared_td": 154, "decai": [154, 217, 221, 222, 259, 302, 329, 330, 332, 341], "9999": [154, 336], "0001": [154, 177, 196, 331, 336], "fly": [154, 252, 325, 331, 336, 338, 341], "to_observation_norm": 154, "underflow": [154, 302], "build_td_for_shared_vecnorm": 154, "memmori": 154, "queue": [154, 338], "td_share": 154, "state_dim": [155, 168, 173, 200, 203, 204, 218], "action_dim": [155, 168, 169, 171, 173, 200, 218, 329, 334], "gsde": [155, 256, 320], "func": 155, "gsdemodul": 155, "check_dtyp": 156, "short": [156, 183, 184, 330, 331, 335], "discrep": [156, 238, 240, 241, 242, 252, 255, 257, 266], "imposs": 156, "probabilistictdmodul": [161, 162, 187, 225, 229, 267, 300], "next_tensordict": 163, "keep_oth": [163, 336], "exclude_reward": 163, "exclude_don": 163, "exclude_act": 163, "next_": 163, "funtion": 163, "write_full_fals": 164, "leav": [164, 329], "_terminated_or_trunc": 164, "entropi": [165, 238, 239, 240, 245, 251, 252, 254, 255, 256, 258, 260, 335], "botev": 165, "et": 165, "2013": 165, "cem": 165, "plan": [165, 188, 189], "varianc": [165, 182, 196, 208, 209, 325, 329, 331, 335], "k": [165, 179, 180, 183, 184], "repeat": [165, 331, 335, 336], "maximis": [165, 169, 171, 189, 324, 329, 330, 331, 335], "horizon": [165, 189, 331], "modelbasedenv": [165, 189], "planning_horizon": [165, 189], "optim_step": [165, 189, 330], "mpc": [165, 188, 189], "num_candid": [165, 189], "candid": [165, 189], "top_k": [165, 189], "modelbasedenvbas": [165, 188, 189, 322], "safemodul": [165, 188, 214, 216, 229, 238, 239, 245, 251, 255, 256, 257, 258, 260, 309, 310, 316, 322, 340], "num_cel": [166, 167, 169, 170, 171, 172, 177, 178, 181, 185, 187, 192, 193, 214, 330, 331, 332, 335, 340], "elu": [166, 167, 169, 170, 171, 172, 177, 178, 192, 330, 340], "activation_kwarg": [166, 167, 187], "norm_class": [166, 167, 169, 170, 187], "norm_kwarg": [166, 167, 187], "bias_last_lay": [166, 167, 169, 170, 171, 172, 178, 187], "aggregator_class": [166, 167, 169, 170, 330, 332, 340], "squashdim": [166, 167, 169, 192, 340], "aggregator_kwarg": [166, 167, 169, 170, 330, 332], "squeeze_output": [166, 167, 169, 170, 330, 332], "convolut": [166, 167, 169, 170, 192, 205], "produc": [166, 167, 187, 193, 199, 214, 216, 218, 287, 331, 332, 338, 341], "cell": [166, 167, 179, 180, 181, 183, 184, 185, 187, 192, 193, 331], "kernel": [166, 167, 178, 186, 192], "cnet": [166, 167], "conv3d": 166, "34": [166, 167, 187, 330, 336, 338], "35": [166, 167, 187, 328, 330, 332, 336, 337, 339], "transformer_config": [168, 200, 218], "decisiontransform": [168, 200], "dtconfig": [168, 173, 200], "2202": [168, 173, 200, 254], "05607": [168, 173, 200, 254], "return_to_go": [168, 173, 200, 218], "conv_net_kwarg": [169, 170], "mlp_net_kwarg": [169, 170, 171], "use_avg_pool": [169, 170], "WITH": [169, 170, 171, 172, 224, 259], "1509": [169, 170, 171, 172, 189, 224, 242, 250, 259, 336], "02971": [169, 170, 171, 172, 224, 259], "convnet": [169, 192, 332, 340], "ndims_in": 169, "avgpool": [169, 170], "adaptiveavgpool2d": [170, 330, 332], "400": [171, 172, 335, 336, 338], "mlp_net_kwargs_net1": 172, "mlp_net_kwargs_net2": 172, "decion": 173, "desdescrib": 173, "n_embd": 173, "n_layer": [173, 179, 183], "n_head": 173, "n_inner": 173, "n_posit": 173, "resid_pdrop": 173, "attn_pdrop": 173, "gpt2config": 173, "atol": [174, 207], "06": [174, 207, 328, 329, 330, 331, 332, 336, 339], "rtol": [174, 207], "batch_shap": [174, 207], "event_shap": [174, 207], "absolut": [174, 207, 329], "densiti": [174, 190, 191, 199, 209], "mass": [174, 190, 191, 199, 209, 336], "rsampl": [174, 191, 199, 229], "sample_shap": [174, 190, 191, 199], "dqnet": 175, "atom": 175, "softmax": [175, 191, 199, 219, 220], "var_num": [176, 202, 219, 220, 227], "action_value_kei": [176, 202, 219, 220, 226, 227, 253, 266], "action_mask_kei": [176, 202, 219, 220, 221, 222, 226, 227], "perspect": [176, 220, 246, 331], "1707": [176, 220, 246, 255], "06887": [176, 220, 246], "mult": [176, 193, 202, 219, 220, 226, 227], "tensordict_modul": [176, 179, 180, 183, 184, 202, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 238, 239, 241, 245, 251, 255, 256, 257, 258, 260, 324], "nbin": [176, 219, 324], "customdistributionalqv": 176, "log_softmax": [176, 219], "from_modul": [176, 225, 228, 231, 233], "one_hot": [176, 191, 202], "qvalue_actor": [176, 202, 219, 226, 324], "to_modul": [176, 225, 228, 231, 233], "std_bia": 177, "std_min_val": 177, "belief": [177, 197, 203, 204], "1912": [177, 247, 248, 249], "01603": [177, 247, 248, 249], "softplu": [177, 196, 235, 236, 237], "out_features_valu": 178, "cnn_kwarg": [178, 330], "mlp_kwarg": [178, 186, 330], "duel": 178, "cnn": [178, 192, 330, 340], "06581": 178, "512": [178, 330, 336, 338], "input_s": [179, 180, 181, 183, 184, 185, 186, 332], "hidden_s": [179, 180, 181, 183, 184, 185, 186, 332], "num_lay": [179, 181, 183, 185, 197, 198], "batch_first": [179, 181, 183, 185, 332], "bidirect": [179, 183, 332], "cudnn": [179, 180, 183, 184, 332], "vmap": [179, 180, 183, 184, 211, 228, 231, 340], "rnn": [179, 180, 183, 184, 332], "device_count": [179, 180, 183, 184, 329, 330, 332, 337, 341], "els": [179, 180, 183, 184, 197, 324, 326, 329, 330, 331, 332, 335, 336, 337], "n_in": [179, 180, 183, 184], "n_out": [179, 180, 183, 184], "h0": [179, 180, 183, 184], "h1": [179, 180, 183, 184], "call_gru": [179, 180], "h_out": [179, 180, 183, 184], "batched_cal": [179, 180, 183, 184], "gate": [179, 180, 183], "r_t": 179, "sigma": [179, 180, 182, 183, 184, 200, 208, 209, 217, 224, 331], "w_": [179, 180, 183, 184], "ir": [179, 180], "x_t": [179, 183], "b_": [179, 180, 183, 184], "hr": [179, 180, 183], "h_": [179, 180, 183], "z_t": 179, "iz": [179, 180], "hz": [179, 180], "n_t": 179, "odot": [179, 180, 183, 184], "hn": [179, 180, 183], "h_t": [179, 183], "sigmoid": [179, 180, 183, 184], "hadamard": [179, 180, 183, 184], "multilay": [179, 183], "_t": [179, 183, 335, 336], "ge": [179, 183], "bernoulli": [179, 183], "b_ih": [179, 180, 183, 184, 185], "b_hh": [179, 180, 183, 184, 185], "seq": [179, 181, 183, 185, 332, 334], "h_0": [179, 183, 184], "unbatch": [179, 183], "pack": [179, 183, 331, 341], "pack_padded_sequ": [179, 183], "pack_sequ": [179, 183], "num": [179, 183], "_layer": [179, 183], "_size": [179, 180, 183, 184], "h_n": [179, 183], "packedsequ": [179, 183], "weight_ih_l": [179, 183], "learnabl": [179, 180, 183, 184], "w_ir": 179, "w_iz": 179, "w_in": 179, "num_direct": [179, 183], "weight_hh_l": [179, 183], "w_hr": 179, "w_hz": 179, "w_hn": 179, "bias_ih_l": [179, 183], "b_ir": 179, "b_iz": 179, "b_in": 179, "bias_hh_l": [179, 183], "b_hr": 179, "b_hz": 179, "b_hn": 179, "bias": [179, 180, 183, 184, 235, 325, 329], "mathcal": [179, 180, 183, 184], "sqrt": [179, 180, 183, 184, 224], "frac": [179, 180, 183, 184, 331], "seq_len": [179, 183], "subtli": 179, "matrix": [179, 183, 194, 195], "contrast": [179, 250, 338], "hx": [179, 180, 183, 184], "gru": [180, 181], "lstmcell": [180, 185], "gru_cel": 180, "z": 180, "weight_ih": [180, 184], "weight_hh": [180, 184], "bias_ih": [180, 184], "bias_hh": [180, 184], "rocm": [180, 184], "embedd": [181, 185, 186], "grucel": [181, 228], "proj_siz": [181, 183], "python_bas": [181, 185], "recurrent_st": [181, 332], "custom_kei": [181, 185], "recurrent_mod": [181, 185], "set_recurrent_mod": [181, 185, 332], "gru_modul": 181, "rs": [181, 329], "gru_module_train": 181, "policy_train": [181, 185], "traj_td": [181, 185], "policy_infer": [181, 185], "td_inf": [181, 185], "assert_clos": [181, 185], "upscal": [182, 208, 209], "tanh_loc": [182, 208, 209], "event_dim": [182, 207, 208], "ultim": [182, 208, 209], "poor": [182, 208, 209], "explos": [182, 208, 209], "switch": [182, 209], "formula": [182, 208, 209, 238, 240, 252, 255, 325, 331], "c0": [183, 184], "c1": [183, 184], "call_lstm": [183, 184], "c_out": [183, 184], "i_t": 183, "ii": [183, 184], "hi": [183, 184], "f_t": 183, "hf": [183, 184], "g_t": 183, "ig": [183, 184], "hg": [183, 184], "o_t": 183, "ho": [183, 184], "c_t": 183, "c_": 183, "forget": 183, "consequ": 183, "1402": 183, "1128": 183, "c_0": [183, 184], "proj": 183, "c_n": 183, "w_ii": 183, "w_if": 183, "w_ig": 183, "w_io": 183, "w_hi": 183, "w_hf": 183, "w_hg": 183, "w_ho": 183, "b_ii": 183, "b_if": 183, "b_ig": 183, "b_io": 183, "b_hi": 183, "b_hf": 183, "b_hg": 183, "b_ho": 183, "weight_hr_l": 183, "_revers": 183, "analog": 183, "cn": 183, "lstm_cell": 184, "h_1": 184, "c_1": 184, "time_step": [184, 186], "cx": 184, "trust": 185, "correspont": 185, "recurrent_state_h": [185, 332], "recurrent_state_c": [185, 332], "triplet": [185, 226, 227], "lstm_modul": 185, "rs_h": 185, "rs_c": 185, "hidden0": 185, "hidden1": 185, "lstm_kwarg": 186, "next_observ": [186, 238, 239, 241, 242, 244, 245, 251, 255, 256, 257, 258, 260, 334], "2d": [186, 335], "hidden0_in": 186, "hidden1_in": 186, "hidden0_out": 186, "hidden1_out": 186, "single_bias_last_lay": 187, "layer_class": 187, "layer_kwarg": 187, "perceptron": 187, "seamless": 187, "lazylinear": [187, 324, 331, 336, 337, 340], "42": [187, 238, 239, 241, 251, 258, 328, 330, 335, 336, 339, 341], "noisylinear": [187, 194, 322, 330], "noisylazylinear": [187, 322], "At": [188, 221, 330, 331, 332, 334, 336, 337], "mpcplanner": 188, "tensordict_out": [188, 341], "mppi": 189, "covari": 189, "william": [189, 257], "aldrich": 189, "theodor": 189, "01149": 189, "hansen": 189, "wang": 189, "su": 189, "04955": 189, "valueoper": [189, 214, 215, 216, 238, 239, 240, 241, 245, 251, 252, 255, 256, 257, 258, 260, 316, 324, 329, 331], "tdlambdaestim": [189, 322, 329], "value_net": [189, 242, 244, 257, 268, 269, 270, 271, 331], "adv": 189, "lmbda": [189, 262, 268, 271, 273, 279, 280, 281, 284, 285, 325, 329, 331, 335], "95": [189, 262, 329, 330, 331, 332, 336], "value_network": [189, 241, 242, 244, 246, 251, 258, 268, 269, 270, 271, 325, 329, 331], "temperatur": [189, 239, 251], "neg_inf": [190, 191], "inf": [190, 191], "www": [190, 191], "api_doc": [190, 191], "tf_agent": [190, 191], "event": [190, 191, 199, 277, 278, 279, 280, 282, 283, 284, 285, 338], "unnorm": [190, 191, 199], "sparse_mask": [190, 191], "dens": [190, 191], "0831": [190, 191], "1203": [190, 191], "0928": [190, 191], "1972": [190, 191], "grad_method": [191, 199], "reparamgradientstrategi": [191, 199], "passthrough": [191, 199], "proxi": [191, 199, 325], "relaxedonehot": [191, 199], "zeros_lik": [191, 336], "sample_non_valid": 191, "centralis": [192, 193, 335], "share_param": [192, 193, 335], "basi": [192, 338], "homogen": [192, 193, 335], "agent_network": [192, 193], "modulelist": [192, 193, 313, 340], "lazyconv2d": [192, 340], "2592": [192, 330], "decentralis": [192, 335], "n_agent_input": [193, 335], "n_agent_output": [193, 335], "toech": 193, "centalis": 193, "shown": [193, 324, 334, 335, 338], "std_init": [194, 195], "initialize_paramet": 194, "isol": [194, 253], "1706": [195, 210], "10295v3": 195, "induc": 195, "aid": 195, "scale_map": 196, "biased_softplus_1": 196, "scale_lb": [196, 203, 204], "exp": [196, 237], "module_norm": 196, "decod": 197, "1803": [197, 198, 201], "10122": [197, 198], "rnn_hidden": 197, "latent": 198, "excacli": 199, "inres": 200, "mu": [200, 224, 331], "state_shap": [201, 266], "mixing_embed_dim": [201, 266], "qmix": [201, 335], "mixer": [201, 210, 266], "monoton": 201, "hyper": 201, "11485": 201, "qmixerloss": [201, 210], "qmix_vdn": [201, 210], "eventu": [201, 332, 336], "vdn": [201, 210], "greedi": [202, 220, 221, 222, 227, 330, 332], "hidden_dim": [203, 204], "posterior": [203, 248], "rssm": [203, 204, 248], "1811": [203, 204], "04551": [203, 204], "obs_embed": 203, "rnn_hidden_dim": 204, "dream": 204, "tanhtransform": 208, "decomposit": 210, "05296": 210, "hide": [211, 331, 335], "satisfi": [211, 324], "tensordictmodulebas": [211, 219, 226, 332], "vmap_dim": 211, "lam": 211, "sample_in": 211, "sample_in_td": 211, "vm": 211, "translat": [213, 225], "character": [213, 219, 225, 226, 228, 338], "overflow": [213, 219, 220, 225, 226, 227, 228, 229], "td_modul": [213, 214, 215, 216, 225, 228, 229, 231, 233, 340], "3635": 213, "0340": 213, "1476": 213, "3911": [213, 336], "1664": [213, 330, 336], "5455": 213, "2247": 213, "4583": 213, "2916": 213, "2160": 213, "5337": 213, "5193": 213, "grad_fn": [213, 221, 222, 340], "addmmbackward0": 213, "actorvalueoper": [214, 324], "get_policy_oper": [214, 215, 216, 240, 252, 255, 324], "standalon": [214, 215, 216], "tdmodul": [214, 215, 216, 316], "get_critic_oper": 214, "common_oper": [214, 216], "policy_oper": [214, 215, 216], "value_oper": [214, 215, 216], "normalparamwrapp": [214, 215, 216, 225, 231, 238, 239, 245, 251, 255, 256, 257, 258, 260, 322, 340], "module_hidden": [214, 216], "td_module_hidden": [214, 216], "module_act": [214, 216], "td_module_act": [214, 215, 216], "module_valu": [214, 215, 216], "td_module_valu": [214, 215, 216], "state_action_valu": [214, 233, 239, 258, 267, 313, 316, 324, 329, 340], "td_clone": [214, 215, 216], "tensordictmodulewrapp": [214, 309, 310, 316], "get_policy_head": [214, 215, 216], "safesequenti": [214, 215, 216, 266], "head": [214, 216, 240, 252, 255], "get_value_head": [214, 215, 216], "get_value_oper": [214, 215, 216, 240, 252, 255], "action_modul": 215, "state_valu": [215, 216, 233, 240, 252, 255, 256, 258, 268, 269, 270, 271, 273, 275, 277, 279, 281, 282, 284, 324, 329, 331, 335], "qualiti": [216, 324], "actorcriticoper": [216, 240, 252, 255, 324], "embeddig": 216, "refet": 216, "actorcriticwrapp": [216, 324, 329], "po": [217, 222], "sigma_init": 217, "epsilon": [217, 221, 222, 224, 259, 302, 330, 331, 332], "sigma_end": 217, "annealing_num_step": [217, 221, 222, 224, 329, 330, 332], "captur": [217, 221, 222, 224], "omiss": [217, 221, 222, 224], "ommit": [217, 221, 222, 224, 338], "inferec": 218, "set_tensor_kei": 218, "dt_inference_wrapp": 218, "baz": 218, "inference_context": 218, "obs_dim": 218, "tanhdelta": [218, 322, 329], "dtactor": 218, "actor_modul": [218, 340], "dist_class": 218, "dist_kwarg": 218, "distribution_kwarg": [218, 225, 229, 331, 335], "inference_actor": 218, "sequence_length": 218, "mask_context": 218, "out_act": 218, "qvaluemodul": [219, 226, 266, 332], "distributionaldqnnet": 219, "make_log_softmax": 219, "my_action_valu": [220, 227], "chanc": 220, "thid": 220, "threshold": [221, 239, 240, 331], "eps_init": [221, 222, 224, 330, 332], "eps_end": [221, 222, 224, 330], "explorative_polici": [221, 222, 224], "9055": [221, 222, 336], "9277": [221, 222], "6295": [221, 222], "2532": [221, 222], "addbackward0": [221, 222], "lmheadmodel": 223, "extract": [223, 329, 331], "actor_head": [223, 240, 252, 255], "base_model": 223, "lm_head": 223, "ornstein": 224, "uhlenbeck": 224, "ou": [224, 329], "correl": 224, "noise_t": 224, "noise_": 224, "theta": [224, 331, 336], "sigma_t": 224, "sigma_": 224, "anneal": 224, "ou_prev_nois": 224, "ou_step": 224, "x0": 224, "sigma_min": 224, "n_steps_ann": 224, "is_init_kei": 224, "_ou_prev_nois": 224, "_ou_step": 224, "default_interaction_typ": [225, 229], "interaction_typ": [225, 229], "set_interaction_typ": [225, 229], "cache_dist": [225, 229], "n_empirical_estim": [225, 229], "compound": 225, "compositedistribut": 225, "categ": 225, "distribution_map": 225, "chose": 227, "functionalmodul": 228, "functionalmodulewithbuff": 228, "td_fmodul": 228, "td_function": 228, "td_state": 228, "ensembl": [228, 256], "params_repeat": 228, "td_vmap": [228, 231], "random_sampl": [228, 229], "suppli": 229, "fist": 229, "log_prob_kei": [229, 335], "probabilistictensordictsequenti": [230, 238, 240, 252, 255, 257, 309, 310, 340], "partial_toler": [230, 231, 334], "who": [230, 231], "AND": [230, 231], "tensordictsequenci": 231, "tensordictsequ": 231, "safeprobabilisticmodul": [231, 324], "spec1": 231, "net1": 231, "module1": 231, "td_module1": 231, "spec2": 231, "module2": 231, "td_module2": 231, "clamp": [232, 248, 304, 336], "boundari": [232, 331, 335], "resolut": 232, "simplest": [232, 329, 331, 332, 335, 338, 341], "9944": 232, "9991": 232, "3020": 232, "2299": [232, 336], "5418": 232, "2989": 232, "6849": 232, "3169": 232, "2690": 232, "9649": [232, 336], "5686": 232, "8602": 232, "0315": 232, "8455": [232, 336], "6027": 232, "4746": 232, "7843": 232, "7782": 232, "2111": 232, "5115": 232, "4687": 232, "5760": 232, "custommodul": 233, "cat": [233, 239, 241, 251, 256, 258, 260, 340], "imaginari": 234, "imagin": 234, "transition_model": 234, "get_reward_oper": 234, "get_transition_model_oper": 234, "min_val": [235, 237], "_bia": 235, "invert": [236, 331], "surject": 237, "expln": 237, "biased_softplu": [237, 322], "beggin": 237, "biased_softplus_": 237, "syntax": [237, 329], "met": [237, 336], "1602": 238, "01783v2": 238, "entropy_bonu": [238, 240, 252, 255, 331], "favour": [238, 240, 252, 255], "samples_mc_entropi": [238, 240, 252, 254, 255], "mont": [238, 240, 252, 255, 329], "carlo": [238, 240, 252, 255, 329], "entropy_coef": [238, 240, 252, 255, 331, 335], "critic_coef": [238, 240, 252, 255, 331], "loss_critic_typ": [238, 240, 252, 255, 257, 331], "l1": [238, 240, 241, 242, 245, 252, 255, 256, 257, 260, 263, 266, 324, 329], "l2": [238, 240, 241, 242, 243, 244, 245, 248, 249, 252, 255, 256, 257, 260, 263, 266, 329], "smooth_l1": [238, 239, 240, 241, 242, 245, 251, 252, 255, 256, 257, 258, 260, 263, 266, 331], "separate_loss": [238, 240, 241, 245, 251, 252, 255, 256, 257, 258, 260], "propag": [238, 240, 241, 245, 251, 252, 255, 256, 257, 258, 260, 268, 269, 270, 271, 331, 335], "advantage_kei": [238, 240, 252, 255, 257, 268, 269, 270, 271], "value_target_kei": [238, 240, 252, 255, 257, 268, 269, 270, 271, 331], "value_target": [238, 240, 252, 255, 257, 268, 269, 270, 271, 331, 335], "loss_crit": [238, 255, 331, 335], "loss_entropi": [238, 255, 331, 335], "loss_object": [238, 255, 331, 335], "recur": [238, 239, 241, 242, 244, 245, 251, 255, 256, 257, 258, 260, 268, 269, 270, 271, 272], "next_reward": [238, 239, 241, 242, 244, 245, 251, 255, 256, 257, 258, 260, 268, 269, 270, 271], "next_don": [238, 239, 241, 242, 244, 245, 251, 255, 256, 257, 258, 260, 268, 269, 270, 271], "next_termin": [238, 239, 241, 242, 244, 245, 251, 255, 256, 257, 258, 260, 268, 269, 270, 271], "loss_obj": 238, "sacloss": [238, 250, 259, 322], "select_out_kei": [238, 239, 241, 245, 251, 255, 256, 258, 260], "essenti": [238, 239, 240, 245, 246, 247, 248, 249, 251, 252, 253, 255, 256, 257, 258, 260, 266, 330, 336, 338], "make_value_estim": [238, 239, 241, 242, 244, 245, 246, 247, 251, 253, 255, 256, 257, 258, 260, 261, 266, 325, 329, 330, 335], "value_typ": [238, 239, 241, 242, 244, 245, 246, 247, 251, 253, 255, 256, 257, 258, 260, 262, 266, 329], "valueestim": [238, 239, 241, 242, 244, 245, 246, 247, 251, 253, 255, 256, 257, 258, 260, 262, 266, 322, 325, 329, 335], "hyperparam": [238, 239, 241, 242, 244, 245, 246, 247, 251, 253, 255, 256, 257, 258, 260, 266, 329], "enum": [238, 239, 241, 242, 244, 245, 246, 247, 251, 253, 255, 256, 257, 258, 260, 262, 266, 329], "default_value_estim": [238, 239, 241, 242, 244, 245, 246, 247, 251, 253, 255, 256, 257, 258, 260, 266, 329], "refin": [238, 239, 241, 242, 244, 245, 246, 247, 251, 253, 255, 256, 257, 258, 260, 266], "default_value_kwarg": [238, 239, 241, 242, 244, 245, 246, 247, 251, 253, 255, 256, 257, 258, 260, 266, 322, 329], "dqn_loss": [238, 239, 241, 242, 244, 245, 246, 247, 251, 253, 255, 256, 257, 258, 260, 261, 266], "conserv": [239, 244], "2006": [239, 244, 336], "actor_network": [239, 241, 243, 245, 251, 254, 256, 258, 260, 329], "qvalue_network": [239, 245, 251, 256, 258, 260], "loss_funct": [239, 241, 242, 243, 244, 245, 251, 256, 258, 260, 263, 266, 329], "alpha_init": [239, 245, 254, 256, 258], "min_alpha": [239, 245, 254, 256, 258], "max_alpha": [239, 245, 254, 256, 258], "fixed_alpha": [239, 245, 254, 256, 258], "target_entropi": [239, 245, 254, 256, 258], "prod": [239, 254, 258], "n_action": [239, 242, 244, 254, 258], "delay_actor": [239, 241, 258, 260], "delay_qvalu": [239, 245, 256, 258, 260], "min_q_weight": 239, "max_q_backup": 239, "backup": 239, "deterministic_backup": 239, "num_random": 239, "with_lagrang": 239, "lagrang": 239, "lagrange_thresh": 239, "valueclass": [239, 241, 245, 251, 256, 258, 260], "qvalu": [239, 245, 251, 256, 258, 260, 313], "loss_actor": [239, 241, 245, 251, 256, 257, 258, 260, 299, 329, 340], "loss_alpha": [239, 245, 256, 258], "loss_alpha_prim": 239, "loss_qvalu": [239, 245, 251, 256, 258, 260], "clip_epsilon": [240, 331, 335], "normalize_advantag": [240, 252, 255, 335], "value_kei": [240, 252, 255, 268, 269, 270, 271, 329], "somemodul": [240, 252, 255], "someactor": [240, 252, 255], "value_head": [240, 252, 255], "somevalu": [240, 252, 255], "loss_modul": [240, 250, 252, 253, 255, 259, 304, 315, 316, 325, 326, 329, 330, 331, 335, 338], "ppoloss": [240, 252, 322], "delay_valu": [241, 242, 244, 246, 257, 258, 266, 330, 332], "loss_valu": [241, 251, 257, 258, 329, 331, 335, 340], "pred_valu": [241, 260, 329, 340], "pred_value_max": [241, 329, 340], "target_valu": [241, 256, 260, 267, 325, 329, 340], "target_value_max": [241, 329, 340], "qvalueactor": [242, 244, 266, 324, 330, 332], "double_dqn": 242, "06461": [242, 250], "mult_one_hot": [242, 245, 266], "loss_val": [242, 244, 325, 329, 331, 332, 335, 338], "2106": 243, "01345": 243, "distanc": [244, 252, 263, 267, 268, 335], "loss_cql": 244, "dcql_loss": 244, "ste": 245, "num_qvalue_net": [245, 251, 256, 258, 260], "target_entropy_weight": 245, "onehotcategor": [245, 322], "disctount": 246, "distributionalqvalueactor": [246, 324], "input_tensordict": [246, 329], "actor_model": 247, "value_model": [247, 249], "model_based_env": 247, "dreamerenv": [247, 322], "imagination_horizon": 247, "unrol": [247, 273, 274, 277, 278, 279, 280, 281, 282, 283, 284, 285], "discount_loss": [247, 249], "lambda_kl": 248, "lambda_reco": 248, "lambda_reward": 248, "reco_loss": 248, "reward_loss": 248, "free_nat": 248, "nat": 248, "delayed_clamp": 248, "global_averag": 248, "value_loss": 249, "fake_data": 249, "ddpgloss": [250, 259, 316, 322, 329, 340], "td3loss": [250, 259, 322], "value_network_update_interv": 250, "2110": 251, "06169": 251, "expectil": 251, "tau": [251, 259, 329, 330], "antmaz": 251, "sticht": 251, "loss_value_diff": 251, "diff": 251, "old_polici": 252, "new_polici": 252, "apart": [252, 335], "dtarg": 252, "samples_mc_kl": 252, "analyt": 252, "decrement": 252, "loss_": [253, 299, 325, 329], "equip": [253, 332], "gh": 253, "_acceptedkei": 253, "dataclass": [253, 313], "_forward_value_estimator_kei": 253, "alter": [253, 324], "value_estim": [253, 268, 269, 270, 271, 272, 325, 329, 335], "myloss": 253, "action2": 253, "convert_to_funct": [253, 329], "expand_dim": 253, "create_target_param": [253, 329], "compare_against": [253, 329], "_param": 253, "expans": 253, "resampl": 253, "_target_param": 253, "blend": 253, "upcom": [253, 277, 278, 279, 280, 282, 283, 284, 285, 329], "proxim": [255, 331, 335], "optimis": [255, 300, 331, 335], "flavour": [255, 335, 340], "clipppoloss": [255, 322, 331, 335], "klpenppoloss": [255, 322], "regularis": 255, "06347": 255, "gae": [255, 322, 325, 329, 331, 335], "ppo_loss": 255, "tdlambda": [255, 262, 325, 329], "base_lay": 255, "randn_lik": 255, "samplelogprob": 255, "openreview": [256, 313], "ay8zfzm0tdd": [256, 313], "sub_sample_len": 256, "subsampl": [256, 295, 326], "action_log_prob_actor": 256, "state_action_value_actor": [256, 260], "connectionist": 257, "1992": 257, "doi": 257, "1007": 257, "bf00992696": 257, "actor_net": [257, 329, 331], "1801": 258, "01290": 258, "applic": [258, 266, 336], "1812": 258, "05905": 258, "redqloss": [259, 322], "math": 259, "theta_t": [259, 336], "theta_": [259, 336], "polyak": 259, "policy_nois": 260, "noise_clip": 260, "next_state_valu": [260, 273, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 322], "td0": [261, 329], "strict_shap": 263, "view_a": 263, "qmixer": [266, 322], "local_valu": 266, "visibl": [266, 335], "dafault": 266, "acceptedkei": 266, "global_valu": 266, "penultim": 266, "local_value_network": 266, "mixer_network": 266, "suggest": [266, 335], "value_modul": [266, 331, 340], "qnet": [266, 329], "next_val_kei": 267, "pred_next_v": 267, "usus": 267, "mse": 267, "q_valu": 267, "n_steps_to_next": 267, "value_next_st": 267, "1506": [268, 273, 281], "02438": [268, 273, 281], "exponenti": [268, 269, 270, 271, 273, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 302], "average_ga": [268, 331], "skip_exist": [268, 269, 270, 271], "advang": 268, "gradient_mod": 268, "value_error": [268, 269, 270, 271, 272], "sign": 268, "target_param": [268, 269, 270, 271, 272, 329, 335], "98": [268, 269, 270, 271, 330, 336, 337, 338], "94": [268, 271, 330, 336, 337], "unpack": [268, 269, 270, 271], "tensor_kei": [268, 269, 270, 271, 272], "next_valu": [268, 269, 270, 271, 272], "aka": [269, 330], "average_reward": [269, 270, 271], "tdestim": [269, 270, 272], "infti": 270, "valuefunctionbas": 272, "time_dim": [273, 274, 277, 278, 279, 280, 281, 282, 283, 284, 285], "old_stat": [273, 275, 277, 279, 281, 282, 284], "new_stat": [273, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285], "rolling_gamma": [277, 278, 279, 280, 282, 283, 284, 285], "g1": [277, 278, 279, 280, 282, 283, 284, 285], "g2": [277, 278, 279, 280, 282, 283, 284, 285], "g3": [277, 278, 279, 280, 282, 283, 284, 285], "g4": [277, 278, 279, 280, 282, 283, 284, 285], "v3": [277, 278, 279, 280, 282, 283, 284, 285], "out_file_bas": 286, "skip_reset": 286, "interv": [286, 287, 296, 306, 330, 336], "center_crop": 287, "make_grid": 287, "grid": 287, "exp_nam": [288, 289, 292, 293, 294, 316, 330], "log_dir": [288, 289, 291, 293, 330], "templat": 288, "csv": [289, 291, 330], "minim": [289, 338], "dependeci": 289, "experiment_nam": [290, 291], "uuid": [290, 330, 341], "date": 290, "logger_typ": 291, "logger_nam": 291, "tensorboard": [291, 293, 340], "wandb": [291, 294, 340], "mlflow": [291, 292], "wandb_kwarg": 291, "mlflow_kwarg": 291, "tracking_uri": 292, "uri": 292, "datastor": 292, "tb_log": 293, "tensoarboard": 293, "sub_traj_len": 295, "min_sub_traj_len": 295, "register_op": [295, 296, 297, 298, 299, 300, 301, 302, 303, 305, 306, 326, 330], "process_optim_batch": [295, 301, 302, 326], "td_out": [295, 303], "_process_optim_batch_hook": [295, 326], "batch_subsampl": 295, "clear_cuda": 296, "pre_optim_step": [296, 326], "counter": [297, 326], "log_pbar": [297, 298, 300, 302, 326, 330], "progress": [297, 298, 300, 304, 326, 330, 332, 341], "count_fram": 297, "pre_steps_log": [297, 298, 326], "count_frames_log": 297, "lognam": 298, "r_train": [298, 330], "log_reward": [298, 330], "loss_compon": 299, "appl": 299, "omit": [299, 331, 336, 338], "optimizer_hook": 299, "record_interv": [300, 329, 330], "record_fram": [300, 307, 329, 330], "policy_explor": [300, 316, 329, 330], "log_kei": [300, 330], "suffix": 300, "underestim": 300, "set_exploration_typ": [300, 322, 331, 332, 340], "r_evalu": [300, 329], "flatten_tensordict": [301, 330], "max_dim": 301, "rb_trainer": 301, "batch_process": [301, 302, 303, 326], "post_loss": [301, 326], "999": [302, 330], "jitter": 302, "finfo": 302, "default_dtyp": 302, "get_default_dtyp": 302, "reward_norm": 302, "update_reward_stat": 302, "normalize_reward": 302, "make_train": [303, 322], "_process_batch_hook": [303, 326], "select_kei": [303, 326], "versatil": 304, "optim_steps_per_batch": [304, 326, 330], "epoch": [304, 331, 335], "clip_grad_norm": 304, "clip_norm": 304, "progress_bar": 304, "save_trainer_interv": 304, "log_interv": [304, 330], "save_trainer_fil": [304, 326], "datacollectorbas": [306, 309, 310, 316, 322], "update_weights_interv": [306, 330], "sit": [306, 330], "update_weight": 306, "post_step": [306, 326], "cfg": [307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 320], "dictconfig": [307, 308, 309, 310, 313, 314, 315, 316, 317, 320], "divid": [307, 324, 329, 335, 336], "unknowingli": 307, "annealing_fram": [307, 329], "init_env_step": [307, 308, 329], "proof_environ": [308, 313, 329], "sta": 308, "ot": 308, "actor_model_explor": [309, 310, 329], "make_env_kwarg": [309, 310], "targetnetupdat": [311, 312, 315, 316], "redqloss_deprec": 312, "actor_net_kwarg": 313, "qvalue_net_kwarg": 313, "observation_kei": 313, "dummi": [313, 329, 341], "parser_env_arg": 313, "parser_model_args_continu": 313, "cattensor": [313, 329, 334, 336, 341], "hydra": 313, "config_stor": 313, "configstor": 313, "config_field": 313, "config_cl": 313, "redqmodelconfig": 313, "envconfig": 313, "make_dataclass": 313, "cls_name": 313, "cs": 313, "config_path": 313, "config_nam": 313, "replayargsconfig": 314, "target_net_updat": [316, 329, 330], "constitu": 316, "learnt": [316, 329, 331], "tensorboardlogg": [316, 322], "egreedywrapp": [316, 330, 332], "env_proof": 316, "obs_spec": 316, "net_valu": 316, "dir": [316, 326, 330], "gettempdir": 316, "argpars": [317, 320], "namespac": [317, 320], "parser": [317, 320], "transformed_env_constructor": [317, 322], "num_env_per_collector": [318, 319], "video_tag": 320, "norm_obs_onli": 320, "use_env_cr": 320, "custom_env_mak": 320, "custom_env": 320, "return_transformed_env": 320, "action_dim_gsd": 320, "state_dim_gsd": 320, "obs_norm_state_dict": 320, "wheter": 320, "maker": 320, "asyncdatacollector": 322, "distributedsyncdatacollector": 322, "submitit_delayed_launch": 322, "raycollector": 322, "tensordictmaxvaluewrit": 322, "d4rlexperiencereplai": 322, "minariexperiencereplai": 322, "openmlexperiencereplai": 322, "vd4rlexperiencereplai": 322, "unboundeddiscretetensorspec": [322, 341], "lazystackedtensorspec": 322, "lazystackedcompositespec": 322, "prompttensordicttoken": 322, "rolloutfrommodel": 322, "tokenizeddatasetload": 322, "create_infinite_iter": 322, "consolidate_spec": 322, "check_no_exclusive_kei": 322, "contains_lazy_spec": 322, "check_marl_group": 322, "tensordictrecord": 322, "videorecord": [322, 331], "get_available_librari": 322, "set_exploration_mod": 322, "make_composite_from_td": [322, 336], "terminated_or_trunc": 322, "braxwrapp": 322, "dmcontrolenv": [322, 329, 334, 341], "dmcontrolwrapp": [322, 341], "jumanjienv": 322, "jumanjiwrapp": 322, "mogymenv": 322, "mogymwrapp": 322, "multithreadedenvwrapp": 322, "openmlenv": 322, "pettingzooenv": 322, "robohiveenv": 322, "smacv2env": 322, "smacv2wrapp": 322, "vmaswrapp": 322, "qvaluehook": 322, "distributionalqvaluehook": 322, "reset_nois": 322, "cemplann": 322, "mpcplannerbas": 322, "mppiplann": 322, "independentnorm": 322, "truncatednorm": 322, "maskedonehotcategor": 322, "inv_softplu": 322, "vmapmodul": 322, "distributionaldqnloss": [322, 330], "discretesacloss": 322, "iqlloss": 322, "cqlloss": 322, "discretecqlloss": 322, "dtloss": 322, "onlinedtloss": 322, "a2closs": 322, "reinforceloss": 322, "dreameractorloss": 322, "dreamermodelloss": 322, "dreamervalueloss": 322, "td0estim": [322, 329], "td1estim": [322, 329], "td0_return_estim": 322, "td0_advantage_estim": 322, "td1_return_estim": 322, "vec_td1_return_estim": 322, "td1_advantage_estim": 322, "vec_td1_advantage_estim": 322, "td_lambda_return_estim": 322, "vec_td_lambda_return_estim": 322, "td_lambda_advantage_estim": 322, "vec_td_lambda_advantage_estim": 322, "generalized_advantage_estim": 322, "vec_generalized_advantage_estim": 322, "reward2go": 322, "distance_loss": [322, 329], "hold_out_net": 322, "hold_out_param": [322, 329], "softupd": [322, 329, 330, 332], "hardupd": [322, 329], "batchsubsampl": [322, 326], "clearcudacach": 322, "countframeslog": 322, "logreward": [322, 326, 330], "optimizerhook": [322, 330], "replaybuffertrain": [322, 326, 330], "rewardnorm": 322, "selectkei": [322, 326], "trainerhookbas": [322, 326, 330], "updateweight": [322, 326, 330], "make_collector_offpolici": 322, "make_collector_onpolici": 322, "make_dqn_loss": 322, "make_redq_loss": 322, "make_redq_model": 322, "make_replay_buff": [322, 329], "make_target_updat": 322, "parallel_env_constructor": [322, 329], "sync_async_collector": 322, "sync_sync_collector": 322, "correct_for_frame_skip": 322, "get_stats_random_rollout": 322, "csvlogger": [322, 330], "mlflowlogg": 322, "wandblogg": 322, "get_logg": 322, "generate_exp_nam": 322, "journei": 323, "textbook": 323, "highlight": 323, "ever": [323, 335], "bump": 323, "think": [323, 331, 335, 341], "benefit": [323, 335, 338], "pr": 323, "ground": [324, 329, 336], "categori": [324, 326], "recycl": [324, 338], "impos": 324, "violat": 324, "noisier": 324, "Their": [324, 335], "sd": 324, "prob_modul": 324, "pick": [324, 329, 330], "tabl": [324, 330], "customari": 324, "hopefulli": [324, 330], "functional_modul": 324, "make_funct": [324, 340], "mathbb": [324, 330], "rightarrow": [324, 330], "soften": 324, "backbon": [324, 332, 334, 340], "make_actor": 324, "make_valu": 324, "shared_param": 324, "make_common": 324, "reusabl": [325, 329, 338], "swappabl": [325, 329], "characterist": [325, 329, 336], "trainabl": [325, 329, 337], "whatev": [325, 329], "smth": [325, 329], "metric": [325, 329], "nutshel": [325, 329], "barto": [325, 335], "chapter": 325, "significantli": [325, 329, 330, 335], "next_stat": 325, "value_net_loss": 325, "pow": [325, 329], "therebi": 325, "room": 325, "convers": 325, "signifi": [325, 335], "underperform": 325, "thin": 325, "intric": 325, "believ": 326, "scheme": [326, 341], "substenti": 326, "_pre_steps_log_hook": 326, "_pre_optim_hook": 326, "sub_batch": 326, "_post_loss_hook": 326, "_post_optim_hook": 326, "post_optim": [326, 330], "_post_optim_log": 326, "post_optim_log": 326, "_post_steps_hook": 326, "_post_steps_log_hook": 326, "post_steps_log": 326, "comment": [326, 330, 340], "reserv": 326, "logginghook": 326, "logging_hook": 326, "save_dict": 326, "some_valu": 326, "torchsnapshot": 326, "ckpt_backend": 326, "pt": [326, 337], "filepath": 326, "save_train": 326, "load_from_fil": 326, "835": [328, 339], "galleri": [328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 340, 341], "mem": [328, 339], "mb": [328, 329, 330, 331, 332, 334, 335, 336, 337, 338, 339, 340, 341], "torchrl_demo": [328, 339, 340], "342": [328, 336, 339, 340], "torchrl_env": [328, 339, 341], "619": [328, 336, 339, 341], "31": [328, 329, 330, 332, 336, 337, 339], "dqn_with_rnn": [328, 332, 339], "879": [328, 332, 339], "1587": [328, 336, 339], "multiagent_ppo": [328, 335, 339], "coding_dqn": [328, 330, 339], "434": [328, 330, 336, 339], "686": [328, 330, 339], "rb_tutori": [328, 338, 339], "02": [328, 329, 330, 331, 332, 335, 336, 337, 339], "606": [328, 336, 338, 339], "376": [328, 336, 339], "566": [328, 336, 339], "coding_ddpg": [328, 329, 339], "335": [328, 329, 331, 336, 339], "coding_ppo": [328, 331, 339], "303": [328, 331, 336, 339], "pretrained_model": [328, 337, 339], "00": [328, 329, 330, 331, 332, 335, 336, 337, 339], "54": [328, 330, 332, 336, 337, 339], "792": [328, 337, 339], "3583": [328, 336, 337, 339], "multi_task": [328, 334, 339], "859": [328, 334, 339], "25": [328, 329, 330, 335, 336, 339], "author": [329, 330, 331, 332, 335, 336, 338], "vincent": [329, 330, 331, 332, 336, 338], "moen": [329, 330, 331, 332, 336, 338], "assembl": 329, "focus": 329, "straightforward": [329, 330, 338], "overview": [329, 331, 335, 340], "transpar": [329, 332], "understood": 329, "sota": [329, 330, 340], "illustr": [329, 330, 338], "loss_dict": 329, "modal": 329, "oblivi": [329, 331, 338], "elementari": 329, "didact": 329, "dilut": 329, "pessimist": [329, 330, 331], "target_actor_network_param": 329, "actor_in_kei": 329, "actor_crit": 329, "noth": [329, 331], "compromis": 329, "hp": 329, "hasattr": 329, "_value_estim": 329, "elif": [329, 330], "notimplementederror": 329, "unknown": 329, "_loss_actor": 329, "td_copi": 329, "actor_network_param": 329, "value_network_param": 329, "_loss_valu": 329, "pred_val": 329, "target_value_network_param": 329, "smooth": [329, 330], "loss_funt": 329, "glue": 329, "_forward": 329, "ndimens": 329, "remaind": 329, "focu": [329, 330, 331], "pixels_onli": [329, 330, 340, 341], "env_librari": 329, "env_task": 329, "env_arg": 329, "friendli": 329, "torchr": 329, "rescal": 329, "presum": 329, "make_transformed_env": 329, "reward_sc": 329, "double_to_float_list": 329, "double_to_float_inv_list": 329, "marker": 329, "env_per_collector": 329, "transform_state_dict": 329, "make_t_env": 329, "adjust": [329, 335, 336], "seem": [329, 332], "cheat": 329, "10m": 329, "cautiou": 329, "magnitud": 329, "thousand": [329, 332], "get_env_stat": 329, "proof_env": 329, "5000": [329, 330, 331], "maxim": [329, 336], "recal": [329, 331], "ddpgmlpactor": 329, "ddpgmlpqnet": 329, "materi": 329, "ornsteinuhlenbeckprocesswrapp": 329, "make_ddpg_actor": 329, "q_net": 329, "moduless": 329, "sugges": 329, "tight": 329, "10_000": [329, 331, 338], "traj_len": [329, 332], "make_record": 329, "recorder_obj": 329, "flavor": 329, "circular": 329, "buffer_s": [329, 330], "random_crop_len": 329, "prb": 329, "buffer_scratch_dir": 329, "temporari": 329, "dirrectori": 329, "trajecotri": 329, "sampel": 329, "dataflow": 329, "ceil_div": 329, "utd": [329, 332], "update_to_data": 329, "realiz": 329, "_must_": 329, "001": [329, 336], "outdat": 329, "trick": [329, 330], "despit": 329, "adam": [329, 330, 331, 332, 335, 336], "optimizer_actor": 329, "lr": [329, 330, 331, 332, 335, 336], "weight_decai": [329, 330], "optimizer_valu": 329, "total_collection_step": 329, "pretti": [329, 338], "rewards_ev": 329, "collected_fram": 329, "pbar": [329, 331, 332, 335, 336], "r0": 329, "numel": [329, 331, 332, 337, 338], "current_fram": 329, "sampled_tensordict": 329, "gn1": 329, "clip_grad_norm_": [329, 331, 335, 336], "gn2": 329, "gn": [329, 336], "td_record": 329, "rn": 329, "set_descript": [329, 331, 332, 335, 336], "2f": 329, "800": [329, 330], "2941": 329, "02it": [329, 330, 336], "1600": [329, 330], "1030": 329, "04it": [329, 330], "3200": [329, 330], "2143": 329, "53it": [329, 330, 336], "48": [329, 330, 336, 337], "4800": [329, 330, 336], "3062": 329, "44it": [329, 330], "86": [329, 330, 335, 336, 337, 338], "141": [329, 336, 338], "90": [329, 330, 331, 335, 336], "47": [329, 330, 332, 336, 338], "68": [329, 330, 336, 337], "56": [329, 330, 336, 337], "5600": 329, "6400": [329, 340], "1280": [329, 330], "25it": [329, 330], "92": [329, 330, 336, 337], "361": [329, 336], "72": [329, 330, 336, 337], "7200": 329, "813": [329, 336], "45": [329, 330, 336], "36": [329, 330, 336], "107": [329, 336], "388": [329, 336], "77": [329, 330, 336, 338], "43": [329, 330, 336, 337], "05": [329, 330, 336, 337], "80": [329, 330, 331, 335, 336, 337], "8000": [329, 331], "621": [329, 336], "63it": [329, 331, 336], "66": [329, 330, 336, 337, 338], "127": [329, 336, 338], "270": [329, 336], "65": [329, 330, 336, 337, 338], "8800": 329, "532": [329, 336], "57it": [329, 330, 336], "74": [329, 330, 336, 337, 338], "82": [329, 330, 336], "57": [329, 330, 336, 337], "83": [329, 330, 335, 336, 337, 338], "365": [329, 336], "76": [329, 330, 336, 337], "96": [329, 330, 336, 337], "9600": 329, "402": [329, 336], "36it": [329, 330, 336], "154": [329, 336, 338], "456": [329, 336], "73": [329, 330, 336, 337], "10400it": 329, "391": [329, 336], "99it": [329, 330, 336], "201": [329, 336], "79": [329, 330, 335, 336], "plot": [329, 331, 332, 335, 336], "mention": [329, 332, 338, 341], "matplotlib": [329, 331, 332, 335, 336, 338, 341], "pyplot": [329, 331, 332, 335, 336, 338, 341], "plt": [329, 331, 332, 335, 336, 338, 341], "zip": [329, 333], "legend": 329, "xlabel": [329, 332, 335, 336], "ylabel": [329, 335], "tight_layout": 329, "concret": [329, 331], "takeawai": [329, 330], "minut": [329, 330, 331, 332, 334, 335, 336, 337, 338, 340, 341], "jupyt": [329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 340, 341], "ipynb": [329, 330, 331, 332, 334, 335, 336, 337, 338, 340, 341], "sphinx": [329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 340, 341], "customis": [330, 335], "road": 330, "aspect": 330, "highest": 330, "prerequisit": [330, 332], "familiar": [330, 335, 341], "lookup": 330, "amort": [330, 331], "conjunct": 330, "cart": 330, "pole": 330, "un": 330, "actuat": 330, "frictionless": 330, "upright": 330, "duelingcnndqnet": 330, "is_notebook": 330, "shell": 330, "get_ipython": 330, "__class__": 330, "zmqinteractiveshel": 330, "qtconsol": 330, "terminalinteractiveshel": 330, "ipython": [330, 335, 336], "nameerror": 330, "umbrella": 330, "misplac": 330, "misus": 330, "orchestr": 330, "everyth": [330, 332], "five": [330, 331], "64x64": 330, "motion": [330, 336], "obs_norm_sd": 330, "simpler": 330, "get_norm_stat": 330, "test_env": 330, "make_model": 330, "dummy_env": 330, "output_s": [330, 332], "init_bia": 330, "actor_explor": 330, "eps_greedy_v": 330, "eps_greedy_val_env": 330, "get_replay_buff": 330, "n_optim": 330, "themselv": 330, "simplic": [330, 331, 337, 338], "get_collector": 330, "data_collector": 330, "bunch": 330, "concept": [330, 338], "power": 330, "ubiquit": 330, "get_loss_modul": 330, "target_updat": 330, "995": [330, 336], "sensit": 330, "variat": 330, "2e": [330, 336], "wd": 330, "upd": 330, "harder": [330, 340], "5_000": 330, "500000": 330, "100000": 330, "005": 330, "mandatori": [330, 331, 335, 336], "fairer": 330, "budget": [330, 331], "dqn_exp_": 330, "uuid1": [330, 341], "9895": 330, "0737": 330, "tmp": [330, 338], "tmpfm8r66m2": 330, "dqn_exp_5886385a": 330, "a341": 330, "11ee": [330, 341], "8838": [330, 341], "0242ac110002": [330, 341], "registr": 330, "cumbersom": 330, "buffer_hook": 330, "weight_updat": 330, "descript": [330, 331], "aliv": 330, "total_reward": 330, "81it": [330, 336], "4948": 330, "9346": [330, 336], "09": [330, 331, 335, 336], "08it": [330, 336], "3802": 330, "30it": [330, 336], "4497": 330, "73it": [330, 336], "4345": 330, "192": [330, 336], "19it": 330, "4676": 330, "224": [330, 336], "94it": 330, "4193": 330, "3682": 330, "288": [330, 336], "58it": [330, 336], "51": [330, 332, 335, 336], "52it": [330, 332], "3650": 330, "352": [330, 336], "72it": [330, 336], "384": [330, 336], "54it": [330, 331], "4045": 330, "416": [330, 336], "58": [330, 336, 337], "24it": 330, "448": [330, 336], "59": [330, 336, 337], "76it": [330, 336], "480": [330, 336, 337], "60": [330, 331, 335, 336, 338, 340], "06it": 330, "62it": [330, 336], "4586": 330, "544": [330, 336], "61": [330, 336, 337], "28it": 330, "4526": 330, "576": [330, 336], "68it": [330, 336], "608": [330, 336], "17it": 330, "640": 330, "10it": 330, "4797": 330, "672": 330, "41it": 330, "704": 330, "67it": 330, "736": 330, "62": [330, 336, 337, 338], "26it": 330, "768": 330, "07": [330, 336], "49it": 330, "832": 330, "03it": [330, 336], "4074": [330, 336], "864": 330, "896": 330, "98it": 330, "928": 330, "69it": [330, 332], "960": 330, "79it": [330, 336], "4164": [330, 336], "992": [330, 336], "16it": 330, "1056": 330, "37it": 330, "1088": 330, "61it": [330, 336], "1120": 330, "63": [330, 336, 338], "1152": 330, "93it": 330, "1184": 330, "89it": [330, 331], "1216": 330, "86it": [330, 336], "1248": 330, "65it": 330, "14it": 330, "1344": 330, "1376": 330, "40it": 330, "1408": 330, "1440": 330, "00it": [330, 331], "1472": 330, "31it": 330, "1504": 330, "18it": 330, "1536": 330, "55": [330, 335, 336], "71it": [330, 336], "1568": 330, "92it": 330, "53": [330, 332, 336, 337], "1632": 330, "39it": [330, 336], "52": [330, 336, 338], "13it": 330, "1696": 330, "97it": 330, "1728": 330, "38it": [330, 331], "1760": 330, "1792": 330, "21it": 330, "1824": 330, "37": [330, 331, 332, 336], "1856": 330, "49": [330, 336], "1888": 330, "1920": 330, "1952": 330, "64it": [330, 336], "40": [330, 331, 335, 336, 338], "1984": 330, "2016": 330, "41": [330, 336, 337], "2048": [330, 337], "2080": 330, "2112": [330, 336], "2144": 330, "78it": [330, 336], "2176": 330, "2208": 330, "56it": [330, 336], "2240": 330, "2272": 330, "2304": 330, "95it": 330, "2336": 330, "2368": 330, "2400": 330, "01it": 330, "2432": 330, "2464": 330, "77it": [330, 336], "2496": 330, "87it": 330, "2528": [330, 336], "84it": [330, 331, 336], "2560": 330, "2624": 330, "2656": [330, 336], "2688": 330, "51it": [330, 336], "2720": [330, 336], "43it": [330, 331, 336], "2752": 330, "2784": 330, "05it": 330, "2816": 330, "2848": 330, "2880": 330, "2912": 330, "48it": [330, 336], "2944": [330, 336], "2976": [330, 336], "3008": 330, "3040": 330, "3072": 330, "3104": 330, "34it": 330, "3136": 330, "3168": 330, "11it": [330, 336], "3232": [330, 336], "6923": 330, "3264": 330, "3296": 330, "67": [330, 334, 336, 337], "3328": 330, "3360": 330, "3392": 330, "3424": 330, "09it": [330, 331], "69": [330, 336, 337], "3456": [330, 336], "88it": [330, 336], "70": [330, 331, 335, 336, 337], "3488": 330, "83it": [330, 336], "3520": 330, "29it": [330, 336], "71": [330, 336, 337], "3552": 330, "3584": 330, "3616": 330, "75it": [330, 332, 336], "3648": 330, "3680": 330, "4134": 330, "3712": 330, "3744": 330, "3776": 330, "3808": 330, "3840": 330, "3872": 330, "4224": 330, "78": [330, 335, 336, 337], "3904": 330, "3936": 330, "3968": 330, "4000": [330, 331], "22it": [330, 332, 336], "4032": 330, "15it": 330, "4064": 330, "4096": 330, "4128": [330, 336], "4160": 330, "4192": 330, "85": [330, 336, 337], "4256": [330, 336], "4288": [330, 336], "4320": 330, "50it": 330, "4352": 330, "59it": 330, "4384": 330, "4416": 330, "89": [330, 336, 337, 338], "4448": 330, "4480": 330, "74it": [330, 336], "4512": 330, "91": [330, 336, 337], "4544": 330, "55it": [330, 336], "4576": 330, "4608": 330, "70it": [330, 331, 336], "93": [330, 336], "4640": 330, "4672": [330, 336], "4704": 330, "35it": 330, "4736": 330, "4768": 330, "97": [330, 336, 337], "4832": 330, "4864": 330, "23it": 330, "4896": 330, "4928": 330, "33it": 330, "4960": 330, "4992": 330, "5024it": 330, "print_csv_files_in_fold": 330, "folder_path": 330, "csv_file": 330, "output_str": 330, "dirpath": 330, "walk": [330, 334], "endswith": 330, "strip": 330, "45859628915786743": 330, "4948333501815796": 330, "4044681191444397": 330, "4676021933555603": 330, "44965073466300964": 330, "9322315454483032": 330, "49071115255355835": 330, "4428161382675171": 330, "28000953793525696": 330, "38701915740966797": 330, "2986108362674713": 330, "34433481097221375": 330, "44184523820877075": 330, "5258951187133789": 330, "grad_norm_0": 330, "053668022155762": 330, "057593822479248": 330, "724571704864502": 330, "764434814453125": 330, "4078726768493652": 330, "798689842224121": 330, "8071482181549072": 330, "764038562774658": 330, "53350830078125": 330, "10000000894069672": 330, "69230842590332": 330, "qvaluenetwork": 330, "worst": 330, "accuraci": 330, "fanci": 330, "demonstr": [331, 335, 336, 341], "talk": 331, "repetit": 331, "six": 331, "sophist": [331, 335], "invent": 331, "theta_k": 331, "pi_": 331, "exceed": 331, "discourag": [331, 336], "indispens": 331, "analyz": 331, "lingua": 331, "franca": 331, "defaultdict": [331, 336], "has_cuda": [331, 335, 341], "3e": [331, 332, 335], "max_grad_norm": [331, 335], "ourselv": [331, 341], "benefici": 331, "errat": 331, "hamper": [331, 338], "reactiv": 331, "xy": 331, "sub_batch_s": 331, "num_epoch": [331, 335], "entropy_ep": [331, 335], "generalist": 331, "interchang": [331, 337, 338], "panel": 331, "charact": 331, "inverteddoublependulum": 331, "transmit": 331, "stai": 331, "supplementari": [331, 341], "told": 331, "stringent": [331, 335], "confid": [331, 335], "ran": 331, "f_": 331, "mu_": 331, "difficulti": [331, 341], "brought": [331, 332], "d_ob": 331, "d_action": 331, "policy_modul": [331, 335], "That": 331, "said": 331, "briefli": [331, 335], "refil": [331, 335], "conveni": [331, 335, 336], "easiest": [331, 335], "mathemat": [331, 335], "tradeoff": [331, 335], "advantage_modul": 331, "lr_schedul": [331, 336], "cosineannealinglr": [331, 336], "eval_str": 331, "tensordict_data": [331, 335], "data_view": [331, 335], "subdata": [331, 335], "cum_reward_str": 331, "4f": [331, 332, 336], "stepcount_str": 331, "param_group": 331, "lr_str": 331, "eval_rollout": 331, "nice": 331, "331": [331, 336], "129": [331, 336], "2849": 331, "0849": 331, "0003": [331, 336], "332": [331, 336], "1217": 331, "3000": 331, "333": [331, 336], "1528": 331, "334": [331, 336], "1739": 331, "0002": [331, 336], "1995": 331, "6000": 331, "336": [331, 336], "2180": 331, "7000": 331, "329": [331, 336], "2266": 331, "2413": 331, "9000": 331, "45it": [331, 336], "2438": 331, "2526": 331, "cap": [331, 338], "figsiz": [331, 336], "subplot": [331, 336, 341], "titl": [331, 332, 335, 336], "bit": [331, 332, 335, 338], "lstmmodul": 332, "84x84": 332, "accessori": 332, "stamp": 332, "tensordictprim": 332, "assist": 332, "emb": 332, "n_cell": 332, "customiz": 332, "almost": 332, "wouldn": 332, "make_tensordict_prim": 332, "interpolationmod": 332, "qval": 332, "stoch_polici": 332, "opportun": 332, "coupl": [332, 336, 338], "uniniti": 332, "again": [332, 335, 337, 338, 341], "redund": 332, "strongli": 332, "million": 332, "sake": [332, 337, 338], "20_000": [332, 336], "longest": 332, "npai": 332, "action_spread": 332, "1000000": 332, "110": [332, 336, 338], "0014": [332, 336], "125": [332, 336], "0008": [332, 336], "150": [332, 336], "163": [332, 336, 337], "182": [332, 336], "0007": [332, 336], "1588": [332, 336], "tutorials_python": 333, "tutorials_jupyt": 333, "humanoid": 334, "env1_obs_kei": 334, "observation_stand": 334, "env2_obs_kei": 334, "observation_walk": 334, "tdreset1": 334, "tdreset2": 334, "tdreset": 334, "policy_common": 334, "policy_stand": 334, "policy_walk": 334, "But": 334, "exclusive_field": [334, 340], "stack_dim": [334, 340], "env1_mak": 334, "env2_mak": 334, "_single_task": 334, "td_rollout": 334, "matteo": 335, "bettini": 335, "maddpg": 335, "navig": 335, "lidar": 335, "sensor": 335, "collis": 335, "tie": 335, "mappo": 335, "ippo": 335, "phase": [335, 338], "mathbf": 335, "pi": [335, 336], "fed": [335, 338], "approxim": [335, 341], "literatur": 335, "overcom": 335, "stationari": 335, "concurr": 335, "analys": 335, "gui": 335, "visualis": 335, "multiagentmlp": 335, "divic": 335, "vmas_devic": 335, "6_000": 335, "team": [335, 340], "n_iter": 335, "minibatch_s": 335, "generalis": 335, "furthermor": 335, "simd": 335, "parallelis": 335, "warp": 335, "todai": 335, "circl": 335, "surround": 335, "dot": [335, 336], "collid": 335, "drag": 335, "elast": 335, "acceler": 335, "penalis": 335, "num_vmas_env": 335, "scenario_nam": 335, "four": [335, 336], "environmnet": 335, "final_rew": 335, "agent_collis": 335, "stress": 335, "paramount": 335, "n_rollout_step": 335, "evolut": 335, "yourself": 335, "utilis": 335, "n_actions_per_ag": 335, "n_obs_per_ag": 335, "share_parameters_polici": 335, "policy_net": 335, "denot": 335, "carefulli": [335, 341], "grant": 335, "converg": 335, "cooper": 335, "share_parameters_crit": 335, "critic_net": 335, "fantast": 335, "minibatch": 335, "desc": 335, "episode_reward_mean": 335, "episode_reward_mean_list": 335, "get_item_shap": 335, "critic_param": 335, "target_critic_param": 335, "refresh": 335, "3641679584980011": 335, "4940122067928314": 335, "0600677728652954": 335, "4344534873962402": 335, "1100871562957764": 335, "304917335510254": 335, "6943857669830322": 335, "871443748474121": 335, "8500826358795166": 335, "759843587875366": 335, "xvfb": 335, "pyvirtualdisplai": 335, "1400": [335, 336], "900": 335, "pil": 335, "rendering_callback": 335, "fromarrai": 335, "rgb_arrai": [335, 336], "gif": 335, "save_al": 335, "append_imag": 335, "profici": 335, "master": 335, "freeli": 336, "codebas": 336, "touch": 336, "undertaken": 336, "broader": 336, "wider": 336, "algebra": 336, "acquaint": 336, "avenu": 336, "_apply_to_composit": 336, "default_x": 336, "default_i": 336, "torqu": 336, "upward": 336, "angular": 336, "sin": 336, "rad": 336, "sec": 336, "gravit": 336, "angl": 336, "deleg": 336, "new_th": 336, "new_thdot": 336, "thdot": 336, "g_forc": 336, "max_torqu": 336, "angle_norm": 336, "max_spe": 336, "albeit": 336, "gen_param": 336, "high_th": 336, "high_thdot": 336, "low_th": 336, "low_thdot": 336, "rng": 336, "lazili": 336, "organ": [336, 338], "trivial": 336, "neither": 336, "shortcut": [336, 341], "irrelev": 336, "_make_spec": 336, "td_param": 336, "pseudo": 336, "render_mod": 336, "render_fp": 336, "random_": 336, "_make_step": 336, "staticmethod": 336, "complic": [336, 338, 341], "showcas": 336, "skeleton": 336, "_apply_transform": [336, 341], "_inv_apply_transform": [336, 341], "subset": [336, 337], "unitari": 336, "sine": 336, "cosin": 336, "sintransform": 336, "tensordict_reset": 336, "costransform": 336, "t_sin": 336, "t_co": 336, "cat_transform": 336, "mdp": 336, "simple_rollout": 336, "unexplor": 336, "recreat": 336, "init_td": 336, "traj_return": 336, "last_reward": 336, "is_ipython": 336, "inlin": 336, "get_backend": 336, "ion": 336, "gcf": 336, "clear_output": 336, "625": 336, "0488": 336, "0748": 336, "519": 336, "46it": 336, "0499": 336, "4472": 336, "073": 336, "0685": 336, "0408": [336, 341], "552": 336, "5154": 336, "9086": 336, "527": 336, "9385": 336, "155": 336, "2568": 336, "4981": 336, "223": 336, "82it": 336, "8929": 336, "4491": 336, "581": 336, "3233": 336, "0664": 336, "596": 336, "1021": 336, "5263": 336, "9579": 336, "5807": 336, "8075": 336, "212": 336, "2009": 336, "5525": 336, "914": 336, "2894": 336, "0115": 336, "85it": 336, "0977": 336, "1845": 336, "1830": 336, "4858": 336, "233": 336, "2863": 336, "0297": 336, "464": 336, "4617": 336, "5997": 336, "904": 336, "1647": 336, "0777": 336, "901": 336, "4709": 336, "6813": 336, "8317": 336, "3221": 336, "5554": 336, "276": 336, "3353": 336, "701": 336, "8570": 336, "6656": 336, "463": 336, "7779": 336, "6911": 336, "875": 336, "0796": 336, "7082": 336, "308": 336, "0421": 336, "1496": 336, "5037": 336, "1755": 336, "5029": 336, "9454": 336, "665": 336, "9330": 336, "2118": 336, "444": 336, "0995": 336, "6294": 336, "3146": 336, "2909": 336, "461": 336, "9720": 336, "1298": 336, "9923": 336, "0345": 336, "3438": 336, "3688": 336, "424": 336, "6953": 336, "5233": 336, "411": 336, "8011": 336, "5329": 336, "2677": 336, "6969": 336, "7010": 336, "9352": 336, "7707": 336, "6178": 336, "5646": 336, "348": 336, "7304": 336, "9407": 336, "942": 336, "3882": 336, "7604": 336, "3507": 336, "8928": 336, "258": 336, "6978": 336, "4641": 336, "549": 336, "6047": 336, "5005": 336, "4136": 336, "2993": 336, "3222": 336, "4046": 336, "7314": 336, "275": 336, "6331": 336, "9318": 336, "961": 336, "8331": 336, "1604": 336, "4099": 336, "4761": 336, "4262": 336, "6363": 336, "382": 336, "3593": 336, "7377": 336, "2847": 336, "3443": 336, "867": 336, "3592": 336, "4760": 336, "441": 336, "9950": 336, "8021": 336, "3528": 336, "1214": 336, "708": 336, "4023": 336, "041": 336, "3801": 336, "0310": 336, "120": 336, "4244": 336, "2039": 336, "4850": 336, "8748": 336, "706": 336, "4897": 336, "9210": 336, "8964": 336, "0832": 336, "3934": 336, "8971": 336, "2933": 336, "3377": 336, "6996": 336, "2274": 336, "8916": 336, "098": 336, "80it": 336, "2660": 336, "9110": 336, "4503": 336, "6956": 336, "9172": 336, "4026": 336, "946": 336, "9229": 336, "5205": 336, "294": 336, "8872": 336, "6637": 336, "019": 336, "9281": 336, "2082": 336, "724": 336, "8561": 336, "6574": 336, "357": 336, "4138": 336, "5230": 336, "385": 336, "4065": 336, "5642": 336, "921": 336, "9786": 336, "4129": 336, "5831": 336, "266": 336, "7723": 336, "4152": 336, "0898": 336, "389": 336, "5155": 336, "5376": 336, "5616": 336, "4094": 336, "283": 336, "5333": 336, "4803": 336, "895": 336, "6566": 336, "2588": 336, "662": 336, "4732": 336, "7503": 336, "068": 336, "0714": 336, "3370": 336, "059": 336, "8612": 336, "1915": 336, "3855": 336, "0349": 336, "9644": 336, "4538": 336, "445": 336, "0392": 336, "4080": 336, "1648": 336, "9599": 336, "143": 336, "4284": 336, "5946": 336, "2590": 336, "9181": 336, "4621": 336, "9075": 336, "674": 336, "1772": 336, "9444": 336, "351": 336, "9391": 336, "5595": 336, "8673": 336, "6240": 336, "5919": 336, "0018": 336, "1071": 336, "9127": 336, "251": 336, "9799": 336, "3131": 336, "9612": 336, "9705": 336, "8741": 336, "2230": 336, "0972": 336, "0337": 336, "0350": 336, "0654": 336, "102": [336, 338], "2441": 336, "4596": 336, "362": 336, "103": 336, "4362": 336, "171": 336, "104": 336, "4041": 336, "6907": 336, "105": 336, "4664": 336, "2760": 336, "0299": 336, "9712": 336, "349": 336, "3332": 336, "4479": 336, "772": 336, "108": 336, "4357": 336, "9591": 336, "543": 336, "109": 336, "6216": 336, "1353": 336, "692": 336, "6261": 336, "7086": 336, "496": 336, "111": 336, "7758": 336, "9818": 336, "112": 336, "7772": 336, "5055": 336, "113": 336, "5840": 336, "3180": 336, "2083": 336, "115": 336, "5275": 336, "6873": 336, "116": 336, "4107": 336, "1624": 336, "117": 336, "6372": 336, "2571": 336, "118": 336, "4039": 336, "4428": 336, "119": 336, "4728": 336, "5628": 336, "6767": 336, "2466": 336, "522": 336, "121": [336, 341], "5873": 336, "5072": 336, "122": [336, 341], "6548": 336, "3766": 336, "123": [336, 338], "5134": 336, "1955": 336, "124": 336, "2481": 336, "0591": 336, "4500": 336, "3368": 336, "126": 336, "9708": 336, "7059": 336, "3031": 336, "2534": 336, "843": 336, "3327": 336, "6193": 336, "4831": 336, "1172": 336, "2593": 336, "4219": 336, "962": 336, "8380": 336, "899": 336, "132": 336, "2721": 336, "9048": 336, "166": 336, "133": 336, "2419": 336, "5248": 336, "134": 336, "2139": 336, "4278": 336, "135": 336, "0690": 336, "5140": 336, "136": [336, 338], "1140": 336, "7402": 336, "137": 336, "5356": 336, "1636": 336, "138": 336, "0671": 336, "8798": 336, "139": 336, "8918": 336, "3298": 336, "307": 336, "140": 336, "1779": 336, "1771": 336, "3624": 336, "936": 336, "142": 336, "1683": 336, "4810": 336, "9373": 336, "4435": 336, "144": 336, "4396": 336, "8092": 336, "145": 336, "2572": 336, "146": 336, "4212": 336, "0260": 336, "147": 336, "0939": 336, "6478": 336, "605": 336, "148": 336, "6606": 336, "7289": 336, "149": 336, "9300": 336, "7193": 336, "563": 336, "1166": 336, "8514": 336, "151": 336, "9108": 336, "0672": 336, "292": 336, "152": 336, "8591": 336, "3768": 336, "153": 336, "9976": 336, "0576": 336, "0067": 336, "935": 336, "4199": 336, "1722": 336, "156": 336, "8310": 336, "3466": 336, "157": 336, "8631": 336, "2492": 336, "158": [336, 338], "8763": 336, "1277": 336, "159": 336, "5562": 336, "7446": 336, "1082": 336, "9830": 336, "161": 336, "0946": 336, "5229": 336, "162": 336, "4574": 336, "6900": 336, "2229": 336, "0318": 336, "482": 336, "164": 336, "0543": 336, "0817": 336, "761": 336, "165": 336, "2809": 336, "5118": 336, "366": 336, "1142": 336, "5635": 336, "167": [336, 338], "1949": 336, "2327": 336, "982": 336, "168": 336, "0967": 336, "0387": 336, "457": 336, "169": 336, "0782": 336, "2150": 336, "170": 336, "5222": 336, "3725": 336, "9288": 336, "9837": 336, "172": 336, "1416": 336, "1099": 336, "173": 336, "8620": 336, "8475": 336, "174": 336, "1807": 336, "4375": 336, "175": 336, "1148": 336, "0645": 336, "2751": 336, "8313": 336, "177": 336, "9286": 336, "9770": 336, "178": 336, "5735": 336, "2837": 336, "179": [336, 338], "2926": 336, "9489": 336, "180": 336, "1507": 336, "181": 336, "8724": 336, "3567": 336, "3574": 336, "6140": 336, "183": 336, "7895": 336, "2518": 336, "184": 336, "6146": 336, "185": 336, "8776": 336, "7358": 336, "186": 336, "3722": 336, "8428": 336, "187": 336, "7955": 336, "188": 336, "0092": 336, "7106": 336, "829": 336, "189": 336, "2264": 336, "6919": 336, "190": 336, "1438": 336, "1362": 336, "191": 336, "0618": 336, "8217": 336, "9420": 336, "6765": 336, "193": 336, "7745": 336, "0709": 336, "194": 336, "9478": 336, "6867": 336, "195": 336, "6507": 336, "6225": 336, "196": 336, "2244": 336, "2195": 336, "197": 336, "5385": 336, "9263": 336, "198": 336, "1878": 336, "2374": 336, "199": 336, "8054": 336, "3504": 336, "557": 336, "0766": 336, "6825": 336, "2011": 336, "8393": 336, "202": 336, "0803": 336, "7815": 336, "203": 336, "8363": 336, "2460": 336, "204": 336, "8643": 336, "2191": 336, "593": 336, "205": 336, "0773": 336, "1343": 336, "206": 336, "8657": 336, "207": 336, "9304": 336, "7584": 336, "208": 336, "8752": 336, "2307": 336, "209": 336, "5250": 336, "4869": 336, "7837": 336, "5762": 336, "211": 336, "6661": 336, "8600": 336, "2502": 336, "1752": 336, "213": 336, "3075": 336, "8871": 336, "214": 336, "9406": 336, "8090": 336, "215": 336, "6291": 336, "8923": 336, "876": 336, "216": 336, "9504": 336, "21e": 336, "217": 336, "7431": 336, "7880": 336, "218": 336, "4463": 336, "5432": 336, "219": 336, "3793": 336, "3313": 336, "220": 336, "8843": 336, "0369": 336, "065": 336, "221": 336, "4828": 336, "8391": 336, "222": 336, "6265": 336, "2913": 336, "947": 336, "5541": 336, "1252": 336, "7342": 336, "2396": 336, "225": 336, "5936": 336, "1924": 336, "226": 336, "9975": 336, "2045": 336, "227": 336, "8367": 336, "9540": 336, "228": 336, "7259": 336, "6743": 336, "229": 336, "4827": 336, "7528": 336, "230": 336, "7361": 336, "8756": 336, "231": 336, "7646": 336, "1116": 336, "232": 336, "5426": 336, "8385": 336, "5662": 336, "8585": 336, "234": 336, "8234": 336, "7930": 336, "235": 336, "2648": 336, "9309": 336, "236": 336, "6817": 336, "237": 336, "0943": 336, "1533": 336, "238": 336, "3045": 336, "0483": 336, "239": 336, "240": [336, 340, 341], "6415": 336, "0201": 336, "241": 336, "4437": 336, "4365": 336, "242": 336, "0358": 336, "4943": 336, "243": 336, "1272": 336, "5003": 336, "1180": 336, "2637": 336, "245": 336, "7197": 336, "0873": 336, "246": 336, "2917": 336, "247": 336, "0160": 336, "0738": 336, "248": 336, "3689": 336, "0120": 336, "249": 336, "5570": 336, "0475": 336, "250": 336, "4423": 336, "2220": 336, "6803": 336, "252": 336, "1465": 336, "7214": 336, "253": 336, "8801": 336, "7034": 336, "254": 336, "9136": 336, "4076": 336, "7589": 336, "5013": 336, "8150": 336, "2241": 336, "257": 336, "0753": 336, "8081": 336, "1951": 336, "8314": 336, "259": 336, "0038": 336, "260": 336, "0889": 336, "4616": 336, "261": 336, "0655": 336, "262": 336, "8333": 336, "9476": 336, "263": 336, "7554": 336, "3798": 336, "264": 336, "3717": 336, "3947": 336, "529": 336, "265": 336, "3060": 336, "6495": 336, "7467": 336, "8889": 336, "267": 336, "8457": 336, "591": 336, "268": 336, "7137": 336, "0536": 336, "771": 336, "269": 336, "1651": 336, "8246": 336, "5709": 336, "281": 336, "271": 336, "7502": 336, "0521": 336, "032": 336, "272": 336, "5475": 336, "7253": 336, "273": 336, "2856": 336, "7130": 336, "274": 336, "2778": 336, "4122": 336, "8368": 336, "1841": 336, "9622": 336, "1603": 336, "003e": 336, "277": 336, "0247": 336, "346": 336, "278": 336, "2238": 336, "6418": 336, "279": 336, "0626": 336, "2538": 336, "280": 336, "0149": 336, "7380": 336, "2167": 336, "8911": 336, "282": 336, "8725": 336, "1983": 336, "8142": 336, "3709": 336, "284": 336, "4989": 336, "285": 336, "6464": 336, "6210": 336, "286": 336, "9726": 336, "0820": 336, "287": 336, "6975": 336, "9091": 336, "4926": 336, "4791": 336, "289": 336, "0905": 336, "3500": 336, "290": 336, "2287": 336, "291": 336, "9918": 336, "5543": 336, "60it": 336, "9245": 336, "6444": 336, "631": 336, "293": 336, "0448": 336, "4769": 336, "8566": 336, "7208": 336, "295": 336, "0966": 336, "296": 336, "12it": 336, "5303": 336, "1537": 336, "023": 336, "297": 336, "32it": 336, "2682": 336, "564": 336, "298": 336, "47it": 336, "4318": 336, "5063": 336, "299": 336, "7475": 336, "4190": 336, "8186": 336, "5077": 336, "301": 336, "1883": 336, "5291": 336, "472": 336, "302": 336, "1256": 336, "3998": 336, "3622": 336, "0930": 336, "626": 336, "304": 336, "9500": 336, "0075": 336, "5664": 336, "305": 336, "5697": 336, "3024": 336, "306": 336, "3117": 336, "0052": 336, "006": 336, "0981": 336, "9312": 336, "3873": 336, "309": 336, "0411": 336, "2650": 336, "310": 336, "1656": 336, "0228": 336, "004": 336, "311": 336, "1196": 336, "2478": 336, "312": 336, "7353": 336, "0812": 336, "313": 336, "3022": 336, "758": 336, "314": 336, "1406": 336, "4626": 336, "315": 336, "2156": 336, "851": 336, "316": 336, "1953": 336, "3774": 336, "317": 336, "6385": 336, "9917": 336, "318": 336, "2764": 336, "905": 336, "319": 336, "6391": 336, "9317": 336, "9748": 336, "2679": 336, "321": 336, "8495": 336, "5125": 336, "8177": 336, "6602": 336, "323": 336, "0704": 336, "5776": 336, "324": 336, "9833": [336, 340], "1339": 336, "325": 336, "1238": 336, "326": 336, "9299": 336, "0227": 336, "327": 336, "7727": 336, "1607": 336, "328": 336, "3958": 336, "3223": 336, "763": 336, "4742": 336, "1797": 336, "330": 336, "0144": 336, "0085": 336, "791": 336, "8284": 336, "0428": 336, "0098": 336, "7365": 336, "4566": 336, "0781": 336, "086": 336, "3355": 336, "0230": 336, "0423": 336, "076": 336, "3711": 336, "1335": 336, "6855": 336, "337": 336, "0304": 336, "0023": 336, "8459": 336, "338": 336, "9998": 336, "4399": 336, "339": 336, "2303": 336, "1346": 336, "340": 336, "2915": 336, "7116": 336, "341": 336, "5560": 336, "0487": 336, "5119": 336, "061": 336, "343": 336, "3305": 336, "3705": 336, "957": 336, "344": 336, "6068": 336, "345": 336, "5731": 336, "3897": 336, "0376": 336, "347": 336, "0434": 336, "012": 336, "1300": 336, "1215": 336, "0968": 336, "0885": 336, "350": 336, "1348": 336, "0073": 336, "5052": 336, "4184": 336, "2817": 336, "8887": 336, "353": 336, "4779": 336, "1009": 336, "354": 336, "0604": 336, "599": 336, "355": 336, "4486": 336, "1176": 336, "656": 336, "356": 336, "2436": 336, "0668": 336, "8849": 336, "0012": 336, "358": 336, "7511": 336, "8804": 336, "359": 336, "8870": 336, "6728": 336, "360": 336, "8841": 336, "5508": 336, "5242": 336, "0268": 336, "0013": 336, "6185": 336, "363": 336, "1378": 336, "0204": 336, "364": 336, "0355": 336, "685": 336, "4884": 336, "0231": 336, "0770": 336, "6793": 336, "367": 336, "9834": 336, "863": 336, "368": 336, "6709": 336, "462": 336, "369": 336, "5199": 336, "9790": 336, "370": 336, "9401": 336, "7802": 336, "371": 336, "6723": 336, "372": 336, "2678": 336, "6201": 336, "373": 336, "2184": 336, "7385": 336, "374": 336, "6344": 336, "617": 336, "375": 336, "9945": 336, "0772": 336, "567": 336, "7576": 336, "0398": 336, "377": [336, 338], "3396": 336, "0022": 336, "094": 336, "378": 336, "3073": 336, "4018": 336, "379": 336, "1869": 336, "380": 336, "0481": 336, "1117": 336, "381": 336, "6823": 336, "981": 336, "8305": 336, "0210": 336, "383": 336, "4908": 336, "0272": 336, "538": 336, "3267": 336, "0111": 336, "7965": 336, "1796": 336, "0039": 336, "5396": 336, "386": 336, "3757": 336, "0490": 336, "387": 336, "1394": 336, "4187": 336, "2986": 336, "7954": 336, "1274": 336, "0063": 336, "390": 336, "8706": 336, "0114": 336, "6922": 336, "0004": 336, "2423": 336, "392": 336, "9115": 336, "2602": 336, "393": 336, "2449": 336, "0783": 336, "394": 336, "66it": 336, "0631": 336, "0057": 336, "7444": 336, "395": 336, "3339": 336, "0167": 336, "396": 336, "4806": 336, "397": 336, "4171": 336, "067": 336, "398": 336, "2618": 336, "5809": 336, "399": 336, "0054": 336, "3364": 336, "8733": 336, "0184": 336, "401": 336, "9137": 336, "0113": 336, "025": 336, "0386": 336, "0625": 336, "403": 336, "1332": 336, "0582": 336, "7816": 336, "404": 336, "8341": 336, "0941": 336, "854": 336, "405": 336, "8615": 336, "588": 336, "406": 336, "3849": 336, "008": 336, "407": 336, "9395": 336, "0765": 336, "055": 336, "408": 336, "2685": 336, "2235": 336, "688": 336, "409": 336, "3052": 336, "4249": 336, "410": 336, "6806": 336, "6383": 336, "3721": 336, "9981": 336, "412": 336, "1862": 336, "822": 336, "413": 336, "9811": 336, "0171": 336, "013": 336, "414": 336, "0252": 336, "0049": 336, "6205": 336, "415": 336, "1108": 336, "4921": 336, "9142": 336, "8130": 336, "417": 336, "1725": 336, "0036": 336, "3196": 336, "418": 336, "7795": 336, "0242": 336, "799": 336, "419": 336, "7737": 336, "0138": 336, "420": 336, "1462": 336, "0053": 336, "421": 336, "9226": 336, "6139": 336, "422": 336, "9889": 336, "0403": 336, "423": 336, "6194": 336, "0032": 336, "3989": 336, "0104": 336, "425": 336, "9960": 336, "0009": 336, "6009": 336, "426": 336, "2697": 336, "0914": 336, "427": 336, "1114": 336, "428": 336, "9862": 336, "1932": 336, "429": 336, "0637": 336, "0623": 336, "082": 336, "430": 336, "9906": 336, "2031": 336, "431": 336, "9948": 336, "0895": 336, "432": 336, "1970": 336, "0256": 336, "433": 336, "4231": 336, "0449": 336, "644": 336, "1039": 336, "1973": 336, "435": 336, "4561": 336, "1225": 336, "436": 336, "0211": 336, "2125": 336, "437": 336, "3866": 336, "0050": 336, "7202": 336, "438": 336, "6388": 336, "0072": 336, "439": 336, "1187": 336, "0015": 336, "5116": 336, "440": 336, "0432": 336, "0025": 336, "7809": 336, "1925": 336, "0103": 336, "442": 336, "9570": 336, "443": 336, "0871": 336, "5601": 336, "0165": 336, "0047": 336, "6061": 336, "2746": 336, "0027": 336, "7887": 336, "446": 336, "1835": 336, "0035": 336, "855": 336, "447": 336, "8420": 336, "548": 336, "2653": 336, "0126": 336, "9736": 336, "449": 336, "0594": 336, "0119": 336, "6196": 336, "450": 336, "4509": 336, "0373": 336, "451": 336, "0620": 336, "452": 336, "6898": 336, "3235": 336, "687": 336, "453": 336, "5879": 336, "454": 336, "8406": 336, "0694": 336, "455": 336, "8259": 336, "0235": 336, "8500": 336, "0024": 336, "4054": 336, "458": 336, "2027": 336, "0894": 336, "459": 336, "5966": 336, "460": 336, "6942": 336, "0016": 336, "4254": 336, "6703": 336, "0145": 336, "8124": 336, "0218": 336, "9196": 336, "0188": 336, "8986": 336, "0884": 336, "0084": 336, "5624": 336, "465": 336, "8862": 336, "0006": 336, "5384": 336, "466": 336, "5837": 336, "467": 336, "8954": 336, "0101": 336, "6751": 336, "468": 336, "8063": 336, "0122": 336, "9635": 336, "469": 336, "0692": 336, "4216": 336, "470": 336, "1227": 336, "0586": 336, "162e": 336, "471": 336, "9690": 336, "0074": 336, "4166": 336, "6324": 336, "473": 336, "0778": 336, "474": 336, "8548": 336, "0017": 336, "4408": 336, "475": 336, "8125": 336, "1515": 336, "476": 336, "2733": 336, "0044": 336, "2836": 336, "477": 336, "7497": 336, "7681": 336, "478": 336, "8547": 336, "0105": 336, "7212": 336, "479": 336, "9848": 336, "0019": 336, "6498": 336, "1987": 336, "0011": 336, "5473": 336, "481": 336, "8991": 336, "0033": 336, "6091": 336, "9189": 336, "5771": 336, "483": 336, "6781": 336, "7542": 336, "484": 336, "5959": 336, "0064": 336, "4295": 336, "485": 336, "2547": 336, "486": 336, "0636": 336, "547": 336, "487": 336, "0065": 336, "488": 336, "1694": 336, "0083": 336, "5759": 336, "489": 336, "0493": 336, "0021": 336, "7805": 336, "490": 336, "0950": 336, "497": 336, "491": 336, "9717": 336, "3672": 336, "492": 336, "0207": 336, "493": 336, "8266": 336, "0069": 336, "5365": 336, "494": 336, "2623": 336, "5078": 336, "495": 336, "4545": 336, "09636": 336, "8754": 336, "0010": 336, "498": 336, "0031": 336, "8269": 336, "499": 336, "4082": 336, "6642": 336, "2284": 336, "501": 336, "9130": 336, "502": 336, "503": 336, "7624": 336, "0056": 336, "3858": 336, "504": 336, "0890": 336, "0042": 336, "505": 336, "7505": 336, "2157": 336, "506": 336, "8394": 336, "3413": 336, "507": 336, "9609": 336, "0041": 336, "6905": 336, "508": 336, "8467": 336, "4409": 336, "509": 336, "510": 336, "8128": 336, "3559": 336, "511": 336, "1479": 336, "0264": 336, "1589": 336, "513": 336, "2756": 336, "0046": 336, "5266": 336, "514": 336, "9873": 336, "0112": 336, "9314": 336, "515": 336, "3791": 336, "0721": 336, "516": 336, "4580": 336, "0758": 336, "6114": 336, "517": 336, "2431": 336, "518": 336, "1958": 336, "5553": 336, "8924": 336, "0097": 336, "520": 336, "3737": 336, "0234": 336, "521": 336, "9125": 336, "4623": 336, "3230": 336, "0589": 336, "3784": 336, "523": 336, "9482": 336, "0051": 336, "524": 336, "1979": 336, "0045": 336, "6401": 336, "525": 336, "0048": 336, "6255": 336, "526": 336, "6084": 336, "3477": 336, "1475": 336, "0209": 336, "528": 336, "7611": 336, "1040": 336, "0099": 336, "0173": 336, "643": 336, "530": 336, "8189": 336, "4358": 336, "531": 336, "9897": 336, "1548": 336, "9751": 336, "533": 336, "6362": 336, "7495": 336, "534": 336, "1749": [336, 341], "9513": 336, "535": 336, "7708": 336, "0371": 336, "536": 336, "2649": 336, "0437": 336, "537": 336, "5491": 336, "0276": 336, "6426": 336, "7294": 336, "078e": 336, "539": 336, "9928": 336, "540": 336, "7937": 336, "0124": 336, "9664": 336, "541": 336, "3342": 336, "542": 336, "2046": 336, "5496": 336, "0956": 336, "0059": 336, "545": 336, "9028": 336, "5843": 336, "546": 336, "0674": 336, "0178": 336, "797": 336, "2815": 336, "0599": 336, "9276": 336, "8228": 336, "6164": 336, "551": 336, "6850": 336, "9167": 336, "3092": 336, "0670": 336, "9177": 336, "553": 336, "1599": 336, "0043": 336, "554": 336, "6367": 336, "555": 336, "3657": 336, "556": 336, "6694": 336, "2622": 336, "0372": 336, "4841": 336, "558": 336, "2707": 336, "0058": 336, "757": 336, "559": 336, "2267": 336, "5415": 336, "560": 336, "4556": 336, "0163": 336, "561": 336, "1839": 336, "0809": 336, "6262": 336, "562": 336, "0278": 336, "1112": 336, "6155": 336, "565": 336, "1427": 336, "3582": 336, "624": 336, "7870": 336, "9490": 336, "0439": 336, "8796": 336, "568": 336, "8026": 336, "612": 336, "569": 336, "3147": 336, "8486": 336, "570": 336, "7917": 336, "0129": 336, "571": 336, "9553": 336, "0020": 336, "6871": 336, "572": 336, "3132": 336, "0159": 336, "8646": 336, "573": 336, "5320": 336, "0269": 336, "574": 336, "2955": 336, "0245": 336, "575": 336, "3347": 336, "0179": 336, "9718": 336, "1629": 336, "804": 336, "577": 336, "0070": 336, "4335": 336, "578": 336, "579": 336, "3049": 336, "9063": 336, "580": 336, "8785": 336, "3295": 336, "5184": 336, "0546": 336, "582": 336, "4589": 336, "583": 336, "4697": 336, "2476": 336, "584": 336, "2397": 336, "585": 336, "4953": 336, "1775": 336, "586": 336, "2258": 336, "0110": 336, "7671": 336, "587": 336, "3981": 336, "8590": 336, "589": 336, "9820": 336, "4221": 336, "590": 336, "1293": 336, "0116": 336, "868": 336, "1675": 336, "5931": 336, "592": 336, "2910": 336, "5219": 336, "2124": 336, "1730": 336, "737": 336, "594": 336, "2914": 336, "0206": 336, "595": 336, "0172": 336, "3982": 336, "0945": 336, "0121": 336, "4789": 336, "597": 336, "3805": 336, "598": 336, "3310": 336, "5065": 336, "6028": 336, "6316": 336, "6724": 336, "6523": 336, "601": 336, "0136": 336, "4298": 336, "602": 336, "3524": 336, "2629": 336, "603": 336, "2635": 336, "7839": 336, "604": 336, "6041": 336, "8027": 336, "4170": 336, "4675": 336, "3153": 336, "9316": 336, "607": 336, "0649": 336, "9722": 336, "7989": 336, "0329": 336, "609": 336, "1976": 336, "6852": 336, "610": 336, "4793": 336, "1255": 336, "611": 336, "4581": 336, "0394": 336, "2047": 336, "0326": 336, "613": 336, "8967": 336, "8619": 336, "614": 336, "5906": 336, "6491": 336, "615": 336, "6634": 336, "4394": 336, "616": 336, "0624": 336, "0061": 336, "5676": 336, "3259": 336, "0131": 336, "7733": 336, "618": 336, "7515": 336, "0189": 336, "5575": 336, "9313": 336, "6286": 336, "620": 336, "4325": 336, "7832": 336, "1134": 336, "622": 336, "4572": 336, "0500": 336, "5838": 336, "623": 336, "3818": 336, "8623": 336, "1253": 336, "6622": 336, "subject": 336, "saw": [336, 338], "explain": 337, "semat": 337, "r3mtransform": 337, "embodi": 337, "ai": 337, "env_transform": [337, 341], "s3": 337, "amazonaw": 337, "r3m_50": 337, "374m": 337, "148mb": 337, "9m": 337, "126mb": 337, "0mb": 337, "8mb": 337, "5m": 337, "4mb": 337, "5mb": 337, "7mb": 337, "6m": 337, "106m": 337, "115m": 337, "131m": 337, "3mb": 337, "147m": 337, "162m": 337, "171m": 337, "179m": 337, "187m": 337, "197m": 337, "212m": 337, "219m": 337, "229m": 337, "1mb": 337, "245m": 337, "253m": 337, "261m": 337, "269m": 337, "279m": 337, "293m": 337, "301m": 337, "310m": 337, "317m": 337, "326m": 337, "332m": 337, "343m": 337, "350m": 337, "359m": 337, "366m": 337, "2mb": 337, "wiser": 337, "conclud": 337, "_storag": [337, 338], "supervis": [338, 341], "pull": 338, "temporarili": 338, "ram": [338, 341], "batteri": 338, "dataliststorag": 338, "datalazytensorstorag": 338, "tensordidct": 338, "datalazymemmapstorag": 338, "buffer_list": 338, "lowest": 338, "medium": 338, "buffer_lazytensor": 338, "buffer_lazymemmap": 338, "tempdir": 338, "tmpukvls44j": 338, "fullest": 338, "convini": 338, "mydata": 338, "background": 338, "question": [338, 340], "_i": 338, "artifici": 338, "0892946e": 338, "she": 338, "augment": 338, "proport": 338, "hist": 338, "barcontain": 338, "artist": 338, "revert": 338, "expens": 338, "reappear": 338, "unfold": 338, "problemat": 338, "window": 338, "4th": 338, "demo": 340, "icml": 340, "vmoen": 340, "fb": 340, "invest": 340, "platform": 340, "media": 340, "predominantli": 340, "tensordict1": 340, "tensordict2": 340, "tensordict_sampl": 340, "_sampler": 340, "_sum_tre": 340, "modulenotfounderror": 340, "28791671991348267": 340, "gym_env": 340, "noopresetenv": [340, 341], "backbone_modul": 340, "params_expand": 340, "tensordict_exp": 340, "base_modul": 340, "0137": 340, "1524": 340, "0641": 340, "viewbackward0": 340, "asstridedbackward0": 340, "8728": 340, "1334": 340, "3494": 340, "6887": 340, "6402": 340, "_safetanhbackward": 340, "1132": 340, "1762": 340, "3430": 340, "2668": 340, "2918": 340, "6239": 340, "roughli": 340, "tensordicts_prealloc": 340, "tensordicts_stack": 340, "tensordict_rollout": [340, 341], "disclaim": 340, "concatmodul": 340, "loss_td": 340, "year": 340, "roadmap": 340, "compris": 340, "contributor": 340, "curiou": 340, "nascent": 340, "unsupervis": 341, "rom": 341, "licens": 341, "pygam": 341, "unifi": 341, "_build_env": 341, "adventur": 341, "airraid": 341, "alien": 341, "amidar": 341, "assault": 341, "deserv": 341, "__episode__": 341, "__trajectory__": 341, "void": 341, "reproduct": 341, "tensordict_tprim": 341, "imshow": 341, "axesimag": 341, "0x7fae26a43730": 341, "inconsist": 341, "0x7fae7c715ac0": 341, "swingup": 341, "wrapper1": 341, "wrapper2": 341, "obviou": 341, "truth": 341, "env0": 341, "env_transformed_bi": 341, "stanc": 341, "transformeddistribut": 341, "base_dist": 341, "concat": 341, "mofidi": 341, "transformedenviron": 341, "moderet": 341, "computation": 341, "legitim": 341, "incom": 341, "amongst": 341, "wor": 341, "convention": 341, "scope": 341, "markovian": 341, "3288080526": 341, "constain": 341, "bar_": 341, "get_someth": 341, "bar_68e40232": 341, "a340": 341, "aargh": 341, "foo_list": 341, "batched_env": 341, "_dispatch_caller_parallel": 341, "0x7fad57ce08b0": 341, "bar_709d44ac": 341, "90bc": 341, "bar_70995374": 341, "8c6d": 341, "bar_709cb7da": 341, "bef7": 341, "parallen": 341, "particularili": 341, "evolv": 341, "steadi": 341, "approx": 341, "4978": 341, "3037": 341, "0864": 341, "8369": 341, "9655": 341, "9427": 341, "_extra_st": 341, "observation_ssq": 341, "observation_sum": 341, "4194": 341, "0220": 341, "3053": 341, "2217": 341, "2546": 341, "dispach": 341, "absor": 341}, "objects": {"torchrl._utils": [[11, 0, 1, "", "implement_for"]], "torchrl._utils.implement_for": [[11, 1, 1, "", "get_class_that_defined_method"], [11, 1, 1, "", "import_module"], [11, 1, 1, "", "module_set"], [11, 1, 1, "", "reset"]], "torchrl.collectors.collectors": [[12, 0, 1, "", "DataCollectorBase"], [13, 0, 1, "", "MultiSyncDataCollector"], [14, 0, 1, "", "MultiaSyncDataCollector"], [15, 0, 1, "", "RandomPolicy"], [16, 0, 1, "", "SyncDataCollector"], [17, 0, 1, "", "aSyncDataCollector"]], "torchrl.collectors.collectors.DataCollectorBase": [[12, 1, 1, "", "update_policy_weights_"]], "torchrl.collectors.collectors.MultiSyncDataCollector": [[13, 1, 1, "", "load_state_dict"], [13, 1, 1, "", "reset"], [13, 1, 1, "", "set_seed"], [13, 1, 1, "", "shutdown"], [13, 1, 1, "", "state_dict"], [13, 1, 1, "", "update_policy_weights_"]], "torchrl.collectors.collectors.MultiaSyncDataCollector": [[14, 1, 1, "", "load_state_dict"], [14, 1, 1, "", "reset"], [14, 1, 1, "", "set_seed"], [14, 1, 1, "", "shutdown"], [14, 1, 1, "", "state_dict"], [14, 1, 1, "", "update_policy_weights_"]], "torchrl.collectors.collectors.SyncDataCollector": [[16, 1, 1, "", "iterator"], [16, 1, 1, "", "load_state_dict"], [16, 1, 1, "", "reset"], [16, 1, 1, "", "rollout"], [16, 1, 1, "", "set_seed"], [16, 1, 1, "", "shutdown"], [16, 1, 1, "", "state_dict"], [16, 1, 1, "", "update_policy_weights_"]], "torchrl.collectors.collectors.aSyncDataCollector": [[17, 1, 1, "", "load_state_dict"], [17, 1, 1, "", "reset"], [17, 1, 1, "", "set_seed"], [17, 1, 1, "", "shutdown"], [17, 1, 1, "", "state_dict"], [17, 1, 1, "", "update_policy_weights_"]], "torchrl.collectors.distributed": [[18, 0, 1, "", "DistributedDataCollector"], [19, 0, 1, "", "DistributedSyncDataCollector"], [20, 0, 1, "", "RPCDataCollector"], [21, 0, 1, "", "RayCollector"], [22, 0, 1, "", "submitit_delayed_launcher"]], "torchrl.collectors.distributed.DistributedDataCollector": [[18, 1, 1, "", "update_policy_weights_"]], "torchrl.collectors.distributed.DistributedSyncDataCollector": [[19, 1, 1, "", "update_policy_weights_"]], "torchrl.collectors.distributed.RPCDataCollector": [[20, 1, 1, "", "update_policy_weights_"]], "torchrl.collectors.distributed.RayCollector": [[21, 1, 1, "", "add_collectors"], [21, 1, 1, "", "load_state_dict"], [21, 1, 1, "", "local_policy"], [21, 1, 1, "", "remote_collectors"], [21, 1, 1, "", "set_seed"], [21, 1, 1, "", "shutdown"], [21, 1, 1, "", "state_dict"], [21, 1, 1, "", "stop_remote_collectors"], [21, 1, 1, "", "update_policy_weights_"]], "torchrl.collectors.utils": [[23, 2, 1, "", "split_trajectories"]], "torchrl.data": [[24, 0, 1, "", "BinaryDiscreteTensorSpec"], [25, 0, 1, "", "BoundedTensorSpec"], [26, 0, 1, "", "CompositeSpec"], [27, 0, 1, "", "DiscreteTensorSpec"], [28, 0, 1, "", "LazyStackedCompositeSpec"], [29, 0, 1, "", "LazyStackedTensorSpec"], [30, 0, 1, "", "MultiDiscreteTensorSpec"], [31, 0, 1, "", "MultiOneHotDiscreteTensorSpec"], [32, 0, 1, "", "MultiStep"], [33, 0, 1, "", "OneHotDiscreteTensorSpec"], [34, 0, 1, "", "PairwiseDataset"], [35, 0, 1, "", "PrioritizedReplayBuffer"], [36, 0, 1, "", "PromptData"], [37, 0, 1, "", "PromptTensorDictTokenizer"], [38, 0, 1, "", "ReplayBuffer"], [39, 0, 1, "", "RewardData"], [40, 0, 1, "", "RolloutFromModel"], [41, 0, 1, "", "TensorDictPrioritizedReplayBuffer"], [42, 0, 1, "", "TensorDictReplayBuffer"], [43, 0, 1, "", "TensorDictTokenizer"], [44, 0, 1, "", "TensorSpec"], [45, 0, 1, "", "TokenizedDatasetLoader"], [46, 0, 1, "", "UnboundedContinuousTensorSpec"], [47, 0, 1, "", "UnboundedDiscreteTensorSpec"], [48, 0, 1, "", "check_no_exclusive_keys"], [49, 0, 1, "", "consolidate_spec"], [50, 0, 1, "", "contains_lazy_spec"], [51, 0, 1, "", "create_infinite_iterator"], [57, 0, 1, "", "get_dataloader"]], "torchrl.data.BinaryDiscreteTensorSpec": [[24, 1, 1, "", "assert_is_in"], [24, 1, 1, "", "encode"], [24, 1, 1, "", "expand"], [24, 1, 1, "", "implements_for_spec"], [24, 1, 1, "", "index"], [24, 1, 1, "", "is_in"], [24, 1, 1, "", "project"], [24, 1, 1, "", "rand"], [24, 1, 1, "", "squeeze"], [24, 1, 1, "", "to_numpy"], [24, 1, 1, "", "to_one_hot"], [24, 1, 1, "", "to_one_hot_spec"], [24, 1, 1, "", "type_check"], [24, 1, 1, "", "zero"]], "torchrl.data.BoundedTensorSpec": [[25, 1, 1, "", "assert_is_in"], [25, 1, 1, "", "encode"], [25, 1, 1, "", "expand"], [25, 1, 1, "", "implements_for_spec"], [25, 1, 1, "", "index"], [25, 1, 1, "", "is_in"], [25, 1, 1, "", "project"], [25, 1, 1, "", "rand"], [25, 1, 1, "", "squeeze"], [25, 1, 1, "", "to_numpy"], [25, 1, 1, "", "type_check"], [25, 1, 1, "", "zero"]], "torchrl.data.CompositeSpec": [[26, 1, 1, "", "assert_is_in"], [26, 1, 1, "", "empty"], [26, 1, 1, "", "encode"], [26, 1, 1, "", "expand"], [26, 1, 1, "", "implements_for_spec"], [26, 1, 1, "", "index"], [26, 1, 1, "", "is_empty"], [26, 1, 1, "", "is_in"], [26, 1, 1, "", "items"], [26, 1, 1, "", "keys"], [26, 1, 1, "", "lock_"], [26, 1, 1, "", "project"], [26, 1, 1, "", "rand"], [26, 1, 1, "", "squeeze"], [26, 1, 1, "", "to_numpy"], [26, 1, 1, "", "type_check"], [26, 1, 1, "", "unlock_"], [26, 1, 1, "", "values"], [26, 1, 1, "", "zero"]], "torchrl.data.DiscreteTensorSpec": [[27, 1, 1, "", "assert_is_in"], [27, 1, 1, "", "encode"], [27, 1, 1, "", "expand"], [27, 1, 1, "", "implements_for_spec"], [27, 1, 1, "", "index"], [27, 1, 1, "", "is_in"], [27, 1, 1, "", "project"], [27, 1, 1, "", "rand"], [27, 1, 1, "", "squeeze"], [27, 1, 1, "", "to_numpy"], [27, 1, 1, "", "to_one_hot"], [27, 1, 1, "", "to_one_hot_spec"], [27, 1, 1, "", "type_check"], [27, 1, 1, "", "zero"]], "torchrl.data.LazyStackedCompositeSpec": [[28, 1, 1, "", "assert_is_in"], [28, 1, 1, "", "empty"], [28, 1, 1, "", "encode"], [28, 1, 1, "", "expand"], [28, 1, 1, "", "implements_for_spec"], [28, 1, 1, "", "index"], [28, 1, 1, "", "is_empty"], [28, 1, 1, "", "is_in"], [28, 1, 1, "", "items"], [28, 1, 1, "", "keys"], [28, 1, 1, "", "lock_"], [28, 1, 1, "", "project"], [28, 1, 1, "", "rand"], [28, 1, 1, "", "squeeze"], [28, 1, 1, "", "to_numpy"], [28, 1, 1, "", "type_check"], [28, 1, 1, "", "unlock_"], [28, 1, 1, "", "values"], [28, 1, 1, "", "zero"]], "torchrl.data.LazyStackedTensorSpec": [[29, 1, 1, "", "assert_is_in"], [29, 1, 1, "", "encode"], [29, 1, 1, "", "expand"], [29, 1, 1, "", "implements_for_spec"], [29, 1, 1, "", "index"], [29, 1, 1, "", "is_in"], [29, 1, 1, "", "project"], [29, 1, 1, "", "rand"], [29, 1, 1, "", "squeeze"], [29, 1, 1, "", "to_numpy"], [29, 1, 1, "", "type_check"], [29, 1, 1, "", "zero"]], "torchrl.data.MultiDiscreteTensorSpec": [[30, 1, 1, "", "assert_is_in"], [30, 1, 1, "", "encode"], [30, 1, 1, "", "expand"], [30, 1, 1, "", "implements_for_spec"], [30, 1, 1, "", "index"], [30, 1, 1, "", "is_in"], [30, 1, 1, "", "project"], [30, 1, 1, "", "rand"], [30, 1, 1, "", "squeeze"], [30, 1, 1, "", "to_numpy"], [30, 1, 1, "", "to_one_hot"], [30, 1, 1, "", "to_one_hot_spec"], [30, 1, 1, "", "type_check"], [30, 1, 1, "", "zero"]], "torchrl.data.MultiOneHotDiscreteTensorSpec": [[31, 1, 1, "", "assert_is_in"], [31, 1, 1, "", "encode"], [31, 1, 1, "", "expand"], [31, 1, 1, "", "implements_for_spec"], [31, 1, 1, "", "index"], [31, 1, 1, "", "is_in"], [31, 1, 1, "", "project"], [31, 1, 1, "", "rand"], [31, 1, 1, "", "squeeze"], [31, 1, 1, "", "to_categorical"], [31, 1, 1, "", "to_categorical_spec"], [31, 1, 1, "", "to_numpy"], [31, 1, 1, "", "type_check"], [31, 1, 1, "", "zero"]], "torchrl.data.MultiStep": [[32, 1, 1, "", "add_module"], [32, 1, 1, "", "apply"], [32, 1, 1, "", "bfloat16"], [32, 1, 1, "", "buffers"], [32, 1, 1, "", "children"], [32, 1, 1, "", "compile"], [32, 1, 1, "", "cpu"], [32, 1, 1, "", "cuda"], [32, 1, 1, "", "double"], [32, 1, 1, "", "eval"], [32, 1, 1, "", "extra_repr"], [32, 1, 1, "", "float"], [32, 1, 1, "", "forward"], [32, 1, 1, "", "get_buffer"], [32, 1, 1, "", "get_extra_state"], [32, 1, 1, "", "get_parameter"], [32, 1, 1, "", "get_submodule"], [32, 1, 1, "", "half"], [32, 1, 1, "", "ipu"], [32, 1, 1, "", "load_state_dict"], [32, 1, 1, "", "modules"], [32, 1, 1, "", "named_buffers"], [32, 1, 1, "", "named_children"], [32, 1, 1, "", "named_modules"], [32, 1, 1, "", "named_parameters"], [32, 1, 1, "", "parameters"], [32, 1, 1, "", "register_backward_hook"], [32, 1, 1, "", "register_buffer"], [32, 1, 1, "", "register_forward_hook"], [32, 1, 1, "", "register_forward_pre_hook"], [32, 1, 1, "", "register_full_backward_hook"], [32, 1, 1, "", "register_full_backward_pre_hook"], [32, 1, 1, "", "register_load_state_dict_post_hook"], [32, 1, 1, "", "register_module"], [32, 1, 1, "", "register_parameter"], [32, 1, 1, "", "register_state_dict_pre_hook"], [32, 1, 1, "", "requires_grad_"], [32, 1, 1, "", "set_extra_state"], [32, 1, 1, "", "share_memory"], [32, 1, 1, "", "state_dict"], [32, 1, 1, "", "to"], [32, 1, 1, "", "to_empty"], [32, 1, 1, "", "train"], [32, 1, 1, "", "type"], [32, 1, 1, "", "xpu"], [32, 1, 1, "", "zero_grad"]], "torchrl.data.OneHotDiscreteTensorSpec": [[33, 1, 1, "", "assert_is_in"], [33, 1, 1, "", "encode"], [33, 1, 1, "", "expand"], [33, 1, 1, "", "implements_for_spec"], [33, 1, 1, "", "index"], [33, 1, 1, "", "is_in"], [33, 1, 1, "", "project"], [33, 1, 1, "", "rand"], [33, 1, 1, "", "squeeze"], [33, 1, 1, "", "to_categorical"], [33, 1, 1, "", "to_categorical_spec"], [33, 1, 1, "", "to_numpy"], [33, 1, 1, "", "type_check"], [33, 1, 1, "", "zero"]], "torchrl.data.PairwiseDataset": [[34, 3, 1, "", "batch_size"], [34, 3, 1, "", "device"], [34, 1, 1, "", "from_dataset"], [34, 1, 1, "", "from_dict"], [34, 1, 1, "", "from_tensordict"], [34, 1, 1, "", "get"], [34, 1, 1, "", "load_state_dict"], [34, 1, 1, "", "memmap"], [34, 1, 1, "", "memmap_"], [34, 1, 1, "", "memmap_like"], [34, 1, 1, "", "set"], [34, 1, 1, "", "state_dict"], [34, 1, 1, "", "to_tensordict"], [34, 1, 1, "", "unbind"]], "torchrl.data.PrioritizedReplayBuffer": [[35, 1, 1, "", "add"], [35, 1, 1, "", "append_transform"], [35, 1, 1, "", "dumps"], [35, 1, 1, "", "empty"], [35, 1, 1, "", "extend"], [35, 1, 1, "", "insert_transform"], [35, 1, 1, "", "loads"], [35, 1, 1, "", "sample"]], "torchrl.data.PromptData": [[36, 3, 1, "", "batch_size"], [36, 3, 1, "", "device"], [36, 1, 1, "", "from_dataset"], [36, 1, 1, "", "from_dict"], [36, 1, 1, "", "from_tensordict"], [36, 1, 1, "", "get"], [36, 1, 1, "", "load_state_dict"], [36, 1, 1, "", "memmap"], [36, 1, 1, "", "memmap_"], [36, 1, 1, "", "memmap_like"], [36, 1, 1, "", "set"], [36, 1, 1, "", "state_dict"], [36, 1, 1, "", "to_tensordict"], [36, 1, 1, "", "unbind"]], "torchrl.data.ReplayBuffer": [[38, 1, 1, "", "add"], [38, 1, 1, "", "append_transform"], [38, 1, 1, "", "dumps"], [38, 1, 1, "", "empty"], [38, 1, 1, "", "extend"], [38, 1, 1, "", "insert_transform"], [38, 1, 1, "", "loads"], [38, 1, 1, "", "sample"]], "torchrl.data.RewardData": [[39, 3, 1, "", "batch_size"], [39, 3, 1, "", "device"], [39, 1, 1, "", "from_dict"], [39, 1, 1, "", "from_tensordict"], [39, 1, 1, "", "get"], [39, 1, 1, "", "load_state_dict"], [39, 1, 1, "", "memmap"], [39, 1, 1, "", "memmap_"], [39, 1, 1, "", "memmap_like"], [39, 1, 1, "", "set"], [39, 1, 1, "", "state_dict"], [39, 1, 1, "", "to_tensordict"], [39, 1, 1, "", "unbind"]], "torchrl.data.RolloutFromModel": [[40, 1, 1, "", "create_rollout_td"], [40, 1, 1, "", "generate"], [40, 1, 1, "", "logprobs_of_labels"]], "torchrl.data.TensorDictPrioritizedReplayBuffer": [[41, 1, 1, "", "add"], [41, 1, 1, "", "append_transform"], [41, 1, 1, "", "dumps"], [41, 1, 1, "", "empty"], [41, 1, 1, "", "extend"], [41, 1, 1, "", "insert_transform"], [41, 1, 1, "", "loads"], [41, 1, 1, "", "sample"]], "torchrl.data.TensorDictReplayBuffer": [[42, 1, 1, "", "add"], [42, 1, 1, "", "append_transform"], [42, 1, 1, "", "dumps"], [42, 1, 1, "", "empty"], [42, 1, 1, "", "extend"], [42, 1, 1, "", "insert_transform"], [42, 1, 1, "", "loads"], [42, 1, 1, "", "sample"]], "torchrl.data.TensorSpec": [[44, 1, 1, "", "assert_is_in"], [44, 1, 1, "", "encode"], [44, 1, 1, "", "expand"], [44, 1, 1, "", "implements_for_spec"], [44, 1, 1, "", "index"], [44, 1, 1, "", "is_in"], [44, 1, 1, "", "project"], [44, 1, 1, "", "rand"], [44, 1, 1, "", "squeeze"], [44, 1, 1, "", "to_numpy"], [44, 1, 1, "", "type_check"], [44, 1, 1, "", "zero"]], "torchrl.data.TokenizedDatasetLoader": [[45, 1, 1, "", "dataset_to_tensordict"], [45, 1, 1, "", "load"]], "torchrl.data.UnboundedContinuousTensorSpec": [[46, 1, 1, "", "assert_is_in"], [46, 1, 1, "", "encode"], [46, 1, 1, "", "expand"], [46, 1, 1, "", "implements_for_spec"], [46, 1, 1, "", "index"], [46, 1, 1, "", "is_in"], [46, 1, 1, "", "project"], [46, 1, 1, "", "rand"], [46, 1, 1, "", "squeeze"], [46, 1, 1, "", "to_numpy"], [46, 1, 1, "", "type_check"], [46, 1, 1, "", "zero"]], "torchrl.data.UnboundedDiscreteTensorSpec": [[47, 1, 1, "", "assert_is_in"], [47, 1, 1, "", "encode"], [47, 1, 1, "", "expand"], [47, 1, 1, "", "implements_for_spec"], [47, 1, 1, "", "index"], [47, 1, 1, "", "is_in"], [47, 1, 1, "", "project"], [47, 1, 1, "", "rand"], [47, 1, 1, "", "squeeze"], [47, 1, 1, "", "to_numpy"], [47, 1, 1, "", "type_check"], [47, 1, 1, "", "zero"]], "torchrl.data.datasets": [[52, 0, 1, "", "D4RLExperienceReplay"], [53, 0, 1, "", "MinariExperienceReplay"], [54, 0, 1, "", "OpenMLExperienceReplay"], [55, 0, 1, "", "RobosetExperienceReplay"], [56, 0, 1, "", "VD4RLExperienceReplay"]], "torchrl.data.datasets.D4RLExperienceReplay": [[52, 1, 1, "", "add"], [52, 1, 1, "", "append_transform"], [52, 1, 1, "", "dumps"], [52, 1, 1, "", "empty"], [52, 1, 1, "", "extend"], [52, 1, 1, "", "insert_transform"], [52, 1, 1, "", "loads"], [52, 1, 1, "", "sample"]], "torchrl.data.datasets.MinariExperienceReplay": [[53, 1, 1, "", "add"], [53, 1, 1, "", "append_transform"], [53, 1, 1, "", "dumps"], [53, 1, 1, "", "empty"], [53, 1, 1, "", "extend"], [53, 1, 1, "", "insert_transform"], [53, 1, 1, "", "loads"], [53, 1, 1, "", "sample"]], "torchrl.data.datasets.OpenMLExperienceReplay": [[54, 1, 1, "", "add"], [54, 1, 1, "", "append_transform"], [54, 1, 1, "", "dumps"], [54, 1, 1, "", "empty"], [54, 1, 1, "", "extend"], [54, 1, 1, "", "insert_transform"], [54, 1, 1, "", "loads"], [54, 1, 1, "", "sample"]], "torchrl.data.datasets.RobosetExperienceReplay": [[55, 1, 1, "", "add"], [55, 1, 1, "", "append_transform"], [55, 1, 1, "", "dumps"], [55, 1, 1, "", "empty"], [55, 1, 1, "", "extend"], [55, 1, 1, "", "insert_transform"], [55, 1, 1, "", "loads"], [55, 1, 1, "", "sample"]], "torchrl.data.datasets.VD4RLExperienceReplay": [[56, 1, 1, "", "add"], [56, 1, 1, "", "append_transform"], [56, 1, 1, "", "dumps"], [56, 1, 1, "", "empty"], [56, 1, 1, "", "extend"], [56, 1, 1, "", "insert_transform"], [56, 1, 1, "", "loads"], [56, 1, 1, "", "sample"]], "torchrl.data.replay_buffers": [[58, 0, 1, "", "LazyMemmapStorage"], [59, 0, 1, "", "LazyTensorStorage"], [60, 0, 1, "", "ListStorage"], [61, 0, 1, "", "PrioritizedSampler"], [62, 0, 1, "", "RandomSampler"], [63, 0, 1, "", "RoundRobinWriter"], [64, 0, 1, "", "Sampler"], [65, 0, 1, "", "SamplerWithoutReplacement"], [66, 0, 1, "", "SliceSampler"], [67, 0, 1, "", "SliceSamplerWithoutReplacement"], [68, 0, 1, "", "Storage"], [69, 0, 1, "", "TensorDictMaxValueWriter"], [70, 0, 1, "", "TensorDictRoundRobinWriter"], [71, 0, 1, "", "TensorStorage"], [72, 0, 1, "", "Writer"]], "torchrl.data.replay_buffers.LazyMemmapStorage": [[58, 1, 1, "", "attach"]], "torchrl.data.replay_buffers.LazyTensorStorage": [[59, 1, 1, "", "attach"]], "torchrl.data.replay_buffers.ListStorage": [[60, 1, 1, "", "attach"]], "torchrl.data.replay_buffers.PrioritizedSampler": [[61, 1, 1, "", "update_priority"]], "torchrl.data.replay_buffers.RoundRobinWriter": [[63, 1, 1, "", "add"], [63, 1, 1, "", "extend"]], "torchrl.data.replay_buffers.Storage": [[68, 1, 1, "", "attach"]], "torchrl.data.replay_buffers.TensorDictMaxValueWriter": [[69, 1, 1, "", "add"], [69, 1, 1, "", "extend"], [69, 1, 1, "", "get_insert_index"]], "torchrl.data.replay_buffers.TensorDictRoundRobinWriter": [[70, 1, 1, "", "add"], [70, 1, 1, "", "extend"]], "torchrl.data.replay_buffers.TensorStorage": [[71, 1, 1, "", "attach"]], "torchrl.data.replay_buffers.Writer": [[72, 1, 1, "", "add"], [72, 1, 1, "", "extend"]], "torchrl.envs": [[73, 2, 1, "", "BraxEnv"], [74, 2, 1, "", "BraxWrapper"], [75, 2, 1, "", "DMControlEnv"], [76, 2, 1, "", "DMControlWrapper"], [77, 0, 1, "", "EnvBase"], [78, 0, 1, "", "EnvCreator"], [79, 0, 1, "", "EnvMetaData"], [80, 2, 1, "", "GymEnv"], [81, 0, 1, "", "GymLikeEnv"], [82, 2, 1, "", "GymWrapper"], [83, 2, 1, "", "HabitatEnv"], [84, 2, 1, "", "IsaacGymEnv"], [85, 2, 1, "", "IsaacGymWrapper"], [86, 2, 1, "", "JumanjiEnv"], [87, 2, 1, "", "JumanjiWrapper"], [88, 2, 1, "", "MOGymEnv"], [89, 2, 1, "", "MOGymWrapper"], [90, 2, 1, "", "MarlGroupMapType"], [91, 2, 1, "", "ModelBasedEnvBase"], [92, 2, 1, "", "MultiThreadedEnv"], [93, 2, 1, "", "MultiThreadedEnvWrapper"], [94, 2, 1, "", "OpenMLEnv"], [95, 0, 1, "", "ParallelEnv"], [96, 2, 1, "", "PettingZooEnv"], [97, 2, 1, "", "PettingZooWrapper"], [98, 2, 1, "", "RoboHiveEnv"], [99, 2, 1, "", "SMACv2Env"], [100, 2, 1, "", "SMACv2Wrapper"], [101, 0, 1, "", "SerialEnv"], [102, 2, 1, "", "VmasEnv"], [103, 2, 1, "", "VmasWrapper"], [104, 2, 1, "", "check_marl_grouping"], [105, 2, 1, "", "gym_backend"], [91, 1, 1, "", "rand_step"], [91, 1, 1, "", "reset"], [91, 1, 1, "", "rollout"], [107, 2, 1, "", "set_gym_backend"], [91, 1, 1, "", "set_seed"], [91, 1, 1, "", "step"]], "torchrl.envs.EnvBase": [[77, 3, 1, "", "action_key"], [77, 3, 1, "", "action_keys"], [77, 3, 1, "", "action_spec"], [77, 1, 1, "", "add_module"], [77, 1, 1, "", "apply"], [77, 3, 1, "", "batch_locked"], [77, 1, 1, "", "bfloat16"], [77, 1, 1, "", "buffers"], [77, 1, 1, "", "children"], [77, 1, 1, "", "compile"], [77, 1, 1, "", "cpu"], [77, 1, 1, "", "cuda"], [77, 3, 1, "", "done_key"], [77, 3, 1, "", "done_keys"], [77, 3, 1, "", "done_keys_groups"], [77, 3, 1, "", "done_spec"], [77, 1, 1, "", "double"], [77, 1, 1, "", "empty_cache"], [77, 1, 1, "", "eval"], [77, 1, 1, "", "extra_repr"], [77, 1, 1, "", "fake_tensordict"], [77, 1, 1, "", "float"], [77, 1, 1, "", "forward"], [77, 3, 1, "", "full_action_spec"], [77, 3, 1, "", "full_done_spec"], [77, 3, 1, "", "full_reward_spec"], [77, 3, 1, "", "full_state_spec"], [77, 1, 1, "", "get_buffer"], [77, 1, 1, "", "get_extra_state"], [77, 1, 1, "", "get_parameter"], [77, 1, 1, "", "get_submodule"], [77, 1, 1, "", "half"], [77, 3, 1, "", "input_spec"], [77, 1, 1, "", "ipu"], [77, 1, 1, "", "load_state_dict"], [77, 1, 1, "", "modules"], [77, 1, 1, "", "named_buffers"], [77, 1, 1, "", "named_children"], [77, 1, 1, "", "named_modules"], [77, 1, 1, "", "named_parameters"], [77, 3, 1, "", "observation_spec"], [77, 3, 1, "", "output_spec"], [77, 1, 1, "", "parameters"], [77, 1, 1, "", "rand_action"], [77, 1, 1, "id0", "rand_step"], [77, 1, 1, "", "register_backward_hook"], [77, 1, 1, "", "register_buffer"], [77, 1, 1, "", "register_forward_hook"], [77, 1, 1, "", "register_forward_pre_hook"], [77, 1, 1, "", "register_full_backward_hook"], [77, 1, 1, "", "register_full_backward_pre_hook"], [77, 1, 1, "", "register_load_state_dict_post_hook"], [77, 1, 1, "", "register_module"], [77, 1, 1, "", "register_parameter"], [77, 1, 1, "", "register_state_dict_pre_hook"], [77, 1, 1, "", "requires_grad_"], [77, 1, 1, "id1", "reset"], [77, 3, 1, "", "reset_keys"], [77, 3, 1, "", "reward_key"], [77, 3, 1, "", "reward_keys"], [77, 3, 1, "", "reward_spec"], [77, 1, 1, "id2", "rollout"], [77, 1, 1, "", "set_extra_state"], [77, 1, 1, "id3", "set_seed"], [77, 1, 1, "", "share_memory"], [77, 3, 1, "", "specs"], [77, 1, 1, "", "state_dict"], [77, 3, 1, "", "state_spec"], [77, 1, 1, "id4", "step"], [77, 1, 1, "", "step_and_maybe_reset"], [77, 1, 1, "", "to"], [77, 1, 1, "", "to_empty"], [77, 1, 1, "", "train"], [77, 1, 1, "", "type"], [77, 1, 1, "", "xpu"], [77, 1, 1, "", "zero_grad"]], "torchrl.envs.GymLikeEnv": [[81, 3, 1, "", "action_key"], [81, 3, 1, "", "action_keys"], [81, 3, 1, "", "action_spec"], [81, 1, 1, "", "add_module"], [81, 1, 1, "", "apply"], [81, 3, 1, "", "batch_locked"], [81, 1, 1, "", "bfloat16"], [81, 1, 1, "", "buffers"], [81, 1, 1, "", "children"], [81, 1, 1, "", "close"], [81, 1, 1, "", "compile"], [81, 1, 1, "", "cpu"], [81, 1, 1, "", "cuda"], [81, 3, 1, "", "done_key"], [81, 3, 1, "", "done_keys"], [81, 3, 1, "", "done_keys_groups"], [81, 3, 1, "", "done_spec"], [81, 1, 1, "", "double"], [81, 1, 1, "", "empty_cache"], [81, 1, 1, "", "eval"], [81, 1, 1, "", "extra_repr"], [81, 1, 1, "", "fake_tensordict"], [81, 1, 1, "", "float"], [81, 1, 1, "", "forward"], [81, 3, 1, "", "full_action_spec"], [81, 3, 1, "", "full_done_spec"], [81, 3, 1, "", "full_reward_spec"], [81, 3, 1, "", "full_state_spec"], [81, 1, 1, "", "get_buffer"], [81, 1, 1, "", "get_extra_state"], [81, 1, 1, "", "get_parameter"], [81, 1, 1, "", "get_submodule"], [81, 1, 1, "", "half"], [81, 3, 1, "", "input_spec"], [81, 1, 1, "", "ipu"], [81, 1, 1, "", "load_state_dict"], [81, 1, 1, "", "modules"], [81, 1, 1, "", "named_buffers"], [81, 1, 1, "", "named_children"], [81, 1, 1, "", "named_modules"], [81, 1, 1, "", "named_parameters"], [81, 3, 1, "", "observation_spec"], [81, 3, 1, "", "output_spec"], [81, 1, 1, "", "parameters"], [81, 1, 1, "", "rand_action"], [81, 1, 1, "", "rand_step"], [81, 1, 1, "", "read_action"], [81, 1, 1, "", "read_done"], [81, 1, 1, "", "read_obs"], [81, 1, 1, "", "read_reward"], [81, 1, 1, "", "register_backward_hook"], [81, 1, 1, "", "register_buffer"], [81, 1, 1, "", "register_forward_hook"], [81, 1, 1, "", "register_forward_pre_hook"], [81, 1, 1, "", "register_full_backward_hook"], [81, 1, 1, "", "register_full_backward_pre_hook"], [81, 1, 1, "", "register_load_state_dict_post_hook"], [81, 1, 1, "", "register_module"], [81, 1, 1, "", "register_parameter"], [81, 1, 1, "", "register_state_dict_pre_hook"], [81, 1, 1, "", "requires_grad_"], [81, 1, 1, "", "reset"], [81, 3, 1, "", "reset_keys"], [81, 3, 1, "", "reward_key"], [81, 3, 1, "", "reward_keys"], [81, 3, 1, "", "reward_spec"], [81, 1, 1, "", "rollout"], [81, 1, 1, "", "set_extra_state"], [81, 1, 1, "", "set_info_dict_reader"], [81, 1, 1, "", "set_seed"], [81, 1, 1, "", "share_memory"], [81, 3, 1, "", "specs"], [81, 1, 1, "", "state_dict"], [81, 3, 1, "", "state_spec"], [81, 1, 1, "", "step"], [81, 1, 1, "", "step_and_maybe_reset"], [81, 1, 1, "", "to"], [81, 1, 1, "", "to_empty"], [81, 1, 1, "", "train"], [81, 1, 1, "", "type"], [81, 1, 1, "", "xpu"], [81, 1, 1, "", "zero_grad"]], "torchrl.envs.ParallelEnv": [[95, 3, 1, "", "action_key"], [95, 3, 1, "", "action_keys"], [95, 3, 1, "", "action_spec"], [95, 1, 1, "", "add_module"], [95, 1, 1, "", "apply"], [95, 3, 1, "", "batch_locked"], [95, 1, 1, "", "bfloat16"], [95, 1, 1, "", "buffers"], [95, 1, 1, "", "children"], [95, 1, 1, "", "compile"], [95, 1, 1, "", "cpu"], [95, 1, 1, "", "cuda"], [95, 3, 1, "", "done_key"], [95, 3, 1, "", "done_keys"], [95, 3, 1, "", "done_keys_groups"], [95, 3, 1, "", "done_spec"], [95, 1, 1, "", "double"], [95, 1, 1, "", "empty_cache"], [95, 1, 1, "", "eval"], [95, 1, 1, "", "extra_repr"], [95, 1, 1, "", "fake_tensordict"], [95, 1, 1, "", "float"], [95, 1, 1, "", "forward"], [95, 3, 1, "", "full_action_spec"], [95, 3, 1, "", "full_done_spec"], [95, 3, 1, "", "full_reward_spec"], [95, 3, 1, "", "full_state_spec"], [95, 1, 1, "", "get_buffer"], [95, 1, 1, "", "get_extra_state"], [95, 1, 1, "", "get_parameter"], [95, 1, 1, "", "get_submodule"], [95, 1, 1, "", "half"], [95, 3, 1, "", "input_spec"], [95, 1, 1, "", "ipu"], [95, 1, 1, "", "load_state_dict"], [95, 1, 1, "", "modules"], [95, 1, 1, "", "named_buffers"], [95, 1, 1, "", "named_children"], [95, 1, 1, "", "named_modules"], [95, 1, 1, "", "named_parameters"], [95, 3, 1, "", "observation_spec"], [95, 3, 1, "", "output_spec"], [95, 1, 1, "", "parameters"], [95, 1, 1, "", "rand_action"], [95, 1, 1, "", "rand_step"], [95, 1, 1, "", "register_backward_hook"], [95, 1, 1, "", "register_buffer"], [95, 1, 1, "", "register_forward_hook"], [95, 1, 1, "", "register_forward_pre_hook"], [95, 1, 1, "", "register_full_backward_hook"], [95, 1, 1, "", "register_full_backward_pre_hook"], [95, 1, 1, "", "register_load_state_dict_post_hook"], [95, 1, 1, "", "register_module"], [95, 1, 1, "", "register_parameter"], [95, 1, 1, "", "register_state_dict_pre_hook"], [95, 1, 1, "", "requires_grad_"], [95, 1, 1, "", "reset"], [95, 3, 1, "", "reset_keys"], [95, 3, 1, "", "reward_key"], [95, 3, 1, "", "reward_keys"], [95, 3, 1, "", "reward_spec"], [95, 1, 1, "", "rollout"], [95, 1, 1, "", "set_extra_state"], [95, 1, 1, "", "set_seed"], [95, 1, 1, "", "share_memory"], [95, 3, 1, "", "specs"], [95, 1, 1, "", "state_dict"], [95, 3, 1, "", "state_spec"], [95, 1, 1, "", "step"], [95, 1, 1, "", "step_and_maybe_reset"], [95, 1, 1, "", "to"], [95, 1, 1, "", "to_empty"], [95, 1, 1, "", "train"], [95, 1, 1, "", "type"], [95, 1, 1, "", "update_kwargs"], [95, 1, 1, "", "xpu"], [95, 1, 1, "", "zero_grad"]], "torchrl.envs.SerialEnv": [[101, 3, 1, "", "action_key"], [101, 3, 1, "", "action_keys"], [101, 3, 1, "", "action_spec"], [101, 1, 1, "", "add_module"], [101, 1, 1, "", "apply"], [101, 3, 1, "", "batch_locked"], [101, 1, 1, "", "bfloat16"], [101, 1, 1, "", "buffers"], [101, 1, 1, "", "children"], [101, 1, 1, "", "compile"], [101, 1, 1, "", "cpu"], [101, 1, 1, "", "cuda"], [101, 3, 1, "", "done_key"], [101, 3, 1, "", "done_keys"], [101, 3, 1, "", "done_keys_groups"], [101, 3, 1, "", "done_spec"], [101, 1, 1, "", "double"], [101, 1, 1, "", "empty_cache"], [101, 1, 1, "", "eval"], [101, 1, 1, "", "extra_repr"], [101, 1, 1, "", "fake_tensordict"], [101, 1, 1, "", "float"], [101, 1, 1, "", "forward"], [101, 3, 1, "", "full_action_spec"], [101, 3, 1, "", "full_done_spec"], [101, 3, 1, "", "full_reward_spec"], [101, 3, 1, "", "full_state_spec"], [101, 1, 1, "", "get_buffer"], [101, 1, 1, "", "get_extra_state"], [101, 1, 1, "", "get_parameter"], [101, 1, 1, "", "get_submodule"], [101, 1, 1, "", "half"], [101, 3, 1, "", "input_spec"], [101, 1, 1, "", "ipu"], [101, 1, 1, "", "load_state_dict"], [101, 1, 1, "", "modules"], [101, 1, 1, "", "named_buffers"], [101, 1, 1, "", "named_children"], [101, 1, 1, "", "named_modules"], [101, 1, 1, "", "named_parameters"], [101, 3, 1, "", "observation_spec"], [101, 3, 1, "", "output_spec"], [101, 1, 1, "", "parameters"], [101, 1, 1, "", "rand_action"], [101, 1, 1, "", "rand_step"], [101, 1, 1, "", "register_backward_hook"], [101, 1, 1, "", "register_buffer"], [101, 1, 1, "", "register_forward_hook"], [101, 1, 1, "", "register_forward_pre_hook"], [101, 1, 1, "", "register_full_backward_hook"], [101, 1, 1, "", "register_full_backward_pre_hook"], [101, 1, 1, "", "register_load_state_dict_post_hook"], [101, 1, 1, "", "register_module"], [101, 1, 1, "", "register_parameter"], [101, 1, 1, "", "register_state_dict_pre_hook"], [101, 1, 1, "", "requires_grad_"], [101, 1, 1, "", "reset"], [101, 3, 1, "", "reset_keys"], [101, 3, 1, "", "reward_key"], [101, 3, 1, "", "reward_keys"], [101, 3, 1, "", "reward_spec"], [101, 1, 1, "", "rollout"], [101, 1, 1, "", "set_extra_state"], [101, 1, 1, "", "set_seed"], [101, 1, 1, "", "share_memory"], [101, 3, 1, "", "specs"], [101, 1, 1, "", "state_dict"], [101, 3, 1, "", "state_spec"], [101, 1, 1, "", "step"], [101, 1, 1, "", "step_and_maybe_reset"], [101, 1, 1, "", "to"], [101, 1, 1, "", "to_empty"], [101, 1, 1, "", "train"], [101, 1, 1, "", "type"], [101, 1, 1, "", "update_kwargs"], [101, 1, 1, "", "xpu"], [101, 1, 1, "", "zero_grad"]], "torchrl.envs.model_based.dreamer": [[106, 2, 1, "", "DreamerEnv"]], "torchrl.envs.transforms": [[108, 0, 1, "", "ActionMask"], [109, 0, 1, "", "BinarizeReward"], [110, 0, 1, "", "CatFrames"], [111, 0, 1, "", "CatTensors"], [112, 0, 1, "", "CenterCrop"], [113, 0, 1, "", "ClipTransform"], [114, 0, 1, "", "Compose"], [115, 0, 1, "", "DTypeCastTransform"], [116, 0, 1, "", "DeviceCastTransform"], [117, 0, 1, "", "DiscreteActionProjection"], [118, 0, 1, "", "DoubleToFloat"], [119, 0, 1, "", "EndOfLifeTransform"], [120, 0, 1, "", "ExcludeTransform"], [121, 0, 1, "", "FiniteTensorDictCheck"], [122, 0, 1, "", "FlattenObservation"], [123, 0, 1, "", "FrameSkipTransform"], [124, 0, 1, "", "GrayScale"], [125, 0, 1, "", "InitTracker"], [126, 0, 1, "", "KLRewardTransform"], [127, 0, 1, "", "NoopResetEnv"], [128, 0, 1, "", "ObservationNorm"], [129, 0, 1, "", "ObservationTransform"], [130, 0, 1, "", "PermuteTransform"], [131, 0, 1, "", "PinMemoryTransform"], [132, 0, 1, "", "R3MTransform"], [133, 0, 1, "", "RandomCropTensorDict"], [134, 0, 1, "", "RenameTransform"], [135, 0, 1, "", "Resize"], [136, 0, 1, "", "Reward2GoTransform"], [137, 0, 1, "", "RewardClipping"], [138, 0, 1, "", "RewardScaling"], [139, 0, 1, "", "RewardSum"], [140, 0, 1, "", "SelectTransform"], [141, 0, 1, "", "SqueezeTransform"], [142, 0, 1, "", "StepCounter"], [143, 0, 1, "", "TargetReturn"], [144, 0, 1, "", "TensorDictPrimer"], [145, 0, 1, "", "TimeMaxPool"], [146, 0, 1, "", "ToTensorImage"], [147, 0, 1, "", "Transform"], [148, 0, 1, "", "TransformedEnv"], [149, 0, 1, "", "UnsqueezeTransform"], [150, 0, 1, "", "VC1Transform"], [151, 0, 1, "", "VIPRewardTransform"], [152, 0, 1, "", "VIPTransform"], [153, 0, 1, "", "VecGymEnvTransform"], [154, 0, 1, "", "VecNorm"], [155, 0, 1, "", "gSDENoise"]], "torchrl.envs.transforms.ActionMask": [[108, 1, 1, "", "forward"]], "torchrl.envs.transforms.BinarizeReward": [[109, 1, 1, "", "transform_reward_spec"]], "torchrl.envs.transforms.CatFrames": [[110, 1, 1, "", "forward"], [110, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.CatTensors": [[111, 1, 1, "", "forward"], [111, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.CenterCrop": [[112, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.ClipTransform": [[113, 1, 1, "", "transform_observation_spec"], [113, 1, 1, "", "transform_reward_spec"]], "torchrl.envs.transforms.Compose": [[114, 1, 1, "", "forward"], [114, 1, 1, "", "to"], [114, 1, 1, "", "transform_env_device"], [114, 1, 1, "", "transform_input_spec"], [114, 1, 1, "", "transform_observation_spec"], [114, 1, 1, "", "transform_output_spec"], [114, 1, 1, "", "transform_reward_spec"]], "torchrl.envs.transforms.DTypeCastTransform": [[115, 1, 1, "", "forward"], [115, 1, 1, "", "transform_input_spec"], [115, 1, 1, "", "transform_observation_spec"], [115, 1, 1, "", "transform_output_spec"]], "torchrl.envs.transforms.DeviceCastTransform": [[116, 1, 1, "", "forward"], [116, 1, 1, "", "transform_done_spec"], [116, 1, 1, "", "transform_env_device"], [116, 1, 1, "", "transform_input_spec"], [116, 1, 1, "", "transform_observation_spec"], [116, 1, 1, "", "transform_output_spec"], [116, 1, 1, "", "transform_reward_spec"]], "torchrl.envs.transforms.DiscreteActionProjection": [[117, 1, 1, "", "transform_input_spec"]], "torchrl.envs.transforms.EndOfLifeTransform": [[119, 1, 1, "", "forward"], [119, 1, 1, "", "register_keys"], [119, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.ExcludeTransform": [[120, 1, 1, "", "forward"], [120, 1, 1, "", "transform_output_spec"]], "torchrl.envs.transforms.FiniteTensorDictCheck": [[121, 1, 1, "", "forward"]], "torchrl.envs.transforms.FlattenObservation": [[122, 1, 1, "", "forward"], [122, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.FrameSkipTransform": [[123, 1, 1, "", "forward"]], "torchrl.envs.transforms.GrayScale": [[124, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.InitTracker": [[125, 1, 1, "", "forward"], [125, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.KLRewardTransform": [[126, 1, 1, "", "forward"], [126, 1, 1, "", "transform_output_spec"]], "torchrl.envs.transforms.ObservationNorm": [[128, 1, 1, "", "init_stats"], [128, 1, 1, "", "transform_input_spec"], [128, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.PermuteTransform": [[130, 1, 1, "", "transform_input_spec"], [130, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.PinMemoryTransform": [[131, 1, 1, "", "forward"]], "torchrl.envs.transforms.R3MTransform": [[132, 1, 1, "", "to"]], "torchrl.envs.transforms.RandomCropTensorDict": [[133, 1, 1, "", "forward"]], "torchrl.envs.transforms.RenameTransform": [[134, 1, 1, "", "forward"], [134, 1, 1, "", "transform_input_spec"], [134, 1, 1, "", "transform_output_spec"]], "torchrl.envs.transforms.Resize": [[135, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.Reward2GoTransform": [[136, 1, 1, "", "forward"]], "torchrl.envs.transforms.RewardClipping": [[137, 1, 1, "", "transform_reward_spec"]], "torchrl.envs.transforms.RewardScaling": [[138, 1, 1, "", "transform_reward_spec"]], "torchrl.envs.transforms.RewardSum": [[139, 1, 1, "", "forward"], [139, 1, 1, "", "transform_input_spec"], [139, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.SelectTransform": [[140, 1, 1, "", "forward"], [140, 1, 1, "", "transform_output_spec"]], "torchrl.envs.transforms.StepCounter": [[142, 1, 1, "", "forward"], [142, 1, 1, "", "transform_input_spec"], [142, 1, 1, "", "transform_observation_spec"], [142, 1, 1, "", "transform_output_spec"]], "torchrl.envs.transforms.TargetReturn": [[143, 1, 1, "", "forward"], [143, 1, 1, "", "transform_input_spec"], [143, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.TensorDictPrimer": [[144, 1, 1, "", "forward"], [144, 1, 1, "", "to"], [144, 1, 1, "", "transform_input_spec"], [144, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.TimeMaxPool": [[145, 1, 1, "", "forward"], [145, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.ToTensorImage": [[146, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.Transform": [[147, 3, 1, "", "container"], [147, 1, 1, "", "forward"], [147, 3, 1, "", "parent"], [147, 1, 1, "", "to"], [147, 1, 1, "", "transform_done_spec"], [147, 1, 1, "", "transform_env_device"], [147, 1, 1, "", "transform_input_spec"], [147, 1, 1, "", "transform_observation_spec"], [147, 1, 1, "", "transform_output_spec"], [147, 1, 1, "", "transform_reward_spec"]], "torchrl.envs.transforms.TransformedEnv": [[148, 3, 1, "", "batch_locked"], [148, 1, 1, "", "empty_cache"], [148, 1, 1, "", "eval"], [148, 3, 1, "", "input_spec"], [148, 1, 1, "", "load_state_dict"], [148, 3, 1, "", "output_spec"], [148, 1, 1, "", "set_missing_tolerance"], [148, 1, 1, "", "set_seed"], [148, 1, 1, "", "state_dict"], [148, 1, 1, "", "to"], [148, 1, 1, "", "train"]], "torchrl.envs.transforms.UnsqueezeTransform": [[149, 1, 1, "", "transform_input_spec"], [149, 1, 1, "", "transform_observation_spec"], [149, 1, 1, "", "transform_reward_spec"]], "torchrl.envs.transforms.VC1Transform": [[150, 1, 1, "", "forward"], [150, 1, 1, "", "make_noload_model"], [150, 1, 1, "", "to"], [150, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.VIPRewardTransform": [[151, 1, 1, "", "forward"], [151, 1, 1, "", "transform_input_spec"]], "torchrl.envs.transforms.VIPTransform": [[152, 1, 1, "", "to"]], "torchrl.envs.transforms.VecGymEnvTransform": [[153, 1, 1, "", "forward"], [153, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.VecNorm": [[154, 1, 1, "", "build_td_for_shared_vecnorm"], [154, 1, 1, "", "forward"], [154, 1, 1, "", "get_extra_state"], [154, 1, 1, "", "set_extra_state"], [154, 1, 1, "", "to_observation_norm"]], "torchrl.envs.utils": [[156, 2, 1, "", "check_env_specs"], [157, 2, 1, "", "exploration_mode"], [158, 2, 1, "", "exploration_type"], [159, 2, 1, "", "get_available_libraries"], [160, 2, 1, "", "make_composite_from_td"], [161, 2, 1, "", "set_exploration_mode"], [162, 2, 1, "", "set_exploration_type"], [163, 2, 1, "", "step_mdp"], [164, 2, 1, "", "terminated_or_truncated"]], "torchrl.modules": [[165, 0, 1, "", "CEMPlanner"], [166, 0, 1, "", "Conv3dNet"], [167, 0, 1, "", "ConvNet"], [168, 0, 1, "", "DTActor"], [169, 0, 1, "", "DdpgCnnActor"], [170, 0, 1, "", "DdpgCnnQNet"], [171, 0, 1, "", "DdpgMlpActor"], [172, 0, 1, "", "DdpgMlpQNet"], [173, 0, 1, "", "DecisionTransformer"], [174, 0, 1, "", "Delta"], [175, 0, 1, "", "DistributionalDQNnet"], [176, 0, 1, "", "DistributionalQValueHook"], [177, 0, 1, "", "DreamerActor"], [178, 0, 1, "", "DuelingCnnDQNet"], [179, 0, 1, "", "GRU"], [180, 0, 1, "", "GRUCell"], [181, 0, 1, "", "GRUModule"], [182, 0, 1, "", "IndependentNormal"], [183, 0, 1, "", "LSTM"], [184, 0, 1, "", "LSTMCell"], [185, 0, 1, "", "LSTMModule"], [186, 0, 1, "", "LSTMNet"], [187, 0, 1, "", "MLP"], [188, 0, 1, "", "MPCPlannerBase"], [189, 0, 1, "", "MPPIPlanner"], [190, 0, 1, "", "MaskedCategorical"], [191, 0, 1, "", "MaskedOneHotCategorical"], [192, 0, 1, "", "MultiAgentConvNet"], [193, 0, 1, "", "MultiAgentMLP"], [194, 0, 1, "", "NoisyLazyLinear"], [195, 0, 1, "", "NoisyLinear"], [196, 0, 1, "", "NormalParamWrapper"], [197, 0, 1, "", "ObsDecoder"], [198, 0, 1, "", "ObsEncoder"], [199, 0, 1, "", "OneHotCategorical"], [200, 0, 1, "", "OnlineDTActor"], [201, 0, 1, "", "QMixer"], [202, 0, 1, "", "QValueHook"], [203, 0, 1, "", "RSSMPosterior"], [204, 0, 1, "", "RSSMPrior"], [205, 0, 1, "", "Squeeze2dLayer"], [206, 0, 1, "", "SqueezeLayer"], [207, 0, 1, "", "TanhDelta"], [208, 0, 1, "", "TanhNormal"], [209, 0, 1, "", "TruncatedNormal"], [210, 0, 1, "", "VDNMixer"], [211, 0, 1, "", "VmapModule"], [212, 0, 1, "", "reset_noise"]], "torchrl.modules.CEMPlanner": [[165, 1, 1, "", "planning"]], "torchrl.modules.Conv3dNet": [[166, 1, 1, "", "forward"]], "torchrl.modules.ConvNet": [[167, 1, 1, "", "forward"]], "torchrl.modules.DTActor": [[168, 1, 1, "", "default_config"], [168, 1, 1, "", "forward"]], "torchrl.modules.DdpgCnnActor": [[169, 1, 1, "", "forward"]], "torchrl.modules.DdpgCnnQNet": [[170, 1, 1, "", "forward"]], "torchrl.modules.DdpgMlpActor": [[171, 1, 1, "", "forward"]], "torchrl.modules.DdpgMlpQNet": [[172, 1, 1, "", "forward"]], "torchrl.modules.DecisionTransformer": [[173, 0, 1, "", "DTConfig"], [173, 1, 1, "", "forward"]], "torchrl.modules.Delta": [[174, 1, 1, "", "log_prob"], [174, 3, 1, "", "mean"], [174, 3, 1, "", "mode"], [174, 1, 1, "", "rsample"], [174, 1, 1, "", "sample"]], "torchrl.modules.DistributionalDQNnet": [[175, 1, 1, "", "forward"]], "torchrl.modules.DreamerActor": [[177, 1, 1, "", "forward"]], "torchrl.modules.DuelingCnnDQNet": [[178, 1, 1, "", "forward"]], "torchrl.modules.GRU": [[179, 1, 1, "", "forward"]], "torchrl.modules.GRUCell": [[180, 1, 1, "", "forward"]], "torchrl.modules.GRUModule": [[181, 1, 1, "", "forward"], [181, 1, 1, "id0", "set_recurrent_mode"]], "torchrl.modules.IndependentNormal": [[182, 3, 1, "", "mode"]], "torchrl.modules.LSTM": [[183, 1, 1, "", "forward"]], "torchrl.modules.LSTMCell": [[184, 1, 1, "", "forward"]], "torchrl.modules.LSTMModule": [[185, 1, 1, "", "forward"], [185, 1, 1, "id0", "set_recurrent_mode"]], "torchrl.modules.LSTMNet": [[186, 1, 1, "", "forward"]], "torchrl.modules.MLP": [[187, 1, 1, "", "forward"]], "torchrl.modules.MPCPlannerBase": [[188, 1, 1, "", "forward"], [188, 1, 1, "", "planning"]], "torchrl.modules.MPPIPlanner": [[189, 1, 1, "", "planning"]], "torchrl.modules.MaskedCategorical": [[190, 1, 1, "", "log_prob"], [190, 1, 1, "", "sample"]], "torchrl.modules.MaskedOneHotCategorical": [[191, 1, 1, "", "log_prob"], [191, 1, 1, "", "rsample"], [191, 1, 1, "", "sample"]], "torchrl.modules.MultiAgentConvNet": [[192, 1, 1, "", "forward"]], "torchrl.modules.MultiAgentMLP": [[193, 1, 1, "", "forward"]], "torchrl.modules.NoisyLazyLinear": [[194, 1, 1, "", "initialize_parameters"]], "torchrl.modules.NormalParamWrapper": [[196, 1, 1, "", "forward"]], "torchrl.modules.ObsDecoder": [[197, 1, 1, "", "forward"]], "torchrl.modules.ObsEncoder": [[198, 1, 1, "", "forward"]], "torchrl.modules.OneHotCategorical": [[199, 1, 1, "", "log_prob"], [199, 3, 1, "", "mode"], [199, 1, 1, "", "rsample"], [199, 1, 1, "", "sample"]], "torchrl.modules.OnlineDTActor": [[200, 1, 1, "", "default_config"], [200, 1, 1, "", "forward"]], "torchrl.modules.QMixer": [[201, 1, 1, "", "mix"]], "torchrl.modules.RSSMPosterior": [[203, 1, 1, "", "forward"]], "torchrl.modules.RSSMPrior": [[204, 1, 1, "", "forward"]], "torchrl.modules.SqueezeLayer": [[206, 1, 1, "", "forward"]], "torchrl.modules.TanhDelta": [[207, 3, 1, "", "mean"], [207, 3, 1, "", "mode"]], "torchrl.modules.TanhNormal": [[208, 3, 1, "", "mode"]], "torchrl.modules.TruncatedNormal": [[209, 1, 1, "", "log_prob"], [209, 3, 1, "", "mode"]], "torchrl.modules.VDNMixer": [[210, 1, 1, "", "mix"]], "torchrl.modules.VmapModule": [[211, 1, 1, "", "forward"]], "torchrl.modules.tensordict_module": [[213, 0, 1, "", "Actor"], [214, 0, 1, "", "ActorCriticOperator"], [215, 0, 1, "", "ActorCriticWrapper"], [216, 0, 1, "", "ActorValueOperator"], [217, 0, 1, "", "AdditiveGaussianWrapper"], [218, 0, 1, "", "DecisionTransformerInferenceWrapper"], [219, 0, 1, "", "DistributionalQValueActor"], [220, 0, 1, "", "DistributionalQValueModule"], [221, 0, 1, "", "EGreedyModule"], [222, 0, 1, "", "EGreedyWrapper"], [223, 0, 1, "", "LMHeadActorValueOperator"], [224, 0, 1, "", "OrnsteinUhlenbeckProcessWrapper"], [225, 0, 1, "", "ProbabilisticActor"], [226, 0, 1, "", "QValueActor"], [227, 0, 1, "", "QValueModule"], [228, 0, 1, "", "SafeModule"], [229, 0, 1, "", "SafeProbabilisticModule"], [230, 0, 1, "", "SafeProbabilisticTensorDictSequential"], [231, 0, 1, "", "SafeSequential"], [232, 0, 1, "", "TanhModule"], [233, 0, 1, "", "ValueOperator"], [234, 0, 1, "", "WorldModelWrapper"]], "torchrl.modules.tensordict_module.ActorCriticOperator": [[214, 1, 1, "", "get_critic_operator"], [214, 1, 1, "", "get_policy_head"], [214, 1, 1, "", "get_value_head"], [214, 1, 1, "", "get_value_operator"]], "torchrl.modules.tensordict_module.ActorCriticWrapper": [[215, 1, 1, "", "get_policy_head"], [215, 1, 1, "", "get_policy_operator"], [215, 1, 1, "", "get_value_head"], [215, 1, 1, "", "get_value_operator"]], "torchrl.modules.tensordict_module.ActorValueOperator": [[216, 1, 1, "", "get_policy_head"], [216, 1, 1, "", "get_policy_operator"], [216, 1, 1, "", "get_value_head"], [216, 1, 1, "", "get_value_operator"]], "torchrl.modules.tensordict_module.AdditiveGaussianWrapper": [[217, 1, 1, "", "forward"], [217, 1, 1, "", "step"]], "torchrl.modules.tensordict_module.DecisionTransformerInferenceWrapper": [[218, 1, 1, "", "forward"], [218, 1, 1, "", "mask_context"], [218, 1, 1, "", "set_tensor_keys"]], "torchrl.modules.tensordict_module.DistributionalQValueModule": [[220, 1, 1, "", "forward"]], "torchrl.modules.tensordict_module.EGreedyModule": [[221, 1, 1, "", "forward"], [221, 1, 1, "", "step"]], "torchrl.modules.tensordict_module.EGreedyWrapper": [[222, 1, 1, "", "forward"], [222, 1, 1, "", "step"]], "torchrl.modules.tensordict_module.OrnsteinUhlenbeckProcessWrapper": [[224, 1, 1, "", "forward"], [224, 1, 1, "", "step"]], "torchrl.modules.tensordict_module.QValueModule": [[227, 1, 1, "", "forward"]], "torchrl.modules.tensordict_module.SafeModule": [[228, 1, 1, "", "random"], [228, 1, 1, "", "random_sample"], [228, 1, 1, "", "to"]], "torchrl.modules.tensordict_module.SafeProbabilisticModule": [[229, 1, 1, "", "random"], [229, 1, 1, "", "random_sample"]], "torchrl.modules.tensordict_module.TanhModule": [[232, 1, 1, "", "forward"]], "torchrl.modules.tensordict_module.WorldModelWrapper": [[234, 1, 1, "", "get_reward_operator"], [234, 1, 1, "", "get_transition_model_operator"]], "torchrl.modules.utils": [[235, 0, 1, "", "biased_softplus"], [236, 0, 1, "", "inv_softplus"], [237, 0, 1, "", "mappings"]], "torchrl.modules.utils.biased_softplus": [[235, 1, 1, "", "forward"]], "torchrl.objectives": [[238, 0, 1, "", "A2CLoss"], [239, 0, 1, "", "CQLLoss"], [240, 0, 1, "", "ClipPPOLoss"], [241, 0, 1, "", "DDPGLoss"], [242, 0, 1, "", "DQNLoss"], [243, 0, 1, "", "DTLoss"], [244, 0, 1, "", "DiscreteCQLLoss"], [245, 0, 1, "", "DiscreteSACLoss"], [246, 0, 1, "", "DistributionalDQNLoss"], [247, 0, 1, "", "DreamerActorLoss"], [248, 0, 1, "", "DreamerModelLoss"], [249, 0, 1, "", "DreamerValueLoss"], [250, 0, 1, "", "HardUpdate"], [251, 0, 1, "", "IQLLoss"], [252, 0, 1, "", "KLPENPPOLoss"], [253, 0, 1, "", "LossModule"], [254, 0, 1, "", "OnlineDTLoss"], [255, 0, 1, "", "PPOLoss"], [256, 0, 1, "", "REDQLoss"], [257, 0, 1, "", "ReinforceLoss"], [258, 0, 1, "", "SACLoss"], [259, 0, 1, "", "SoftUpdate"], [260, 0, 1, "", "TD3Loss"], [261, 0, 1, "", "ValueEstimators"], [262, 0, 1, "", "default_value_kwargs"], [263, 0, 1, "", "distance_loss"], [264, 0, 1, "", "hold_out_net"], [265, 0, 1, "", "hold_out_params"], [267, 0, 1, "", "next_state_value"]], "torchrl.objectives.A2CLoss": [[238, 1, 1, "", "forward"], [238, 1, 1, "", "make_value_estimator"]], "torchrl.objectives.CQLLoss": [[239, 1, 1, "", "forward"], [239, 1, 1, "", "make_value_estimator"]], "torchrl.objectives.ClipPPOLoss": [[240, 1, 1, "", "forward"]], "torchrl.objectives.DDPGLoss": [[241, 1, 1, "", "forward"], [241, 1, 1, "", "make_value_estimator"]], "torchrl.objectives.DQNLoss": [[242, 1, 1, "", "forward"], [242, 1, 1, "", "make_value_estimator"]], "torchrl.objectives.DTLoss": [[243, 1, 1, "", "forward"]], "torchrl.objectives.DiscreteCQLLoss": [[244, 1, 1, "", "forward"], [244, 1, 1, "", "make_value_estimator"]], "torchrl.objectives.DiscreteSACLoss": [[245, 1, 1, "", "forward"], [245, 1, 1, "", "make_value_estimator"]], "torchrl.objectives.DistributionalDQNLoss": [[246, 1, 1, "", "forward"], [246, 1, 1, "", "make_value_estimator"]], "torchrl.objectives.DreamerActorLoss": [[247, 1, 1, "", "forward"], [247, 1, 1, "", "make_value_estimator"]], "torchrl.objectives.DreamerModelLoss": [[248, 1, 1, "", "forward"]], "torchrl.objectives.DreamerValueLoss": [[249, 1, 1, "", "forward"]], "torchrl.objectives.IQLLoss": [[251, 1, 1, "", "forward"], [251, 1, 1, "", "loss_value_diff"], [251, 1, 1, "", "make_value_estimator"]], "torchrl.objectives.KLPENPPOLoss": [[252, 1, 1, "", "forward"]], "torchrl.objectives.LossModule": [[253, 1, 1, "", "convert_to_functional"], [253, 1, 1, "", "forward"], [253, 1, 1, "", "make_value_estimator"], [253, 1, 1, "", "named_parameters"], [253, 1, 1, "", "parameters"], [253, 1, 1, "", "set_keys"], [253, 3, 1, "", "value_estimator"]], "torchrl.objectives.OnlineDTLoss": [[254, 1, 1, "", "forward"]], "torchrl.objectives.PPOLoss": [[255, 1, 1, "", "forward"], [255, 1, 1, "", "make_value_estimator"]], "torchrl.objectives.REDQLoss": [[256, 1, 1, "", "forward"], [256, 1, 1, "", "make_value_estimator"]], "torchrl.objectives.ReinforceLoss": [[257, 1, 1, "", "forward"], [257, 1, 1, "", "make_value_estimator"]], "torchrl.objectives.SACLoss": [[258, 1, 1, "", "forward"], [258, 1, 1, "", "load_state_dict"], [258, 1, 1, "", "make_value_estimator"], [258, 1, 1, "", "state_dict"]], "torchrl.objectives.TD3Loss": [[260, 1, 1, "", "forward"], [260, 1, 1, "", "make_value_estimator"]], "torchrl.objectives.multiagent": [[266, 0, 1, "", "QMixerLoss"]], "torchrl.objectives.multiagent.QMixerLoss": [[266, 1, 1, "", "forward"], [266, 1, 1, "", "make_value_estimator"]], "torchrl.objectives.value": [[268, 0, 1, "", "GAE"], [269, 0, 1, "", "TD0Estimator"], [270, 0, 1, "", "TD1Estimator"], [271, 0, 1, "", "TDLambdaEstimator"], [272, 0, 1, "", "ValueEstimatorBase"]], "torchrl.objectives.value.GAE": [[268, 1, 1, "", "forward"], [268, 1, 1, "", "value_estimate"]], "torchrl.objectives.value.TD0Estimator": [[269, 1, 1, "", "forward"], [269, 1, 1, "", "value_estimate"]], "torchrl.objectives.value.TD1Estimator": [[270, 1, 1, "", "forward"], [270, 1, 1, "", "value_estimate"]], "torchrl.objectives.value.TDLambdaEstimator": [[271, 1, 1, "", "forward"], [271, 1, 1, "", "value_estimate"]], "torchrl.objectives.value.ValueEstimatorBase": [[272, 1, 1, "", "forward"], [272, 1, 1, "", "set_keys"], [272, 1, 1, "", "value_estimate"]], "torchrl.objectives.value.functional": [[273, 0, 1, "", "generalized_advantage_estimate"], [274, 0, 1, "", "reward2go"], [275, 0, 1, "", "td0_advantage_estimate"], [276, 0, 1, "", "td0_return_estimate"], [277, 0, 1, "", "td1_advantage_estimate"], [278, 0, 1, "", "td1_return_estimate"], [279, 0, 1, "", "td_lambda_advantage_estimate"], [280, 0, 1, "", "td_lambda_return_estimate"], [281, 0, 1, "", "vec_generalized_advantage_estimate"], [282, 0, 1, "", "vec_td1_advantage_estimate"], [283, 0, 1, "", "vec_td1_return_estimate"], [284, 0, 1, "", "vec_td_lambda_advantage_estimate"], [285, 0, 1, "", "vec_td_lambda_return_estimate"]], "torchrl.record": [[286, 2, 1, "", "TensorDictRecorder"], [287, 2, 1, "", "VideoRecorder"]], "torchrl.record.loggers": [[288, 2, 1, "", "Logger"], [290, 2, 1, "", "generate_exp_name"], [291, 2, 1, "", "get_logger"]], "torchrl.record.loggers.csv": [[289, 2, 1, "", "CSVLogger"]], "torchrl.record.loggers.mlflow": [[292, 2, 1, "", "MLFlowLogger"]], "torchrl.record.loggers.tensorboard": [[293, 2, 1, "", "TensorboardLogger"]], "torchrl.record.loggers.wandb": [[294, 2, 1, "", "WandbLogger"]], "torchrl.trainers": [[295, 0, 1, "", "BatchSubSampler"], [296, 0, 1, "", "ClearCudaCache"], [297, 0, 1, "", "CountFramesLog"], [298, 0, 1, "", "LogReward"], [299, 0, 1, "", "OptimizerHook"], [300, 0, 1, "", "Recorder"], [301, 0, 1, "", "ReplayBufferTrainer"], [302, 0, 1, "", "RewardNormalizer"], [303, 0, 1, "", "SelectKeys"], [304, 0, 1, "", "Trainer"], [305, 0, 1, "", "TrainerHookBase"], [306, 0, 1, "", "UpdateWeights"]], "torchrl.trainers.BatchSubSampler": [[295, 1, 1, "", "register"]], "torchrl.trainers.ClearCudaCache": [[296, 1, 1, "", "register"]], "torchrl.trainers.CountFramesLog": [[297, 1, 1, "", "register"]], "torchrl.trainers.LogReward": [[298, 1, 1, "", "register"]], "torchrl.trainers.OptimizerHook": [[299, 1, 1, "", "register"]], "torchrl.trainers.Recorder": [[300, 1, 1, "", "register"]], "torchrl.trainers.ReplayBufferTrainer": [[301, 1, 1, "", "register"]], "torchrl.trainers.RewardNormalizer": [[302, 1, 1, "", "register"]], "torchrl.trainers.SelectKeys": [[303, 1, 1, "", "register"]], "torchrl.trainers.TrainerHookBase": [[305, 1, 1, "", "register"]], "torchrl.trainers.UpdateWeights": [[306, 1, 1, "", "register"]], "torchrl.trainers.helpers": [[307, 2, 1, "", "correct_for_frame_skip"], [308, 2, 1, "", "get_stats_random_rollout"], [309, 2, 1, "", "make_collector_offpolicy"], [310, 2, 1, "", "make_collector_onpolicy"], [311, 2, 1, "", "make_dqn_loss"], [312, 2, 1, "", "make_redq_loss"], [313, 2, 1, "", "make_redq_model"], [314, 2, 1, "", "make_replay_buffer"], [315, 2, 1, "", "make_target_updater"], [316, 2, 1, "", "make_trainer"], [317, 2, 1, "", "parallel_env_constructor"], [318, 2, 1, "", "sync_async_collector"], [319, 2, 1, "", "sync_sync_collector"], [320, 2, 1, "", "transformed_env_constructor"]]}, "objtypes": {"0": "py:class", "1": "py:method", "2": "py:function", "3": "py:property"}, "objnames": {"0": ["py", "class", "Python class"], "1": ["py", "method", "Python method"], "2": ["py", "function", "Python function"], "3": ["py", "property", "Python property"]}, "titleterms": {"torchrl": [0, 1, 2, 3, 6, 9, 324, 325, 326, 327, 329, 330, 331, 335, 336, 340, 341], "tutori": [0, 331, 335], "basic": [0, 338], "intermedi": [0, 8], "advanc": 0, "refer": [0, 322], "knowledg": [0, 323], "base": [0, 7, 323], "indic": 0, "tabl": 0, "collector": [1, 329, 330, 331, 332, 335, 340], "packag": [1, 2, 3, 324, 325, 326, 327], "singl": [1, 4], "node": 1, "data": [1, 2, 4, 329, 330, 331, 335, 340], "distribut": [1, 324], "helper": [1, 3], "function": [1, 4, 325, 330, 331, 335, 340], "replai": [2, 329, 330, 331, 332, 335, 338, 340], "buffer": [2, 329, 330, 331, 332, 335, 338, 340], "compos": [2, 114], "share": 2, "across": 2, "process": 2, "store": [2, 330], "trajectori": 2, "checkpoint": [2, 326], "dataset": 2, "tensorspec": [2, 44], "reinforc": [2, 325, 331, 335], "learn": [2, 4, 331, 335], "from": [2, 6, 7], "human": 2, "feedback": 2, "rlhf": 2, "util": [2, 324, 325, 326], "env": [3, 336, 340, 341], "vector": [3, 340], "multi": [3, 324, 325, 334, 335], "agent": [3, 4, 324, 325, 335], "environ": [3, 4, 6, 7, 329, 330, 331, 332, 334, 335, 336, 340, 341], "transform": [3, 147, 329, 331, 335, 336, 338, 340, 341], "clone": [3, 7], "mask": 3, "action": [3, 4, 332, 336], "record": [3, 300, 326, 329], "domain": [3, 324], "specif": [3, 324, 334], "librari": [3, 340], "thing": [4, 329, 336], "consid": 4, "when": [4, 7], "debug": 4, "rl": [4, 9, 340], "gener": [4, 324], "have": 4, "you": 4, "valid": 4, "your": [4, 6, 329, 336], "algorithm": [4, 324], "implement": 4, "few": 4, "small": 4, "toi": 4, "problem": 4, "known": 4, "optim": [4, 329, 330], "return": [4, 325], "e": 4, "g": 4, "gridworld": 4, "mountaincar": 4, "visual": 4, "Be": 4, "veri": 4, "care": 4, "ani": 4, "augment": 4, "polici": [4, 329, 331, 332, 334, 335, 336], "doe": 4, "entropi": 4, "converg": 4, "too": [4, 8], "quickli": 4, "slowli": 4, "chang": [4, 340], "drastic": 4, "reward": 4, "beyond": 4, "go": 4, "up": [4, 6], "Is": 4, "favor": 4, "compon": 4, "i": 4, "veloc": 4, "vs": 4, "l2": 4, "magnitud": 4, "task": [4, 334], "horizon": 4, "extrem": 4, "long": 4, "ar": 4, "normal": [4, 329, 330, 331], "standard": 4, "explor": [4, 324, 329, 330], "valu": [4, 324, 325, 329, 331, 332], "loss": [4, 329, 330, 331, 332, 335], "earli": 4, "train": [4, 8, 325, 329, 331, 332, 335, 336], "roughli": 4, "uniformli": 4, "random": [4, 335], "intrins": 4, "decai": 4, "progress": 4, "singleton": 4, "episod": 4, "remain": 4, "constant": [4, 330], "increas": 4, "an": [4, 331, 332, 336], "dynam": [4, 338], "can": 4, "low": 4, "forward": [4, 329], "model": [4, 324, 329, 330, 332, 337, 340], "also": 4, "us": [4, 6, 9, 332, 337, 338, 340], "offlin": 4, "observ": [4, 329], "space": 4, "effect": [4, 336], "dramat": 4, "dure": [4, 7], "high": 4, "dimension": 4, "work": [5, 6, 7], "gym": [5, 341], "what": 5, "openai": 5, "version": [5, 7, 10], "habitat": 6, "lab": 6, "set": 6, "instal": [6, 7, 340], "pip": [6, 7], "common": [6, 7, 8], "issu": [6, 7, 10], "mujoco": 7, "prerequisit": 7, "render": [7, 335, 341], "all": 7, "new": 7, "bindindg": 7, "2": 7, "1": 7, "old": 7, "bind": 7, "py": 7, "option": 7, "repo": [7, 9], "import": [7, 329], "pytorch": [8, 9, 10], "error": 8, "solut": 8, "gradient": 8, "relat": 8, "newcom": 8, "my": 8, "slow": 8, "bug": 8, "resourc": 9, "paper": 9, "document": 9, "functorch": 9, "blog": 9, "websit": 9, "educ": 9, "forum": 9, "how": 10, "reproduc": [10, 336], "workaround": 10, "implement_for": 11, "datacollectorbas": 12, "multisyncdatacollector": 13, "multiasyncdatacollector": 14, "randompolici": 15, "syncdatacollector": 16, "asyncdatacollector": 17, "distributeddatacollector": 18, "distributedsyncdatacollector": 19, "rpcdatacollector": 20, "raycollector": 21, "submitit_delayed_launch": 22, "split_trajectori": 23, "binarydiscretetensorspec": 24, "boundedtensorspec": 25, "compositespec": 26, "discretetensorspec": 27, "lazystackedcompositespec": 28, "lazystackedtensorspec": 29, "multidiscretetensorspec": 30, "multionehotdiscretetensorspec": 31, "multistep": 32, "onehotdiscretetensorspec": 33, "pairwisedataset": 34, "prioritizedreplaybuff": 35, "promptdata": 36, "prompttensordicttoken": 37, "replaybuff": 38, "rewarddata": 39, "rolloutfrommodel": 40, "tensordictprioritizedreplaybuff": 41, "tensordictreplaybuff": 42, "tensordicttoken": 43, "tokenizeddatasetload": 45, "unboundedcontinuoustensorspec": 46, "unboundeddiscretetensorspec": 47, "check_no_exclusive_kei": 48, "consolidate_spec": 49, "contains_lazy_spec": 50, "create_infinite_iter": 51, "d4rlexperiencereplai": 52, "minariexperiencereplai": 53, "openmlexperiencereplai": 54, "robosetexperiencereplai": 55, "vd4rlexperiencereplai": 56, "get_dataload": 57, "lazymemmapstorag": 58, "lazytensorstorag": 59, "liststorag": 60, "prioritizedsampl": 61, "randomsampl": 62, "roundrobinwrit": 63, "sampler": 64, "samplerwithoutreplac": 65, "slicesampl": 66, "slicesamplerwithoutreplac": 67, "storag": [68, 329, 338], "tensordictmaxvaluewrit": 69, "tensordictroundrobinwrit": 70, "tensorstorag": 71, "writer": 72, "braxenv": 73, "braxwrapp": 74, "dmcontrolenv": 75, "dmcontrolwrapp": 76, "envbas": [77, 336], "envcreat": 78, "envmetadata": 79, "gymenv": 80, "gymlikeenv": 81, "gymwrapp": 82, "habitatenv": 83, "isaacgymenv": 84, "isaacgymwrapp": 85, "jumanjienv": 86, "jumanjiwrapp": 87, "mogymenv": 88, "mogymwrapp": 89, "marlgroupmaptyp": 90, "modelbasedenvbas": 91, "multithreadedenv": 92, "multithreadedenvwrapp": 93, "openmlenv": 94, "parallelenv": 95, "pettingzooenv": 96, "pettingzoowrapp": 97, "robohiveenv": 98, "smacv2env": 99, "smacv2wrapp": 100, "serialenv": 101, "vmasenv": 102, "vmaswrapp": 103, "check_marl_group": 104, "gym_backend": 105, "dreamerenv": 106, "set_gym_backend": 107, "actionmask": 108, "binarizereward": 109, "catfram": [110, 338], "cattensor": 111, "centercrop": 112, "cliptransform": 113, "dtypecasttransform": 115, "devicecasttransform": 116, "discreteactionproject": 117, "doubletofloat": 118, "endoflifetransform": 119, "excludetransform": 120, "finitetensordictcheck": 121, "flattenobserv": 122, "frameskiptransform": 123, "grayscal": 124, "inittrack": 125, "klrewardtransform": 126, "noopresetenv": 127, "observationnorm": 128, "observationtransform": 129, "permutetransform": 130, "pinmemorytransform": 131, "r3mtransform": 132, "randomcroptensordict": 133, "renametransform": 134, "resiz": 135, "reward2gotransform": 136, "rewardclip": 137, "rewardsc": 138, "rewardsum": 139, "selecttransform": 140, "squeezetransform": 141, "stepcount": 142, "targetreturn": 143, "tensordictprim": 144, "timemaxpool": 145, "totensorimag": 146, "transformedenv": 148, "unsqueezetransform": 149, "vc1transform": 150, "viprewardtransform": 151, "viptransform": 152, "vecgymenvtransform": 153, "vecnorm": [154, 341], "gsdenois": 155, "check_env_spec": 156, "exploration_mod": 157, "exploration_typ": 158, "get_available_librari": 159, "make_composite_from_td": 160, "set_exploration_mod": 161, "set_exploration_typ": 162, "step_mdp": 163, "terminated_or_trunc": 164, "cemplann": 165, "conv3dnet": 166, "convnet": 167, "dtactor": 168, "ddpgcnnactor": 169, "ddpgcnnqnet": 170, "ddpgmlpactor": 171, "ddpgmlpqnet": 172, "decisiontransform": 173, "delta": 174, "distributionaldqnnet": 175, "distributionalqvaluehook": 176, "dreameractor": 177, "duelingcnndqnet": 178, "gru": 179, "grucel": 180, "grumodul": 181, "independentnorm": 182, "lstm": [183, 332], "lstmcell": 184, "lstmmodul": 185, "lstmnet": 186, "mlp": [187, 332], "mpcplannerbas": 188, "mppiplann": 189, "maskedcategor": 190, "maskedonehotcategor": 191, "multiagentconvnet": 192, "multiagentmlp": 193, "noisylazylinear": 194, "noisylinear": 195, "normalparamwrapp": 196, "obsdecod": 197, "obsencod": 198, "onehotcategor": 199, "onlinedtactor": 200, "qmixer": [201, 325], "qvaluehook": 202, "rssmposterior": 203, "rssmprior": 204, "squeeze2dlay": 205, "squeezelay": 206, "tanhdelta": 207, "tanhnorm": 208, "truncatednorm": 209, "vdnmixer": 210, "vmapmodul": 211, "reset_nois": 212, "actor": [213, 324, 329], "actorcriticoper": 214, "actorcriticwrapp": 215, "actorvalueoper": 216, "additivegaussianwrapp": 217, "decisiontransformerinferencewrapp": 218, "distributionalqvalueactor": 219, "distributionalqvaluemodul": 220, "egreedymodul": 221, "egreedywrapp": 222, "lmheadactorvalueoper": 223, "ornsteinuhlenbeckprocesswrapp": 224, "probabilisticactor": 225, "qvalueactor": 226, "qvaluemodul": 227, "safemodul": [228, 324], "safeprobabilisticmodul": 229, "safeprobabilistictensordictsequenti": 230, "safesequenti": 231, "tanhmodul": 232, "valueoper": 233, "worldmodelwrapp": 234, "biased_softplu": 235, "inv_softplu": 236, "map": 237, "a2closs": 238, "cqlloss": 239, "clipppoloss": 240, "ddpgloss": 241, "dqnloss": 242, "dtloss": 243, "discretecqlloss": 244, "discretesacloss": 245, "distributionaldqnloss": 246, "dreameractorloss": 247, "dreamermodelloss": 248, "dreamervalueloss": 249, "hardupd": 250, "iqlloss": 251, "klpenppoloss": 252, "lossmodul": [253, 329], "onlinedtloss": 254, "ppoloss": 255, "redqloss": 256, "reinforceloss": 257, "sacloss": 258, "softupd": 259, "td3loss": 260, "valueestim": 261, "default_value_kwarg": 262, "distance_loss": 263, "hold_out_net": 264, "hold_out_param": 265, "qmixerloss": 266, "next_state_valu": 267, "gae": 268, "td0estim": 269, "td1estim": 270, "tdlambdaestim": 271, "valueestimatorbas": 272, "generalized_advantage_estim": 273, "reward2go": 274, "td0_advantage_estim": 275, "td0_return_estim": 276, "td1_advantage_estim": 277, "td1_return_estim": 278, "td_lambda_advantage_estim": 279, "td_lambda_return_estim": 280, "vec_generalized_advantage_estim": 281, "vec_td1_advantage_estim": 282, "vec_td1_return_estim": 283, "vec_td_lambda_advantage_estim": 284, "vec_td_lambda_return_estim": 285, "tensordictrecord": 286, "videorecord": 287, "logger": [288, 326], "csvlogger": 289, "generate_exp_nam": 290, "get_logg": 291, "mlflowlogg": 292, "tensorboardlogg": 293, "wandblogg": 294, "batchsubsampl": 295, "clearcudacach": 296, "countframeslog": 297, "logreward": 298, "optimizerhook": 299, "replaybuffertrain": 301, "rewardnorm": 302, "selectkei": 303, "trainer": [304, 326, 330], "trainerhookbas": 305, "updateweight": 306, "correct_for_frame_skip": 307, "get_stats_random_rollout": 308, "make_collector_offpolici": 309, "make_collector_onpolici": 310, "make_dqn_loss": 311, "make_redq_loss": 312, "make_redq_model": 313, "make_replay_buff": 314, "make_target_updat": 315, "make_train": 316, "parallel_env_constructor": 317, "sync_async_collector": 318, "sync_sync_collector": 319, "transformed_env_constructor": 320, "readm": [321, 333], "tuto": [321, 333], "api": 322, "contribut": [323, 340], "content": 323, "modul": [324, 329, 332, 340], "tensordict": [324, 338, 340], "wrapper": 324, "probabilist": 324, "q": [324, 330, 332], "oper": 324, "join": 324, "hook": [324, 326, 330], "regular": 324, "planner": 324, "object": [325, 329, 340], "dqn": [325, 330, 332], "ddpg": [325, 329], "sac": 325, "redq": 325, "iql": 325, "cql": 325, "dt": 325, "td3": 325, "ppo": [325, 331, 335], "a2c": 325, "dreamer": 325, "builder": 326, "_util": 327, "comput": [328, 330, 336, 339], "time": [328, 329, 339], "code": [329, 336], "setup": [329, 332], "The": 329, "__init__": 329, "method": 329, "estim": 329, "put": 329, "togeth": [329, 336], "call": 329, "parallel": [329, 334, 341], "execut": [329, 334, 336], "stat": 329, "build": [329, 330, 338], "evalu": 329, "batch": [329, 336, 338], "size": [329, 338], "construct": 329, "target": [329, 330], "network": [329, 330, 331, 332, 335], "updat": 329, "experi": [329, 336], "result": [329, 331, 335], "conclus": [329, 330, 331, 332, 335, 336, 338], "A": [330, 338], "exampl": [330, 338], "deep": 330, "collect": [330, 331], "paramet": [330, 331], "hyperparamet": [330, 331, 335], "regist": 330, "possibl": 330, "improv": 330, "defin": [331, 335], "loop": [331, 332, 335, 336], "next": [331, 335], "step": [331, 335, 341], "recurr": 332, "overview": 332, "convolut": 332, "select": 332, "further": 332, "read": 332, "divers": 334, "rollout": [334, 335, 336, 341], "critic": 335, "pendulum": 336, "write": 336, "_step": 336, "reset": [336, 341], "simul": 336, "_reset": 336, "metadata": 336, "_spec": 336, "spec": [336, 341], "shape": 336, "seed": [336, 341], "wrap": 336, "class": [336, 340], "test": 336, "our": 336, "custom": [336, 338], "simpl": 336, "pretrain": 337, "vanilla": 338, "integr": 338, "tensorclass": 338, "sampl": 338, "iter": 338, "over": 338, "fix": 338, "priorit": 338, "save": 338, "raw": 338, "imag": 338, "more": 338, "complex": 338, "introduct": 340, "config": 340, "tensordictmodul": 340, "sequenc": 340, "program": 340, "ensembl": 340, "meta": 340, "special": 340, "state": 340, "frame_skip": 341, "deepmind": 341, "control": 341, "devic": 341, "run": 341, "close": 341, "access": 341, "attribut": 341, "kwarg": 341}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 6, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.viewcode": 1, "sphinx.ext.intersphinx": 1, "sphinx": 56}})