Search.setIndex({"docnames": ["index", "reference/collectors", "reference/data", "reference/envs", "reference/generated/knowledge_base/DEBUGGING_RL", "reference/generated/knowledge_base/GYM", "reference/generated/knowledge_base/HABITAT", "reference/generated/knowledge_base/MUJOCO_INSTALLATION", "reference/generated/knowledge_base/PRO-TIPS", "reference/generated/knowledge_base/RESOURCES", "reference/generated/knowledge_base/VERSIONING_ISSUES", "reference/generated/torchrl._utils.implement_for", "reference/generated/torchrl.collectors.collectors.DataCollectorBase", "reference/generated/torchrl.collectors.collectors.MultiSyncDataCollector", "reference/generated/torchrl.collectors.collectors.MultiaSyncDataCollector", "reference/generated/torchrl.collectors.collectors.RandomPolicy", "reference/generated/torchrl.collectors.collectors.SyncDataCollector", "reference/generated/torchrl.collectors.collectors.aSyncDataCollector", "reference/generated/torchrl.collectors.distributed.DistributedDataCollector", "reference/generated/torchrl.collectors.distributed.DistributedSyncDataCollector", "reference/generated/torchrl.collectors.distributed.RPCDataCollector", "reference/generated/torchrl.collectors.distributed.RayCollector", "reference/generated/torchrl.collectors.distributed.submitit_delayed_launcher", "reference/generated/torchrl.collectors.utils.split_trajectories", "reference/generated/torchrl.data.BinaryDiscreteTensorSpec", "reference/generated/torchrl.data.BoundedTensorSpec", "reference/generated/torchrl.data.CompositeSpec", "reference/generated/torchrl.data.DiscreteTensorSpec", "reference/generated/torchrl.data.LazyStackedCompositeSpec", "reference/generated/torchrl.data.LazyStackedTensorSpec", "reference/generated/torchrl.data.MultiDiscreteTensorSpec", "reference/generated/torchrl.data.MultiOneHotDiscreteTensorSpec", "reference/generated/torchrl.data.MultiStep", "reference/generated/torchrl.data.OneHotDiscreteTensorSpec", "reference/generated/torchrl.data.PairwiseDataset", "reference/generated/torchrl.data.PrioritizedReplayBuffer", "reference/generated/torchrl.data.PromptData", "reference/generated/torchrl.data.PromptTensorDictTokenizer", "reference/generated/torchrl.data.ReplayBuffer", "reference/generated/torchrl.data.RewardData", "reference/generated/torchrl.data.RolloutFromModel", "reference/generated/torchrl.data.TensorDictPrioritizedReplayBuffer", "reference/generated/torchrl.data.TensorDictReplayBuffer", "reference/generated/torchrl.data.TensorDictTokenizer", "reference/generated/torchrl.data.TensorSpec", "reference/generated/torchrl.data.TokenizedDatasetLoader", "reference/generated/torchrl.data.UnboundedContinuousTensorSpec", "reference/generated/torchrl.data.UnboundedDiscreteTensorSpec", "reference/generated/torchrl.data.check_no_exclusive_keys", "reference/generated/torchrl.data.consolidate_spec", "reference/generated/torchrl.data.contains_lazy_spec", "reference/generated/torchrl.data.create_infinite_iterator", "reference/generated/torchrl.data.datasets.D4RLExperienceReplay", "reference/generated/torchrl.data.datasets.MinariExperienceReplay", "reference/generated/torchrl.data.datasets.OpenMLExperienceReplay", "reference/generated/torchrl.data.datasets.RobosetExperienceReplay", "reference/generated/torchrl.data.datasets.VD4RLExperienceReplay", "reference/generated/torchrl.data.get_dataloader", "reference/generated/torchrl.data.replay_buffers.LazyMemmapStorage", "reference/generated/torchrl.data.replay_buffers.LazyTensorStorage", "reference/generated/torchrl.data.replay_buffers.ListStorage", "reference/generated/torchrl.data.replay_buffers.PrioritizedSampler", "reference/generated/torchrl.data.replay_buffers.RandomSampler", "reference/generated/torchrl.data.replay_buffers.RoundRobinWriter", "reference/generated/torchrl.data.replay_buffers.Sampler", "reference/generated/torchrl.data.replay_buffers.SamplerWithoutReplacement", "reference/generated/torchrl.data.replay_buffers.SliceSampler", "reference/generated/torchrl.data.replay_buffers.SliceSamplerWithoutReplacement", "reference/generated/torchrl.data.replay_buffers.Storage", "reference/generated/torchrl.data.replay_buffers.TensorDictMaxValueWriter", "reference/generated/torchrl.data.replay_buffers.TensorDictRoundRobinWriter", "reference/generated/torchrl.data.replay_buffers.TensorStorage", "reference/generated/torchrl.data.replay_buffers.Writer", "reference/generated/torchrl.envs.BraxEnv", "reference/generated/torchrl.envs.BraxWrapper", "reference/generated/torchrl.envs.DMControlEnv", "reference/generated/torchrl.envs.DMControlWrapper", "reference/generated/torchrl.envs.EnvBase", "reference/generated/torchrl.envs.EnvCreator", "reference/generated/torchrl.envs.EnvMetaData", "reference/generated/torchrl.envs.GymEnv", "reference/generated/torchrl.envs.GymLikeEnv", "reference/generated/torchrl.envs.GymWrapper", "reference/generated/torchrl.envs.HabitatEnv", "reference/generated/torchrl.envs.IsaacGymEnv", "reference/generated/torchrl.envs.IsaacGymWrapper", "reference/generated/torchrl.envs.JumanjiEnv", "reference/generated/torchrl.envs.JumanjiWrapper", "reference/generated/torchrl.envs.MOGymEnv", "reference/generated/torchrl.envs.MOGymWrapper", "reference/generated/torchrl.envs.MarlGroupMapType", "reference/generated/torchrl.envs.ModelBasedEnvBase", "reference/generated/torchrl.envs.MultiThreadedEnv", "reference/generated/torchrl.envs.MultiThreadedEnvWrapper", "reference/generated/torchrl.envs.OpenMLEnv", "reference/generated/torchrl.envs.ParallelEnv", "reference/generated/torchrl.envs.PettingZooEnv", "reference/generated/torchrl.envs.PettingZooWrapper", "reference/generated/torchrl.envs.RoboHiveEnv", "reference/generated/torchrl.envs.SMACv2Env", "reference/generated/torchrl.envs.SMACv2Wrapper", "reference/generated/torchrl.envs.SerialEnv", "reference/generated/torchrl.envs.VmasEnv", "reference/generated/torchrl.envs.VmasWrapper", "reference/generated/torchrl.envs.check_marl_grouping", "reference/generated/torchrl.envs.gym_backend", "reference/generated/torchrl.envs.model_based.dreamer.DreamerEnv", "reference/generated/torchrl.envs.set_gym_backend", "reference/generated/torchrl.envs.transforms.ActionMask", "reference/generated/torchrl.envs.transforms.BinarizeReward", "reference/generated/torchrl.envs.transforms.BurnInTransform", "reference/generated/torchrl.envs.transforms.CatFrames", "reference/generated/torchrl.envs.transforms.CatTensors", "reference/generated/torchrl.envs.transforms.CenterCrop", "reference/generated/torchrl.envs.transforms.ClipTransform", "reference/generated/torchrl.envs.transforms.Compose", "reference/generated/torchrl.envs.transforms.DTypeCastTransform", "reference/generated/torchrl.envs.transforms.DeviceCastTransform", "reference/generated/torchrl.envs.transforms.DiscreteActionProjection", "reference/generated/torchrl.envs.transforms.DoubleToFloat", "reference/generated/torchrl.envs.transforms.EndOfLifeTransform", "reference/generated/torchrl.envs.transforms.ExcludeTransform", "reference/generated/torchrl.envs.transforms.FiniteTensorDictCheck", "reference/generated/torchrl.envs.transforms.FlattenObservation", "reference/generated/torchrl.envs.transforms.FrameSkipTransform", "reference/generated/torchrl.envs.transforms.GrayScale", "reference/generated/torchrl.envs.transforms.InitTracker", "reference/generated/torchrl.envs.transforms.KLRewardTransform", "reference/generated/torchrl.envs.transforms.NoopResetEnv", "reference/generated/torchrl.envs.transforms.ObservationNorm", "reference/generated/torchrl.envs.transforms.ObservationTransform", "reference/generated/torchrl.envs.transforms.PermuteTransform", "reference/generated/torchrl.envs.transforms.PinMemoryTransform", "reference/generated/torchrl.envs.transforms.R3MTransform", "reference/generated/torchrl.envs.transforms.RandomCropTensorDict", "reference/generated/torchrl.envs.transforms.RenameTransform", "reference/generated/torchrl.envs.transforms.Resize", "reference/generated/torchrl.envs.transforms.Reward2GoTransform", "reference/generated/torchrl.envs.transforms.RewardClipping", "reference/generated/torchrl.envs.transforms.RewardScaling", "reference/generated/torchrl.envs.transforms.RewardSum", "reference/generated/torchrl.envs.transforms.SelectTransform", "reference/generated/torchrl.envs.transforms.SqueezeTransform", "reference/generated/torchrl.envs.transforms.StepCounter", "reference/generated/torchrl.envs.transforms.TargetReturn", "reference/generated/torchrl.envs.transforms.TensorDictPrimer", "reference/generated/torchrl.envs.transforms.TimeMaxPool", "reference/generated/torchrl.envs.transforms.ToTensorImage", "reference/generated/torchrl.envs.transforms.Transform", "reference/generated/torchrl.envs.transforms.TransformedEnv", "reference/generated/torchrl.envs.transforms.UnsqueezeTransform", "reference/generated/torchrl.envs.transforms.VC1Transform", "reference/generated/torchrl.envs.transforms.VIPRewardTransform", "reference/generated/torchrl.envs.transforms.VIPTransform", "reference/generated/torchrl.envs.transforms.VecGymEnvTransform", "reference/generated/torchrl.envs.transforms.VecNorm", "reference/generated/torchrl.envs.transforms.gSDENoise", "reference/generated/torchrl.envs.utils.check_env_specs", "reference/generated/torchrl.envs.utils.exploration_mode", "reference/generated/torchrl.envs.utils.exploration_type", "reference/generated/torchrl.envs.utils.get_available_libraries", "reference/generated/torchrl.envs.utils.make_composite_from_td", "reference/generated/torchrl.envs.utils.set_exploration_mode", "reference/generated/torchrl.envs.utils.set_exploration_type", "reference/generated/torchrl.envs.utils.step_mdp", "reference/generated/torchrl.envs.utils.terminated_or_truncated", "reference/generated/torchrl.modules.CEMPlanner", "reference/generated/torchrl.modules.Conv3dNet", "reference/generated/torchrl.modules.ConvNet", "reference/generated/torchrl.modules.DTActor", "reference/generated/torchrl.modules.DdpgCnnActor", "reference/generated/torchrl.modules.DdpgCnnQNet", "reference/generated/torchrl.modules.DdpgMlpActor", "reference/generated/torchrl.modules.DdpgMlpQNet", "reference/generated/torchrl.modules.DecisionTransformer", "reference/generated/torchrl.modules.Delta", "reference/generated/torchrl.modules.DistributionalDQNnet", "reference/generated/torchrl.modules.DistributionalQValueHook", "reference/generated/torchrl.modules.DreamerActor", "reference/generated/torchrl.modules.DuelingCnnDQNet", "reference/generated/torchrl.modules.GRU", "reference/generated/torchrl.modules.GRUCell", "reference/generated/torchrl.modules.GRUModule", "reference/generated/torchrl.modules.IndependentNormal", "reference/generated/torchrl.modules.LSTM", "reference/generated/torchrl.modules.LSTMCell", "reference/generated/torchrl.modules.LSTMModule", "reference/generated/torchrl.modules.LSTMNet", "reference/generated/torchrl.modules.MLP", "reference/generated/torchrl.modules.MPCPlannerBase", "reference/generated/torchrl.modules.MPPIPlanner", "reference/generated/torchrl.modules.MaskedCategorical", "reference/generated/torchrl.modules.MaskedOneHotCategorical", "reference/generated/torchrl.modules.MultiAgentConvNet", "reference/generated/torchrl.modules.MultiAgentMLP", "reference/generated/torchrl.modules.NoisyLazyLinear", "reference/generated/torchrl.modules.NoisyLinear", "reference/generated/torchrl.modules.NormalParamWrapper", "reference/generated/torchrl.modules.ObsDecoder", "reference/generated/torchrl.modules.ObsEncoder", "reference/generated/torchrl.modules.OneHotCategorical", "reference/generated/torchrl.modules.OnlineDTActor", "reference/generated/torchrl.modules.QMixer", "reference/generated/torchrl.modules.QValueHook", "reference/generated/torchrl.modules.RSSMPosterior", "reference/generated/torchrl.modules.RSSMPrior", "reference/generated/torchrl.modules.Squeeze2dLayer", "reference/generated/torchrl.modules.SqueezeLayer", "reference/generated/torchrl.modules.TanhDelta", "reference/generated/torchrl.modules.TanhNormal", "reference/generated/torchrl.modules.TruncatedNormal", "reference/generated/torchrl.modules.VDNMixer", "reference/generated/torchrl.modules.VmapModule", "reference/generated/torchrl.modules.reset_noise", "reference/generated/torchrl.modules.tensordict_module.Actor", "reference/generated/torchrl.modules.tensordict_module.ActorCriticOperator", "reference/generated/torchrl.modules.tensordict_module.ActorCriticWrapper", "reference/generated/torchrl.modules.tensordict_module.ActorValueOperator", "reference/generated/torchrl.modules.tensordict_module.AdditiveGaussianWrapper", "reference/generated/torchrl.modules.tensordict_module.DecisionTransformerInferenceWrapper", "reference/generated/torchrl.modules.tensordict_module.DistributionalQValueActor", "reference/generated/torchrl.modules.tensordict_module.DistributionalQValueModule", "reference/generated/torchrl.modules.tensordict_module.EGreedyModule", "reference/generated/torchrl.modules.tensordict_module.EGreedyWrapper", "reference/generated/torchrl.modules.tensordict_module.LMHeadActorValueOperator", "reference/generated/torchrl.modules.tensordict_module.OrnsteinUhlenbeckProcessWrapper", "reference/generated/torchrl.modules.tensordict_module.ProbabilisticActor", "reference/generated/torchrl.modules.tensordict_module.QValueActor", "reference/generated/torchrl.modules.tensordict_module.QValueModule", "reference/generated/torchrl.modules.tensordict_module.SafeModule", "reference/generated/torchrl.modules.tensordict_module.SafeProbabilisticModule", "reference/generated/torchrl.modules.tensordict_module.SafeProbabilisticTensorDictSequential", "reference/generated/torchrl.modules.tensordict_module.SafeSequential", "reference/generated/torchrl.modules.tensordict_module.TanhModule", "reference/generated/torchrl.modules.tensordict_module.ValueOperator", "reference/generated/torchrl.modules.tensordict_module.WorldModelWrapper", "reference/generated/torchrl.modules.utils.biased_softplus", "reference/generated/torchrl.modules.utils.inv_softplus", "reference/generated/torchrl.modules.utils.mappings", "reference/generated/torchrl.objectives.A2CLoss", "reference/generated/torchrl.objectives.CQLLoss", "reference/generated/torchrl.objectives.ClipPPOLoss", "reference/generated/torchrl.objectives.DDPGLoss", "reference/generated/torchrl.objectives.DQNLoss", "reference/generated/torchrl.objectives.DTLoss", "reference/generated/torchrl.objectives.DiscreteCQLLoss", "reference/generated/torchrl.objectives.DiscreteSACLoss", "reference/generated/torchrl.objectives.DistributionalDQNLoss", "reference/generated/torchrl.objectives.DreamerActorLoss", "reference/generated/torchrl.objectives.DreamerModelLoss", "reference/generated/torchrl.objectives.DreamerValueLoss", "reference/generated/torchrl.objectives.HardUpdate", "reference/generated/torchrl.objectives.IQLLoss", "reference/generated/torchrl.objectives.KLPENPPOLoss", "reference/generated/torchrl.objectives.LossModule", "reference/generated/torchrl.objectives.OnlineDTLoss", "reference/generated/torchrl.objectives.PPOLoss", "reference/generated/torchrl.objectives.REDQLoss", "reference/generated/torchrl.objectives.ReinforceLoss", "reference/generated/torchrl.objectives.SACLoss", "reference/generated/torchrl.objectives.SoftUpdate", "reference/generated/torchrl.objectives.TD3Loss", "reference/generated/torchrl.objectives.ValueEstimators", "reference/generated/torchrl.objectives.default_value_kwargs", "reference/generated/torchrl.objectives.distance_loss", "reference/generated/torchrl.objectives.hold_out_net", "reference/generated/torchrl.objectives.hold_out_params", "reference/generated/torchrl.objectives.multiagent.QMixerLoss", "reference/generated/torchrl.objectives.next_state_value", "reference/generated/torchrl.objectives.value.GAE", "reference/generated/torchrl.objectives.value.TD0Estimator", "reference/generated/torchrl.objectives.value.TD1Estimator", "reference/generated/torchrl.objectives.value.TDLambdaEstimator", "reference/generated/torchrl.objectives.value.ValueEstimatorBase", "reference/generated/torchrl.objectives.value.functional.generalized_advantage_estimate", "reference/generated/torchrl.objectives.value.functional.reward2go", "reference/generated/torchrl.objectives.value.functional.td0_advantage_estimate", "reference/generated/torchrl.objectives.value.functional.td0_return_estimate", "reference/generated/torchrl.objectives.value.functional.td1_advantage_estimate", "reference/generated/torchrl.objectives.value.functional.td1_return_estimate", "reference/generated/torchrl.objectives.value.functional.td_lambda_advantage_estimate", "reference/generated/torchrl.objectives.value.functional.td_lambda_return_estimate", "reference/generated/torchrl.objectives.value.functional.vec_generalized_advantage_estimate", "reference/generated/torchrl.objectives.value.functional.vec_td1_advantage_estimate", "reference/generated/torchrl.objectives.value.functional.vec_td1_return_estimate", "reference/generated/torchrl.objectives.value.functional.vec_td_lambda_advantage_estimate", "reference/generated/torchrl.objectives.value.functional.vec_td_lambda_return_estimate", "reference/generated/torchrl.record.TensorDictRecorder", "reference/generated/torchrl.record.VideoRecorder", "reference/generated/torchrl.record.loggers.Logger", "reference/generated/torchrl.record.loggers.csv.CSVLogger", "reference/generated/torchrl.record.loggers.generate_exp_name", "reference/generated/torchrl.record.loggers.get_logger", "reference/generated/torchrl.record.loggers.mlflow.MLFlowLogger", "reference/generated/torchrl.record.loggers.tensorboard.TensorboardLogger", "reference/generated/torchrl.record.loggers.wandb.WandbLogger", "reference/generated/torchrl.trainers.BatchSubSampler", "reference/generated/torchrl.trainers.ClearCudaCache", "reference/generated/torchrl.trainers.CountFramesLog", "reference/generated/torchrl.trainers.LogReward", "reference/generated/torchrl.trainers.OptimizerHook", "reference/generated/torchrl.trainers.Recorder", "reference/generated/torchrl.trainers.ReplayBufferTrainer", "reference/generated/torchrl.trainers.RewardNormalizer", "reference/generated/torchrl.trainers.SelectKeys", "reference/generated/torchrl.trainers.Trainer", "reference/generated/torchrl.trainers.TrainerHookBase", "reference/generated/torchrl.trainers.UpdateWeights", "reference/generated/torchrl.trainers.helpers.correct_for_frame_skip", "reference/generated/torchrl.trainers.helpers.get_stats_random_rollout", "reference/generated/torchrl.trainers.helpers.make_collector_offpolicy", "reference/generated/torchrl.trainers.helpers.make_collector_onpolicy", "reference/generated/torchrl.trainers.helpers.make_dqn_loss", "reference/generated/torchrl.trainers.helpers.make_redq_loss", "reference/generated/torchrl.trainers.helpers.make_redq_model", "reference/generated/torchrl.trainers.helpers.make_replay_buffer", "reference/generated/torchrl.trainers.helpers.make_target_updater", "reference/generated/torchrl.trainers.helpers.make_trainer", "reference/generated/torchrl.trainers.helpers.parallel_env_constructor", "reference/generated/torchrl.trainers.helpers.sync_async_collector", "reference/generated/torchrl.trainers.helpers.sync_sync_collector", "reference/generated/torchrl.trainers.helpers.transformed_env_constructor", "reference/generated/tutorials/README", "reference/index", "reference/knowledge_base", "reference/modules", "reference/objectives", "reference/trainers", "reference/utils", "sg_execution_times", "tutorials/coding_ddpg", "tutorials/coding_dqn", "tutorials/coding_ppo", "tutorials/dqn_with_rnn", "tutorials/index", "tutorials/multi_task", "tutorials/multiagent_ppo", "tutorials/pendulum", "tutorials/pretrained_models", "tutorials/rb_tutorial", "tutorials/sg_execution_times", "tutorials/torchrl_demo", "tutorials/torchrl_envs"], "filenames": ["index.rst", "reference/collectors.rst", "reference/data.rst", "reference/envs.rst", "reference/generated/knowledge_base/DEBUGGING_RL.rst", "reference/generated/knowledge_base/GYM.rst", "reference/generated/knowledge_base/HABITAT.rst", "reference/generated/knowledge_base/MUJOCO_INSTALLATION.rst", "reference/generated/knowledge_base/PRO-TIPS.rst", "reference/generated/knowledge_base/RESOURCES.rst", "reference/generated/knowledge_base/VERSIONING_ISSUES.rst", "reference/generated/torchrl._utils.implement_for.rst", "reference/generated/torchrl.collectors.collectors.DataCollectorBase.rst", "reference/generated/torchrl.collectors.collectors.MultiSyncDataCollector.rst", "reference/generated/torchrl.collectors.collectors.MultiaSyncDataCollector.rst", "reference/generated/torchrl.collectors.collectors.RandomPolicy.rst", "reference/generated/torchrl.collectors.collectors.SyncDataCollector.rst", "reference/generated/torchrl.collectors.collectors.aSyncDataCollector.rst", "reference/generated/torchrl.collectors.distributed.DistributedDataCollector.rst", "reference/generated/torchrl.collectors.distributed.DistributedSyncDataCollector.rst", "reference/generated/torchrl.collectors.distributed.RPCDataCollector.rst", "reference/generated/torchrl.collectors.distributed.RayCollector.rst", "reference/generated/torchrl.collectors.distributed.submitit_delayed_launcher.rst", "reference/generated/torchrl.collectors.utils.split_trajectories.rst", "reference/generated/torchrl.data.BinaryDiscreteTensorSpec.rst", "reference/generated/torchrl.data.BoundedTensorSpec.rst", "reference/generated/torchrl.data.CompositeSpec.rst", "reference/generated/torchrl.data.DiscreteTensorSpec.rst", "reference/generated/torchrl.data.LazyStackedCompositeSpec.rst", "reference/generated/torchrl.data.LazyStackedTensorSpec.rst", "reference/generated/torchrl.data.MultiDiscreteTensorSpec.rst", "reference/generated/torchrl.data.MultiOneHotDiscreteTensorSpec.rst", "reference/generated/torchrl.data.MultiStep.rst", "reference/generated/torchrl.data.OneHotDiscreteTensorSpec.rst", "reference/generated/torchrl.data.PairwiseDataset.rst", "reference/generated/torchrl.data.PrioritizedReplayBuffer.rst", "reference/generated/torchrl.data.PromptData.rst", "reference/generated/torchrl.data.PromptTensorDictTokenizer.rst", "reference/generated/torchrl.data.ReplayBuffer.rst", "reference/generated/torchrl.data.RewardData.rst", "reference/generated/torchrl.data.RolloutFromModel.rst", "reference/generated/torchrl.data.TensorDictPrioritizedReplayBuffer.rst", "reference/generated/torchrl.data.TensorDictReplayBuffer.rst", "reference/generated/torchrl.data.TensorDictTokenizer.rst", "reference/generated/torchrl.data.TensorSpec.rst", "reference/generated/torchrl.data.TokenizedDatasetLoader.rst", "reference/generated/torchrl.data.UnboundedContinuousTensorSpec.rst", "reference/generated/torchrl.data.UnboundedDiscreteTensorSpec.rst", "reference/generated/torchrl.data.check_no_exclusive_keys.rst", "reference/generated/torchrl.data.consolidate_spec.rst", "reference/generated/torchrl.data.contains_lazy_spec.rst", "reference/generated/torchrl.data.create_infinite_iterator.rst", "reference/generated/torchrl.data.datasets.D4RLExperienceReplay.rst", "reference/generated/torchrl.data.datasets.MinariExperienceReplay.rst", "reference/generated/torchrl.data.datasets.OpenMLExperienceReplay.rst", "reference/generated/torchrl.data.datasets.RobosetExperienceReplay.rst", "reference/generated/torchrl.data.datasets.VD4RLExperienceReplay.rst", "reference/generated/torchrl.data.get_dataloader.rst", "reference/generated/torchrl.data.replay_buffers.LazyMemmapStorage.rst", "reference/generated/torchrl.data.replay_buffers.LazyTensorStorage.rst", "reference/generated/torchrl.data.replay_buffers.ListStorage.rst", "reference/generated/torchrl.data.replay_buffers.PrioritizedSampler.rst", "reference/generated/torchrl.data.replay_buffers.RandomSampler.rst", "reference/generated/torchrl.data.replay_buffers.RoundRobinWriter.rst", "reference/generated/torchrl.data.replay_buffers.Sampler.rst", "reference/generated/torchrl.data.replay_buffers.SamplerWithoutReplacement.rst", "reference/generated/torchrl.data.replay_buffers.SliceSampler.rst", "reference/generated/torchrl.data.replay_buffers.SliceSamplerWithoutReplacement.rst", "reference/generated/torchrl.data.replay_buffers.Storage.rst", "reference/generated/torchrl.data.replay_buffers.TensorDictMaxValueWriter.rst", "reference/generated/torchrl.data.replay_buffers.TensorDictRoundRobinWriter.rst", "reference/generated/torchrl.data.replay_buffers.TensorStorage.rst", "reference/generated/torchrl.data.replay_buffers.Writer.rst", "reference/generated/torchrl.envs.BraxEnv.rst", "reference/generated/torchrl.envs.BraxWrapper.rst", "reference/generated/torchrl.envs.DMControlEnv.rst", "reference/generated/torchrl.envs.DMControlWrapper.rst", "reference/generated/torchrl.envs.EnvBase.rst", "reference/generated/torchrl.envs.EnvCreator.rst", "reference/generated/torchrl.envs.EnvMetaData.rst", "reference/generated/torchrl.envs.GymEnv.rst", "reference/generated/torchrl.envs.GymLikeEnv.rst", "reference/generated/torchrl.envs.GymWrapper.rst", "reference/generated/torchrl.envs.HabitatEnv.rst", "reference/generated/torchrl.envs.IsaacGymEnv.rst", "reference/generated/torchrl.envs.IsaacGymWrapper.rst", "reference/generated/torchrl.envs.JumanjiEnv.rst", "reference/generated/torchrl.envs.JumanjiWrapper.rst", "reference/generated/torchrl.envs.MOGymEnv.rst", "reference/generated/torchrl.envs.MOGymWrapper.rst", "reference/generated/torchrl.envs.MarlGroupMapType.rst", "reference/generated/torchrl.envs.ModelBasedEnvBase.rst", "reference/generated/torchrl.envs.MultiThreadedEnv.rst", "reference/generated/torchrl.envs.MultiThreadedEnvWrapper.rst", "reference/generated/torchrl.envs.OpenMLEnv.rst", "reference/generated/torchrl.envs.ParallelEnv.rst", "reference/generated/torchrl.envs.PettingZooEnv.rst", "reference/generated/torchrl.envs.PettingZooWrapper.rst", "reference/generated/torchrl.envs.RoboHiveEnv.rst", "reference/generated/torchrl.envs.SMACv2Env.rst", "reference/generated/torchrl.envs.SMACv2Wrapper.rst", "reference/generated/torchrl.envs.SerialEnv.rst", "reference/generated/torchrl.envs.VmasEnv.rst", "reference/generated/torchrl.envs.VmasWrapper.rst", "reference/generated/torchrl.envs.check_marl_grouping.rst", "reference/generated/torchrl.envs.gym_backend.rst", "reference/generated/torchrl.envs.model_based.dreamer.DreamerEnv.rst", "reference/generated/torchrl.envs.set_gym_backend.rst", "reference/generated/torchrl.envs.transforms.ActionMask.rst", "reference/generated/torchrl.envs.transforms.BinarizeReward.rst", "reference/generated/torchrl.envs.transforms.BurnInTransform.rst", "reference/generated/torchrl.envs.transforms.CatFrames.rst", "reference/generated/torchrl.envs.transforms.CatTensors.rst", "reference/generated/torchrl.envs.transforms.CenterCrop.rst", "reference/generated/torchrl.envs.transforms.ClipTransform.rst", "reference/generated/torchrl.envs.transforms.Compose.rst", "reference/generated/torchrl.envs.transforms.DTypeCastTransform.rst", "reference/generated/torchrl.envs.transforms.DeviceCastTransform.rst", "reference/generated/torchrl.envs.transforms.DiscreteActionProjection.rst", "reference/generated/torchrl.envs.transforms.DoubleToFloat.rst", "reference/generated/torchrl.envs.transforms.EndOfLifeTransform.rst", "reference/generated/torchrl.envs.transforms.ExcludeTransform.rst", "reference/generated/torchrl.envs.transforms.FiniteTensorDictCheck.rst", "reference/generated/torchrl.envs.transforms.FlattenObservation.rst", "reference/generated/torchrl.envs.transforms.FrameSkipTransform.rst", "reference/generated/torchrl.envs.transforms.GrayScale.rst", "reference/generated/torchrl.envs.transforms.InitTracker.rst", "reference/generated/torchrl.envs.transforms.KLRewardTransform.rst", "reference/generated/torchrl.envs.transforms.NoopResetEnv.rst", "reference/generated/torchrl.envs.transforms.ObservationNorm.rst", "reference/generated/torchrl.envs.transforms.ObservationTransform.rst", "reference/generated/torchrl.envs.transforms.PermuteTransform.rst", "reference/generated/torchrl.envs.transforms.PinMemoryTransform.rst", "reference/generated/torchrl.envs.transforms.R3MTransform.rst", "reference/generated/torchrl.envs.transforms.RandomCropTensorDict.rst", "reference/generated/torchrl.envs.transforms.RenameTransform.rst", "reference/generated/torchrl.envs.transforms.Resize.rst", "reference/generated/torchrl.envs.transforms.Reward2GoTransform.rst", "reference/generated/torchrl.envs.transforms.RewardClipping.rst", "reference/generated/torchrl.envs.transforms.RewardScaling.rst", "reference/generated/torchrl.envs.transforms.RewardSum.rst", "reference/generated/torchrl.envs.transforms.SelectTransform.rst", "reference/generated/torchrl.envs.transforms.SqueezeTransform.rst", "reference/generated/torchrl.envs.transforms.StepCounter.rst", "reference/generated/torchrl.envs.transforms.TargetReturn.rst", "reference/generated/torchrl.envs.transforms.TensorDictPrimer.rst", "reference/generated/torchrl.envs.transforms.TimeMaxPool.rst", "reference/generated/torchrl.envs.transforms.ToTensorImage.rst", "reference/generated/torchrl.envs.transforms.Transform.rst", "reference/generated/torchrl.envs.transforms.TransformedEnv.rst", "reference/generated/torchrl.envs.transforms.UnsqueezeTransform.rst", "reference/generated/torchrl.envs.transforms.VC1Transform.rst", "reference/generated/torchrl.envs.transforms.VIPRewardTransform.rst", "reference/generated/torchrl.envs.transforms.VIPTransform.rst", "reference/generated/torchrl.envs.transforms.VecGymEnvTransform.rst", "reference/generated/torchrl.envs.transforms.VecNorm.rst", "reference/generated/torchrl.envs.transforms.gSDENoise.rst", "reference/generated/torchrl.envs.utils.check_env_specs.rst", "reference/generated/torchrl.envs.utils.exploration_mode.rst", "reference/generated/torchrl.envs.utils.exploration_type.rst", "reference/generated/torchrl.envs.utils.get_available_libraries.rst", "reference/generated/torchrl.envs.utils.make_composite_from_td.rst", "reference/generated/torchrl.envs.utils.set_exploration_mode.rst", "reference/generated/torchrl.envs.utils.set_exploration_type.rst", "reference/generated/torchrl.envs.utils.step_mdp.rst", "reference/generated/torchrl.envs.utils.terminated_or_truncated.rst", "reference/generated/torchrl.modules.CEMPlanner.rst", "reference/generated/torchrl.modules.Conv3dNet.rst", "reference/generated/torchrl.modules.ConvNet.rst", "reference/generated/torchrl.modules.DTActor.rst", "reference/generated/torchrl.modules.DdpgCnnActor.rst", "reference/generated/torchrl.modules.DdpgCnnQNet.rst", "reference/generated/torchrl.modules.DdpgMlpActor.rst", "reference/generated/torchrl.modules.DdpgMlpQNet.rst", "reference/generated/torchrl.modules.DecisionTransformer.rst", "reference/generated/torchrl.modules.Delta.rst", "reference/generated/torchrl.modules.DistributionalDQNnet.rst", "reference/generated/torchrl.modules.DistributionalQValueHook.rst", "reference/generated/torchrl.modules.DreamerActor.rst", "reference/generated/torchrl.modules.DuelingCnnDQNet.rst", "reference/generated/torchrl.modules.GRU.rst", "reference/generated/torchrl.modules.GRUCell.rst", "reference/generated/torchrl.modules.GRUModule.rst", "reference/generated/torchrl.modules.IndependentNormal.rst", "reference/generated/torchrl.modules.LSTM.rst", "reference/generated/torchrl.modules.LSTMCell.rst", "reference/generated/torchrl.modules.LSTMModule.rst", "reference/generated/torchrl.modules.LSTMNet.rst", "reference/generated/torchrl.modules.MLP.rst", "reference/generated/torchrl.modules.MPCPlannerBase.rst", "reference/generated/torchrl.modules.MPPIPlanner.rst", "reference/generated/torchrl.modules.MaskedCategorical.rst", "reference/generated/torchrl.modules.MaskedOneHotCategorical.rst", "reference/generated/torchrl.modules.MultiAgentConvNet.rst", "reference/generated/torchrl.modules.MultiAgentMLP.rst", "reference/generated/torchrl.modules.NoisyLazyLinear.rst", "reference/generated/torchrl.modules.NoisyLinear.rst", "reference/generated/torchrl.modules.NormalParamWrapper.rst", "reference/generated/torchrl.modules.ObsDecoder.rst", "reference/generated/torchrl.modules.ObsEncoder.rst", "reference/generated/torchrl.modules.OneHotCategorical.rst", "reference/generated/torchrl.modules.OnlineDTActor.rst", "reference/generated/torchrl.modules.QMixer.rst", "reference/generated/torchrl.modules.QValueHook.rst", "reference/generated/torchrl.modules.RSSMPosterior.rst", "reference/generated/torchrl.modules.RSSMPrior.rst", "reference/generated/torchrl.modules.Squeeze2dLayer.rst", "reference/generated/torchrl.modules.SqueezeLayer.rst", "reference/generated/torchrl.modules.TanhDelta.rst", "reference/generated/torchrl.modules.TanhNormal.rst", "reference/generated/torchrl.modules.TruncatedNormal.rst", "reference/generated/torchrl.modules.VDNMixer.rst", "reference/generated/torchrl.modules.VmapModule.rst", "reference/generated/torchrl.modules.reset_noise.rst", "reference/generated/torchrl.modules.tensordict_module.Actor.rst", "reference/generated/torchrl.modules.tensordict_module.ActorCriticOperator.rst", "reference/generated/torchrl.modules.tensordict_module.ActorCriticWrapper.rst", "reference/generated/torchrl.modules.tensordict_module.ActorValueOperator.rst", "reference/generated/torchrl.modules.tensordict_module.AdditiveGaussianWrapper.rst", "reference/generated/torchrl.modules.tensordict_module.DecisionTransformerInferenceWrapper.rst", "reference/generated/torchrl.modules.tensordict_module.DistributionalQValueActor.rst", "reference/generated/torchrl.modules.tensordict_module.DistributionalQValueModule.rst", "reference/generated/torchrl.modules.tensordict_module.EGreedyModule.rst", "reference/generated/torchrl.modules.tensordict_module.EGreedyWrapper.rst", "reference/generated/torchrl.modules.tensordict_module.LMHeadActorValueOperator.rst", "reference/generated/torchrl.modules.tensordict_module.OrnsteinUhlenbeckProcessWrapper.rst", "reference/generated/torchrl.modules.tensordict_module.ProbabilisticActor.rst", "reference/generated/torchrl.modules.tensordict_module.QValueActor.rst", "reference/generated/torchrl.modules.tensordict_module.QValueModule.rst", "reference/generated/torchrl.modules.tensordict_module.SafeModule.rst", "reference/generated/torchrl.modules.tensordict_module.SafeProbabilisticModule.rst", "reference/generated/torchrl.modules.tensordict_module.SafeProbabilisticTensorDictSequential.rst", "reference/generated/torchrl.modules.tensordict_module.SafeSequential.rst", "reference/generated/torchrl.modules.tensordict_module.TanhModule.rst", "reference/generated/torchrl.modules.tensordict_module.ValueOperator.rst", "reference/generated/torchrl.modules.tensordict_module.WorldModelWrapper.rst", "reference/generated/torchrl.modules.utils.biased_softplus.rst", "reference/generated/torchrl.modules.utils.inv_softplus.rst", "reference/generated/torchrl.modules.utils.mappings.rst", "reference/generated/torchrl.objectives.A2CLoss.rst", "reference/generated/torchrl.objectives.CQLLoss.rst", "reference/generated/torchrl.objectives.ClipPPOLoss.rst", "reference/generated/torchrl.objectives.DDPGLoss.rst", "reference/generated/torchrl.objectives.DQNLoss.rst", "reference/generated/torchrl.objectives.DTLoss.rst", "reference/generated/torchrl.objectives.DiscreteCQLLoss.rst", "reference/generated/torchrl.objectives.DiscreteSACLoss.rst", "reference/generated/torchrl.objectives.DistributionalDQNLoss.rst", "reference/generated/torchrl.objectives.DreamerActorLoss.rst", "reference/generated/torchrl.objectives.DreamerModelLoss.rst", "reference/generated/torchrl.objectives.DreamerValueLoss.rst", "reference/generated/torchrl.objectives.HardUpdate.rst", "reference/generated/torchrl.objectives.IQLLoss.rst", "reference/generated/torchrl.objectives.KLPENPPOLoss.rst", "reference/generated/torchrl.objectives.LossModule.rst", "reference/generated/torchrl.objectives.OnlineDTLoss.rst", "reference/generated/torchrl.objectives.PPOLoss.rst", "reference/generated/torchrl.objectives.REDQLoss.rst", "reference/generated/torchrl.objectives.ReinforceLoss.rst", "reference/generated/torchrl.objectives.SACLoss.rst", "reference/generated/torchrl.objectives.SoftUpdate.rst", "reference/generated/torchrl.objectives.TD3Loss.rst", "reference/generated/torchrl.objectives.ValueEstimators.rst", "reference/generated/torchrl.objectives.default_value_kwargs.rst", "reference/generated/torchrl.objectives.distance_loss.rst", "reference/generated/torchrl.objectives.hold_out_net.rst", "reference/generated/torchrl.objectives.hold_out_params.rst", "reference/generated/torchrl.objectives.multiagent.QMixerLoss.rst", "reference/generated/torchrl.objectives.next_state_value.rst", "reference/generated/torchrl.objectives.value.GAE.rst", "reference/generated/torchrl.objectives.value.TD0Estimator.rst", "reference/generated/torchrl.objectives.value.TD1Estimator.rst", "reference/generated/torchrl.objectives.value.TDLambdaEstimator.rst", "reference/generated/torchrl.objectives.value.ValueEstimatorBase.rst", "reference/generated/torchrl.objectives.value.functional.generalized_advantage_estimate.rst", "reference/generated/torchrl.objectives.value.functional.reward2go.rst", "reference/generated/torchrl.objectives.value.functional.td0_advantage_estimate.rst", "reference/generated/torchrl.objectives.value.functional.td0_return_estimate.rst", "reference/generated/torchrl.objectives.value.functional.td1_advantage_estimate.rst", "reference/generated/torchrl.objectives.value.functional.td1_return_estimate.rst", "reference/generated/torchrl.objectives.value.functional.td_lambda_advantage_estimate.rst", "reference/generated/torchrl.objectives.value.functional.td_lambda_return_estimate.rst", "reference/generated/torchrl.objectives.value.functional.vec_generalized_advantage_estimate.rst", "reference/generated/torchrl.objectives.value.functional.vec_td1_advantage_estimate.rst", "reference/generated/torchrl.objectives.value.functional.vec_td1_return_estimate.rst", "reference/generated/torchrl.objectives.value.functional.vec_td_lambda_advantage_estimate.rst", "reference/generated/torchrl.objectives.value.functional.vec_td_lambda_return_estimate.rst", "reference/generated/torchrl.record.TensorDictRecorder.rst", "reference/generated/torchrl.record.VideoRecorder.rst", "reference/generated/torchrl.record.loggers.Logger.rst", "reference/generated/torchrl.record.loggers.csv.CSVLogger.rst", "reference/generated/torchrl.record.loggers.generate_exp_name.rst", "reference/generated/torchrl.record.loggers.get_logger.rst", "reference/generated/torchrl.record.loggers.mlflow.MLFlowLogger.rst", "reference/generated/torchrl.record.loggers.tensorboard.TensorboardLogger.rst", "reference/generated/torchrl.record.loggers.wandb.WandbLogger.rst", "reference/generated/torchrl.trainers.BatchSubSampler.rst", "reference/generated/torchrl.trainers.ClearCudaCache.rst", "reference/generated/torchrl.trainers.CountFramesLog.rst", "reference/generated/torchrl.trainers.LogReward.rst", "reference/generated/torchrl.trainers.OptimizerHook.rst", "reference/generated/torchrl.trainers.Recorder.rst", "reference/generated/torchrl.trainers.ReplayBufferTrainer.rst", "reference/generated/torchrl.trainers.RewardNormalizer.rst", "reference/generated/torchrl.trainers.SelectKeys.rst", "reference/generated/torchrl.trainers.Trainer.rst", "reference/generated/torchrl.trainers.TrainerHookBase.rst", "reference/generated/torchrl.trainers.UpdateWeights.rst", "reference/generated/torchrl.trainers.helpers.correct_for_frame_skip.rst", "reference/generated/torchrl.trainers.helpers.get_stats_random_rollout.rst", "reference/generated/torchrl.trainers.helpers.make_collector_offpolicy.rst", "reference/generated/torchrl.trainers.helpers.make_collector_onpolicy.rst", "reference/generated/torchrl.trainers.helpers.make_dqn_loss.rst", "reference/generated/torchrl.trainers.helpers.make_redq_loss.rst", "reference/generated/torchrl.trainers.helpers.make_redq_model.rst", "reference/generated/torchrl.trainers.helpers.make_replay_buffer.rst", "reference/generated/torchrl.trainers.helpers.make_target_updater.rst", "reference/generated/torchrl.trainers.helpers.make_trainer.rst", "reference/generated/torchrl.trainers.helpers.parallel_env_constructor.rst", "reference/generated/torchrl.trainers.helpers.sync_async_collector.rst", "reference/generated/torchrl.trainers.helpers.sync_sync_collector.rst", "reference/generated/torchrl.trainers.helpers.transformed_env_constructor.rst", "reference/generated/tutorials/README.rst", "reference/index.rst", "reference/knowledge_base.rst", "reference/modules.rst", "reference/objectives.rst", "reference/trainers.rst", "reference/utils.rst", "sg_execution_times.rst", "tutorials/coding_ddpg.rst", "tutorials/coding_dqn.rst", "tutorials/coding_ppo.rst", "tutorials/dqn_with_rnn.rst", "tutorials/index.rst", "tutorials/multi_task.rst", "tutorials/multiagent_ppo.rst", "tutorials/pendulum.rst", "tutorials/pretrained_models.rst", "tutorials/rb_tutorial.rst", "tutorials/sg_execution_times.rst", "tutorials/torchrl_demo.rst", "tutorials/torchrl_envs.rst"], "titles": ["TorchRL", "torchrl.collectors package", "torchrl.data package", "torchrl.envs package", "Things to consider when debugging RL", "Working with gym", "Working with <code class=\"docutils literal notranslate\"><span class=\"pre\">habitat-lab</span></code>", "Working with MuJoCo-based environments", "Common PyTorch errors and solutions", "Useful resources", "Versioning Issues", "implement_for", "DataCollectorBase", "MultiSyncDataCollector", "MultiaSyncDataCollector", "RandomPolicy", "SyncDataCollector", "aSyncDataCollector", "DistributedDataCollector", "DistributedSyncDataCollector", "RPCDataCollector", "RayCollector", "submitit_delayed_launcher", "split_trajectories", "BinaryDiscreteTensorSpec", "BoundedTensorSpec", "CompositeSpec", "DiscreteTensorSpec", "LazyStackedCompositeSpec", "LazyStackedTensorSpec", "MultiDiscreteTensorSpec", "MultiOneHotDiscreteTensorSpec", "MultiStep", "OneHotDiscreteTensorSpec", "PairwiseDataset", "PrioritizedReplayBuffer", "PromptData", "PromptTensorDictTokenizer", "ReplayBuffer", "RewardData", "RolloutFromModel", "TensorDictPrioritizedReplayBuffer", "TensorDictReplayBuffer", "TensorDictTokenizer", "TensorSpec", "TokenizedDatasetLoader", "UnboundedContinuousTensorSpec", "UnboundedDiscreteTensorSpec", "check_no_exclusive_keys", "consolidate_spec", "contains_lazy_spec", "create_infinite_iterator", "D4RLExperienceReplay", "MinariExperienceReplay", "OpenMLExperienceReplay", "RobosetExperienceReplay", "VD4RLExperienceReplay", "get_dataloader", "LazyMemmapStorage", "LazyTensorStorage", "ListStorage", "PrioritizedSampler", "RandomSampler", "RoundRobinWriter", "Sampler", "SamplerWithoutReplacement", "SliceSampler", "SliceSamplerWithoutReplacement", "Storage", "TensorDictMaxValueWriter", "TensorDictRoundRobinWriter", "TensorStorage", "Writer", "BraxEnv", "BraxWrapper", "DMControlEnv", "DMControlWrapper", "EnvBase", "EnvCreator", "EnvMetaData", "GymEnv", "GymLikeEnv", "GymWrapper", "HabitatEnv", "IsaacGymEnv", "IsaacGymWrapper", "JumanjiEnv", "JumanjiWrapper", "MOGymEnv", "MOGymWrapper", "MarlGroupMapType", "ModelBasedEnvBase", "MultiThreadedEnv", "MultiThreadedEnvWrapper", "OpenMLEnv", "ParallelEnv", "PettingZooEnv", "PettingZooWrapper", "RoboHiveEnv", "SMACv2Env", "SMACv2Wrapper", "SerialEnv", "VmasEnv", "VmasWrapper", "check_marl_grouping", "gym_backend", "DreamerEnv", "set_gym_backend", "ActionMask", "BinarizeReward", "BurnInTransform", "CatFrames", "CatTensors", "CenterCrop", "ClipTransform", "Compose", "DTypeCastTransform", "DeviceCastTransform", "DiscreteActionProjection", "DoubleToFloat", "EndOfLifeTransform", "ExcludeTransform", "FiniteTensorDictCheck", "FlattenObservation", "FrameSkipTransform", "GrayScale", "InitTracker", "KLRewardTransform", "NoopResetEnv", "ObservationNorm", "ObservationTransform", "PermuteTransform", "PinMemoryTransform", "R3MTransform", "RandomCropTensorDict", "RenameTransform", "Resize", "Reward2GoTransform", "RewardClipping", "RewardScaling", "RewardSum", "SelectTransform", "SqueezeTransform", "StepCounter", "TargetReturn", "TensorDictPrimer", "TimeMaxPool", "ToTensorImage", "Transform", "TransformedEnv", "UnsqueezeTransform", "VC1Transform", "VIPRewardTransform", "VIPTransform", "VecGymEnvTransform", "VecNorm", "gSDENoise", "check_env_specs", "exploration_mode", "exploration_type", "get_available_libraries", "make_composite_from_td", "set_exploration_mode", "set_exploration_type", "step_mdp", "terminated_or_truncated", "CEMPlanner", "Conv3dNet", "ConvNet", "DTActor", "DdpgCnnActor", "DdpgCnnQNet", "DdpgMlpActor", "DdpgMlpQNet", "DecisionTransformer", "Delta", "DistributionalDQNnet", "DistributionalQValueHook", "DreamerActor", "DuelingCnnDQNet", "GRU", "GRUCell", "GRUModule", "IndependentNormal", "LSTM", "LSTMCell", "LSTMModule", "LSTMNet", "MLP", "MPCPlannerBase", "MPPIPlanner", "MaskedCategorical", "MaskedOneHotCategorical", "MultiAgentConvNet", "MultiAgentMLP", "NoisyLazyLinear", "NoisyLinear", "NormalParamWrapper", "ObsDecoder", "ObsEncoder", "OneHotCategorical", "OnlineDTActor", "QMixer", "QValueHook", "RSSMPosterior", "RSSMPrior", "Squeeze2dLayer", "SqueezeLayer", "TanhDelta", "TanhNormal", "TruncatedNormal", "VDNMixer", "VmapModule", "reset_noise", "Actor", "ActorCriticOperator", "ActorCriticWrapper", "ActorValueOperator", "AdditiveGaussianWrapper", "DecisionTransformerInferenceWrapper", "DistributionalQValueActor", "DistributionalQValueModule", "EGreedyModule", "EGreedyWrapper", "LMHeadActorValueOperator", "OrnsteinUhlenbeckProcessWrapper", "ProbabilisticActor", "QValueActor", "QValueModule", "SafeModule", "SafeProbabilisticModule", "SafeProbabilisticTensorDictSequential", "SafeSequential", "TanhModule", "ValueOperator", "WorldModelWrapper", "biased_softplus", "inv_softplus", "mappings", "A2CLoss", "CQLLoss", "ClipPPOLoss", "DDPGLoss", "DQNLoss", "DTLoss", "DiscreteCQLLoss", "DiscreteSACLoss", "DistributionalDQNLoss", "DreamerActorLoss", "DreamerModelLoss", "DreamerValueLoss", "HardUpdate", "IQLLoss", "KLPENPPOLoss", "LossModule", "OnlineDTLoss", "PPOLoss", "REDQLoss", "ReinforceLoss", "SACLoss", "SoftUpdate", "TD3Loss", "ValueEstimators", "default_value_kwargs", "distance_loss", "hold_out_net", "hold_out_params", "QMixerLoss", "next_state_value", "GAE", "TD0Estimator", "TD1Estimator", "TDLambdaEstimator", "ValueEstimatorBase", "generalized_advantage_estimate", "reward2go", "td0_advantage_estimate", "td0_return_estimate", "td1_advantage_estimate", "td1_return_estimate", "td_lambda_advantage_estimate", "td_lambda_return_estimate", "vec_generalized_advantage_estimate", "vec_td1_advantage_estimate", "vec_td1_return_estimate", "vec_td_lambda_advantage_estimate", "vec_td_lambda_return_estimate", "TensorDictRecorder", "VideoRecorder", "Logger", "CSVLogger", "generate_exp_name", "get_logger", "MLFlowLogger", "TensorboardLogger", "WandbLogger", "BatchSubSampler", "ClearCudaCache", "CountFramesLog", "LogReward", "OptimizerHook", "Recorder", "ReplayBufferTrainer", "RewardNormalizer", "SelectKeys", "Trainer", "TrainerHookBase", "UpdateWeights", "correct_for_frame_skip", "get_stats_random_rollout", "make_collector_offpolicy", "make_collector_onpolicy", "make_dqn_loss", "make_redq_loss", "make_redq_model", "make_replay_buffer", "make_target_updater", "make_trainer", "parallel_env_constructor", "sync_async_collector", "sync_sync_collector", "transformed_env_constructor", "README Tutos", "API Reference", "Knowledge Base", "torchrl.modules package", "torchrl.objectives package", "torchrl.trainers package", "torchrl._utils package", "Computation times", "TorchRL objectives: Coding a DDPG loss", "TorchRL trainer: A DQN example", "Reinforcement Learning (PPO) with TorchRL Tutorial", "Recurrent DQN: Training recurrent policies", "README Tutos", "Task-specific policy in multi-task environments", "Multi-Agent Reinforcement Learning (PPO) with TorchRL Tutorial", "Pendulum: Writing your environment and transforms with TorchRL", "Using pretrained models", "Using Replay Buffers", "Computation times", "Introduction to TorchRL", "TorchRL envs"], "terms": {"an": [0, 1, 2, 3, 5, 8, 9, 10, 13, 14, 16, 17, 18, 19, 20, 21, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 44, 46, 47, 51, 52, 53, 54, 55, 56, 58, 59, 60, 63, 68, 69, 70, 71, 72, 75, 77, 78, 81, 91, 92, 94, 95, 96, 97, 101, 104, 108, 110, 111, 113, 116, 118, 119, 122, 128, 129, 133, 134, 135, 137, 144, 145, 146, 147, 148, 149, 151, 154, 155, 157, 167, 168, 170, 171, 172, 173, 180, 182, 184, 186, 187, 188, 189, 193, 194, 195, 199, 206, 207, 215, 216, 217, 218, 219, 220, 221, 222, 224, 225, 226, 227, 230, 231, 235, 238, 239, 240, 241, 243, 246, 247, 248, 249, 250, 252, 253, 254, 256, 257, 258, 259, 261, 267, 269, 270, 271, 272, 273, 288, 291, 300, 301, 305, 306, 309, 318, 319, 320, 321, 324, 325, 326, 330, 331, 335, 336, 338, 339, 341, 342], "open": [0, 5, 7, 11, 331, 336, 341], "sourc": [0, 1, 4, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 160, 161, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 341, 342], "reinforc": [0, 3, 9, 111, 170, 171, 172, 173, 177, 221, 225, 239, 240, 244, 245, 247, 251, 252, 258, 259, 260, 323, 329, 331, 334, 337, 340, 341], "learn": [0, 3, 7, 8, 9, 18, 32, 54, 55, 56, 111, 170, 171, 172, 173, 177, 190, 196, 221, 225, 239, 240, 244, 245, 247, 251, 252, 257, 258, 259, 260, 323, 325, 326, 329, 330, 331, 333, 334, 335, 337, 339, 340, 341, 342], "rl": [0, 1, 2, 3, 5, 8, 10, 13, 14, 16, 17, 91, 144, 196, 214, 226, 234, 239, 254, 256, 296, 324, 325, 326, 327, 330, 331, 332, 336, 338, 339, 342], "librari": [0, 1, 2, 5, 6, 7, 8, 9, 10, 18, 19, 20, 37, 43, 85, 92, 160, 323, 324, 325, 328, 330, 331, 332, 336, 337, 342], "pytorch": [0, 1, 2, 3, 53, 147, 180, 184, 195, 196, 305, 324, 327, 330, 332, 333, 336, 337, 338, 341, 342], "It": [0, 2, 3, 4, 7, 32, 37, 40, 41, 43, 45, 52, 53, 55, 56, 77, 81, 83, 91, 92, 95, 96, 97, 101, 110, 120, 127, 129, 134, 144, 149, 154, 157, 170, 172, 178, 193, 194, 202, 204, 205, 211, 212, 221, 222, 225, 228, 230, 239, 240, 241, 246, 247, 248, 249, 250, 252, 253, 254, 256, 257, 258, 259, 260, 261, 267, 268, 269, 301, 314, 324, 325, 326, 330, 331, 333, 336, 337, 338, 339, 341, 342], "provid": [0, 1, 2, 3, 5, 8, 9, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 24, 30, 31, 32, 33, 35, 38, 41, 42, 45, 49, 52, 53, 54, 55, 56, 57, 58, 62, 66, 67, 69, 77, 81, 91, 95, 96, 97, 101, 110, 111, 112, 113, 114, 116, 119, 123, 128, 129, 131, 133, 134, 136, 137, 140, 141, 144, 145, 146, 149, 151, 153, 154, 155, 165, 167, 168, 174, 177, 180, 181, 182, 184, 185, 186, 187, 188, 189, 191, 192, 193, 194, 212, 214, 218, 221, 222, 223, 225, 226, 227, 228, 233, 239, 240, 242, 243, 245, 246, 247, 248, 252, 254, 256, 257, 258, 259, 261, 267, 268, 269, 270, 271, 272, 273, 274, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 288, 292, 296, 302, 309, 314, 317, 324, 325, 326, 327, 330, 331, 332, 333, 335, 336, 337, 338, 339, 341, 342], "python": [0, 3, 5, 6, 7, 10, 21, 107, 180, 181, 182, 184, 185, 186, 191, 192, 327, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 341, 342], "first": [0, 1, 3, 4, 5, 7, 8, 18, 20, 21, 26, 28, 52, 53, 55, 56, 58, 59, 66, 67, 71, 81, 111, 112, 123, 129, 133, 134, 147, 149, 151, 180, 182, 184, 186, 188, 193, 194, 195, 199, 214, 219, 220, 221, 226, 227, 229, 230, 241, 249, 253, 254, 256, 287, 304, 325, 330, 331, 332, 333, 335, 336, 337, 338, 339, 341, 342], "low": [0, 25, 77, 81, 95, 101, 114, 118, 161, 221, 226, 233, 330, 331, 332, 336, 337, 341, 342], "high": [0, 9, 25, 41, 77, 81, 95, 101, 114, 118, 128, 161, 221, 226, 233, 269, 274, 282, 330, 331, 332, 336, 337, 339, 341, 342], "level": [0, 3, 4, 22, 26, 28, 111, 143, 253, 330, 331, 341], "abstract": [0, 3, 8, 24, 25, 26, 27, 28, 29, 30, 44, 46, 47, 72, 77, 130, 189, 273, 297, 306, 327, 332, 337, 341], "ar": [0, 1, 2, 3, 7, 8, 9, 10, 13, 14, 16, 17, 18, 19, 20, 21, 23, 28, 29, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 45, 48, 52, 53, 54, 55, 56, 57, 58, 59, 60, 67, 68, 71, 77, 78, 81, 90, 91, 94, 95, 96, 97, 98, 101, 103, 110, 111, 114, 115, 116, 118, 119, 120, 122, 123, 127, 128, 131, 133, 137, 140, 145, 146, 147, 148, 149, 150, 151, 153, 154, 155, 161, 165, 166, 173, 175, 180, 181, 182, 184, 185, 186, 187, 189, 191, 192, 193, 196, 200, 202, 205, 219, 220, 222, 225, 226, 227, 229, 230, 231, 232, 233, 238, 239, 240, 241, 242, 243, 245, 246, 247, 248, 249, 250, 252, 253, 254, 256, 257, 258, 259, 261, 264, 267, 268, 269, 270, 271, 272, 273, 302, 317, 321, 325, 326, 327, 328, 330, 331, 332, 333, 335, 336, 337, 338, 339, 341, 342], "intend": [0, 7, 13, 14, 16, 17, 18, 19, 20, 21, 45, 110, 118, 212, 254, 325, 341], "effici": [0, 1, 2, 4, 8, 180, 196, 325, 330, 331, 332, 333, 335, 336, 338, 339, 341], "modular": [0, 232, 339, 341], "document": [0, 5, 7, 18, 19, 21, 32, 77, 81, 95, 101, 149, 331, 333, 341], "properli": [0, 77, 81, 95, 101, 332, 336, 337, 341], "test": [0, 3, 5, 151, 157, 182, 186, 187, 301, 317, 332, 333, 341], "The": [0, 1, 2, 3, 4, 5, 7, 8, 13, 14, 16, 17, 18, 19, 20, 21, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 52, 53, 54, 55, 56, 57, 66, 67, 68, 69, 77, 81, 85, 95, 96, 97, 101, 110, 111, 115, 116, 119, 120, 121, 129, 131, 133, 137, 139, 140, 141, 143, 144, 145, 148, 149, 151, 153, 154, 164, 165, 166, 170, 171, 172, 173, 174, 177, 180, 181, 182, 184, 185, 186, 187, 189, 190, 191, 192, 193, 196, 197, 203, 204, 205, 214, 215, 219, 220, 221, 225, 226, 227, 228, 229, 230, 232, 234, 235, 236, 239, 240, 241, 242, 243, 245, 246, 247, 248, 249, 250, 252, 253, 254, 256, 257, 258, 259, 261, 267, 268, 269, 270, 271, 272, 273, 275, 290, 293, 294, 295, 296, 300, 317, 319, 320, 325, 326, 327, 331, 332, 333, 336, 337, 338, 339, 341, 342], "code": [0, 3, 5, 7, 8, 77, 81, 95, 101, 133, 149, 151, 180, 181, 182, 184, 185, 186, 232, 329, 331, 332, 333, 334, 335, 336, 338, 339, 340, 341, 342], "aim": [0, 3, 7, 28, 29, 133, 151, 153, 188, 308, 324, 325, 326, 330, 331, 341], "support": [0, 1, 3, 18, 20, 26, 54, 56, 57, 58, 59, 68, 71, 92, 94, 96, 111, 120, 129, 145, 146, 148, 160, 177, 212, 220, 221, 226, 229, 232, 247, 269, 270, 271, 272, 293, 325, 327, 332, 333, 336, 337, 339, 341], "research": [0, 7, 9, 341], "most": [0, 3, 7, 8, 32, 66, 67, 118, 154, 330, 332, 337, 341, 342], "written": [0, 3, 34, 36, 39, 45, 52, 58, 66, 67, 77, 81, 95, 101, 111, 120, 127, 140, 143, 146, 154, 164, 165, 214, 225, 226, 229, 230, 234, 239, 241, 253, 256, 258, 268, 287, 288, 325, 326, 327, 330, 333, 335, 337, 341], "highli": [0, 2, 341, 342], "wai": [0, 2, 3, 4, 53, 85, 133, 135, 153, 154, 184, 256, 269, 270, 271, 272, 325, 330, 331, 332, 335, 336, 337, 338, 339, 341, 342], "can": [0, 1, 2, 3, 5, 6, 7, 8, 10, 11, 13, 14, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 44, 45, 46, 47, 52, 53, 55, 56, 61, 65, 66, 67, 77, 78, 81, 85, 90, 95, 96, 97, 99, 100, 101, 103, 107, 108, 110, 111, 114, 115, 116, 118, 119, 120, 128, 129, 133, 134, 137, 140, 143, 144, 145, 148, 149, 151, 153, 155, 165, 166, 180, 182, 183, 184, 186, 189, 190, 193, 194, 196, 197, 210, 212, 214, 218, 220, 221, 222, 223, 226, 227, 228, 229, 230, 231, 232, 233, 238, 239, 240, 241, 242, 243, 245, 246, 247, 248, 249, 250, 252, 253, 254, 256, 257, 258, 259, 261, 267, 268, 269, 270, 271, 272, 273, 301, 314, 319, 320, 321, 324, 325, 326, 327, 330, 331, 332, 333, 335, 336, 337, 338, 339, 341, 342], "easili": [0, 3, 7, 77, 81, 95, 101, 314, 326, 330, 331, 332, 336, 341, 342], "swap": [0, 3, 154, 332, 338, 341], "compon": [0, 2, 3, 35, 38, 41, 42, 52, 53, 54, 55, 56, 58, 59, 60, 68, 71, 177, 203, 220, 221, 228, 239, 240, 241, 246, 247, 248, 249, 250, 252, 253, 254, 256, 257, 258, 259, 261, 267, 300, 305, 330, 331, 332, 333, 335, 336, 337, 338, 341], "transform": [0, 1, 2, 4, 8, 13, 14, 16, 18, 19, 20, 21, 32, 35, 37, 38, 40, 41, 42, 43, 52, 53, 54, 55, 56, 77, 78, 81, 95, 96, 97, 101, 103, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 149, 150, 151, 152, 153, 154, 155, 156, 169, 170, 174, 177, 178, 201, 202, 203, 211, 219, 224, 233, 236, 238, 244, 255, 288, 302, 314, 321, 323, 329, 331, 333, 334, 338, 340], "them": [0, 2, 3, 7, 9, 21, 32, 35, 37, 38, 41, 42, 52, 53, 54, 55, 56, 77, 78, 81, 85, 90, 95, 96, 97, 101, 103, 116, 119, 149, 167, 168, 169, 170, 171, 172, 173, 174, 176, 178, 179, 180, 181, 182, 184, 185, 186, 187, 188, 193, 194, 197, 198, 199, 201, 204, 205, 207, 211, 212, 218, 219, 221, 222, 223, 225, 228, 233, 236, 253, 259, 288, 330, 331, 333, 335, 336, 337, 338, 339, 341, 342], "write": [0, 3, 8, 23, 32, 34, 36, 37, 39, 45, 81, 114, 131, 132, 140, 143, 147, 165, 214, 229, 230, 232, 234, 242, 243, 245, 246, 252, 257, 259, 261, 268, 273, 288, 325, 327, 329, 330, 331, 332, 333, 334, 335, 336, 338, 339, 340, 341, 342], "new": [0, 2, 3, 4, 8, 13, 14, 16, 17, 21, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 39, 41, 44, 46, 47, 61, 65, 77, 81, 92, 95, 99, 100, 101, 140, 148, 155, 164, 165, 180, 182, 186, 225, 229, 230, 235, 239, 240, 241, 243, 246, 247, 248, 249, 250, 252, 253, 254, 256, 257, 258, 259, 261, 267, 330, 332, 333, 336, 337, 341, 342], "ones": [0, 2, 15, 26, 32, 35, 41, 42, 77, 81, 95, 101, 112, 115, 116, 117, 119, 129, 133, 137, 145, 148, 149, 151, 153, 191, 192, 212, 229, 239, 240, 242, 252, 256, 257, 259, 261, 275, 330, 332, 336, 337, 339, 341, 342], "littl": [0, 3, 43, 332, 333, 339, 341, 342], "effort": [0, 3, 337, 339, 341], "thi": [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 52, 53, 54, 55, 56, 58, 59, 60, 65, 66, 67, 68, 69, 71, 77, 81, 83, 90, 91, 95, 96, 97, 101, 103, 107, 108, 110, 111, 112, 114, 115, 116, 117, 118, 119, 120, 121, 122, 124, 126, 127, 129, 133, 134, 135, 137, 140, 141, 143, 145, 146, 148, 149, 151, 152, 153, 154, 155, 157, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 193, 194, 195, 196, 197, 198, 199, 200, 201, 203, 204, 205, 207, 210, 212, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 232, 233, 235, 236, 239, 240, 241, 242, 243, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 256, 257, 258, 259, 260, 261, 267, 269, 270, 271, 272, 273, 287, 296, 298, 301, 302, 305, 307, 308, 309, 314, 317, 321, 324, 325, 326, 327, 330, 331, 332, 333, 335, 336, 337, 338, 339, 341, 342], "repo": [0, 6, 52, 111, 146, 151, 324, 336, 341], "attempt": [0, 66, 67, 218, 223, 225, 243, 252, 267, 341], "align": [0, 180, 184, 341], "exist": [0, 3, 4, 11, 18, 21, 32, 34, 36, 39, 45, 77, 81, 95, 101, 112, 117, 149, 259, 309, 321, 336, 341, 342], "ecosystem": [0, 341], "ha": [0, 2, 3, 4, 5, 7, 8, 10, 16, 17, 18, 20, 21, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 37, 40, 44, 46, 47, 66, 77, 78, 81, 85, 95, 101, 103, 111, 143, 144, 145, 146, 149, 180, 182, 184, 186, 193, 218, 221, 223, 225, 230, 253, 330, 331, 332, 333, 335, 336, 337, 338, 339, 341, 342], "dataset": [0, 34, 35, 36, 37, 38, 39, 40, 41, 42, 45, 52, 53, 54, 55, 56, 57, 66, 67, 94, 155, 323, 330, 331, 338, 339, 341, 342], "pillar": [0, 341], "environ": [0, 1, 2, 5, 8, 11, 13, 14, 16, 17, 18, 19, 20, 21, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 44, 46, 47, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 106, 108, 110, 111, 112, 116, 117, 118, 119, 124, 128, 129, 133, 134, 140, 143, 144, 145, 146, 148, 149, 151, 154, 155, 157, 166, 182, 186, 187, 189, 190, 218, 225, 245, 248, 269, 270, 271, 272, 273, 274, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 288, 296, 298, 301, 308, 309, 310, 311, 314, 317, 318, 319, 320, 321, 323, 324, 325, 329, 334, 338, 339, 340], "model": [0, 1, 3, 8, 9, 13, 14, 16, 17, 18, 19, 20, 21, 32, 40, 45, 77, 81, 91, 95, 101, 116, 133, 145, 151, 153, 156, 167, 168, 169, 174, 182, 186, 188, 189, 190, 194, 201, 202, 211, 215, 216, 217, 224, 229, 235, 239, 240, 241, 243, 244, 245, 248, 249, 250, 252, 253, 254, 256, 257, 259, 267, 305, 310, 311, 312, 313, 314, 323, 324, 327, 329, 332, 334, 336, 337, 339, 340, 342], "data": [0, 3, 8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 77, 79, 81, 91, 94, 95, 96, 97, 101, 108, 110, 111, 116, 117, 119, 121, 127, 129, 137, 143, 154, 157, 161, 165, 166, 177, 182, 186, 187, 190, 193, 194, 203, 212, 214, 220, 222, 223, 225, 226, 227, 229, 232, 233, 234, 239, 240, 242, 243, 245, 246, 252, 256, 257, 258, 259, 261, 267, 269, 270, 271, 272, 273, 296, 302, 305, 307, 310, 317, 319, 320, 321, 323, 325, 326, 327, 333, 337, 338, 339, 342], "util": [0, 3, 17, 23, 32, 40, 77, 81, 95, 96, 97, 101, 104, 133, 153, 157, 158, 159, 160, 161, 162, 163, 164, 165, 167, 168, 174, 180, 184, 236, 237, 238, 254, 317, 323, 328, 330, 332, 336, 337, 341, 342], "e": [0, 1, 3, 7, 8, 10, 11, 13, 14, 16, 17, 18, 19, 20, 21, 26, 28, 32, 33, 58, 59, 71, 77, 78, 81, 95, 101, 110, 112, 115, 123, 129, 133, 140, 145, 148, 149, 151, 153, 157, 180, 182, 183, 184, 186, 190, 194, 197, 203, 209, 210, 219, 221, 226, 228, 229, 230, 259, 268, 269, 270, 271, 272, 296, 308, 320, 325, 330, 331, 332, 336, 338, 341, 342], "g": [0, 1, 3, 7, 8, 10, 11, 32, 33, 77, 78, 81, 95, 101, 110, 112, 115, 123, 129, 133, 140, 145, 148, 149, 151, 153, 157, 180, 182, 183, 184, 185, 186, 190, 194, 209, 210, 219, 226, 229, 230, 259, 268, 278, 279, 280, 281, 283, 284, 285, 286, 320, 325, 330, 331, 332, 336, 337, 338, 341, 342], "collector": [0, 3, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 40, 66, 67, 111, 137, 143, 225, 302, 305, 307, 310, 311, 317, 319, 320, 323, 327, 339, 342], "contain": [0, 3, 7, 12, 13, 14, 16, 17, 19, 20, 26, 28, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 50, 52, 53, 54, 55, 56, 61, 63, 68, 70, 72, 77, 81, 91, 95, 101, 115, 116, 119, 133, 145, 148, 149, 151, 153, 154, 155, 164, 165, 166, 167, 168, 180, 181, 184, 185, 188, 190, 194, 214, 220, 221, 226, 228, 229, 234, 239, 240, 241, 242, 243, 245, 246, 247, 248, 249, 250, 252, 253, 254, 256, 257, 258, 259, 261, 267, 268, 269, 270, 271, 272, 273, 275, 292, 296, 308, 314, 317, 318, 319, 320, 321, 325, 326, 327, 330, 331, 332, 333, 336, 337, 338, 339, 341, 342], "etc": [0, 3, 7, 8, 11, 32, 46, 47, 77, 81, 95, 101, 127, 149, 188, 194, 330, 331, 332, 339, 341, 342], "have": [0, 1, 2, 3, 5, 6, 7, 8, 9, 13, 14, 17, 18, 20, 21, 26, 30, 32, 34, 35, 36, 38, 39, 40, 41, 42, 45, 52, 53, 54, 55, 56, 65, 68, 77, 81, 95, 96, 97, 101, 111, 116, 119, 120, 127, 128, 129, 143, 148, 149, 155, 157, 165, 167, 168, 187, 188, 193, 194, 212, 231, 232, 239, 241, 253, 256, 264, 267, 269, 270, 271, 272, 273, 274, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 296, 305, 325, 326, 327, 330, 331, 332, 333, 335, 336, 337, 338, 339, 341, 342], "few": [0, 2, 8, 296, 332, 333, 336, 339, 341, 342], "depend": [0, 1, 2, 3, 4, 7, 8, 34, 36, 116, 119, 234, 256, 325, 330, 332, 333, 336, 337, 341, 342], "possibl": [0, 2, 3, 4, 27, 29, 32, 33, 34, 36, 39, 56, 77, 81, 95, 101, 115, 133, 145, 148, 149, 151, 153, 167, 168, 180, 181, 184, 185, 229, 301, 305, 325, 330, 332, 333, 336, 337, 339, 341, 342], "standard": [0, 3, 129, 139, 155, 166, 178, 190, 195, 196, 218, 219, 261, 269, 270, 271, 272, 330, 331, 336, 339, 341], "numpi": [0, 11, 24, 25, 26, 27, 28, 29, 30, 31, 33, 44, 46, 47, 95, 101, 147, 305, 337, 339, 341, 342], "common": [0, 2, 3, 4, 21, 81, 108, 215, 216, 217, 224, 239, 240, 241, 246, 252, 253, 256, 257, 258, 259, 261, 317, 324, 325, 327, 330, 332, 335, 336, 337, 338, 341, 342], "openai": [0, 7, 80, 82, 98, 332, 337, 341, 342], "gym": [0, 1, 3, 4, 8, 11, 13, 14, 16, 17, 21, 22, 77, 78, 80, 81, 82, 85, 95, 98, 101, 105, 107, 111, 114, 120, 126, 127, 129, 131, 135, 137, 140, 145, 148, 154, 155, 314, 317, 324, 330, 331, 332, 333, 337, 338, 339, 341], "onli": [0, 1, 3, 4, 7, 13, 14, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 35, 38, 41, 44, 46, 47, 52, 58, 59, 66, 67, 71, 77, 81, 85, 92, 95, 96, 97, 101, 111, 112, 114, 115, 116, 118, 119, 123, 129, 133, 134, 137, 143, 144, 145, 146, 148, 149, 151, 153, 155, 184, 186, 187, 193, 194, 214, 219, 220, 226, 227, 229, 230, 231, 232, 239, 241, 242, 246, 252, 253, 254, 256, 257, 258, 259, 260, 261, 269, 270, 271, 272, 273, 309, 327, 330, 331, 332, 333, 335, 336, 337, 339, 341, 342], "option": [0, 1, 3, 4, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 65, 66, 67, 71, 75, 77, 78, 81, 91, 94, 95, 96, 97, 98, 101, 103, 108, 110, 111, 112, 113, 114, 116, 118, 119, 120, 123, 124, 126, 127, 128, 129, 133, 134, 135, 136, 137, 139, 140, 141, 143, 144, 145, 146, 147, 148, 149, 150, 151, 153, 154, 155, 157, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 177, 178, 179, 181, 182, 183, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 203, 204, 205, 208, 209, 210, 212, 214, 218, 219, 220, 221, 222, 223, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 239, 240, 241, 242, 243, 245, 246, 247, 248, 249, 250, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 267, 268, 269, 270, 271, 272, 273, 275, 278, 279, 280, 281, 283, 284, 285, 286, 287, 288, 290, 293, 296, 298, 299, 300, 301, 302, 303, 305, 309, 310, 311, 312, 313, 314, 316, 317, 319, 320, 321, 325, 333, 336, 337, 339, 341], "On": [0, 3, 7, 18, 19, 20, 21, 181, 185, 325, 331, 336], "end": [0, 3, 13, 14, 32, 35, 38, 41, 42, 52, 53, 54, 55, 56, 65, 66, 67, 77, 81, 95, 101, 120, 131, 143, 144, 149, 167, 168, 180, 181, 184, 185, 189, 259, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 330, 331, 332, 333, 335, 336, 337, 338, 339, 341, 342], "come": [0, 1, 3, 8, 81, 90, 95, 101, 116, 119, 214, 215, 216, 217, 226, 234, 330, 331, 332, 333, 336, 339, 341, 342], "set": [0, 1, 2, 3, 7, 9, 11, 13, 14, 16, 17, 18, 19, 20, 21, 28, 29, 32, 33, 34, 35, 36, 38, 39, 41, 42, 52, 53, 54, 55, 56, 58, 59, 65, 68, 71, 77, 79, 81, 91, 95, 96, 97, 101, 107, 108, 111, 112, 115, 116, 119, 126, 127, 133, 137, 143, 144, 145, 146, 148, 149, 151, 153, 155, 157, 162, 163, 165, 180, 182, 184, 186, 189, 193, 194, 218, 219, 229, 254, 256, 259, 273, 296, 301, 302, 311, 321, 324, 325, 326, 328, 330, 331, 332, 333, 335, 336, 337, 338, 339, 341, 342], "re": [0, 3, 8, 32, 65, 77, 81, 95, 101, 186, 191, 192, 226, 230, 327, 330, 332, 333, 335, 337, 341, 342], "usabl": [0, 327, 333, 341], "function": [0, 3, 8, 11, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 39, 40, 43, 44, 45, 46, 47, 49, 58, 59, 60, 68, 71, 77, 78, 81, 95, 101, 107, 116, 119, 149, 155, 157, 165, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 178, 179, 180, 181, 182, 184, 185, 186, 187, 188, 191, 192, 193, 194, 197, 198, 199, 200, 201, 204, 205, 207, 210, 212, 215, 216, 217, 218, 219, 221, 222, 223, 225, 226, 228, 229, 230, 232, 233, 234, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 252, 253, 254, 256, 257, 258, 259, 261, 262, 263, 264, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 314, 317, 323, 325, 330, 333, 335, 337, 339, 342], "cost": [0, 2, 27, 330, 331, 336, 337, 339], "return": [0, 2, 3, 7, 8, 11, 13, 14, 16, 17, 18, 19, 20, 21, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 52, 53, 54, 55, 56, 57, 63, 66, 67, 69, 70, 72, 75, 77, 78, 81, 91, 94, 95, 96, 97, 101, 105, 107, 108, 109, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 123, 125, 126, 127, 129, 131, 133, 134, 135, 136, 138, 139, 140, 141, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 158, 159, 160, 164, 165, 166, 169, 170, 171, 172, 173, 175, 177, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 194, 197, 200, 201, 202, 204, 205, 208, 209, 210, 211, 214, 215, 216, 217, 219, 226, 228, 229, 230, 234, 235, 236, 238, 239, 240, 241, 242, 243, 245, 246, 247, 248, 249, 250, 252, 253, 254, 256, 257, 258, 259, 261, 264, 267, 268, 269, 270, 271, 272, 273, 275, 276, 277, 278, 279, 280, 281, 283, 284, 285, 286, 292, 305, 308, 310, 314, 317, 318, 319, 320, 321, 323, 325, 327, 330, 331, 332, 333, 335, 336, 337, 338, 339, 341, 342], "process": [0, 1, 3, 4, 5, 8, 13, 14, 16, 17, 18, 19, 20, 21, 32, 34, 35, 36, 39, 43, 45, 55, 56, 77, 78, 81, 85, 90, 92, 95, 96, 97, 101, 110, 116, 119, 147, 155, 193, 194, 221, 225, 228, 323, 327, 330, 331, 333, 336, 337, 338, 339, 341, 342], "good": [0, 1, 4, 9, 330, 332, 333, 336, 341, 342], "runtim": [0, 3, 32, 77, 81, 95, 101, 337], "perform": [0, 3, 4, 8, 13, 14, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 40, 44, 45, 46, 47, 77, 81, 95, 101, 104, 116, 119, 128, 149, 166, 167, 168, 169, 170, 171, 172, 173, 174, 176, 178, 179, 180, 181, 182, 184, 185, 186, 187, 188, 189, 190, 193, 194, 197, 198, 199, 201, 204, 205, 207, 212, 218, 219, 221, 222, 223, 225, 228, 233, 236, 249, 256, 259, 301, 305, 326, 330, 331, 332, 333, 335, 336, 337, 342], "To": [0, 3, 4, 6, 7, 8, 9, 18, 19, 20, 32, 35, 38, 40, 41, 42, 52, 53, 54, 55, 56, 66, 67, 77, 81, 90, 95, 96, 97, 99, 100, 101, 143, 155, 215, 216, 217, 225, 246, 254, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 325, 326, 330, 331, 332, 333, 336, 337, 338, 339, 341, 342], "read": [0, 2, 3, 7, 17, 23, 37, 40, 58, 59, 60, 68, 71, 77, 81, 95, 101, 108, 110, 111, 112, 114, 115, 116, 117, 118, 120, 121, 122, 123, 124, 126, 127, 131, 132, 134, 135, 137, 140, 141, 143, 144, 145, 146, 148, 151, 152, 154, 155, 165, 200, 214, 215, 216, 217, 220, 226, 229, 230, 232, 234, 235, 239, 240, 241, 246, 247, 248, 249, 250, 252, 253, 254, 256, 257, 258, 259, 261, 267, 269, 270, 271, 272, 273, 288, 301, 305, 314, 325, 330, 331, 332, 335, 336, 337, 338, 342], "more": [0, 2, 3, 4, 6, 8, 9, 11, 13, 14, 16, 17, 18, 19, 20, 21, 32, 35, 38, 41, 42, 43, 52, 53, 54, 55, 56, 77, 81, 84, 85, 95, 96, 97, 101, 103, 147, 151, 156, 177, 184, 188, 195, 197, 214, 218, 220, 221, 229, 234, 239, 247, 254, 256, 269, 274, 282, 300, 324, 326, 327, 330, 331, 332, 333, 335, 336, 337, 338, 342], "about": [0, 2, 3, 5, 7, 9, 18, 19, 20, 43, 55, 56, 326, 330, 331, 332, 336, 337, 341, 342], "philosophi": [0, 9], "capabl": [0, 1, 7, 9, 327, 330, 335, 338, 342], "beyond": 0, "api": [0, 2, 3, 5, 96, 97, 98, 133, 153, 326, 327, 336, 337, 341, 342], "check": [0, 2, 3, 4, 5, 6, 7, 9, 11, 18, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 44, 46, 47, 48, 50, 66, 77, 78, 81, 91, 95, 101, 104, 111, 112, 122, 127, 134, 147, 157, 182, 186, 214, 220, 221, 226, 227, 228, 229, 230, 325, 326, 331, 332, 333, 335, 336, 337, 338, 339, 342], "paper": [0, 133, 151, 153, 180, 202, 211, 245, 251, 314, 330, 332, 336], "ppo": [0, 4, 8, 226, 230, 241, 253, 256, 323, 325, 329, 330, 331, 334, 340], "pendulum": [0, 3, 13, 14, 16, 17, 21, 22, 77, 78, 80, 81, 82, 92, 95, 101, 111, 114, 115, 121, 126, 127, 129, 135, 137, 143, 145, 146, 148, 149, 155, 182, 186, 317, 325, 329, 331, 332, 334, 340, 341, 342], "your": [0, 2, 3, 7, 8, 10, 18, 32, 77, 81, 85, 90, 95, 96, 97, 101, 155, 321, 324, 325, 326, 329, 331, 332, 333, 334, 336, 339, 340, 341], "introduct": [0, 326, 329, 334, 336, 340, 342], "multi": [0, 7, 9, 28, 29, 32, 77, 81, 95, 99, 100, 101, 180, 182, 184, 186, 187, 188, 193, 194, 267, 269, 270, 271, 272, 323, 329, 330, 331, 332, 333, 334, 337, 340, 341], "agent": [0, 9, 28, 29, 90, 96, 97, 99, 100, 102, 103, 104, 143, 144, 191, 192, 193, 194, 196, 202, 211, 267, 323, 329, 334, 337, 340], "env": [0, 1, 2, 5, 6, 7, 8, 13, 14, 16, 17, 18, 19, 20, 21, 22, 32, 40, 52, 53, 55, 56, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 182, 186, 189, 190, 229, 254, 287, 309, 310, 311, 314, 317, 319, 320, 321, 323, 325, 329, 330, 331, 332, 333, 334, 335, 336, 338, 339, 340], "us": [0, 1, 2, 3, 5, 7, 8, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 52, 53, 54, 55, 56, 57, 61, 62, 66, 67, 71, 75, 77, 78, 81, 91, 94, 95, 96, 97, 98, 99, 100, 101, 107, 108, 110, 111, 112, 113, 115, 116, 117, 118, 119, 120, 121, 126, 127, 129, 133, 134, 135, 137, 140, 141, 143, 144, 145, 146, 147, 148, 149, 151, 153, 155, 157, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 174, 177, 178, 180, 181, 182, 183, 184, 185, 186, 188, 189, 190, 192, 193, 194, 196, 197, 200, 201, 202, 203, 209, 210, 211, 212, 214, 219, 220, 221, 222, 224, 225, 226, 227, 228, 229, 230, 233, 234, 235, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 252, 253, 254, 256, 257, 258, 259, 261, 264, 267, 268, 269, 270, 271, 272, 273, 274, 275, 277, 282, 291, 292, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 309, 310, 311, 315, 317, 321, 324, 325, 326, 327, 328, 329, 330, 331, 332, 334, 335, 336, 337, 340, 342], "pretrain": [0, 329, 334, 340], "recurr": [0, 110, 180, 181, 182, 184, 186, 205, 329, 331, 334, 339, 340], "dqn": [0, 120, 177, 220, 221, 239, 240, 242, 243, 245, 246, 247, 248, 251, 252, 254, 256, 257, 258, 259, 260, 261, 267, 312, 323, 325, 329, 334, 340], "train": [0, 1, 3, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 32, 34, 36, 39, 40, 45, 57, 77, 81, 95, 96, 97, 101, 116, 124, 133, 144, 149, 151, 153, 157, 170, 172, 182, 186, 218, 222, 223, 225, 239, 240, 241, 242, 246, 247, 248, 249, 250, 252, 253, 254, 256, 257, 258, 259, 261, 267, 269, 305, 307, 317, 323, 327, 329, 331, 334, 338, 339, 340, 342], "polici": [0, 1, 2, 3, 8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 77, 81, 91, 95, 101, 118, 127, 144, 162, 163, 177, 182, 186, 193, 194, 196, 203, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 225, 226, 227, 228, 229, 230, 233, 239, 240, 241, 242, 246, 252, 253, 255, 256, 257, 258, 259, 261, 301, 307, 310, 311, 317, 319, 320, 325, 326, 327, 329, 331, 334, 338, 339, 340, 341, 342], "replai": [0, 8, 13, 14, 16, 35, 38, 41, 42, 52, 53, 54, 55, 56, 61, 62, 63, 64, 67, 68, 69, 70, 110, 111, 118, 134, 137, 145, 242, 243, 245, 246, 252, 257, 259, 261, 302, 305, 315, 317, 323, 327, 329, 334, 337, 338, 340], "buffer": [0, 1, 3, 4, 8, 13, 14, 16, 32, 34, 35, 36, 38, 39, 41, 42, 52, 53, 54, 55, 56, 58, 59, 60, 61, 62, 63, 64, 67, 68, 69, 70, 71, 77, 81, 91, 95, 101, 110, 111, 115, 118, 133, 134, 137, 145, 148, 149, 151, 153, 229, 232, 242, 243, 245, 246, 252, 257, 259, 261, 302, 305, 315, 317, 323, 327, 329, 334, 337, 338, 340, 342], "task": [0, 3, 9, 28, 29, 40, 45, 75, 81, 84, 95, 96, 97, 98, 101, 133, 143, 151, 153, 252, 329, 330, 331, 332, 333, 334, 336, 337, 340, 341, 342], "specif": [0, 2, 5, 8, 41, 42, 81, 174, 219, 305, 323, 326, 327, 329, 332, 333, 334, 336, 339, 340], "object": [0, 3, 4, 6, 13, 14, 15, 16, 17, 18, 19, 20, 21, 26, 32, 34, 36, 39, 45, 58, 59, 60, 68, 71, 77, 81, 95, 101, 116, 119, 120, 129, 133, 148, 149, 151, 155, 190, 202, 211, 214, 215, 226, 229, 230, 231, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 288, 309, 310, 311, 316, 317, 321, 323, 325, 327, 329, 331, 332, 333, 334, 336, 337, 339, 340, 342], "ddpg": [0, 170, 171, 172, 173, 242, 251, 260, 323, 325, 329, 331, 334, 340], "loss": [0, 3, 8, 36, 120, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 264, 267, 268, 269, 300, 305, 312, 313, 314, 317, 326, 327, 329, 334, 337, 339, 340, 341], "trainer": [0, 239, 240, 241, 246, 247, 248, 249, 250, 252, 253, 254, 256, 257, 258, 259, 261, 267, 296, 297, 298, 299, 300, 301, 302, 303, 304, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 323, 329, 330, 334, 340], "A": [0, 1, 2, 3, 8, 9, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 45, 52, 53, 54, 55, 56, 58, 59, 60, 62, 63, 64, 65, 68, 69, 70, 71, 72, 77, 79, 81, 83, 84, 95, 98, 101, 110, 114, 118, 124, 127, 133, 134, 135, 145, 148, 149, 151, 152, 154, 155, 156, 157, 164, 166, 167, 168, 177, 180, 181, 182, 184, 185, 186, 188, 190, 191, 192, 194, 196, 197, 212, 218, 219, 220, 221, 222, 223, 226, 227, 230, 232, 233, 236, 239, 240, 241, 242, 243, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 256, 257, 258, 259, 260, 261, 264, 267, 269, 270, 271, 272, 273, 275, 289, 290, 293, 298, 305, 307, 314, 317, 326, 329, 330, 332, 334, 336, 337, 340, 342], "exampl": [0, 1, 2, 3, 4, 9, 10, 11, 13, 14, 15, 16, 17, 18, 21, 22, 24, 26, 27, 28, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 52, 53, 54, 55, 56, 57, 58, 59, 66, 67, 69, 71, 73, 74, 75, 76, 77, 78, 80, 81, 82, 84, 86, 87, 88, 89, 91, 94, 95, 96, 97, 99, 100, 101, 102, 103, 104, 105, 107, 108, 110, 111, 112, 114, 115, 116, 117, 118, 119, 120, 121, 126, 127, 129, 131, 133, 135, 136, 137, 140, 143, 144, 145, 146, 147, 148, 149, 151, 153, 155, 161, 164, 165, 166, 167, 168, 169, 174, 177, 180, 181, 182, 184, 185, 186, 187, 188, 190, 193, 194, 197, 200, 201, 202, 203, 211, 212, 214, 215, 216, 217, 219, 220, 221, 222, 223, 225, 226, 227, 228, 229, 232, 233, 234, 239, 240, 242, 243, 245, 246, 247, 248, 252, 254, 256, 257, 258, 259, 261, 262, 263, 267, 269, 270, 271, 272, 275, 296, 297, 298, 299, 300, 302, 303, 304, 307, 314, 317, 325, 326, 327, 329, 330, 332, 333, 334, 335, 336, 337, 338, 340, 341, 342], "packag": [0, 6, 7, 10, 107, 323, 324, 342], "singl": [0, 3, 13, 14, 17, 18, 19, 20, 21, 32, 35, 38, 41, 42, 43, 52, 53, 54, 55, 56, 69, 77, 81, 95, 101, 111, 112, 133, 137, 153, 167, 168, 180, 181, 182, 184, 185, 186, 187, 188, 194, 228, 232, 241, 243, 245, 246, 247, 253, 256, 257, 261, 269, 270, 271, 272, 278, 279, 280, 281, 283, 284, 285, 286, 314, 321, 323, 330, 331, 332, 333, 335, 336, 337, 338, 339], "node": [0, 2, 18, 19, 20, 21, 22, 56, 314, 323], "distribut": [0, 2, 3, 4, 9, 10, 18, 19, 20, 21, 22, 96, 97, 127, 129, 166, 175, 176, 177, 178, 183, 190, 191, 192, 197, 200, 201, 204, 205, 208, 209, 210, 218, 219, 220, 221, 226, 230, 231, 239, 240, 241, 246, 247, 252, 253, 256, 257, 258, 259, 261, 323, 327, 331, 332, 336, 337, 341, 342], "helper": [0, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 323, 330, 331, 333, 337], "compos": [0, 3, 32, 35, 38, 41, 42, 52, 53, 54, 55, 56, 62, 63, 64, 69, 70, 77, 81, 95, 101, 111, 136, 148, 149, 155, 224, 249, 259, 314, 323, 330, 331, 332, 333, 335, 336, 339, 341, 342], "tensorspec": [0, 3, 15, 24, 25, 26, 27, 28, 29, 30, 31, 33, 46, 47, 48, 49, 50, 77, 81, 91, 95, 101, 103, 109, 111, 112, 113, 114, 115, 116, 117, 118, 120, 121, 123, 125, 126, 127, 129, 131, 135, 136, 138, 139, 140, 141, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 154, 165, 205, 214, 218, 219, 220, 221, 222, 223, 225, 226, 227, 228, 229, 230, 231, 233, 240, 243, 246, 257, 259, 261, 267, 323, 337], "from": [0, 1, 3, 4, 5, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 52, 53, 54, 55, 56, 57, 58, 59, 60, 65, 66, 67, 68, 69, 71, 77, 78, 81, 90, 91, 95, 96, 97, 99, 100, 101, 103, 104, 107, 108, 110, 111, 112, 114, 116, 117, 118, 119, 120, 121, 126, 127, 129, 131, 133, 134, 135, 136, 137, 140, 141, 143, 144, 145, 146, 147, 148, 149, 150, 151, 153, 154, 155, 161, 164, 165, 166, 170, 171, 172, 173, 174, 177, 180, 181, 182, 183, 184, 185, 186, 188, 189, 190, 192, 193, 194, 195, 197, 200, 201, 202, 203, 209, 210, 211, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 239, 240, 241, 242, 243, 245, 246, 247, 248, 252, 253, 254, 256, 257, 258, 259, 261, 263, 267, 268, 269, 270, 271, 272, 275, 287, 288, 296, 302, 305, 308, 309, 314, 315, 317, 318, 321, 323, 324, 325, 326, 327, 329, 330, 331, 332, 333, 335, 336, 337, 338, 339, 340, 341, 342], "human": [0, 53, 323, 337], "feedback": [0, 323, 341], "rlhf": [0, 40, 45, 57, 127, 323, 325], "envbas": [0, 3, 13, 14, 16, 17, 18, 19, 20, 21, 78, 81, 95, 101, 108, 116, 119, 128, 135, 148, 149, 155, 157, 166, 189, 190, 301, 309, 310, 311, 314, 317, 319, 320, 321, 323], "gymlikeenv": [0, 323], "envmetadata": [0, 323], "vector": [0, 1, 8, 24, 27, 33, 90, 96, 97, 103, 118, 154, 170, 172, 180, 181, 184, 185, 188, 269, 272, 282, 283, 284, 285, 286, 323, 330, 331, 333, 335, 336, 337, 338, 342], "mask": [0, 1, 4, 23, 27, 30, 31, 33, 96, 97, 108, 134, 177, 191, 192, 203, 219, 220, 221, 222, 223, 227, 228, 302, 323, 331, 333, 342], "action": [0, 2, 8, 9, 13, 14, 15, 16, 17, 21, 27, 33, 40, 44, 53, 55, 56, 74, 77, 81, 87, 90, 91, 95, 96, 97, 99, 100, 101, 102, 103, 108, 114, 116, 118, 119, 120, 121, 124, 127, 128, 131, 135, 137, 141, 143, 149, 154, 161, 164, 166, 169, 170, 171, 172, 173, 174, 176, 177, 178, 182, 186, 188, 189, 190, 191, 192, 193, 201, 202, 203, 205, 208, 209, 211, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 225, 226, 227, 228, 230, 233, 234, 239, 240, 242, 243, 245, 246, 252, 254, 256, 257, 258, 259, 261, 267, 269, 270, 271, 272, 273, 274, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 314, 317, 321, 323, 325, 326, 327, 330, 331, 332, 335, 336, 338, 339, 341, 342], "record": [0, 32, 77, 81, 95, 101, 127, 256, 287, 288, 289, 290, 291, 292, 293, 294, 295, 317, 323, 331, 332], "domain": [0, 2, 8, 24, 25, 26, 27, 28, 29, 30, 31, 33, 44, 46, 47, 77, 81, 95, 101, 118, 145, 161, 214, 220, 221, 226, 227, 228, 229, 230, 231, 232, 323, 332, 333, 336, 337, 341, 342], "modul": [0, 2, 3, 4, 8, 11, 32, 40, 69, 77, 81, 90, 91, 95, 101, 107, 110, 115, 118, 120, 127, 133, 134, 144, 145, 148, 149, 151, 153, 155, 156, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 245, 246, 247, 251, 252, 253, 254, 256, 257, 258, 259, 260, 261, 262, 265, 267, 269, 270, 271, 272, 273, 305, 312, 313, 317, 323, 326, 327, 331, 332, 335, 336, 337, 338, 339], "tensordict": [0, 1, 2, 3, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 52, 53, 54, 55, 56, 58, 59, 61, 66, 67, 69, 70, 71, 74, 77, 78, 79, 81, 87, 90, 91, 94, 95, 96, 97, 99, 100, 101, 102, 103, 108, 110, 111, 112, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 126, 127, 129, 131, 132, 133, 134, 135, 137, 140, 141, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 161, 164, 165, 166, 176, 177, 182, 186, 187, 189, 190, 202, 203, 211, 212, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 252, 253, 254, 255, 256, 257, 258, 259, 261, 267, 268, 269, 270, 271, 272, 273, 287, 296, 300, 301, 302, 304, 305, 314, 323, 326, 327, 330, 331, 332, 333, 335, 336, 337, 338, 342], "actor": [0, 3, 4, 15, 21, 127, 166, 169, 170, 172, 177, 178, 190, 201, 203, 215, 216, 217, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 252, 253, 254, 255, 256, 257, 258, 259, 261, 262, 267, 314, 323, 326, 331, 332, 333, 336, 338, 341], "explor": [0, 1, 156, 196, 214, 218, 220, 221, 222, 223, 225, 226, 227, 228, 229, 230, 239, 301, 310, 311, 317, 323, 332, 333, 336, 337], "valu": [0, 1, 3, 8, 11, 13, 14, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 41, 42, 44, 45, 46, 47, 52, 57, 66, 67, 77, 81, 90, 95, 101, 107, 109, 111, 112, 114, 116, 118, 119, 120, 128, 129, 133, 134, 136, 137, 138, 140, 145, 146, 148, 149, 153, 155, 161, 165, 170, 171, 172, 173, 175, 177, 178, 179, 182, 183, 186, 188, 190, 191, 192, 193, 194, 195, 196, 197, 200, 202, 203, 208, 209, 210, 211, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 233, 234, 236, 237, 238, 239, 240, 241, 242, 243, 245, 246, 247, 248, 249, 250, 252, 253, 254, 255, 256, 257, 258, 259, 261, 262, 263, 264, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 288, 296, 298, 299, 300, 301, 302, 305, 314, 317, 323, 327, 331, 335, 336, 337, 339, 341, 342], "gener": [0, 1, 2, 3, 7, 8, 9, 16, 35, 38, 40, 64, 65, 77, 78, 81, 91, 95, 96, 97, 99, 100, 101, 115, 116, 117, 121, 127, 129, 135, 140, 141, 143, 148, 154, 165, 175, 191, 192, 200, 214, 226, 230, 234, 235, 257, 263, 269, 274, 282, 291, 305, 323, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 341, 342], "hook": [0, 32, 77, 81, 95, 101, 167, 168, 169, 170, 171, 172, 173, 174, 176, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 188, 193, 194, 197, 198, 199, 201, 203, 204, 205, 207, 212, 218, 219, 221, 222, 223, 225, 228, 233, 236, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 323], "planner": [0, 166, 190, 323], "sac": [0, 246, 257, 259, 323], "redq": [0, 257, 313, 314, 323], "iql": [0, 252, 323, 336], "cql": [0, 240, 245, 323], "dt": [0, 225, 323, 337], "td3": [0, 261, 323], "a2c": [0, 239, 323], "dreamer": [0, 106, 178, 248, 249, 250, 323, 325], "checkpoint": [0, 323, 338], "builder": [0, 323, 331, 342], "logger": [0, 288, 290, 291, 292, 293, 294, 295, 299, 305, 317, 321, 323, 331], "_util": [0, 3, 11, 323], "implement_for": [0, 3, 323], "contribut": 0, "thing": [0, 3, 7, 8, 324, 332, 333, 336, 339, 342], "consid": [0, 1, 3, 8, 20, 32, 34, 36, 39, 58, 59, 71, 77, 81, 95, 101, 118, 155, 175, 193, 208, 324, 330, 337, 339], "when": [0, 1, 2, 3, 5, 8, 13, 14, 16, 17, 18, 19, 20, 21, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 35, 38, 41, 42, 44, 45, 46, 47, 52, 53, 54, 55, 56, 58, 59, 60, 62, 65, 68, 71, 77, 78, 81, 90, 92, 94, 95, 96, 97, 101, 108, 110, 111, 115, 116, 118, 119, 127, 128, 129, 133, 134, 140, 145, 148, 149, 151, 153, 154, 155, 162, 163, 166, 177, 180, 181, 184, 185, 188, 189, 190, 191, 192, 195, 203, 209, 226, 229, 230, 232, 236, 241, 243, 247, 253, 256, 259, 262, 267, 268, 269, 270, 271, 272, 287, 288, 302, 321, 324, 325, 327, 330, 331, 332, 333, 336, 337, 338, 339, 342], "debug": [0, 6, 8, 40, 324, 342], "work": [0, 2, 3, 4, 8, 11, 32, 34, 36, 38, 39, 66, 67, 77, 81, 85, 95, 101, 112, 127, 133, 151, 154, 155, 167, 168, 188, 221, 228, 233, 241, 253, 256, 305, 324, 325, 330, 331, 332, 333, 335, 336, 337, 338, 339, 341, 342], "habitat": [0, 3, 83, 324, 338], "lab": [0, 3, 75, 76, 324], "mujoco": [0, 6, 8, 98, 324, 332, 333], "error": [0, 1, 3, 7, 10, 11, 29, 32, 77, 81, 95, 101, 104, 134, 157, 324, 330, 332, 336, 342], "solut": [0, 3, 6, 7, 9, 21, 324, 325, 327, 341], "resourc": [0, 1, 21, 324, 330, 332, 336], "version": [0, 1, 3, 6, 11, 32, 34, 36, 40, 56, 66, 77, 81, 95, 96, 101, 103, 154, 217, 254, 259, 269, 272, 324, 325, 330, 332, 333, 336, 337, 338, 342], "issu": [0, 4, 5, 8, 53, 58, 59, 71, 85, 111, 134, 146, 214, 220, 221, 226, 227, 228, 229, 230, 324, 341], "index": [0, 3, 7, 8, 10, 16, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 52, 53, 54, 55, 56, 58, 59, 61, 63, 69, 70, 71, 72, 77, 81, 95, 101, 103, 111, 118, 164, 191, 192, 335, 336, 339, 341], "search": [0, 165, 331], "page": [0, 7], "somewhat": [1, 326, 342], "equival": [1, 3, 17, 24, 27, 30, 31, 32, 33, 34, 36, 39, 45, 52, 53, 55, 56, 57, 77, 81, 95, 101, 117, 120, 149, 177, 184, 203, 220, 221, 227, 228, 256, 302, 341, 342], "dataload": [1, 57, 65, 67, 331, 332, 339], "except": [1, 2, 3, 13, 14, 16, 18, 19, 20, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 39, 44, 46, 47, 77, 81, 95, 101, 111, 122, 137, 144, 145, 146, 180, 182, 184, 186, 200, 218, 222, 223, 225, 325, 331, 339, 341, 342], "1": [1, 2, 3, 4, 8, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 44, 45, 46, 47, 52, 53, 54, 55, 56, 57, 66, 67, 69, 74, 77, 78, 81, 87, 90, 91, 94, 95, 96, 97, 99, 100, 101, 102, 103, 108, 109, 110, 111, 112, 114, 115, 116, 117, 118, 119, 120, 121, 124, 127, 129, 131, 133, 134, 135, 137, 140, 141, 143, 144, 145, 146, 147, 148, 149, 151, 153, 155, 161, 164, 166, 167, 168, 169, 170, 171, 173, 174, 177, 179, 180, 181, 182, 183, 184, 185, 186, 188, 190, 191, 192, 193, 194, 195, 196, 197, 200, 201, 202, 204, 205, 207, 208, 209, 210, 211, 214, 215, 216, 217, 218, 219, 221, 222, 223, 225, 226, 227, 228, 229, 232, 233, 234, 236, 239, 240, 241, 242, 243, 245, 246, 249, 252, 253, 255, 256, 257, 258, 259, 260, 261, 267, 268, 269, 270, 271, 272, 275, 277, 278, 279, 283, 284, 286, 296, 301, 302, 303, 314, 317, 321, 324, 325, 326, 327, 329, 330, 331, 332, 333, 335, 336, 337, 338, 339, 340, 341, 342], "thei": [1, 2, 3, 4, 8, 9, 18, 19, 20, 21, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 44, 46, 47, 77, 81, 90, 95, 96, 97, 101, 103, 110, 122, 127, 133, 141, 148, 149, 153, 186, 187, 239, 240, 241, 246, 247, 248, 249, 250, 252, 253, 254, 256, 257, 258, 259, 261, 267, 302, 305, 325, 326, 327, 330, 331, 332, 333, 335, 336, 337, 338, 339, 341, 342], "collect": [1, 2, 3, 4, 8, 13, 14, 16, 17, 18, 19, 20, 21, 22, 32, 35, 38, 41, 42, 52, 53, 54, 55, 56, 95, 98, 101, 111, 129, 133, 153, 157, 225, 240, 242, 245, 246, 257, 259, 261, 296, 302, 305, 307, 308, 309, 317, 327, 330, 333, 336, 337, 338, 339, 341, 342], "over": [1, 2, 3, 4, 8, 13, 14, 16, 17, 18, 19, 20, 21, 32, 38, 42, 43, 45, 51, 69, 77, 81, 95, 101, 118, 129, 140, 146, 164, 212, 232, 247, 249, 254, 275, 308, 327, 330, 331, 332, 336, 337, 342], "non": [1, 3, 8, 21, 32, 34, 35, 36, 38, 39, 41, 42, 77, 81, 95, 96, 97, 101, 109, 115, 123, 133, 145, 148, 149, 150, 151, 153, 164, 180, 182, 184, 186, 193, 229, 230, 239, 240, 242, 243, 245, 246, 247, 248, 249, 252, 254, 256, 257, 258, 259, 261, 267, 269, 270, 271, 272, 325, 330, 333, 336, 337, 339, 342], "static": [1, 11, 40, 45, 66, 67, 155, 252, 337, 339], "2": [1, 3, 8, 9, 10, 11, 13, 14, 16, 21, 22, 26, 28, 30, 31, 32, 35, 36, 37, 38, 41, 42, 43, 45, 55, 57, 66, 67, 77, 78, 81, 90, 94, 95, 96, 97, 99, 100, 101, 102, 103, 110, 112, 115, 116, 117, 118, 119, 127, 129, 131, 133, 137, 140, 143, 144, 145, 148, 149, 151, 153, 155, 161, 165, 167, 168, 169, 170, 171, 172, 174, 177, 179, 180, 181, 182, 184, 185, 186, 187, 188, 191, 192, 193, 194, 197, 201, 212, 219, 220, 221, 222, 223, 225, 229, 233, 234, 239, 240, 241, 242, 246, 252, 253, 256, 257, 258, 259, 261, 268, 269, 270, 271, 272, 274, 275, 278, 279, 280, 281, 282, 283, 284, 285, 286, 288, 296, 325, 326, 329, 330, 331, 332, 333, 335, 336, 337, 339, 340, 341, 342], "like": [1, 2, 3, 4, 7, 21, 26, 28, 32, 35, 38, 41, 42, 45, 67, 77, 81, 83, 90, 95, 96, 97, 101, 120, 147, 157, 180, 184, 194, 224, 257, 326, 330, 332, 333, 336, 337, 338, 339, 342], "being": [1, 2, 3, 7, 8, 17, 18, 20, 21, 32, 57, 77, 81, 95, 101, 110, 116, 118, 119, 128, 135, 149, 162, 163, 182, 186, 222, 225, 241, 253, 256, 259, 288, 302, 307, 319, 320, 321, 325, 330, 331, 332, 333, 336, 337, 339], "s": [1, 2, 3, 6, 7, 8, 32, 34, 35, 36, 38, 39, 41, 42, 52, 53, 54, 55, 56, 66, 67, 77, 81, 85, 92, 95, 96, 97, 101, 111, 115, 133, 143, 145, 147, 148, 149, 151, 153, 155, 157, 167, 168, 182, 186, 192, 193, 194, 196, 202, 211, 215, 217, 218, 221, 222, 226, 229, 230, 233, 240, 252, 254, 259, 269, 270, 271, 272, 273, 314, 325, 330, 331, 332, 333, 335, 336, 337, 338, 339, 341, 342], "accept": [1, 13, 14, 16, 17, 18, 19, 20, 21, 32, 38, 53, 55, 56, 57, 77, 81, 91, 95, 101, 111, 115, 123, 133, 140, 145, 148, 149, 150, 151, 153, 212, 229, 230, 231, 259, 327, 332, 342], "two": [1, 2, 3, 4, 8, 10, 32, 40, 65, 67, 77, 81, 95, 101, 129, 133, 153, 173, 180, 182, 184, 186, 206, 230, 253, 264, 301, 305, 314, 326, 330, 331, 332, 333, 335, 336, 337, 339, 341, 342], "main": [1, 2, 3, 5, 20, 22, 56, 78, 230, 305, 325, 326, 330, 331, 335, 342], "argument": [1, 3, 13, 14, 16, 17, 18, 19, 20, 21, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 41, 42, 44, 46, 47, 53, 55, 56, 57, 65, 66, 67, 77, 81, 92, 95, 96, 101, 114, 115, 133, 141, 143, 145, 147, 148, 149, 151, 153, 164, 167, 168, 180, 182, 184, 186, 188, 191, 192, 193, 194, 195, 212, 214, 218, 219, 220, 221, 222, 223, 225, 226, 227, 228, 229, 230, 231, 233, 234, 239, 240, 241, 242, 243, 244, 245, 246, 251, 252, 253, 255, 256, 257, 258, 259, 261, 263, 267, 269, 270, 271, 272, 273, 277, 287, 298, 308, 314, 317, 318, 321, 330, 331, 332, 333, 336, 337, 339, 342], "list": [1, 6, 7, 8, 9, 13, 14, 18, 19, 20, 21, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 35, 38, 41, 42, 44, 45, 46, 47, 49, 52, 53, 54, 55, 56, 60, 65, 66, 67, 68, 77, 81, 91, 95, 96, 97, 101, 103, 104, 110, 114, 116, 119, 127, 129, 131, 133, 140, 147, 149, 151, 153, 155, 164, 176, 182, 186, 188, 191, 192, 198, 203, 221, 227, 228, 230, 232, 233, 234, 254, 259, 266, 269, 272, 287, 301, 302, 319, 320, 325, 330, 332, 335, 337, 338, 339, 341, 342], "constructor": [1, 16, 18, 19, 20, 21, 38, 45, 148, 239, 240, 242, 243, 245, 246, 247, 248, 252, 254, 256, 257, 258, 259, 261, 267, 269, 270, 271, 272, 273, 314, 318, 321, 325, 330, 331, 332, 336, 339], "iter": [1, 11, 13, 14, 16, 20, 21, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 41, 42, 44, 46, 47, 51, 52, 53, 54, 55, 56, 57, 77, 81, 95, 101, 121, 129, 141, 167, 168, 188, 193, 194, 207, 214, 220, 226, 227, 229, 231, 232, 234, 254, 266, 301, 304, 305, 314, 326, 327, 330, 332, 333, 336, 337], "execut": [1, 3, 6, 7, 8, 13, 14, 16, 18, 19, 20, 21, 32, 35, 37, 38, 41, 42, 52, 53, 54, 55, 56, 77, 78, 81, 85, 91, 92, 95, 101, 108, 149, 180, 182, 184, 186, 222, 231, 232, 309, 321, 325, 327, 329, 331, 332, 333, 336, 339, 340, 342], "step": [1, 2, 3, 4, 8, 13, 14, 16, 17, 18, 19, 20, 21, 32, 40, 74, 77, 78, 81, 87, 91, 95, 96, 97, 101, 108, 110, 123, 126, 129, 143, 144, 145, 146, 149, 154, 164, 165, 166, 178, 180, 182, 184, 186, 187, 189, 190, 218, 222, 223, 225, 226, 230, 239, 248, 256, 268, 269, 270, 271, 272, 275, 276, 277, 287, 296, 301, 305, 327, 330, 331, 333, 335, 337, 338, 339, 341], "queri": [1, 3, 13, 14, 16, 17, 32, 34, 36, 39, 77, 81, 95, 101, 133, 148, 151, 155, 232, 330, 337, 341], "defin": [1, 2, 11, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 44, 46, 47, 77, 81, 95, 101, 134, 144, 167, 168, 169, 170, 171, 172, 173, 174, 176, 178, 179, 180, 181, 182, 184, 185, 186, 187, 188, 193, 194, 197, 198, 199, 201, 204, 205, 207, 212, 218, 219, 221, 222, 223, 225, 228, 233, 236, 243, 245, 254, 269, 270, 271, 272, 273, 287, 318, 330, 331, 333, 337, 339, 342], "number": [1, 2, 3, 8, 13, 14, 16, 17, 18, 19, 20, 21, 22, 25, 27, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 45, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 66, 67, 71, 77, 81, 91, 92, 94, 95, 96, 97, 101, 110, 111, 118, 124, 128, 129, 139, 143, 146, 155, 166, 167, 168, 175, 176, 178, 179, 180, 181, 182, 183, 184, 185, 186, 188, 190, 193, 194, 197, 198, 199, 202, 204, 205, 208, 209, 210, 211, 214, 218, 219, 222, 223, 225, 226, 229, 230, 234, 238, 240, 246, 248, 252, 253, 255, 257, 259, 261, 296, 298, 301, 305, 307, 308, 309, 319, 320, 321, 325, 330, 331, 332, 333, 336, 337, 338, 342], "befor": [1, 2, 3, 4, 6, 7, 10, 13, 14, 16, 17, 18, 19, 20, 21, 32, 40, 45, 54, 65, 77, 81, 95, 101, 109, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 123, 125, 126, 127, 128, 129, 131, 135, 136, 138, 139, 140, 141, 143, 144, 145, 146, 147, 148, 150, 151, 152, 154, 180, 182, 186, 188, 195, 196, 239, 240, 241, 246, 247, 248, 249, 250, 252, 253, 254, 256, 257, 258, 259, 261, 267, 270, 271, 272, 302, 330, 332, 333, 336, 337, 339, 342], "deliv": [1, 16, 18, 19, 20, 330, 331, 341], "stack": [1, 3, 7, 8, 18, 20, 21, 28, 29, 50, 77, 81, 90, 95, 96, 97, 101, 155, 180, 182, 184, 185, 186, 231, 232, 287, 296, 325, 331, 335, 337, 341], "user": [1, 2, 3, 5, 8, 21, 32, 52, 53, 55, 56, 67, 77, 81, 95, 101, 144, 149, 174, 187, 256, 259, 318, 326, 327, 330, 331, 337, 341, 342], "reset": [1, 3, 8, 11, 13, 14, 16, 17, 18, 19, 20, 21, 32, 35, 38, 41, 42, 52, 53, 54, 55, 56, 67, 74, 77, 78, 81, 87, 90, 91, 92, 94, 95, 96, 97, 101, 111, 120, 123, 126, 128, 133, 140, 143, 144, 145, 146, 148, 151, 154, 155, 157, 165, 180, 182, 186, 213, 225, 287, 314, 330, 331, 332, 333, 335, 336, 341], "whenev": [1, 2, 3, 32, 35, 38, 41, 42, 107, 126, 149, 154, 254, 269, 270, 271, 272, 307, 325], "reach": [1, 13, 14, 16, 17, 18, 19, 20, 21, 22, 40, 65, 77, 81, 95, 101, 143, 218, 222, 223, 225, 330, 332, 336, 341, 342], "done": [1, 2, 3, 4, 7, 8, 13, 14, 16, 18, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 40, 44, 46, 47, 52, 53, 55, 56, 66, 67, 74, 77, 78, 81, 87, 90, 91, 94, 95, 96, 97, 99, 100, 101, 102, 103, 108, 111, 116, 117, 119, 120, 121, 128, 129, 131, 135, 137, 139, 141, 143, 145, 146, 148, 149, 155, 164, 165, 166, 180, 182, 186, 190, 239, 240, 242, 243, 245, 246, 252, 256, 257, 258, 259, 261, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 314, 326, 330, 332, 333, 335, 336, 337, 338, 339, 341, 342], "state": [1, 2, 3, 4, 13, 14, 16, 17, 32, 35, 38, 40, 41, 42, 52, 53, 54, 55, 56, 74, 77, 81, 87, 91, 95, 96, 97, 99, 100, 101, 110, 111, 112, 114, 120, 129, 135, 143, 144, 148, 149, 155, 164, 165, 166, 169, 174, 178, 180, 181, 182, 184, 185, 186, 187, 188, 190, 198, 201, 202, 204, 205, 211, 215, 229, 235, 239, 241, 245, 253, 254, 256, 257, 258, 259, 267, 268, 269, 270, 271, 272, 273, 321, 325, 326, 330, 331, 332, 333, 336, 337, 342], "after": [1, 2, 3, 8, 13, 14, 18, 20, 21, 26, 32, 40, 77, 81, 85, 95, 101, 108, 109, 111, 112, 113, 114, 115, 116, 117, 118, 120, 121, 123, 125, 126, 127, 128, 129, 131, 135, 136, 138, 139, 140, 141, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 154, 164, 180, 182, 186, 195, 218, 220, 222, 223, 227, 249, 259, 331, 332, 333, 336, 337, 338, 339, 342], "predefin": [1, 331, 332, 333, 339], "becaus": [1, 3, 4, 7, 34, 36, 39, 40, 77, 81, 95, 101, 120, 127, 143, 148, 154, 173, 187, 194, 214, 220, 221, 226, 227, 228, 229, 230, 330, 331, 333, 335, 336, 337, 339, 342], "potenti": [1, 2, 337, 339], "comput": [1, 3, 4, 8, 13, 16, 21, 27, 32, 40, 77, 81, 95, 101, 129, 149, 152, 165, 167, 168, 169, 170, 171, 172, 173, 174, 176, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 192, 193, 194, 197, 198, 199, 200, 201, 204, 205, 207, 209, 210, 212, 215, 218, 219, 221, 222, 223, 225, 226, 228, 230, 233, 236, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 252, 253, 254, 255, 256, 257, 258, 259, 261, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 275, 309, 326, 330, 332, 333, 335, 336, 338, 339], "heavi": [1, 8, 339], "crucial": [1, 218, 222, 223, 225, 252, 254, 330, 331, 332, 333, 336, 337, 342], "configur": [1, 8, 13, 14, 16, 17, 21, 22, 40, 127, 169, 174, 201, 254, 256, 314, 325, 330, 331, 332, 336, 337], "hyperparamet": [1, 239, 240, 242, 243, 245, 246, 247, 248, 252, 254, 256, 257, 258, 259, 261, 267, 330, 337, 339], "appropri": [1, 3, 4, 7, 13, 14, 16, 17, 63, 69, 70, 72, 95, 101, 120, 318, 321, 330, 339], "paramet": [1, 8, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 65, 68, 71, 75, 76, 77, 78, 81, 91, 92, 94, 95, 96, 97, 98, 101, 103, 104, 105, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 123, 124, 125, 126, 127, 128, 129, 131, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 157, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 207, 208, 209, 210, 211, 212, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 263, 264, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 290, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 314, 317, 318, 319, 320, 321, 325, 326, 330, 333, 336, 337, 338, 341], "take": [1, 3, 8, 23, 40, 77, 81, 95, 101, 114, 143, 146, 148, 167, 168, 169, 170, 171, 172, 173, 174, 176, 178, 179, 180, 181, 182, 184, 185, 186, 187, 188, 193, 194, 197, 198, 199, 201, 204, 205, 207, 212, 218, 219, 221, 222, 223, 224, 225, 226, 228, 233, 236, 238, 274, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 296, 307, 325, 327, 330, 331, 332, 336, 337, 339, 342], "consider": [1, 3, 8, 331, 336, 339], "whether": [1, 2, 3, 13, 14, 16, 17, 18, 19, 20, 21, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 35, 37, 38, 40, 41, 42, 43, 44, 46, 47, 52, 53, 54, 55, 56, 77, 81, 91, 95, 96, 97, 98, 101, 103, 116, 119, 144, 149, 165, 167, 168, 182, 186, 188, 234, 240, 241, 242, 243, 245, 246, 247, 253, 254, 256, 257, 259, 261, 267, 269, 272, 330, 331, 332, 336, 337, 342], "should": [1, 3, 4, 5, 7, 8, 11, 13, 14, 16, 17, 18, 19, 20, 21, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 35, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 52, 53, 54, 55, 56, 57, 66, 67, 68, 69, 77, 81, 90, 91, 95, 96, 97, 98, 101, 111, 114, 115, 116, 117, 120, 121, 123, 127, 129, 134, 135, 137, 140, 141, 143, 144, 146, 148, 149, 154, 155, 157, 164, 165, 167, 168, 169, 170, 171, 172, 173, 174, 176, 178, 179, 180, 181, 182, 184, 185, 186, 187, 188, 193, 194, 197, 198, 199, 201, 204, 205, 207, 212, 218, 219, 221, 222, 223, 225, 226, 228, 229, 230, 233, 236, 246, 251, 253, 254, 256, 257, 260, 268, 269, 270, 271, 272, 273, 288, 300, 301, 302, 305, 317, 319, 320, 321, 325, 327, 330, 331, 332, 333, 335, 336, 337, 338, 339, 341, 342], "occur": [1, 8, 14, 28, 29, 112, 129, 134, 154, 165, 214, 220, 221, 226, 227, 228, 229, 230, 249, 339, 342], "serial": [1, 2, 3, 32, 77, 81, 95, 101, 155], "optim": [1, 2, 8, 32, 40, 77, 81, 95, 101, 149, 166, 190, 195, 196, 240, 254, 255, 256, 259, 300, 305, 317, 326, 327, 332, 333, 336, 337], "parallel": [1, 3, 8, 17, 96, 97, 154, 157, 239, 318, 319, 320, 321, 331, 332, 336], "syncdatacollector": [1, 13, 14, 17, 18, 19, 20, 21, 111, 137, 317, 320, 323, 332, 333, 336, 339], "class": [1, 2, 3, 5, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 77, 78, 79, 81, 83, 90, 91, 95, 96, 97, 101, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 319, 320, 321, 325, 326, 327, 330, 331, 332, 333, 336, 339, 342], "worker": [1, 2, 13, 14, 16, 17, 18, 19, 20, 21, 22, 36, 45, 57, 78, 92, 95, 101, 155, 319, 320, 321, 330, 332, 341, 342], "multisyncdatacollector": [1, 18, 19, 20, 21, 320, 323, 332, 341], "split": [1, 13, 14, 16, 17, 18, 19, 20, 21, 34, 36, 45, 52, 53, 55, 56, 57, 66, 67, 90, 96, 97, 180, 184, 239, 240, 241, 246, 247, 248, 249, 250, 252, 253, 254, 256, 257, 258, 259, 261, 267, 325, 327, 332, 339, 341], "workload": 1, "across": [1, 3, 8, 18, 19, 20, 21, 35, 38, 41, 42, 66, 67, 85, 155, 193, 225, 307, 323, 325, 330, 336, 337], "aggreg": [1, 3, 165, 167, 168, 170, 171, 232], "result": [1, 3, 7, 13, 14, 16, 17, 18, 19, 20, 21, 32, 34, 35, 36, 37, 38, 39, 41, 42, 52, 53, 54, 55, 56, 65, 66, 67, 77, 78, 81, 95, 101, 109, 111, 112, 113, 114, 115, 116, 117, 118, 120, 121, 123, 125, 126, 127, 128, 129, 131, 135, 136, 138, 139, 140, 141, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 154, 155, 157, 164, 165, 180, 182, 184, 186, 188, 193, 203, 219, 221, 222, 228, 239, 240, 242, 243, 245, 246, 247, 248, 252, 254, 256, 257, 258, 259, 261, 267, 269, 274, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 307, 325, 331, 333, 337, 338, 341, 342], "final": [1, 3, 4, 21, 34, 36, 39, 40, 154, 180, 182, 184, 186, 193, 218, 222, 223, 224, 225, 231, 269, 301, 325, 330, 331, 332, 336, 337, 342], "multiasyncdatacollector": [1, 17, 18, 19, 20, 21, 319, 323, 330, 331, 332, 341], "sever": [1, 8, 30, 32, 45, 77, 81, 95, 101, 112, 114, 149, 256, 330, 332, 339, 342], "batch": [1, 3, 13, 14, 16, 17, 18, 19, 20, 21, 23, 27, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 52, 53, 54, 55, 56, 57, 58, 59, 62, 65, 66, 67, 69, 71, 77, 81, 91, 92, 94, 95, 101, 111, 123, 129, 131, 134, 137, 145, 149, 150, 154, 155, 165, 175, 176, 180, 181, 182, 184, 185, 186, 187, 191, 192, 193, 194, 195, 200, 202, 208, 212, 225, 229, 239, 240, 241, 242, 243, 245, 246, 247, 248, 249, 250, 252, 253, 254, 256, 257, 258, 259, 261, 267, 269, 270, 271, 272, 273, 274, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 288, 296, 299, 302, 303, 304, 305, 307, 319, 320, 321, 327, 331, 332, 333, 335, 336, 338, 341, 342], "gather": [1, 3, 18, 20, 21, 45, 57, 58, 59, 71, 134, 192, 200, 268, 309, 324, 330, 331, 332, 333, 336, 337, 339, 342], "continu": [1, 9, 25, 46, 67, 77, 81, 95, 96, 97, 101, 161, 170, 171, 172, 173, 225, 232, 239, 240, 246, 252, 256, 257, 258, 259, 260, 261, 269, 274, 282, 325, 330, 332, 333, 336, 337, 339, 341, 342], "concomitantli": 1, "network": [1, 4, 8, 32, 77, 81, 90, 95, 96, 97, 101, 167, 168, 170, 171, 172, 173, 176, 178, 179, 184, 188, 193, 194, 196, 198, 199, 202, 204, 205, 206, 211, 215, 216, 217, 219, 229, 233, 240, 241, 242, 243, 245, 246, 247, 251, 252, 253, 254, 256, 257, 258, 259, 260, 261, 265, 267, 269, 270, 271, 272, 273, 316, 317, 325, 326, 327, 335, 337, 342], "impli": [1, 342], "weight": [1, 4, 9, 12, 13, 14, 16, 17, 18, 19, 20, 21, 32, 35, 40, 77, 81, 95, 99, 100, 101, 115, 133, 145, 148, 149, 151, 153, 180, 181, 182, 184, 185, 186, 193, 196, 229, 239, 240, 241, 246, 249, 259, 307, 316, 325, 327, 330, 331, 332, 333, 335, 337, 339, 341], "mai": [1, 2, 3, 4, 5, 7, 8, 13, 14, 16, 17, 18, 20, 21, 28, 29, 32, 52, 53, 55, 56, 77, 81, 95, 101, 127, 129, 141, 149, 150, 155, 157, 188, 193, 326, 327, 330, 331, 332, 333, 336, 337, 338, 339, 341, 342], "slightli": [1, 325, 326, 333, 337, 338, 339, 342], "lag": [1, 13, 14, 16, 17, 330, 331, 332], "therefor": [1, 3, 7, 55, 56, 77, 81, 95, 101, 137, 256, 267, 342], "although": [1, 8, 77, 81, 95, 101, 167, 168, 169, 170, 171, 172, 173, 174, 176, 178, 179, 180, 181, 182, 184, 185, 186, 187, 188, 193, 194, 197, 198, 199, 201, 204, 205, 207, 212, 218, 219, 221, 222, 223, 225, 228, 233, 236, 327, 330, 331, 339], "fastest": 1, "price": 1, "suitabl": [1, 2], "where": [1, 3, 4, 7, 8, 13, 14, 16, 17, 18, 19, 20, 21, 28, 29, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 52, 53, 54, 55, 56, 57, 58, 59, 66, 67, 69, 71, 77, 81, 90, 91, 94, 95, 96, 97, 101, 108, 111, 120, 127, 133, 137, 140, 143, 144, 146, 148, 150, 153, 154, 164, 165, 180, 181, 184, 185, 191, 192, 193, 218, 222, 223, 225, 226, 229, 230, 238, 239, 240, 241, 246, 247, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 268, 269, 270, 271, 272, 273, 274, 275, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 326, 327, 330, 331, 332, 335, 336, 337, 339, 342], "asynchron": [1, 9, 14, 21, 32, 77, 81, 95, 101, 115, 133, 145, 148, 149, 151, 153, 229, 239, 319, 331, 332], "off": [1, 2, 4, 183, 210, 220, 259, 301, 310, 325, 327, 330, 331, 332, 336, 338, 342], "curriculum": [1, 4], "For": [1, 2, 3, 4, 7, 8, 9, 10, 13, 14, 16, 17, 18, 20, 21, 32, 52, 53, 55, 56, 66, 77, 81, 95, 96, 97, 101, 116, 119, 123, 129, 144, 149, 154, 177, 180, 182, 184, 186, 194, 195, 215, 217, 219, 221, 227, 239, 247, 252, 256, 301, 325, 327, 330, 331, 332, 333, 336, 337, 338, 339, 342], "remot": [1, 2, 18, 19, 20, 21, 95, 101, 342], "rollout": [1, 2, 3, 13, 14, 16, 21, 23, 40, 77, 81, 84, 91, 92, 95, 96, 97, 99, 100, 101, 102, 103, 108, 111, 114, 116, 119, 120, 121, 127, 131, 135, 140, 141, 143, 144, 146, 157, 166, 182, 186, 190, 225, 239, 309, 325, 330, 332, 333, 338, 339, 341], "necessari": [1, 4, 6, 8, 13, 14, 16, 17, 53, 55, 56, 141, 257, 269, 270, 271, 272, 273, 326, 330, 332], "synchronis": [1, 78, 336], "either": [1, 5, 22, 32, 40, 57, 77, 81, 95, 101, 143, 144, 235, 261, 292, 327, 330, 331, 333, 338, 339, 341, 342], "update_policy_weights_": [1, 12, 13, 14, 16, 17, 18, 19, 20, 21, 330, 336, 341], "update_at_each_batch": [1, 13, 14, 17, 330], "true": [1, 3, 4, 8, 13, 14, 16, 17, 18, 19, 20, 21, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 65, 66, 67, 75, 76, 77, 78, 79, 81, 91, 95, 96, 97, 98, 99, 100, 101, 102, 103, 108, 110, 111, 112, 115, 118, 123, 126, 127, 128, 129, 133, 134, 135, 136, 139, 141, 143, 145, 147, 148, 149, 150, 151, 153, 155, 157, 161, 164, 165, 166, 167, 168, 170, 171, 172, 173, 179, 180, 181, 182, 184, 185, 186, 188, 190, 191, 192, 193, 194, 195, 196, 209, 210, 214, 215, 216, 217, 218, 220, 221, 225, 226, 227, 228, 229, 230, 231, 232, 233, 239, 240, 241, 242, 245, 246, 248, 249, 250, 252, 253, 254, 255, 256, 257, 258, 259, 261, 264, 269, 270, 271, 272, 275, 278, 279, 280, 281, 283, 284, 285, 286, 287, 288, 298, 299, 301, 302, 305, 321, 325, 326, 327, 330, 331, 332, 333, 335, 336, 337, 338, 339, 341, 342], "second": [1, 3, 8, 180, 182, 184, 186, 221, 241, 253, 256, 259, 304, 330, 331, 332, 333, 335, 336, 337, 338, 339, 341, 342], "devic": [1, 2, 3, 7, 8, 12, 13, 14, 16, 17, 18, 19, 20, 21, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 53, 55, 56, 57, 58, 59, 71, 74, 77, 79, 81, 84, 85, 87, 90, 91, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 115, 116, 117, 119, 120, 121, 127, 131, 132, 133, 135, 137, 141, 143, 145, 147, 148, 149, 151, 153, 161, 164, 166, 167, 168, 169, 170, 171, 172, 173, 177, 179, 180, 181, 182, 184, 185, 186, 187, 188, 190, 193, 194, 195, 196, 201, 202, 203, 211, 214, 215, 216, 217, 219, 220, 221, 225, 226, 227, 228, 229, 232, 234, 239, 240, 242, 243, 245, 246, 252, 256, 257, 258, 259, 261, 267, 269, 270, 271, 272, 302, 307, 314, 315, 325, 330, 331, 332, 333, 335, 336, 337, 338, 339, 341], "oper": [1, 3, 4, 7, 8, 13, 14, 17, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 39, 44, 45, 46, 47, 77, 81, 95, 101, 123, 127, 148, 176, 177, 181, 185, 197, 215, 216, 217, 220, 221, 224, 229, 235, 239, 241, 242, 243, 247, 253, 256, 258, 267, 268, 269, 270, 271, 272, 305, 314, 323, 327, 330, 331, 332, 333, 335, 336, 337, 342], "instanc": [1, 2, 3, 4, 7, 8, 13, 14, 16, 17, 18, 19, 20, 21, 32, 34, 36, 37, 39, 43, 44, 45, 52, 66, 67, 76, 77, 78, 81, 91, 95, 101, 111, 129, 145, 148, 155, 161, 165, 167, 168, 169, 170, 171, 172, 173, 174, 176, 178, 179, 180, 181, 182, 184, 185, 186, 187, 188, 189, 193, 194, 197, 198, 199, 201, 204, 205, 207, 212, 218, 219, 220, 221, 222, 223, 225, 226, 227, 228, 230, 231, 232, 233, 236, 243, 246, 254, 267, 269, 270, 271, 272, 288, 292, 301, 309, 310, 311, 314, 317, 319, 320, 325, 326, 327, 330, 332, 333, 337, 339, 342], "cpu": [1, 3, 8, 10, 13, 14, 16, 18, 19, 20, 21, 24, 26, 28, 32, 34, 36, 37, 39, 40, 41, 42, 43, 44, 45, 53, 55, 56, 57, 58, 59, 71, 74, 77, 81, 87, 90, 91, 94, 95, 96, 97, 99, 100, 101, 102, 103, 115, 116, 117, 119, 120, 121, 131, 133, 135, 137, 141, 143, 145, 148, 149, 151, 153, 161, 164, 166, 180, 181, 182, 184, 185, 186, 190, 195, 196, 202, 203, 211, 214, 215, 216, 217, 219, 220, 221, 226, 227, 228, 229, 232, 234, 239, 240, 242, 243, 245, 246, 252, 256, 257, 258, 259, 261, 267, 302, 314, 325, 330, 331, 332, 333, 335, 336, 337, 338, 339, 341, 342], "slower": 1, "than": [1, 2, 3, 4, 8, 13, 14, 16, 17, 52, 66, 67, 77, 81, 85, 95, 101, 135, 173, 182, 184, 186, 188, 197, 212, 214, 218, 220, 229, 234, 254, 296, 297, 298, 299, 300, 301, 302, 303, 304, 306, 307, 324, 326, 330, 331, 332, 336, 337, 339, 341, 342], "one": [1, 2, 3, 4, 5, 7, 8, 11, 13, 14, 16, 17, 18, 19, 20, 21, 22, 24, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 52, 53, 54, 55, 56, 61, 63, 66, 67, 68, 70, 72, 77, 78, 81, 85, 90, 94, 95, 96, 97, 101, 103, 108, 111, 114, 116, 117, 118, 119, 128, 129, 133, 137, 140, 142, 144, 145, 146, 148, 149, 150, 153, 155, 167, 168, 169, 170, 171, 172, 173, 174, 176, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 188, 193, 194, 197, 198, 199, 200, 201, 203, 204, 205, 207, 212, 214, 218, 219, 220, 221, 222, 223, 225, 226, 227, 228, 229, 230, 233, 234, 236, 238, 239, 240, 241, 242, 243, 245, 246, 247, 248, 252, 253, 254, 256, 257, 258, 259, 260, 261, 267, 269, 270, 271, 272, 276, 277, 298, 300, 301, 305, 309, 314, 321, 324, 325, 326, 327, 330, 331, 332, 333, 335, 336, 337, 338, 339, 342], "cuda": [1, 3, 7, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 44, 46, 47, 77, 81, 84, 85, 95, 101, 115, 127, 132, 133, 145, 148, 149, 151, 153, 180, 181, 184, 185, 229, 245, 297, 330, 331, 332, 333, 336, 338, 342], "multipl": [1, 2, 3, 5, 8, 13, 14, 16, 17, 18, 19, 20, 21, 27, 43, 95, 101, 112, 114, 118, 128, 137, 140, 143, 148, 155, 180, 184, 186, 187, 193, 195, 196, 214, 220, 226, 227, 229, 230, 233, 241, 246, 253, 256, 257, 261, 275, 314, 321, 325, 327, 330, 331, 332, 336, 337, 339, 341], "infer": [1, 95, 101, 111, 155, 182, 186, 195, 219, 245, 330, 332, 339], "run": [1, 3, 4, 5, 6, 7, 8, 10, 13, 14, 17, 21, 32, 75, 76, 77, 81, 91, 95, 101, 128, 129, 149, 155, 167, 168, 169, 170, 171, 172, 173, 174, 176, 178, 179, 180, 181, 182, 184, 185, 186, 187, 188, 193, 194, 197, 198, 199, 201, 204, 205, 207, 212, 218, 219, 221, 222, 223, 225, 228, 231, 232, 233, 236, 259, 301, 319, 320, 321, 324, 327, 330, 331, 332, 333, 335, 336, 337, 338, 339, 341], "dispatch": [1, 18, 19, 20, 21, 212], "avail": [1, 3, 4, 6, 21, 56, 65, 85, 95, 96, 97, 110, 127, 177, 203, 226, 230, 254, 319, 320, 325, 330, 331, 332, 333, 336, 337, 339, 342], "speed": [1, 2, 4, 8, 27, 95, 101, 326, 330, 331, 332, 333, 336, 337, 339], "up": [1, 2, 3, 8, 9, 13, 14, 16, 27, 40, 52, 53, 55, 56, 95, 101, 110, 146, 148, 256, 324, 325, 326, 330, 331, 332, 333, 336, 337, 339, 342], "avoid": [1, 32, 58, 59, 71, 77, 81, 95, 101, 107, 149, 155, 214, 229, 234, 241, 253, 256, 259, 308, 332, 336], "oom": [1, 58, 59, 71], "choic": [1, 2, 52, 53, 55, 56, 95, 197, 325, 326, 330, 331, 336], "size": [1, 2, 3, 13, 14, 16, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 52, 53, 54, 55, 56, 57, 58, 59, 62, 65, 66, 67, 68, 69, 71, 74, 77, 79, 81, 87, 90, 91, 92, 94, 95, 96, 97, 99, 100, 101, 102, 103, 110, 112, 116, 119, 120, 121, 123, 131, 133, 135, 137, 141, 142, 143, 145, 147, 148, 149, 150, 153, 155, 161, 164, 166, 167, 168, 169, 174, 175, 177, 180, 181, 182, 184, 185, 186, 187, 188, 190, 191, 192, 193, 194, 197, 200, 201, 202, 203, 204, 205, 208, 211, 212, 214, 215, 216, 217, 219, 220, 221, 222, 223, 225, 226, 227, 228, 229, 232, 234, 239, 240, 242, 243, 245, 246, 252, 254, 256, 257, 258, 259, 261, 267, 268, 269, 270, 271, 272, 273, 288, 296, 302, 314, 325, 331, 332, 333, 335, 336, 337, 338, 341, 342], "pass": [1, 3, 4, 13, 14, 16, 18, 19, 20, 21, 22, 26, 32, 35, 38, 40, 41, 42, 45, 53, 55, 56, 58, 59, 69, 71, 77, 78, 79, 81, 90, 92, 95, 96, 97, 101, 116, 119, 135, 148, 150, 155, 167, 168, 169, 170, 171, 172, 173, 174, 176, 178, 179, 180, 181, 182, 184, 185, 186, 187, 188, 193, 194, 195, 197, 198, 199, 201, 202, 204, 205, 207, 211, 212, 214, 218, 219, 220, 221, 222, 223, 225, 226, 227, 228, 229, 230, 232, 233, 234, 236, 241, 253, 254, 256, 269, 270, 271, 272, 273, 302, 319, 320, 321, 325, 330, 331, 332, 333, 335, 336, 337, 339, 342], "ie": [1, 3, 18, 20, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 39, 41, 44, 45, 46, 47, 61, 67, 77, 81, 85, 94, 95, 101, 111, 123, 150, 155, 165, 182, 186, 219, 239, 241, 242, 246, 252, 253, 256, 257, 258, 259, 261, 269, 270, 271, 272, 325, 326, 331, 332, 336, 339], "store": [1, 3, 8, 13, 14, 16, 17, 20, 26, 32, 34, 36, 37, 39, 41, 42, 43, 45, 55, 57, 58, 59, 60, 61, 71, 77, 81, 95, 101, 154, 155, 166, 187, 190, 239, 240, 242, 243, 245, 246, 247, 248, 252, 254, 256, 257, 258, 259, 261, 267, 314, 323, 327, 330, 332, 333, 336, 338, 339, 342], "while": [1, 3, 7, 8, 32, 77, 81, 95, 101, 137, 149, 167, 168, 169, 170, 171, 172, 173, 174, 176, 178, 179, 180, 181, 182, 184, 185, 186, 187, 188, 193, 194, 197, 198, 199, 201, 204, 205, 207, 212, 218, 219, 221, 222, 223, 225, 228, 233, 236, 252, 253, 256, 259, 325, 330, 332, 333, 336, 337, 338, 339, 341], "wait": [1, 20, 21, 22, 333, 337], "also": [1, 2, 3, 8, 9, 11, 32, 34, 36, 39, 41, 53, 55, 56, 57, 58, 59, 71, 77, 81, 95, 96, 97, 101, 107, 110, 111, 118, 129, 135, 137, 140, 141, 143, 145, 149, 180, 184, 205, 226, 231, 232, 233, 239, 240, 242, 243, 245, 246, 252, 256, 259, 269, 276, 277, 325, 327, 330, 331, 332, 333, 335, 336, 337, 339, 342], "impact": [1, 116, 119, 331, 333, 336], "memori": [1, 2, 3, 8, 21, 27, 32, 34, 36, 39, 45, 52, 53, 55, 56, 58, 77, 78, 81, 85, 95, 101, 111, 115, 133, 145, 148, 149, 151, 153, 155, 184, 185, 229, 321, 327, 330, 331, 332, 333, 335, 336, 337, 338, 339, 341, 342], "manag": [1, 8, 265, 266, 269, 270, 271, 272, 301], "kei": [1, 2, 3, 7, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 52, 66, 67, 69, 77, 81, 95, 101, 108, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 126, 127, 129, 132, 133, 134, 135, 137, 140, 141, 143, 144, 145, 146, 147, 148, 149, 151, 152, 153, 154, 155, 164, 165, 166, 176, 177, 182, 186, 189, 190, 203, 214, 218, 219, 220, 221, 222, 223, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 238, 239, 240, 241, 242, 243, 245, 246, 247, 248, 249, 250, 252, 253, 254, 256, 257, 258, 259, 261, 267, 268, 269, 270, 271, 272, 273, 288, 299, 300, 301, 303, 304, 305, 309, 314, 326, 327, 330, 332, 333, 335, 336, 337, 339, 341, 342], "control": [1, 3, 5, 8, 16, 75, 76, 90, 96, 97, 118, 164, 170, 171, 172, 173, 182, 186, 189, 190, 205, 212, 225, 229, 230, 231, 239, 241, 253, 256, 260, 269, 274, 282, 325, 327, 330, 331, 332, 336, 337, 339], "which": [1, 2, 3, 4, 7, 8, 11, 13, 14, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 39, 40, 41, 42, 44, 45, 46, 47, 52, 53, 55, 56, 57, 65, 77, 81, 85, 92, 95, 98, 101, 111, 112, 116, 119, 124, 127, 128, 129, 133, 134, 143, 145, 146, 148, 149, 151, 157, 180, 181, 183, 184, 185, 186, 191, 192, 193, 210, 215, 216, 217, 219, 226, 229, 230, 232, 239, 240, 241, 243, 246, 247, 248, 249, 250, 252, 253, 254, 256, 257, 258, 259, 261, 264, 267, 269, 270, 271, 272, 296, 300, 314, 325, 326, 327, 330, 331, 332, 333, 335, 336, 337, 338, 339, 342], "storing_devic": [1, 13, 14, 16, 17, 18, 19, 20, 21, 330, 331, 336, 341], "dure": [1, 3, 13, 14, 16, 17, 18, 19, 20, 36, 40, 45, 52, 53, 54, 55, 56, 57, 77, 81, 95, 96, 97, 101, 111, 114, 116, 119, 124, 131, 149, 182, 186, 301, 305, 326, 330, 331, 332, 333, 336, 337, 339, 342], "heurist": [1, 4, 24, 25, 26, 27, 28, 29, 30, 31, 33, 44, 46, 47, 225, 330, 342], "usual": [1, 3, 4, 6, 7, 8, 52, 77, 81, 95, 101, 196, 256, 269, 270, 271, 272, 273, 287, 314, 324, 325, 327, 330, 331, 332, 333, 336, 339, 342], "same": [1, 2, 3, 4, 11, 13, 14, 16, 18, 19, 20, 21, 28, 29, 32, 34, 36, 39, 43, 45, 52, 65, 77, 78, 81, 90, 95, 96, 97, 101, 111, 116, 118, 119, 124, 128, 129, 148, 149, 155, 167, 168, 181, 182, 185, 186, 188, 191, 192, 193, 194, 219, 225, 233, 259, 330, 331, 332, 335, 336, 338, 339, 342], "storag": [1, 2, 8, 32, 34, 35, 36, 38, 39, 41, 42, 52, 53, 54, 55, 56, 58, 59, 60, 65, 66, 67, 69, 71, 77, 79, 81, 95, 101, 110, 111, 116, 119, 137, 323, 327, 331, 332, 333, 336, 338], "default": [1, 2, 3, 10, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 52, 53, 54, 55, 56, 57, 58, 59, 61, 65, 66, 67, 71, 75, 77, 81, 94, 95, 96, 97, 98, 101, 103, 108, 110, 111, 112, 116, 118, 119, 120, 123, 127, 128, 129, 131, 133, 134, 137, 139, 141, 143, 144, 145, 146, 147, 149, 150, 151, 153, 154, 155, 157, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 188, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 201, 203, 204, 205, 207, 208, 209, 210, 214, 218, 219, 220, 221, 222, 223, 225, 226, 227, 228, 229, 230, 233, 234, 236, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 261, 263, 264, 267, 268, 269, 270, 271, 272, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 314, 317, 321, 327, 330, 331, 332, 333, 338, 339, 341, 342], "behaviour": [1, 3, 21, 81, 112, 116, 119, 129, 134, 144, 164, 182, 183, 186, 210, 301, 325, 331, 339], "besid": 1, "those": [1, 2, 3, 5, 7, 26, 28, 95, 101, 111, 116, 119, 129, 145, 146, 186, 226, 230, 231, 232, 307, 319, 320, 325, 330, 331, 336, 337, 342], "choos": [1, 90, 182, 186, 256, 325, 326, 330, 331, 332, 336, 339], "follow": [1, 2, 3, 6, 7, 8, 32, 34, 36, 37, 39, 40, 52, 54, 77, 81, 91, 94, 95, 96, 97, 99, 100, 101, 103, 127, 133, 151, 167, 168, 180, 182, 184, 186, 188, 221, 227, 228, 238, 239, 240, 241, 242, 246, 252, 253, 256, 257, 258, 259, 261, 305, 314, 325, 326, 327, 330, 331, 332, 333, 335, 336, 337, 339, 341, 342], "max_frames_per_traj": [1, 13, 14, 16, 17, 18, 19, 20, 21, 308, 330, 332, 341], "frame": [1, 2, 13, 14, 16, 17, 18, 19, 20, 21, 32, 111, 124, 218, 222, 223, 225, 287, 288, 298, 301, 305, 308, 309, 330, 331, 332, 333, 336, 339, 341, 342], "call": [1, 2, 3, 7, 8, 11, 13, 14, 16, 17, 18, 19, 20, 21, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 44, 45, 46, 47, 49, 52, 53, 54, 55, 56, 57, 58, 59, 60, 62, 65, 68, 71, 77, 81, 94, 95, 101, 111, 114, 115, 118, 123, 126, 127, 129, 131, 132, 133, 140, 145, 148, 149, 151, 153, 154, 155, 157, 162, 163, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 176, 178, 179, 180, 181, 182, 184, 185, 186, 187, 188, 190, 193, 194, 195, 197, 198, 199, 201, 204, 205, 207, 212, 218, 219, 221, 222, 223, 225, 228, 229, 230, 232, 233, 236, 241, 253, 256, 259, 268, 269, 270, 271, 272, 287, 301, 327, 331, 332, 333, 336, 337, 339, 342], "frames_per_batch": [1, 13, 14, 16, 17, 18, 19, 20, 21, 111, 137, 308, 330, 331, 332, 333, 336, 339, 341], "each": [1, 2, 3, 4, 7, 8, 11, 13, 14, 16, 17, 18, 19, 20, 21, 23, 30, 31, 32, 40, 41, 52, 66, 67, 77, 78, 81, 95, 96, 97, 101, 103, 133, 137, 140, 143, 144, 145, 146, 153, 155, 177, 180, 181, 182, 184, 186, 193, 194, 198, 202, 203, 211, 218, 220, 221, 222, 228, 232, 275, 278, 279, 280, 281, 283, 284, 285, 286, 301, 302, 319, 320, 325, 330, 331, 332, 333, 336, 337, 338, 339, 341, 342], "init_random_fram": [1, 13, 14, 16, 17, 18, 19, 20, 21, 308, 330, 331], "random": [1, 3, 13, 14, 15, 16, 17, 18, 19, 20, 21, 24, 25, 26, 27, 28, 29, 30, 31, 33, 40, 44, 46, 47, 56, 62, 77, 81, 91, 95, 101, 118, 128, 129, 145, 157, 180, 182, 184, 186, 222, 226, 229, 230, 240, 257, 301, 309, 325, 330, 331, 332, 333, 337, 338, 339, 341, 342], "rand_step": [1, 3, 73, 75, 76, 77, 78, 80, 81, 82, 86, 88, 89, 91, 92, 95, 101, 126, 145, 155, 337, 341, 342], "reset_at_each_it": [1, 13, 14, 16, 17, 18, 19, 20, 21, 330], "split_traj": [1, 13, 14, 16, 17, 18, 19, 20, 21, 52, 53, 55, 56, 330, 331, 332], "trajectori": [1, 3, 13, 14, 16, 17, 18, 19, 20, 21, 23, 32, 41, 52, 53, 55, 56, 61, 66, 67, 69, 77, 81, 95, 101, 134, 143, 148, 166, 186, 190, 225, 256, 269, 272, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 296, 323, 326, 330, 331, 332, 333, 337, 339, 341, 342], "pad": [1, 2, 3, 23, 37, 43, 52, 53, 55, 56, 111, 167, 168, 170, 171, 186, 187, 191, 192, 193, 302], "along": [1, 2, 3, 23, 28, 29, 34, 36, 39, 40, 45, 52, 53, 55, 56, 59, 66, 67, 71, 110, 111, 112, 129, 131, 134, 140, 147, 186, 188, 191, 192, 196, 220, 226, 229, 230, 254, 325, 330, 331, 333, 336, 337, 339], "point": [1, 2, 3, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 44, 46, 47, 54, 61, 63, 69, 70, 72, 77, 81, 95, 101, 110, 111, 115, 133, 144, 145, 147, 148, 149, 151, 153, 189, 229, 238, 247, 305, 324, 331, 332, 335, 336, 337, 339, 342], "boolean": [1, 13, 14, 16, 17, 18, 19, 20, 21, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 40, 44, 46, 47, 81, 134, 143, 165, 191, 192, 218, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 327, 333], "repres": [1, 3, 13, 14, 16, 17, 18, 19, 20, 21, 26, 28, 41, 53, 77, 81, 95, 101, 103, 124, 134, 155, 177, 191, 192, 203, 220, 221, 227, 228, 230, 264, 269, 302, 330, 332, 333, 336], "valid": [1, 3, 23, 34, 36, 37, 45, 57, 104, 134, 149, 167, 168, 188, 191, 192, 218, 225, 253, 269, 270, 271, 272, 302, 327, 342], "exploration_typ": [1, 13, 14, 16, 18, 19, 20, 21, 301, 323, 330, 331], "strategi": [1, 2, 16, 90, 192, 200, 222, 325, 327, 330, 331, 336, 339], "reset_when_don": [1, 13, 14, 16, 18, 19, 20, 21], "These": [1, 2, 7, 32, 40, 56, 77, 81, 95, 101, 133, 153, 325, 326, 330, 332, 336, 337, 339, 342], "tool": [1, 2, 3, 5, 333, 337, 339, 342], "backend": [1, 3, 7, 11, 18, 19, 21, 22, 95, 105, 107, 327, 330, 332, 333, 337], "gloo": [1, 18, 19, 22], "nccl": [1, 18, 19], "mpi": [1, 18, 19], "distributeddatacollector": [1, 22, 323], "rpc": [1, 20, 22], "rpcdatacollector": [1, 22, 323], "launcher": [1, 18, 19, 20, 22], "rai": [1, 21], "submitit": [1, 18, 19, 20, 22], "torch": [1, 2, 3, 8, 9, 10, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 52, 53, 54, 55, 56, 57, 58, 59, 61, 65, 66, 67, 69, 71, 74, 77, 78, 81, 87, 90, 91, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 108, 110, 112, 115, 116, 117, 118, 119, 120, 121, 127, 129, 131, 133, 135, 137, 139, 140, 141, 143, 144, 145, 146, 147, 148, 149, 151, 153, 155, 161, 164, 165, 166, 167, 168, 169, 174, 175, 177, 178, 180, 181, 182, 183, 184, 185, 186, 187, 188, 190, 191, 192, 193, 194, 195, 196, 197, 200, 201, 202, 203, 208, 209, 210, 211, 212, 214, 215, 216, 217, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 232, 233, 234, 237, 239, 240, 242, 243, 245, 246, 247, 248, 252, 254, 256, 257, 258, 259, 261, 267, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 296, 303, 304, 314, 317, 325, 326, 327, 330, 331, 332, 333, 335, 336, 337, 338, 339, 341, 342], "multiprocess": [1, 2, 3, 18, 19, 20, 78, 79, 155, 331, 332, 337, 342], "synchron": [1, 13, 19, 21, 92, 319, 320, 331, 332], "mode": [1, 6, 13, 14, 16, 18, 19, 20, 21, 32, 77, 81, 92, 95, 101, 116, 119, 144, 149, 155, 158, 162, 163, 175, 182, 183, 186, 200, 208, 209, 210, 226, 230, 254, 301, 330, 331, 333, 336, 341, 342], "find": [1, 4, 6, 7, 18, 19, 20, 35, 37, 43, 66, 67, 184, 218, 225, 299, 303, 330, 331, 336], "dedic": [1, 2, 3, 18, 19, 20, 21, 215, 216, 217, 325, 330, 335, 336], "folder": [1, 2, 331], "sub": [1, 2, 3, 13, 14, 18, 19, 20, 21, 66, 77, 81, 95, 101, 134, 231, 232, 296, 305, 325, 330, 331, 332, 335, 341, 342], "all": [1, 2, 3, 4, 8, 13, 14, 16, 17, 18, 19, 20, 21, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 44, 46, 47, 49, 56, 77, 78, 81, 91, 95, 96, 97, 101, 103, 104, 110, 111, 114, 115, 116, 117, 119, 122, 127, 128, 129, 133, 140, 145, 146, 148, 149, 151, 153, 155, 160, 161, 162, 163, 164, 167, 168, 169, 170, 171, 172, 173, 174, 176, 178, 179, 180, 181, 182, 184, 185, 186, 187, 188, 193, 194, 197, 198, 199, 201, 204, 205, 207, 212, 218, 219, 221, 222, 223, 225, 228, 229, 230, 232, 233, 236, 249, 254, 274, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 300, 305, 308, 319, 320, 321, 324, 325, 326, 327, 329, 330, 331, 332, 333, 334, 335, 336, 337, 339, 341, 342], "variou": [1, 3, 13, 14, 16, 17, 182, 186, 239, 240, 241, 246, 247, 248, 249, 250, 252, 253, 254, 256, 257, 258, 259, 261, 262, 267, 319, 320, 330, 331, 332, 336, 342], "machin": [1, 7, 18, 19, 20, 32, 54, 85, 336], "One": [1, 2, 4, 8, 31, 33, 45, 111, 137, 151, 200, 218, 229, 233, 260, 264, 292, 330, 331, 339, 342], "wonder": 1, "why": [1, 3, 337, 342], "parallelenv": [1, 2, 3, 13, 14, 16, 17, 20, 77, 81, 92, 96, 97, 101, 318, 323, 330, 331, 332, 335, 341, 342], "instead": [1, 4, 7, 8, 11, 27, 32, 77, 81, 95, 101, 123, 145, 149, 167, 168, 169, 170, 171, 172, 173, 174, 176, 178, 179, 180, 181, 182, 184, 185, 186, 187, 188, 193, 194, 197, 198, 199, 201, 204, 205, 207, 212, 218, 219, 221, 222, 223, 225, 228, 233, 236, 239, 241, 243, 246, 247, 252, 253, 256, 257, 258, 259, 267, 269, 273, 277, 321, 325, 337, 339, 342], "In": [1, 3, 4, 5, 7, 8, 10, 11, 17, 21, 22, 32, 52, 53, 55, 56, 77, 81, 95, 96, 97, 101, 115, 116, 117, 119, 133, 137, 141, 144, 145, 147, 148, 149, 151, 153, 154, 180, 183, 184, 188, 193, 205, 209, 210, 229, 232, 238, 239, 240, 242, 243, 245, 246, 252, 254, 256, 257, 258, 259, 261, 307, 319, 320, 321, 325, 326, 330, 331, 332, 333, 335, 336, 337, 338, 339, 342], "lower": [1, 2, 3, 17, 21, 25, 114, 155, 204, 205, 233, 332, 337], "io": [1, 92, 184, 185], "footprint": [1, 2, 339], "need": [1, 2, 3, 4, 7, 8, 10, 11, 18, 19, 20, 21, 32, 34, 36, 68, 77, 81, 85, 90, 95, 96, 97, 101, 111, 114, 123, 133, 135, 146, 149, 153, 155, 167, 168, 169, 170, 171, 172, 173, 174, 176, 178, 179, 180, 181, 182, 184, 185, 186, 187, 188, 193, 194, 195, 197, 198, 199, 201, 204, 205, 207, 212, 218, 219, 221, 222, 223, 225, 227, 228, 229, 233, 236, 238, 246, 257, 258, 259, 261, 268, 273, 288, 305, 321, 325, 326, 330, 331, 332, 333, 336, 337, 339, 341, 342], "commun": [1, 2, 3, 324, 332, 342], "yet": [1, 338], "spec": [1, 2, 3, 15, 21, 24, 25, 26, 27, 28, 29, 30, 31, 33, 44, 46, 47, 48, 49, 50, 52, 77, 79, 81, 91, 95, 101, 103, 108, 109, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 123, 125, 126, 127, 129, 131, 133, 135, 136, 138, 139, 140, 141, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 154, 157, 161, 165, 177, 203, 205, 214, 218, 219, 220, 221, 222, 223, 225, 226, 227, 228, 229, 230, 232, 233, 239, 240, 242, 243, 245, 246, 252, 256, 257, 258, 259, 261, 267, 314, 325, 330, 331, 332, 333, 335, 336, 341], "plai": [1, 3, 96, 97, 111, 331, 332, 339, 342], "role": [1, 3, 331, 342], "opposit": 1, "direct": [1, 32, 77, 81, 95, 101, 180, 184, 254, 331], "sinc": [1, 2, 3, 4, 5, 7, 32, 35, 38, 41, 42, 56, 67, 77, 81, 95, 96, 97, 101, 164, 167, 168, 169, 170, 171, 172, 173, 174, 176, 178, 179, 180, 181, 182, 184, 185, 186, 187, 188, 193, 194, 197, 198, 199, 201, 204, 205, 207, 212, 218, 219, 220, 221, 222, 223, 225, 227, 228, 233, 236, 330, 331, 332, 333, 337, 338, 339, 341, 342], "faster": [1, 4, 24, 25, 26, 27, 28, 29, 30, 31, 33, 44, 46, 47, 55, 56, 92, 269, 270, 271, 272, 333, 336], "share": [1, 3, 6, 8, 34, 36, 39, 58, 59, 60, 68, 71, 78, 95, 101, 155, 182, 186, 193, 194, 215, 216, 217, 239, 241, 242, 246, 252, 253, 256, 257, 258, 259, 261, 321, 323, 325, 332, 333, 335, 336, 341, 342], "among": [1, 3, 96, 97, 336], "achiev": [1, 3, 4, 32, 77, 81, 85, 95, 101, 144, 165, 302, 327, 330, 331, 332, 333, 336, 337, 342], "via": [1, 4, 7, 8, 35, 38, 41, 42, 52, 53, 54, 55, 56, 95, 133, 148, 153, 244, 254, 326, 327, 330, 331, 332, 333, 339, 342], "prohibit": [1, 3], "slow": [1, 3, 4, 34, 36, 39], "compar": [1, 3, 301, 326, 330, 332, 336, 339, 342], "gpu": [1, 7, 8, 32, 58, 59, 71, 77, 81, 85, 95, 101, 330, 332, 333, 336, 342], "nativ": [1, 7, 9, 53, 77, 81, 95, 101, 111, 333, 339], "driver": [1, 7], "practic": [1, 3, 4, 5, 8, 183, 209, 210, 238, 324, 330, 331, 332, 333, 336, 338, 342], "mean": [1, 2, 3, 4, 7, 13, 14, 16, 18, 19, 20, 21, 34, 36, 39, 41, 61, 81, 129, 155, 166, 175, 178, 180, 182, 184, 186, 187, 190, 208, 218, 226, 230, 269, 270, 271, 272, 274, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 325, 326, 330, 331, 332, 336, 337, 339, 341, 342], "keyword": [1, 3, 13, 14, 16, 18, 19, 20, 21, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 41, 42, 44, 46, 47, 53, 55, 56, 57, 66, 67, 77, 81, 95, 101, 114, 115, 133, 141, 145, 147, 148, 149, 151, 153, 182, 186, 191, 192, 214, 218, 219, 220, 222, 223, 225, 226, 227, 229, 230, 233, 239, 240, 241, 242, 243, 244, 245, 246, 251, 252, 253, 255, 256, 257, 258, 259, 261, 263, 267, 269, 270, 271, 272, 273, 277, 318, 330, 331, 332, 336, 339, 342], "build": [1, 3, 7, 23, 26, 32, 35, 38, 41, 42, 52, 53, 54, 55, 56, 77, 81, 95, 98, 101, 137, 155, 166, 182, 186, 190, 224, 226, 230, 305, 312, 313, 315, 316, 325, 327, 332, 333, 336, 337, 338, 341, 342], "given": [1, 2, 3, 13, 14, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 35, 38, 40, 41, 42, 44, 46, 47, 48, 49, 52, 53, 54, 55, 56, 66, 67, 77, 81, 91, 95, 101, 115, 118, 129, 133, 145, 148, 149, 151, 153, 164, 166, 177, 178, 180, 184, 190, 203, 207, 214, 220, 221, 222, 225, 228, 229, 230, 231, 232, 234, 238, 242, 243, 245, 268, 269, 270, 271, 272, 273, 275, 297, 301, 317, 325, 327, 330, 331, 332, 336, 337, 342], "mani": [1, 3, 4, 38, 77, 239, 241, 246, 253, 256, 257, 261, 325, 330, 331, 332, 336, 337, 339, 342], "eg": [1, 2, 3, 11, 34, 36, 39, 58, 59, 60, 68, 71, 77, 81, 85, 95, 101, 118, 143, 149, 193, 219], "gymnasium": [1, 3, 5, 11, 77, 81, 88, 89, 95, 101, 105, 107, 121, 141, 143, 154, 331, 332, 337, 341], "other": [1, 2, 3, 4, 7, 8, 21, 22, 32, 35, 38, 41, 42, 45, 52, 53, 55, 56, 58, 59, 60, 65, 66, 67, 68, 71, 77, 81, 91, 95, 101, 114, 117, 118, 141, 147, 151, 155, 180, 182, 186, 196, 197, 219, 221, 222, 228, 230, 239, 240, 241, 246, 247, 248, 249, 250, 252, 253, 254, 256, 257, 258, 259, 261, 267, 269, 302, 314, 319, 320, 325, 327, 330, 331, 332, 333, 336, 337, 338, 339, 341, 342], "warn": [1, 3, 218, 222, 223, 225, 331], "quickli": [1, 3, 331, 336, 342], "becom": [1, 3, 4, 21, 180, 184, 336, 342], "quit": [1, 3, 325, 330, 331, 332, 336, 342], "annoi": [1, 3], "By": [1, 2, 3, 33, 77, 81, 95, 96, 97, 101, 103, 212, 230, 254, 301, 321, 330, 338, 339, 342], "filter": [1, 3, 4, 45, 239, 240, 242, 246, 252, 256, 257, 259], "out": [1, 3, 4, 5, 9, 21, 32, 34, 36, 39, 45, 52, 77, 81, 95, 96, 97, 101, 145, 157, 180, 181, 184, 191, 192, 195, 196, 214, 219, 220, 221, 225, 226, 227, 228, 229, 230, 265, 266, 327, 330, 331, 332, 333, 336, 337, 339, 341, 342], "If": [1, 3, 4, 5, 6, 7, 8, 10, 11, 13, 14, 16, 17, 18, 19, 20, 21, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 41, 42, 44, 45, 46, 47, 52, 53, 54, 55, 56, 57, 58, 59, 65, 66, 67, 69, 71, 77, 78, 81, 85, 91, 95, 96, 97, 101, 103, 105, 111, 112, 113, 114, 116, 117, 118, 119, 121, 123, 127, 128, 129, 133, 134, 136, 137, 140, 141, 144, 145, 146, 147, 148, 149, 151, 153, 155, 164, 165, 167, 168, 180, 181, 182, 184, 185, 186, 187, 188, 191, 192, 193, 194, 212, 214, 218, 219, 220, 221, 222, 223, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 236, 238, 239, 240, 241, 242, 243, 245, 246, 247, 248, 249, 252, 253, 254, 256, 257, 258, 259, 261, 267, 268, 269, 270, 271, 272, 273, 283, 284, 285, 286, 292, 300, 302, 305, 307, 309, 314, 317, 321, 324, 330, 331, 332, 333, 335, 336, 337, 339, 341, 342], "still": [1, 2, 3, 9, 218, 253, 254, 330, 331, 333, 335, 337, 339, 342], "wish": [1, 3, 107, 339], "see": [1, 3, 6, 7, 8, 9, 13, 14, 16, 17, 18, 19, 20, 21, 32, 35, 38, 41, 42, 43, 52, 53, 54, 55, 56, 57, 66, 77, 81, 84, 92, 95, 96, 97, 101, 103, 115, 133, 145, 147, 148, 149, 151, 153, 156, 167, 168, 180, 183, 184, 188, 194, 195, 202, 210, 211, 215, 217, 229, 230, 302, 330, 331, 332, 333, 336, 337, 339, 342], "displai": [1, 3, 7, 305, 327, 330, 331, 336, 337], "filter_warnings_subprocess": [1, 3], "fals": [1, 3, 13, 14, 16, 17, 18, 19, 20, 21, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 52, 53, 54, 55, 56, 57, 58, 59, 65, 66, 67, 71, 74, 75, 77, 78, 81, 87, 90, 91, 94, 95, 96, 97, 99, 100, 101, 102, 103, 108, 111, 112, 115, 116, 119, 120, 121, 123, 126, 127, 128, 129, 131, 133, 134, 135, 137, 139, 141, 143, 145, 147, 148, 149, 150, 151, 153, 155, 157, 164, 165, 166, 167, 168, 170, 177, 180, 181, 182, 183, 184, 185, 186, 188, 190, 191, 192, 193, 194, 202, 203, 209, 210, 211, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 225, 226, 227, 228, 229, 230, 232, 233, 234, 239, 240, 241, 242, 243, 245, 246, 248, 249, 250, 252, 253, 254, 255, 256, 257, 258, 259, 261, 264, 267, 269, 270, 271, 272, 278, 279, 280, 281, 283, 284, 285, 286, 298, 299, 301, 302, 303, 305, 314, 321, 325, 327, 330, 331, 332, 333, 335, 336, 337, 338, 339, 341, 342], "central": [2, 193, 330, 331, 336, 339], "part": [2, 4, 8, 32, 40, 53, 55, 56, 77, 81, 95, 101, 129, 137, 140, 182, 186, 234, 296, 321, 330, 332, 333, 337, 342], "algorithm": [2, 3, 8, 9, 13, 14, 91, 124, 239, 256, 257, 258, 259, 296, 310, 323, 326, 327, 330, 331, 332, 333, 336, 338, 339, 341], "implement": [2, 3, 9, 11, 16, 32, 68, 77, 81, 92, 95, 101, 115, 116, 117, 121, 127, 135, 141, 143, 148, 155, 167, 180, 181, 182, 183, 184, 185, 186, 208, 209, 210, 239, 240, 244, 245, 252, 254, 255, 256, 259, 314, 325, 327, 330, 331, 332, 333, 337, 341], "wide": [2, 3, 5], "we": [2, 3, 5, 7, 9, 11, 26, 32, 34, 36, 39, 40, 42, 52, 56, 65, 67, 77, 78, 81, 85, 95, 101, 111, 127, 133, 135, 151, 154, 155, 166, 186, 187, 193, 194, 239, 240, 242, 243, 245, 246, 247, 248, 252, 254, 256, 257, 258, 259, 261, 267, 324, 325, 326, 327, 330, 331, 332, 333, 335, 336, 337, 338, 339, 341, 342], "give": [2, 3, 7, 41, 77, 81, 91, 95, 101, 111, 324, 326, 330, 331, 336, 337, 338, 341], "abil": [2, 254, 337, 339], "veri": [2, 3, 331, 337, 339, 341, 342], "influenti": 2, "sampl": [2, 4, 8, 9, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 38, 40, 41, 42, 44, 46, 47, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 65, 66, 67, 69, 71, 77, 81, 91, 94, 95, 101, 110, 111, 134, 137, 158, 159, 162, 163, 166, 175, 183, 190, 191, 192, 200, 201, 204, 209, 210, 214, 218, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 239, 240, 241, 242, 243, 245, 253, 255, 256, 261, 296, 302, 305, 308, 325, 330, 331, 332, 333, 336, 338, 341, 342], "latenc": 2, "especi": [2, 3, 7, 8, 112], "larger": [2, 4, 252], "volum": 2, "lazymemmapstorag": [2, 35, 38, 41, 42, 52, 53, 54, 55, 56, 66, 67, 110, 111, 323, 330, 331, 333, 338, 339], "advis": [2, 342], "due": [2, 3, 5, 338, 339, 342], "serialis": [2, 34, 36, 39], "memmaptensor": 2, "well": [2, 3, 8, 17, 21, 32, 35, 37, 38, 41, 42, 68, 77, 81, 95, 101, 184, 204, 205, 254, 273, 330, 331, 333, 338, 339, 341, 342], "specifi": [2, 11, 13, 14, 21, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 41, 42, 44, 46, 47, 52, 53, 54, 55, 56, 77, 81, 95, 96, 97, 101, 103, 116, 117, 119, 140, 142, 144, 150, 166, 184, 229, 230, 254, 260, 325, 330, 332, 333], "file": [2, 6, 7, 8, 34, 36, 39, 52, 53, 55, 56, 287, 327, 329, 331, 339, 340], "locat": [2, 7, 34, 36, 39, 45, 56, 77, 81, 95, 101, 120, 129, 139, 183, 197, 209, 210, 296, 297, 298, 299, 300, 301, 302, 303, 304, 306, 307, 330, 331, 332, 336, 339], "improv": [2, 4, 124, 239, 326, 336, 339], "failur": [2, 4], "recoveri": 2, "liststorag": [2, 35, 38, 41, 42, 323, 339], "were": [2, 7, 95, 101, 332, 339], "found": [2, 3, 6, 7, 10, 21, 26, 32, 34, 36, 39, 45, 52, 53, 55, 56, 66, 67, 77, 81, 85, 95, 101, 108, 111, 137, 140, 146, 155, 165, 222, 223, 226, 230, 253, 254, 256, 330, 331, 333], "rough": 2, "benchmark": [2, 3, 9], "http": [2, 5, 6, 7, 10, 18, 19, 20, 35, 43, 54, 55, 56, 61, 85, 92, 96, 97, 98, 111, 133, 151, 169, 170, 171, 172, 173, 174, 177, 178, 179, 184, 190, 191, 192, 196, 198, 199, 201, 202, 204, 205, 211, 221, 225, 239, 240, 243, 244, 245, 247, 248, 249, 250, 251, 252, 255, 256, 257, 258, 259, 260, 269, 274, 282, 314, 338, 341], "github": [2, 5, 6, 7, 10, 18, 19, 20, 53, 96, 97, 98, 151, 341], "com": [2, 5, 6, 7, 10, 18, 19, 20, 55, 85, 96, 97, 98, 338, 341], "tree": [2, 34, 36, 39, 77, 81, 95, 101], "type": [2, 3, 14, 18, 19, 20, 21, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 56, 57, 77, 81, 90, 91, 95, 96, 97, 101, 115, 116, 117, 120, 121, 127, 133, 135, 141, 143, 145, 148, 149, 151, 153, 155, 159, 163, 167, 168, 188, 193, 194, 196, 202, 211, 218, 220, 226, 229, 230, 239, 240, 242, 243, 245, 246, 247, 248, 252, 254, 256, 257, 258, 259, 261, 263, 267, 275, 314, 319, 325, 330, 331, 332, 336, 337, 339, 342], "1x": 2, "lazytensorstorag": [2, 41, 42, 69, 137, 323, 332, 336, 339], "83x": 2, "3": [2, 3, 6, 7, 10, 11, 13, 14, 15, 16, 17, 21, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 38, 39, 41, 42, 52, 53, 54, 55, 56, 66, 67, 77, 81, 84, 90, 92, 94, 95, 96, 97, 99, 100, 101, 108, 111, 115, 118, 120, 121, 127, 129, 131, 133, 135, 137, 140, 141, 143, 144, 145, 147, 148, 149, 151, 153, 161, 166, 167, 168, 170, 171, 174, 177, 179, 180, 181, 182, 184, 185, 186, 187, 188, 190, 193, 194, 197, 200, 202, 212, 214, 215, 216, 217, 220, 221, 226, 228, 229, 232, 233, 234, 239, 240, 242, 243, 245, 246, 247, 248, 249, 252, 254, 256, 257, 258, 259, 261, 267, 269, 270, 271, 272, 275, 278, 279, 280, 281, 283, 284, 285, 286, 288, 304, 325, 327, 330, 331, 332, 333, 336, 337, 338, 339, 341, 342], "44x": 2, "between": [2, 3, 4, 5, 13, 14, 16, 17, 21, 32, 40, 65, 67, 77, 81, 95, 101, 118, 128, 138, 149, 157, 167, 168, 180, 182, 186, 188, 193, 194, 221, 226, 230, 239, 241, 242, 245, 246, 249, 250, 252, 253, 254, 256, 257, 258, 259, 261, 264, 269, 301, 305, 326, 330, 331, 333, 336, 337, 342], "long": [2, 3, 13, 14, 16, 17, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 36, 37, 39, 44, 46, 47, 118, 184, 185, 333, 339], "sharabl": 2, "featur": [2, 3, 4, 13, 14, 16, 17, 18, 19, 20, 21, 33, 45, 53, 66, 67, 77, 81, 90, 95, 96, 97, 99, 100, 101, 111, 123, 127, 131, 145, 146, 150, 155, 167, 168, 178, 179, 180, 181, 182, 184, 185, 186, 188, 195, 196, 230, 269, 270, 271, 272, 273, 274, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 321, 325, 330, 331, 332, 333, 337, 339, 342], "allow": [2, 3, 13, 14, 16, 17, 18, 19, 20, 21, 26, 28, 29, 32, 33, 66, 67, 77, 81, 95, 101, 135, 164, 188, 239, 240, 242, 243, 245, 246, 247, 248, 252, 254, 256, 257, 258, 259, 261, 262, 264, 267, 325, 327, 330, 332, 333, 336, 337, 339, 342], "popul": [2, 3, 35, 38, 41, 42, 52, 53, 54, 55, 56, 126, 145, 330, 332, 333, 337, 339], "collabor": 2, "rather": [2, 4, 135, 330, 331, 332, 336], "incur": 2, "some": [2, 3, 4, 7, 8, 9, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 38, 44, 45, 46, 47, 52, 53, 55, 56, 58, 59, 69, 71, 77, 81, 95, 96, 97, 101, 103, 133, 149, 151, 157, 170, 182, 186, 207, 230, 231, 232, 296, 308, 325, 327, 330, 331, 332, 333, 336, 337, 339, 341, 342], "transmiss": 2, "overhead": [2, 95, 101], "includ": [2, 3, 4, 7, 9, 21, 32, 56, 58, 59, 60, 68, 71, 77, 81, 91, 95, 101, 144, 149, 155, 254, 259, 308, 325, 327, 330, 331, 332, 333, 336, 337, 339, 342], "ani": [2, 3, 5, 8, 26, 28, 32, 34, 35, 36, 38, 39, 41, 42, 52, 53, 54, 55, 56, 58, 59, 60, 63, 65, 67, 68, 69, 70, 71, 72, 77, 78, 81, 95, 96, 97, 101, 103, 108, 123, 133, 134, 137, 149, 151, 155, 157, 165, 167, 168, 174, 188, 196, 219, 229, 230, 231, 232, 239, 240, 242, 243, 245, 246, 252, 254, 256, 257, 258, 259, 261, 269, 293, 305, 324, 330, 331, 332, 336, 337, 339, 341, 342], "subclass": [2, 3, 77, 81, 95, 101, 148, 154, 157, 167, 168, 169, 170, 171, 172, 173, 174, 176, 178, 179, 180, 181, 182, 184, 185, 186, 187, 188, 193, 194, 197, 198, 199, 201, 204, 205, 207, 212, 218, 219, 221, 222, 223, 225, 228, 229, 230, 231, 233, 236, 254, 256, 331, 333, 337, 339], "tensorstorag": [2, 323], "instanti": [2, 3, 21, 34, 36, 39, 85, 148, 194, 330, 331, 336, 337, 339, 342], "content": [2, 8, 13, 14, 16, 26, 28, 34, 35, 36, 38, 39, 41, 42, 65, 92, 167, 168, 188, 193, 194, 226, 254, 332, 337, 341], "map": [2, 3, 8, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 41, 42, 44, 45, 46, 47, 52, 53, 54, 55, 56, 57, 58, 77, 81, 90, 95, 96, 97, 99, 100, 101, 103, 104, 109, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 123, 125, 126, 127, 129, 131, 135, 136, 138, 139, 140, 141, 143, 144, 145, 146, 147, 148, 150, 151, 152, 154, 155, 161, 177, 197, 214, 215, 216, 217, 220, 226, 227, 229, 230, 232, 233, 234, 235, 259, 267, 301, 323, 325, 326, 330, 331, 332, 333, 338], "tensor": [2, 3, 8, 13, 14, 16, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 52, 53, 54, 55, 56, 57, 58, 59, 61, 63, 66, 67, 69, 70, 71, 72, 74, 77, 78, 81, 87, 90, 91, 94, 95, 96, 97, 99, 100, 101, 102, 103, 108, 110, 111, 112, 115, 116, 118, 119, 120, 121, 123, 126, 129, 131, 133, 134, 135, 137, 139, 140, 141, 143, 144, 145, 146, 147, 148, 149, 150, 151, 153, 155, 161, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 177, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 197, 200, 201, 202, 203, 206, 207, 208, 209, 210, 211, 214, 215, 216, 217, 219, 220, 221, 222, 223, 225, 226, 227, 228, 229, 230, 232, 233, 234, 236, 237, 239, 240, 242, 243, 245, 246, 249, 250, 252, 254, 256, 257, 258, 259, 261, 264, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 288, 314, 325, 327, 330, 331, 332, 333, 335, 336, 337, 338, 339, 341, 342], "writer": [2, 38, 42, 52, 53, 54, 55, 56, 63, 69, 70, 323, 332], "tensordictroundrobinwrit": [2, 323], "current": [2, 3, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 40, 44, 46, 47, 67, 77, 81, 83, 92, 95, 101, 111, 134, 144, 145, 146, 148, 149, 158, 159, 164, 178, 187, 205, 225, 247, 259, 291, 327, 330, 331, 332, 333, 336, 337, 341, 342], "goe": [2, 4, 96, 97, 330, 332, 336, 342], "sampler": [2, 35, 38, 41, 42, 52, 53, 54, 55, 56, 58, 59, 60, 61, 62, 65, 66, 67, 68, 69, 71, 134, 243, 247, 267, 323, 330, 332, 336, 339], "prioritizedsampl": [2, 35, 38, 41, 42, 52, 53, 54, 55, 56, 243, 247, 267, 323, 330, 339], "extend": [2, 8, 24, 25, 26, 27, 28, 29, 30, 31, 33, 35, 38, 41, 42, 44, 46, 47, 52, 53, 54, 55, 56, 63, 66, 67, 69, 70, 72, 110, 137, 302, 327, 330, 331, 332, 333, 336, 338, 339, 341], "access": [2, 3, 7, 8, 32, 35, 54, 77, 81, 95, 101, 133, 151, 321, 324, 330, 336, 337, 339], "show": [2, 32, 77, 81, 95, 101, 194, 325, 330, 332, 333, 336, 337, 339, 341], "import": [2, 3, 4, 6, 10, 11, 13, 14, 15, 16, 17, 21, 22, 35, 37, 38, 40, 41, 42, 43, 45, 52, 53, 54, 55, 56, 57, 58, 59, 61, 66, 67, 69, 71, 77, 78, 81, 89, 91, 95, 96, 97, 99, 100, 101, 104, 105, 107, 108, 110, 111, 114, 120, 121, 126, 127, 129, 131, 133, 135, 136, 137, 140, 141, 143, 144, 145, 146, 148, 153, 155, 161, 164, 165, 166, 177, 180, 181, 182, 184, 185, 186, 188, 190, 193, 194, 197, 202, 203, 211, 214, 215, 216, 217, 219, 220, 221, 222, 223, 225, 226, 227, 228, 229, 232, 233, 234, 239, 240, 241, 242, 243, 245, 246, 247, 248, 252, 254, 256, 257, 258, 259, 261, 267, 269, 270, 271, 272, 298, 301, 314, 317, 325, 326, 331, 332, 333, 335, 336, 337, 338, 339, 341, 342], "tensordictreplaybuff": [2, 35, 38, 41, 52, 53, 54, 55, 56, 66, 67, 69, 110, 111, 302, 317, 323, 330, 331, 333, 339], "mp": [2, 18, 19, 20, 78, 155], "def": [2, 3, 11, 22, 32, 77, 78, 81, 91, 95, 101, 107, 108, 116, 119, 166, 177, 180, 181, 184, 185, 190, 226, 234, 240, 242, 246, 252, 254, 257, 259, 261, 327, 330, 331, 335, 336, 337, 341, 342], "rb": [2, 35, 38, 41, 42, 52, 53, 54, 55, 56, 66, 67, 69, 111, 137, 331, 333, 336, 338, 339, 341], "updat": [2, 3, 4, 8, 12, 13, 14, 16, 17, 18, 19, 20, 21, 32, 34, 35, 36, 39, 40, 41, 61, 77, 81, 91, 95, 96, 97, 101, 108, 116, 118, 119, 143, 144, 149, 152, 155, 165, 166, 180, 182, 186, 190, 218, 222, 223, 225, 226, 227, 228, 229, 230, 239, 240, 242, 243, 245, 246, 247, 248, 251, 252, 254, 256, 257, 258, 259, 260, 261, 267, 269, 270, 271, 272, 273, 301, 305, 307, 310, 311, 316, 317, 327, 331, 332, 333, 336, 337, 339, 341, 342], "td": [2, 3, 15, 26, 34, 35, 36, 38, 39, 41, 42, 52, 53, 54, 55, 56, 69, 73, 74, 75, 76, 80, 82, 86, 87, 88, 89, 108, 110, 112, 116, 117, 118, 119, 126, 127, 129, 137, 140, 145, 147, 149, 155, 164, 166, 177, 182, 186, 189, 190, 202, 203, 211, 214, 215, 216, 217, 219, 220, 222, 223, 225, 226, 227, 229, 232, 234, 267, 270, 271, 272, 276, 277, 278, 279, 280, 281, 283, 284, 285, 286, 287, 296, 304, 314, 325, 326, 330, 333, 336, 337, 341, 342], "10": [2, 7, 22, 26, 35, 38, 40, 41, 42, 43, 45, 58, 59, 66, 67, 69, 71, 78, 91, 96, 97, 99, 100, 102, 103, 108, 110, 111, 144, 146, 147, 166, 169, 174, 180, 181, 184, 185, 187, 190, 201, 212, 222, 223, 225, 226, 233, 240, 243, 245, 246, 256, 257, 258, 261, 267, 269, 270, 271, 272, 275, 296, 327, 330, 331, 332, 333, 336, 337, 339, 341, 342], "__name__": [2, 22, 78, 331], "__main__": [2, 22, 78], "21": [2, 55, 67, 96, 97, 331, 332, 335, 337, 338], "zero": [2, 3, 4, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 39, 41, 42, 44, 45, 46, 47, 52, 59, 66, 67, 71, 77, 81, 95, 101, 110, 112, 116, 118, 119, 129, 137, 161, 164, 166, 180, 181, 182, 184, 185, 186, 187, 191, 192, 194, 202, 211, 222, 223, 225, 228, 236, 239, 240, 242, 243, 245, 246, 252, 256, 257, 258, 259, 261, 267, 269, 270, 271, 272, 275, 333, 341], "proc": 2, "target": [2, 4, 8, 21, 32, 77, 78, 81, 95, 101, 144, 148, 229, 230, 239, 240, 241, 242, 243, 245, 246, 247, 250, 251, 253, 254, 255, 256, 257, 258, 259, 260, 261, 267, 268, 269, 270, 271, 272, 273, 308, 316, 317, 326, 327, 333, 337], "arg": [2, 12, 14, 26, 28, 32, 58, 59, 71, 73, 74, 75, 76, 77, 78, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 106, 108, 115, 133, 142, 145, 148, 149, 150, 152, 153, 166, 167, 168, 176, 182, 186, 188, 189, 190, 212, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 252, 253, 254, 255, 256, 257, 258, 259, 261, 267, 269, 270, 271, 272, 273, 295, 298, 302, 305, 321, 331], "start": [2, 3, 4, 5, 13, 21, 45, 56, 66, 67, 78, 90, 164, 300, 330, 331, 336, 337, 339, 342], "join": [2, 78, 323, 331, 332], "now": [2, 3, 7, 35, 111, 194, 330, 331, 332, 333, 335, 336, 338, 339, 342], "length": [2, 17, 20, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 36, 37, 40, 43, 44, 45, 46, 47, 57, 66, 67, 77, 81, 95, 101, 134, 155, 166, 167, 168, 170, 172, 174, 176, 180, 184, 188, 190, 193, 194, 214, 229, 234, 296, 302, 330, 332, 333, 337, 339, 342], "20": [2, 45, 55, 66, 67, 69, 77, 81, 85, 95, 101, 144, 180, 181, 184, 185, 219, 296, 330, 331, 332, 333, 336, 337, 341, 342], "assert": [2, 3, 6, 16, 24, 25, 26, 27, 28, 29, 30, 31, 33, 35, 38, 41, 42, 44, 46, 47, 52, 53, 54, 55, 56, 81, 84, 107, 111, 114, 116, 119, 127, 135, 155, 157, 161, 194, 197, 212, 269, 270, 271, 272, 296, 304, 335, 339, 342], "len": [2, 35, 38, 41, 42, 52, 53, 54, 55, 56, 58, 59, 71, 131, 167, 168, 188, 194, 330, 337, 338, 339, 341], "_data": [2, 337], "0": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 21, 22, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 49, 52, 53, 54, 55, 56, 57, 58, 59, 61, 66, 67, 71, 74, 77, 81, 84, 87, 91, 95, 98, 99, 100, 101, 108, 109, 111, 112, 114, 115, 117, 118, 127, 128, 129, 133, 137, 140, 144, 145, 146, 147, 148, 149, 151, 153, 154, 155, 157, 166, 167, 168, 170, 171, 173, 174, 178, 180, 182, 183, 184, 185, 186, 188, 190, 192, 193, 194, 195, 196, 197, 200, 204, 205, 208, 209, 210, 212, 214, 218, 219, 221, 222, 223, 225, 228, 229, 232, 233, 236, 239, 240, 241, 242, 243, 245, 246, 247, 248, 249, 250, 252, 253, 254, 255, 256, 257, 258, 259, 261, 262, 263, 267, 268, 269, 270, 271, 272, 275, 276, 277, 296, 303, 317, 321, 326, 327, 329, 330, 331, 332, 333, 335, 336, 337, 338, 339, 340, 341, 342], "too": [2, 7, 13, 14, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 36, 37, 39, 40, 44, 46, 47, 95, 101, 128, 145, 183, 209, 210, 239, 240, 241, 242, 243, 245, 246, 247, 248, 249, 250, 252, 253, 254, 256, 257, 258, 259, 261, 267, 269, 270, 271, 272, 331, 332, 337, 339, 342], "difficult": [2, 4], "element": [2, 13, 14, 16, 18, 19, 20, 21, 30, 31, 33, 35, 38, 41, 42, 52, 53, 54, 55, 56, 58, 59, 60, 61, 67, 69, 71, 94, 111, 134, 144, 167, 168, 180, 181, 184, 214, 218, 220, 229, 230, 234, 296, 330, 332, 339, 342], "pai": [2, 8, 330, 333], "attent": [2, 8, 330, 333, 342], "alwai": [2, 3, 20, 26, 28, 32, 57, 77, 81, 95, 101, 127, 128, 247, 254, 325, 326, 331, 332, 333, 336, 337, 339], "lead": [2, 3, 4, 8, 10, 11, 26, 28, 32, 34, 35, 36, 38, 39, 41, 42, 52, 65, 145, 183, 202, 209, 210, 330, 333, 336, 337, 339, 341], "dimens": [2, 3, 16, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 39, 40, 44, 45, 46, 47, 52, 53, 55, 56, 58, 59, 66, 67, 69, 71, 77, 81, 95, 101, 103, 110, 111, 112, 123, 129, 131, 134, 140, 142, 147, 150, 155, 167, 168, 169, 174, 182, 184, 186, 188, 191, 192, 193, 195, 196, 201, 202, 206, 207, 208, 209, 212, 220, 239, 240, 241, 246, 247, 248, 249, 250, 252, 253, 254, 256, 257, 258, 259, 261, 267, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 321, 325, 330, 331, 332, 333, 336, 337, 339], "word": [2, 3, 40, 52, 53, 55, 56, 254, 330, 337, 342], "creat": [2, 3, 4, 5, 6, 7, 10, 13, 14, 16, 17, 18, 19, 20, 21, 26, 28, 32, 34, 35, 36, 38, 39, 41, 42, 45, 56, 57, 77, 78, 81, 85, 92, 95, 96, 101, 111, 133, 148, 149, 151, 154, 155, 161, 164, 167, 168, 170, 171, 172, 173, 174, 179, 182, 186, 188, 189, 193, 194, 219, 230, 243, 247, 257, 259, 267, 288, 302, 309, 310, 311, 317, 319, 320, 325, 330, 331, 332, 333, 336, 337, 338, 339, 341, 342], "1m": [2, 308, 330, 332, 333, 338], "multidimension": [2, 41, 61, 339], "doe": [2, 3, 18, 34, 35, 36, 39, 41, 45, 52, 61, 68, 174, 180, 181, 182, 184, 185, 186, 195, 212, 219, 231, 232, 239, 241, 247, 253, 256, 268, 305, 325, 327, 330, 331, 332, 333, 337, 339, 342], "howev": [2, 3, 5, 7, 32, 77, 81, 95, 101, 111, 140, 144, 149, 259, 325, 330, 331, 332, 333, 337, 339, 342], "episod": [2, 52, 55, 56, 66, 67, 81, 137, 140, 144, 166, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 331, 336], "flatten": [2, 34, 36, 39, 123, 302, 333, 336], "capac": [2, 332], "desir": [2, 3, 32, 77, 81, 95, 101, 115, 129, 131, 133, 134, 145, 148, 149, 151, 153, 162, 163, 167, 168, 188, 194, 214, 220, 221, 226, 227, 228, 229, 230, 325, 330, 336, 337], "diversifi": 2, "make": [2, 3, 4, 7, 32, 34, 36, 39, 40, 52, 53, 54, 55, 56, 68, 77, 81, 82, 85, 87, 89, 92, 95, 101, 121, 129, 133, 134, 137, 143, 151, 157, 180, 181, 184, 185, 193, 194, 195, 220, 230, 256, 269, 270, 271, 272, 302, 311, 321, 325, 326, 330, 331, 332, 333, 335, 336, 337, 338, 339, 341, 342], "offer": [2, 3, 7, 325, 331, 337, 342], "distinct": [2, 3, 335], "accomplish": 2, "slicesampl": [2, 323], "slice": [2, 3, 24, 25, 26, 27, 28, 29, 30, 31, 33, 44, 46, 47, 52, 66, 67, 110], "anoth": [2, 3, 8, 34, 36, 39, 77, 81, 85, 95, 101, 116, 117, 119, 145, 148, 188, 239, 240, 241, 246, 247, 248, 249, 250, 252, 253, 254, 256, 257, 258, 259, 261, 267, 296, 297, 298, 299, 300, 301, 302, 303, 304, 306, 307, 325, 326, 330, 332, 333, 335, 336, 337, 342], "recommend": [2, 4, 7, 34, 36, 39, 85, 336], "__especially__": 2, "offlin": [2, 8, 13, 14, 16, 17, 18, 19, 20, 21, 111, 157, 240, 245, 252, 327, 338, 339, 341], "convent": [2, 3, 103, 326, 330, 333, 336, 337], "requir": [2, 3, 4, 7, 8, 16, 18, 19, 20, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 41, 42, 44, 45, 46, 47, 52, 53, 77, 81, 85, 92, 95, 98, 101, 115, 133, 145, 148, 149, 151, 153, 188, 212, 229, 231, 232, 239, 240, 241, 246, 247, 248, 249, 250, 252, 253, 254, 256, 257, 258, 259, 261, 267, 325, 327, 330, 331, 332, 333, 336, 337, 339, 342], "reshap": [2, 32, 66, 182, 186, 188, 332, 336], "extens": [2, 67, 327, 339], "detail": [2, 3, 5, 6, 7, 32, 77, 81, 95, 96, 97, 101, 147, 149, 177, 180, 184, 221, 239, 247, 256, 324, 331, 335, 339], "independ": [2, 13, 14, 16, 17, 18, 19, 20, 21, 148, 150, 194, 326, 327, 330, 331, 336, 339, 341], "differ": [2, 3, 4, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 39, 40, 44, 45, 46, 47, 52, 77, 81, 90, 95, 96, 97, 101, 111, 118, 129, 135, 149, 150, 177, 180, 181, 182, 184, 185, 186, 188, 190, 193, 194, 203, 252, 256, 264, 269, 270, 271, 275, 276, 277, 301, 305, 307, 319, 320, 325, 326, 327, 330, 331, 332, 335, 336, 337, 338, 339, 342], "congruent": 2, "shape": [2, 3, 13, 14, 16, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 52, 53, 55, 56, 57, 58, 59, 71, 77, 81, 90, 94, 95, 96, 97, 99, 100, 101, 102, 103, 110, 112, 116, 119, 120, 121, 127, 129, 131, 135, 137, 141, 143, 145, 147, 155, 156, 157, 161, 164, 166, 169, 174, 175, 176, 180, 181, 182, 184, 185, 186, 188, 190, 191, 192, 193, 194, 195, 197, 200, 201, 202, 203, 208, 211, 214, 215, 216, 217, 219, 220, 221, 226, 227, 228, 229, 232, 233, 234, 239, 240, 242, 243, 245, 246, 252, 256, 257, 258, 259, 261, 264, 267, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 288, 296, 302, 305, 317, 325, 330, 331, 332, 333, 335, 336, 338, 339, 341, 342], "custom": [2, 3, 5, 32, 77, 81, 95, 101, 151, 193, 194, 233, 247, 256, 262, 321, 325, 330, 331, 332, 333, 336], "name": [2, 3, 6, 7, 11, 16, 32, 34, 36, 39, 45, 52, 54, 56, 57, 75, 77, 81, 90, 92, 95, 96, 97, 98, 101, 103, 104, 118, 121, 135, 140, 141, 143, 149, 151, 154, 165, 182, 186, 220, 227, 239, 240, 241, 246, 247, 248, 249, 250, 252, 253, 254, 256, 257, 258, 259, 261, 267, 273, 290, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 306, 307, 314, 327, 330, 331, 332, 333, 336, 337, 342], "randomcroptensordict": [2, 330], "note": [2, 3, 4, 13, 14, 16, 17, 18, 19, 20, 21, 32, 34, 35, 36, 38, 39, 41, 42, 77, 81, 95, 101, 116, 119, 155, 165, 180, 182, 184, 186, 225, 226, 230, 247, 330, 331, 335, 336, 342], "unlik": [2, 65, 247, 256, 331, 341], "base": [2, 3, 4, 8, 9, 12, 13, 14, 16, 17, 18, 19, 20, 21, 35, 38, 41, 42, 45, 64, 69, 70, 72, 85, 91, 92, 93, 95, 101, 137, 145, 151, 152, 193, 215, 224, 239, 240, 242, 243, 245, 246, 248, 252, 256, 257, 258, 259, 261, 305, 314, 325, 326, 327, 330, 331, 333, 336, 337, 339, 342], "here": [2, 3, 4, 7, 8, 9, 10, 55, 56, 77, 81, 85, 95, 96, 97, 101, 111, 325, 326, 330, 331, 332, 333, 336, 337, 339, 341, 342], "stop": [2, 3, 16, 21, 40, 56, 66, 67, 77, 81, 95, 101, 332, 336, 341, 342], "signal": [2, 3, 17, 52, 53, 55, 56, 66, 67, 81, 111, 120, 143, 146, 165, 326, 330, 332, 336, 339, 342], "isn": [2, 3, 8, 34, 36, 39, 120, 220, 229, 336], "t": [2, 3, 4, 6, 7, 8, 11, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 39, 44, 46, 47, 61, 65, 69, 77, 78, 81, 92, 95, 101, 111, 116, 119, 120, 133, 136, 137, 144, 146, 153, 155, 164, 180, 184, 220, 225, 229, 260, 269, 270, 271, 272, 273, 275, 305, 307, 321, 324, 330, 331, 332, 333, 335, 336, 337, 338, 339, 341, 342], "how": [2, 3, 18, 19, 20, 32, 35, 41, 61, 77, 81, 95, 96, 97, 101, 103, 239, 241, 251, 253, 256, 305, 324, 325, 330, 331, 332, 333, 335, 336, 337, 338, 339, 341, 342], "our": [2, 3, 7, 8, 18, 111, 325, 330, 331, 332, 333, 335, 336, 338, 339, 341], "enjoi": [2, 3], "separ": [2, 4, 8, 13, 14, 17, 18, 20, 21, 23, 133, 153, 240, 242, 245, 246, 257, 259, 261, 330, 331, 336, 339, 342], "save": [2, 8, 32, 34, 35, 36, 38, 39, 41, 42, 52, 53, 54, 55, 56, 77, 81, 95, 101, 154, 287, 305, 327, 336], "disk": [2, 34, 35, 36, 38, 39, 41, 42, 52, 53, 54, 55, 56, 305, 327, 330, 331, 333, 339], "dump": [2, 35, 38, 41, 42, 52, 53, 54, 55, 56, 287], "load": [2, 6, 7, 13, 14, 16, 17, 32, 34, 35, 36, 38, 39, 40, 41, 42, 45, 52, 53, 54, 55, 56, 76, 77, 81, 95, 101, 107, 155, 321, 327, 330, 339], "json": 2, "metadata": [2, 52, 332, 336, 342], "cannot": [2, 3, 4, 7, 22, 26, 27, 28, 31, 33, 66, 67, 77, 81, 85, 95, 101, 116, 119, 134, 140, 227, 331, 332, 333, 336, 337], "anticip": [2, 116, 119], "compli": [2, 24, 25, 26, 27, 28, 29, 30, 31, 33, 44, 46, 47], "structur": [2, 3, 7, 34, 35, 36, 38, 39, 40, 41, 42, 45, 69, 77, 81, 95, 101, 116, 119, 165, 193, 225, 269, 270, 271, 272, 273, 326, 330, 332, 333, 336, 337, 338, 339], "guarante": [2, 32, 34, 36, 39, 58, 59, 60, 68, 71, 77, 81, 95, 101, 155, 341], "back": [2, 24, 25, 26, 27, 28, 29, 30, 31, 33, 35, 44, 46, 47, 52, 154, 214, 220, 221, 226, 227, 228, 229, 230, 332, 336, 337, 339], "exact": [2, 3, 95, 184], "look": [2, 3, 5, 7, 8, 32, 77, 81, 90, 95, 96, 97, 101, 133, 134, 151, 226, 230, 231, 232, 326, 332, 333, 336, 337, 338, 339, 341, 342], "statu": [2, 3], "its": [2, 3, 4, 5, 7, 9, 11, 13, 14, 16, 17, 18, 19, 20, 21, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 39, 41, 44, 46, 47, 49, 77, 81, 91, 95, 96, 97, 101, 104, 110, 111, 120, 127, 143, 144, 148, 149, 154, 155, 167, 168, 191, 192, 193, 194, 218, 220, 226, 227, 230, 233, 239, 240, 241, 246, 247, 248, 249, 250, 252, 253, 254, 255, 256, 257, 258, 259, 261, 267, 305, 317, 327, 330, 331, 332, 333, 336, 337, 338, 339, 342], "prioriti": [2, 4, 35, 41, 42, 58, 59, 60, 61, 68, 71, 242, 243, 245, 246, 247, 252, 257, 259, 261, 267, 327, 330, 331, 339], "max": [2, 23, 33, 36, 41, 45, 57, 61, 118, 146, 208, 209, 210, 219, 225, 240, 241, 246, 255, 257, 259, 330, 332, 333, 336], "heap": 2, "under": [2, 3, 4, 21, 32, 40, 52, 53, 55, 56, 77, 81, 95, 101, 214, 220, 221, 226, 227, 228, 229, 230, 254, 269, 270, 271, 272, 273, 326, 330, 331, 337, 342], "hood": [2, 21, 337], "just": [2, 3, 4, 11, 77, 81, 90, 95, 96, 97, 101, 114, 165, 194, 296, 325, 327, 330, 331, 332, 333, 336, 337, 339, 341, 342], "public": [2, 54, 133, 153], "method": [2, 3, 4, 11, 13, 14, 15, 16, 17, 21, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 45, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 66, 67, 68, 71, 77, 81, 95, 101, 111, 115, 116, 117, 120, 121, 123, 127, 129, 133, 135, 136, 137, 141, 143, 145, 148, 149, 151, 153, 166, 187, 214, 215, 216, 217, 219, 220, 221, 222, 224, 226, 227, 228, 229, 230, 231, 239, 240, 242, 243, 245, 246, 247, 248, 252, 254, 256, 257, 258, 259, 261, 267, 273, 287, 318, 326, 327, 328, 331, 332, 333, 337, 339, 342], "don": [2, 3, 4, 6, 7, 24, 25, 26, 27, 28, 29, 30, 31, 33, 44, 46, 47, 111, 331, 332, 339, 341, 342], "assum": [2, 3, 6, 26, 33, 40, 41, 42, 52, 53, 55, 56, 81, 95, 101, 110, 113, 123, 133, 134, 140, 145, 151, 153, 161, 182, 186, 187, 212, 233, 243, 247, 259, 267, 278, 279, 280, 281, 283, 284, 285, 286, 288, 330, 332, 333, 335, 337], "serializ": 2, "altern": [2, 4, 27, 92, 174, 191, 192, 193, 238, 330, 332, 336], "state_dict": [2, 13, 14, 16, 17, 21, 32, 34, 36, 39, 77, 81, 95, 101, 149, 155, 259, 321, 327, 330, 331, 342], "load_state_dict": [2, 13, 14, 16, 17, 21, 32, 34, 36, 39, 77, 81, 95, 101, 149, 155, 259, 327, 330], "drawback": 2, "struggl": 2, "big": [2, 332, 339, 342], "wrapper": [2, 3, 11, 15, 17, 34, 36, 39, 40, 41, 42, 73, 74, 75, 76, 80, 82, 83, 85, 86, 87, 88, 89, 91, 93, 96, 97, 98, 99, 100, 102, 103, 105, 154, 197, 212, 218, 219, 223, 225, 230, 235, 269, 293, 294, 295, 321, 323, 332, 333, 336, 338, 342], "around": [2, 5, 7, 15, 17, 41, 42, 91, 230, 269, 330, 331, 336, 342], "present": [2, 3, 32, 34, 35, 36, 38, 39, 41, 42, 52, 53, 54, 55, 56, 61, 65, 77, 81, 95, 101, 121, 137, 141, 164, 165, 169, 170, 171, 172, 173, 179, 184, 196, 201, 225, 229, 230, 231, 232, 239, 240, 241, 244, 245, 246, 247, 248, 249, 250, 252, 253, 254, 255, 256, 257, 258, 259, 261, 267, 269, 270, 271, 272, 273, 321, 327, 330, 335, 336, 339, 341], "replaybuff": [2, 41, 42, 72, 111, 134, 137, 243, 247, 267, 315, 317, 323, 332, 336, 338, 339, 341], "promptli": 2, "virtual": [2, 3], "instal": [2, 3, 5, 10, 18, 19, 20, 52, 54, 96, 97, 99, 100, 305, 324, 332, 333, 336, 342], "respons": [2, 3, 8, 305, 342], "d4rl": [2, 52, 53, 55, 56], "clone": [2, 4, 8, 26, 28, 127, 215, 216, 217, 229, 252, 314, 323, 330, 337, 341], "repositori": [2, 7, 53, 54, 56], "latest": [2, 3, 10, 92, 96, 97, 302, 332, 336, 337, 341], "wheel": [2, 332], "publish": 2, "pypi": [2, 341], "openml": [2, 54, 94], "scikit": [2, 54], "panda": [2, 54], "parent": [2, 3, 21, 26, 28, 44, 77, 111, 112, 115, 117, 120, 123, 124, 129, 133, 140, 143, 144, 145, 146, 148, 150, 151, 215, 254, 256, 273, 330, 337, 341, 342], "basic": [2, 91, 325, 332, 342], "properti": [2, 3, 32, 34, 36, 39, 77, 81, 91, 95, 101, 148, 149, 175, 183, 195, 200, 208, 209, 210, 254, 259, 337, 339], "observ": [2, 3, 8, 13, 14, 16, 17, 21, 32, 44, 52, 53, 55, 56, 74, 75, 76, 77, 78, 81, 87, 90, 91, 94, 95, 96, 97, 99, 100, 101, 102, 103, 110, 111, 112, 113, 114, 115, 116, 117, 120, 121, 123, 125, 126, 127, 129, 130, 131, 135, 136, 137, 140, 141, 143, 144, 145, 146, 147, 148, 149, 150, 151, 154, 155, 164, 169, 170, 171, 172, 173, 174, 177, 182, 186, 187, 193, 198, 199, 201, 203, 204, 214, 215, 216, 217, 219, 220, 222, 223, 225, 226, 227, 234, 235, 239, 240, 241, 242, 243, 245, 246, 249, 252, 253, 256, 257, 258, 259, 261, 267, 269, 270, 271, 272, 273, 288, 314, 317, 325, 327, 331, 332, 333, 335, 336, 337, 339, 341, 342], "dtype": [2, 3, 13, 14, 16, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 53, 55, 56, 57, 58, 59, 61, 66, 67, 71, 74, 77, 81, 87, 90, 91, 94, 95, 96, 97, 99, 100, 101, 102, 103, 108, 115, 116, 117, 118, 119, 120, 121, 127, 129, 131, 133, 135, 137, 141, 143, 145, 147, 148, 149, 151, 153, 157, 161, 164, 165, 166, 177, 180, 181, 182, 184, 185, 186, 190, 195, 196, 202, 203, 211, 214, 215, 216, 217, 219, 220, 221, 225, 226, 227, 228, 229, 232, 234, 239, 240, 242, 243, 245, 246, 252, 256, 257, 258, 259, 261, 267, 269, 270, 271, 272, 275, 314, 325, 332, 333, 335, 336, 337, 338, 339, 341, 342], "match": [2, 3, 6, 8, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 44, 46, 47, 52, 53, 54, 55, 56, 77, 78, 81, 95, 101, 109, 111, 112, 113, 114, 115, 116, 117, 118, 120, 121, 123, 125, 126, 127, 129, 131, 135, 136, 138, 139, 140, 141, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 154, 155, 167, 168, 175, 182, 186, 188, 193, 194, 208, 214, 219, 220, 226, 227, 229, 230, 233, 234, 240, 246, 253, 255, 257, 259, 302, 307, 325, 330, 332, 335, 336, 337, 339, 341, 342], "input": [2, 3, 4, 13, 14, 16, 17, 18, 19, 20, 21, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 39, 40, 43, 44, 46, 47, 77, 81, 91, 94, 95, 96, 97, 98, 101, 103, 108, 110, 111, 112, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 126, 127, 129, 131, 132, 133, 134, 135, 137, 140, 141, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 157, 164, 165, 167, 168, 170, 171, 172, 173, 176, 177, 180, 181, 182, 184, 185, 186, 187, 188, 193, 194, 195, 196, 203, 204, 205, 206, 207, 212, 214, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 238, 239, 240, 241, 246, 247, 248, 249, 250, 252, 253, 254, 256, 257, 258, 259, 261, 267, 268, 269, 270, 271, 272, 274, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 299, 303, 308, 317, 325, 326, 327, 330, 331, 332, 333, 336, 337, 341, 342], "output": [2, 3, 4, 13, 14, 16, 17, 32, 35, 38, 41, 42, 52, 53, 54, 55, 56, 66, 67, 77, 81, 91, 94, 95, 96, 97, 98, 101, 103, 111, 114, 115, 116, 117, 119, 121, 127, 129, 133, 135, 140, 141, 143, 146, 148, 151, 153, 154, 157, 165, 167, 168, 169, 170, 171, 174, 176, 177, 178, 180, 181, 182, 184, 185, 186, 187, 188, 193, 194, 197, 203, 212, 214, 215, 218, 219, 220, 221, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 239, 240, 241, 242, 246, 247, 248, 249, 250, 252, 253, 254, 256, 257, 258, 259, 261, 267, 269, 270, 271, 272, 273, 288, 296, 325, 326, 330, 331, 332, 333, 335, 336, 337, 338, 341, 342], "send": [2, 3, 8, 341], "receiv": [2, 3, 32, 40, 77, 81, 95, 101, 148, 188, 275, 326, 330, 332, 335, 337], "spawn": [2, 3, 4, 18, 22, 85, 92, 336], "check_env_spec": [2, 3, 323, 332, 336, 337], "saniti": [2, 3, 7, 157, 332], "utmost": 2, "techniqu": [2, 8, 331, 339], "commonli": [2, 66, 67, 342], "emploi": [2, 196], "realm": 2, "languag": [2, 40], "scarc": 2, "address": [2, 339], "subdomain": 2, "within": [2, 13, 14, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 41, 42, 44, 46, 47, 77, 81, 95, 101, 111, 116, 119, 120, 143, 154, 155, 165, 167, 168, 169, 170, 171, 172, 173, 174, 176, 178, 179, 180, 181, 182, 184, 185, 186, 187, 188, 193, 194, 197, 198, 199, 201, 204, 205, 207, 212, 218, 219, 221, 222, 223, 225, 228, 233, 236, 243, 247, 267, 325, 337, 341], "facilit": [2, 3, 7, 132, 133, 151, 153, 215, 216, 217, 325, 330, 333, 337], "interact": [2, 4, 5, 7, 8, 13, 14, 16, 18, 19, 20, 21, 226, 230, 330, 332, 336, 337, 342], "extern": [2, 3, 116, 119, 342], "consist": [2, 3, 32, 35, 38, 41, 42, 77, 81, 95, 101, 127, 154, 168, 188, 330, 331, 332, 337, 338, 342], "token": [2, 36, 37, 40, 43, 45, 57], "format": [2, 17, 31, 32, 33, 55, 56, 77, 81, 95, 101, 115, 133, 145, 148, 149, 151, 153, 229, 330, 331, 342], "manner": [2, 81, 133, 151, 325, 330, 331, 332, 335, 337, 339], "handl": [3, 21, 32, 77, 81, 95, 101, 154, 155, 186, 188, 305, 319, 320, 330, 331, 332, 336, 339], "dm": [3, 330, 342], "goal": [3, 4, 144, 330, 331, 332, 333, 336, 337], "abl": [3, 90, 96, 97, 330, 332, 333, 335, 336, 337, 339, 341], "experi": [3, 35, 38, 41, 42, 52, 53, 54, 55, 56, 61, 157, 290, 291, 292, 293, 294, 295, 324, 331, 332, 336, 339], "even": [3, 4, 8, 14, 18, 20, 21, 58, 59, 60, 68, 71, 77, 78, 81, 85, 95, 101, 165, 330, 332, 336, 337, 342], "simul": [3, 5, 7, 8, 98, 103, 106, 166, 190, 325, 330, 332, 336], "box": [3, 24, 25, 26, 27, 28, 29, 30, 31, 33, 44, 46, 47], "lib": [3, 5, 6, 7, 9, 10, 13, 14, 16, 17, 21, 22, 77, 78, 81, 95, 96, 97, 99, 100, 101, 111, 114, 120, 126, 127, 129, 131, 135, 137, 140, 145, 148, 154, 155, 314, 317, 330, 331, 332, 333, 335, 336, 338, 339, 341, 342], "hope": 3, "imit": 3, "nn": [3, 13, 14, 16, 17, 21, 32, 40, 77, 81, 91, 95, 101, 115, 118, 120, 127, 133, 145, 148, 149, 151, 153, 166, 167, 168, 170, 171, 172, 173, 176, 177, 178, 179, 180, 181, 182, 184, 185, 186, 188, 190, 192, 193, 194, 197, 202, 203, 211, 214, 215, 216, 217, 219, 220, 222, 223, 225, 226, 227, 229, 230, 231, 232, 234, 239, 240, 242, 243, 245, 246, 247, 248, 252, 254, 256, 257, 258, 259, 261, 267, 269, 270, 271, 272, 314, 317, 325, 326, 330, 331, 332, 333, 335, 336, 337, 338, 341], "typic": [3, 4, 8, 32, 77, 81, 95, 101, 120, 144, 226, 240, 254, 256, 259, 325, 326, 327, 332, 336, 337], "organis": [3, 55, 331], "arbitrari": [3, 33, 95, 101, 325, 330, 331, 337], "nest": [3, 26, 28, 32, 34, 36, 39, 48, 58, 59, 71, 77, 81, 95, 101, 111, 143, 146, 165, 269, 270, 271, 272, 273, 327, 331, 332, 336, 337, 339, 341], "attribut": [3, 4, 32, 34, 36, 39, 45, 77, 81, 95, 101, 120, 133, 151, 182, 186, 230, 239, 240, 242, 243, 245, 246, 247, 248, 252, 254, 256, 257, 258, 259, 261, 267, 330, 333, 337], "batch_siz": [3, 8, 13, 14, 15, 16, 26, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 52, 53, 54, 55, 56, 57, 58, 59, 62, 66, 67, 69, 71, 74, 77, 79, 81, 84, 87, 90, 91, 94, 95, 96, 97, 99, 100, 101, 102, 103, 110, 111, 116, 119, 120, 121, 131, 135, 137, 141, 143, 145, 148, 164, 165, 166, 174, 177, 182, 186, 190, 202, 203, 211, 212, 214, 215, 216, 217, 219, 220, 221, 222, 223, 225, 226, 227, 228, 229, 232, 233, 234, 239, 240, 242, 243, 245, 246, 252, 256, 257, 258, 259, 261, 267, 296, 302, 314, 325, 330, 331, 332, 333, 335, 336, 337, 338, 339, 341, 342], "togeth": [3, 13, 14, 16, 17, 18, 19, 20, 21, 28, 29, 40, 77, 81, 90, 95, 96, 97, 101, 111, 134, 180, 182, 184, 186, 211, 215, 216, 217, 235, 325, 331, 332, 333], "expect": [3, 4, 7, 26, 32, 38, 44, 45, 65, 77, 81, 91, 94, 95, 98, 101, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 120, 121, 123, 125, 126, 127, 129, 131, 133, 135, 136, 138, 139, 140, 141, 143, 144, 145, 146, 147, 148, 150, 151, 152, 154, 157, 180, 181, 182, 184, 185, 186, 193, 194, 221, 225, 229, 232, 239, 240, 241, 242, 243, 245, 246, 252, 253, 254, 256, 257, 258, 259, 261, 267, 309, 324, 325, 326, 327, 330, 332, 333, 336, 337, 339, 342], "live": [3, 12, 13, 14, 16, 17, 19, 20, 32, 35, 38, 41, 42, 52, 53, 54, 55, 56, 77, 81, 91, 95, 101, 120], "actual": [3, 4, 7, 17, 52, 53, 55, 56, 77, 81, 95, 101, 154, 308, 326, 330, 332, 336, 337], "do": [3, 4, 7, 56, 81, 103, 134, 154, 155, 164, 194, 195, 216, 269, 327, 330, 331, 332, 333, 335, 336, 337, 339, 341, 342], "retriev": [3, 34, 35, 36, 38, 39, 41, 42, 52, 53, 54, 55, 56, 77, 81, 95, 101, 112, 117, 120, 129, 164, 166, 167, 190, 226, 230, 233, 239, 240, 241, 243, 253, 256, 257, 259, 261, 267, 269, 270, 271, 272, 314, 321, 327, 331, 332, 337, 342], "care": [3, 8, 77, 81, 95, 101, 148, 167, 168, 169, 170, 171, 172, 173, 174, 176, 178, 179, 180, 181, 182, 184, 185, 186, 187, 188, 193, 194, 197, 198, 199, 201, 204, 205, 207, 212, 218, 219, 221, 222, 223, 225, 228, 233, 236, 330, 332, 336, 337, 339], "below": [3, 7, 13, 14, 16, 17, 18, 19, 20, 21, 32, 57, 77, 81, 95, 101, 115, 133, 145, 148, 149, 151, 153, 167, 168, 180, 183, 184, 188, 194, 210, 229, 302, 330, 331, 332, 333, 337], "parametr": [3, 196, 230, 240, 252, 259, 330, 332], "hardwar": 3, "observation_spec": [3, 77, 81, 91, 95, 101, 108, 111, 112, 113, 114, 115, 116, 117, 119, 120, 123, 125, 126, 127, 129, 131, 133, 136, 140, 143, 144, 145, 146, 147, 148, 150, 151, 154, 166, 182, 186, 190, 309, 317, 330, 332, 335, 336, 337, 342], "compositespec": [3, 28, 49, 77, 79, 81, 91, 95, 101, 108, 116, 117, 118, 119, 121, 127, 135, 141, 143, 145, 148, 161, 165, 166, 190, 214, 218, 226, 232, 233, 323, 330, 332, 333, 336, 337, 342], "pair": [3, 32, 34, 36, 39, 52, 77, 81, 95, 101, 137, 145, 182, 215, 226, 230, 254, 269, 270, 271, 272, 273, 325, 326, 330, 331, 332, 335, 337, 342], "state_spec": [3, 77, 81, 91, 95, 101, 108, 166, 190, 332, 337, 342], "empti": [3, 26, 28, 35, 38, 41, 42, 52, 53, 54, 55, 56, 77, 81, 94, 95, 101, 133, 146, 149, 151, 153, 292, 330, 337], "action_spec": [3, 13, 14, 15, 16, 18, 19, 20, 74, 77, 81, 87, 91, 95, 96, 97, 101, 108, 111, 116, 119, 127, 137, 166, 177, 190, 203, 205, 214, 220, 226, 227, 240, 243, 245, 257, 259, 261, 317, 325, 330, 331, 332, 333, 335, 336, 337, 338, 339, 341, 342], "reward_spec": [3, 77, 81, 91, 95, 101, 108, 109, 114, 115, 116, 117, 119, 138, 139, 140, 148, 150, 166, 190, 332, 336, 337, 342], "reward": [3, 13, 14, 16, 32, 34, 39, 40, 44, 45, 53, 55, 56, 57, 69, 74, 77, 81, 87, 91, 94, 95, 99, 100, 101, 102, 103, 108, 109, 114, 115, 116, 117, 119, 120, 121, 127, 131, 135, 137, 138, 139, 140, 141, 143, 144, 148, 149, 150, 152, 153, 155, 161, 164, 166, 182, 190, 219, 235, 239, 240, 242, 243, 245, 246, 249, 252, 254, 256, 257, 258, 259, 261, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 298, 299, 301, 303, 321, 326, 327, 330, 331, 332, 333, 335, 336, 337, 338, 339, 341, 342], "done_spec": [3, 77, 81, 95, 101, 116, 117, 119, 120, 148, 165, 332, 336, 337, 342], "flag": [3, 8, 35, 38, 41, 42, 52, 53, 54, 55, 56, 103, 225, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 325, 336, 337, 338], "section": [3, 4, 180, 184, 331, 336], "termin": [3, 7, 32, 40, 52, 53, 55, 56, 77, 81, 95, 96, 97, 99, 100, 101, 102, 103, 120, 165, 166, 182, 186, 190, 231, 239, 240, 242, 243, 245, 246, 252, 256, 257, 258, 259, 261, 267, 269, 270, 271, 272, 273, 274, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 330, 331, 332, 333, 335, 336, 337, 338, 339, 341, 342], "input_spec": [3, 77, 81, 91, 95, 101, 115, 116, 117, 118, 129, 131, 135, 140, 141, 143, 144, 145, 148, 149, 150, 152, 337], "full_action_spec": [3, 77, 81, 95, 101, 166, 190, 336], "full_state_spec": [3, 77, 81, 95, 101, 166, 190], "lock": [3, 26, 28, 34, 36, 39, 77, 81, 95, 101, 145, 155, 337], "modifi": [3, 7, 8, 26, 28, 32, 45, 77, 81, 95, 101, 115, 123, 127, 133, 145, 148, 149, 151, 153, 219, 225, 229, 308, 314, 330, 331, 332, 336, 337], "directli": [3, 4, 8, 77, 81, 91, 95, 101, 137, 154, 254, 321, 325, 332, 336, 337, 339], "output_spec": [3, 77, 81, 95, 101, 115, 116, 117, 121, 127, 135, 141, 143, 148, 149, 337], "full_observation_spec": [3, 77, 81, 95, 101, 166, 190], "full_reward_spec": [3, 77, 81, 95, 101, 336], "full_done_spec": [3, 77, 81, 95, 101, 165, 336], "importantli": [3, 226, 230], "4": [3, 7, 24, 26, 27, 28, 33, 34, 35, 36, 38, 39, 40, 41, 42, 52, 53, 54, 55, 56, 66, 67, 75, 76, 77, 80, 81, 86, 88, 89, 90, 91, 95, 99, 100, 101, 108, 111, 120, 137, 143, 144, 155, 166, 167, 168, 169, 170, 171, 174, 177, 178, 179, 180, 181, 184, 185, 187, 188, 190, 193, 194, 197, 198, 199, 200, 201, 202, 203, 211, 214, 215, 216, 217, 219, 220, 221, 222, 223, 225, 226, 227, 228, 229, 232, 234, 239, 240, 242, 243, 245, 246, 247, 248, 252, 254, 256, 257, 258, 259, 261, 267, 287, 325, 329, 330, 331, 332, 333, 336, 337, 338, 339, 340, 341, 342], "action_s": 3, "help": [3, 4, 32, 77, 81, 95, 101, 120, 324, 326, 330, 331, 332, 333, 336], "prealloc": [3, 337], "With": [3, 90, 144, 327, 330, 331, 336, 339, 342], "necessarili": [3, 342], "0s": [3, 145, 333], "stateless": [3, 148, 254, 330, 337, 342], "step_and_maybe_reset": [3, 77, 81, 95, 101], "partial": [3, 77, 81, 95, 101, 110, 111, 144, 145, 146, 305, 333], "next": [3, 4, 8, 13, 14, 16, 26, 28, 32, 35, 38, 40, 41, 42, 52, 53, 54, 55, 56, 57, 66, 67, 69, 74, 77, 78, 81, 87, 91, 95, 99, 100, 101, 102, 103, 110, 111, 116, 119, 120, 121, 126, 127, 131, 135, 137, 140, 141, 143, 145, 154, 155, 161, 164, 166, 181, 182, 185, 186, 190, 205, 235, 239, 240, 242, 243, 245, 246, 247, 252, 256, 257, 258, 259, 261, 267, 268, 269, 270, 271, 272, 273, 299, 301, 303, 330, 331, 333, 335, 337, 338, 339, 341, 342], "step_mdp": [3, 182, 186, 323, 333, 337, 341, 342], "done_kei": [3, 77, 81, 95, 101, 120, 137, 143, 164, 336], "assign": [3, 4, 13, 14, 32, 34, 36, 39, 77, 81, 95, 101, 149, 242, 243, 245, 259, 332, 336, 339], "_reset": [3, 77, 81, 91, 95, 101, 108, 111, 116, 119, 165, 166, 190], "data_": [3, 77, 81, 95, 101], "i": [3, 13, 14, 16, 17, 18, 19, 20, 21, 26, 28, 32, 35, 38, 42, 43, 58, 59, 61, 67, 71, 77, 81, 95, 101, 133, 137, 140, 149, 153, 181, 185, 197, 203, 221, 226, 228, 229, 230, 269, 270, 271, 272, 296, 308, 330, 331, 332, 333, 336, 337, 339, 341, 342], "rang": [3, 4, 8, 11, 27, 35, 38, 40, 41, 42, 52, 53, 54, 55, 56, 58, 59, 69, 77, 78, 81, 95, 101, 137, 147, 155, 181, 185, 253, 261, 326, 327, 330, 332, 333, 336, 337, 339, 341], "n": [3, 6, 7, 24, 27, 32, 33, 40, 77, 81, 95, 101, 111, 118, 123, 150, 180, 181, 184, 190, 225, 230, 239, 246, 254, 268, 302, 325, 327, 331, 332, 333, 336, 339, 342], "append": [3, 8, 35, 38, 41, 42, 52, 53, 54, 55, 56, 77, 78, 81, 95, 101, 114, 137, 145, 154, 181, 182, 185, 186, 220, 227, 330, 331, 332, 333, 336, 337, 338, 339, 341], "set_se": [3, 13, 14, 16, 17, 21, 74, 77, 81, 87, 91, 95, 101, 129, 135, 140, 144, 146, 149, 337, 341, 342], "seed": [3, 13, 14, 16, 17, 21, 55, 75, 77, 81, 91, 95, 96, 97, 101, 102, 103, 108, 116, 119, 149, 157, 305], "determinist": [3, 32, 77, 81, 95, 101, 115, 133, 145, 148, 149, 151, 153, 169, 178, 198, 205, 214, 223, 229, 230, 233, 240, 325, 330, 331, 333, 337, 342], "preced": [3, 187, 333], "without": [3, 7, 9, 32, 40, 52, 66, 67, 77, 81, 95, 101, 103, 108, 116, 119, 147, 180, 181, 184, 185, 216, 217, 239, 240, 242, 243, 245, 246, 252, 256, 257, 258, 259, 261, 268, 269, 270, 271, 272, 273, 317, 324, 325, 330, 331, 332, 336, 337, 339, 342], "risk": [3, 134], "overlap": [3, 41], "consecut": [3, 65, 85, 186, 225, 333, 336, 342], "reproduc": [3, 111, 157, 330, 332, 336], "maximum": [3, 4, 13, 14, 16, 17, 18, 19, 20, 21, 32, 34, 36, 37, 39, 40, 43, 45, 57, 58, 59, 60, 71, 77, 81, 95, 101, 118, 138, 143, 144, 146, 208, 209, 210, 233, 240, 246, 252, 254, 255, 259, 302, 330, 331, 332, 333, 336, 339], "max_step": [3, 13, 77, 81, 91, 95, 101, 102, 103, 143, 336, 341, 342], "tensordictmodul": [3, 13, 14, 16, 17, 20, 21, 40, 91, 110, 127, 177, 182, 186, 190, 202, 203, 211, 212, 215, 216, 217, 218, 219, 220, 223, 225, 226, 227, 228, 229, 231, 232, 233, 235, 240, 242, 246, 248, 249, 250, 252, 254, 257, 259, 261, 267, 268, 269, 270, 271, 272, 301, 317, 325, 330, 332, 333, 335, 336, 337, 338], "compat": [3, 7, 11, 18, 19, 32, 34, 36, 39, 52, 66, 67, 68, 77, 81, 83, 94, 95, 101, 111, 143, 151, 155, 180, 181, 182, 184, 185, 186, 227, 239, 240, 242, 243, 245, 246, 252, 254, 256, 257, 258, 259, 261, 264, 330, 333, 339, 341], "mark": [3, 16, 56, 77, 81, 95, 101, 182, 186], "trail": [3, 155], "time": [3, 4, 7, 8, 13, 14, 16, 17, 18, 20, 21, 32, 35, 38, 40, 41, 42, 55, 69, 77, 78, 81, 90, 94, 95, 96, 97, 101, 107, 110, 112, 134, 140, 145, 146, 155, 164, 178, 180, 184, 186, 187, 225, 241, 246, 249, 253, 254, 256, 257, 261, 269, 270, 271, 272, 273, 274, 275, 278, 279, 280, 281, 282, 283, 284, 285, 286, 305, 325, 326, 331, 332, 333, 335, 336, 337, 338, 339, 341, 342], "treat": 3, "figur": [3, 330, 332, 333, 336, 337, 342], "summar": [3, 337], "brief": [3, 332], "entri": [3, 13, 14, 18, 19, 20, 21, 23, 26, 28, 32, 34, 36, 37, 39, 45, 49, 52, 53, 54, 55, 56, 66, 67, 77, 81, 95, 101, 111, 113, 114, 116, 119, 120, 123, 126, 129, 131, 133, 135, 137, 140, 143, 144, 145, 153, 155, 164, 165, 182, 191, 192, 219, 220, 227, 228, 240, 259, 269, 270, 271, 272, 325, 330, 332, 333, 336, 337, 338, 339, 342], "deliveri": 3, "design": [3, 13, 14, 32, 33, 77, 81, 95, 101, 111, 134, 149, 219, 239, 240, 241, 246, 247, 248, 249, 250, 252, 253, 254, 256, 257, 258, 259, 261, 267, 330, 331, 332, 333, 335, 336, 337, 339, 342], "metaclass": 3, "ensur": [3, 32, 35, 41, 61, 65, 77, 81, 95, 101, 111, 133, 143, 151, 155, 220, 325, 331, 332, 337, 339], "everi": [3, 8, 17, 26, 28, 32, 33, 68, 77, 81, 95, 101, 143, 144, 155, 167, 168, 169, 170, 171, 172, 173, 174, 176, 178, 179, 180, 181, 182, 184, 185, 186, 187, 188, 193, 194, 197, 198, 199, 201, 204, 205, 207, 212, 218, 219, 221, 222, 223, 225, 228, 233, 236, 305, 327, 330, 331, 332, 333, 336, 337], "flank": [3, 333], "dual": 3, "strictli": [3, 8, 32, 77, 81, 95, 101, 149, 259, 330, 332], "refer": [3, 7, 8, 9, 21, 32, 40, 77, 81, 95, 101, 149, 155, 166, 177, 178, 190, 191, 192, 193, 198, 199, 204, 205, 221, 239, 247, 248, 249, 250, 256, 259, 269, 274, 282, 329, 330, 332, 336], "union": [3, 11, 13, 15, 16, 17, 20, 21, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 39, 44, 46, 47, 61, 77, 81, 95, 101, 108, 118, 120, 126, 129, 133, 134, 137, 139, 151, 153, 155, 164, 167, 168, 170, 171, 172, 173, 175, 177, 179, 187, 188, 191, 192, 193, 194, 195, 196, 200, 202, 203, 208, 209, 210, 211, 229, 245, 246, 251, 257, 260, 282, 288, 299, 301, 302, 310, 311, 314, 315, 317, 318, 319, 320, 321], "interpret": [3, 331], "last": [3, 4, 11, 13, 14, 16, 17, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 37, 44, 46, 47, 52, 65, 67, 77, 81, 95, 101, 110, 123, 129, 134, 144, 146, 147, 167, 168, 180, 182, 184, 186, 187, 188, 191, 192, 198, 206, 212, 218, 219, 222, 223, 230, 331, 332, 333, 336, 337, 338, 339, 341, 342], "indic": [3, 8, 11, 13, 14, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 44, 45, 46, 47, 52, 53, 54, 55, 56, 57, 63, 65, 66, 67, 69, 70, 72, 77, 81, 95, 101, 111, 112, 143, 144, 145, 146, 149, 165, 167, 168, 188, 191, 192, 194, 225, 227, 228, 236, 239, 240, 242, 243, 245, 246, 247, 248, 252, 254, 256, 257, 258, 259, 261, 267, 309, 321, 324, 327, 332, 333, 337, 339, 342], "truncat": [3, 13, 14, 16, 18, 19, 20, 21, 37, 43, 45, 52, 53, 55, 56, 66, 67, 77, 81, 95, 96, 97, 101, 120, 121, 128, 137, 143, 165, 182, 186, 210, 275, 330, 332, 333, 335, 338, 339, 341, 342], "carri": [3, 21, 45, 77, 81, 95, 101, 145, 254, 331, 333, 336, 337, 339], "assess": [3, 104, 330], "split_trajectori": [3, 13, 14, 16, 17, 18, 19, 20, 21, 66, 67, 323], "adjac": [3, 23, 123], "reli": [3, 180, 181, 184, 185, 239, 326, 330, 332, 337, 342], "traj_id": [3, 13, 14, 16, 23, 137, 333, 339, 341], "junction": 3, "miss": [3, 4, 6, 7, 11, 26, 32, 77, 81, 95, 101, 149, 164, 231, 232, 259, 324, 330, 333], "context": [3, 5, 8, 32, 77, 78, 81, 94, 95, 101, 145, 150, 194, 195, 219, 265, 266, 269, 270, 271, 272, 274, 282, 301, 325, 326, 330, 331, 332, 336, 337, 338, 339], "through": [3, 4, 5, 8, 11, 16, 18, 20, 21, 26, 28, 85, 90, 95, 96, 97, 101, 116, 119, 134, 188, 202, 226, 230, 231, 232, 236, 269, 270, 271, 272, 325, 330, 331, 332, 335, 336, 337, 338, 339, 342], "inittrack": [3, 182, 186, 330, 333], "tutori": [3, 329, 330, 331, 333, 334, 335, 337, 338, 339, 340, 342], "inform": [3, 4, 13, 14, 16, 17, 18, 19, 20, 21, 32, 34, 36, 39, 43, 77, 78, 81, 84, 95, 101, 167, 168, 188, 194, 326, 327, 330, 331, 332, 333, 336, 337, 339], "scratch": [3, 8, 331, 337], "better": [3, 8, 9, 182, 186, 326, 332, 337], "intens": [3, 8], "gym3": 3, "envpool": [3, 92, 93], "interfac": [3, 84, 94, 188, 195, 325, 330, 332, 337, 339], "simultan": [3, 20, 95, 101, 337], "often": [3, 8, 251, 305, 330, 331, 337, 339, 342], "competit": [3, 336], "advantag": [3, 8, 179, 239, 241, 253, 256, 258, 269, 270, 271, 272, 273, 274, 276, 278, 280, 282, 283, 285, 326, 327, 330, 331, 332, 333, 336, 337, 342], "scale": [3, 4, 52, 111, 127, 129, 139, 144, 147, 178, 183, 197, 204, 205, 209, 210, 215, 216, 217, 226, 230, 232, 239, 240, 252, 256, 257, 258, 259, 303, 309, 314, 321, 325, 330, 331, 332, 333, 336, 341], "varieti": 3, "own": [3, 13, 14, 17, 22, 32, 77, 81, 95, 96, 97, 101, 331, 332, 336, 337], "As": [3, 4, 77, 81, 90, 95, 96, 97, 101, 137, 230, 269, 325, 330, 331, 332, 333, 336, 337, 338, 339, 341, 342], "inherit": [3, 189, 254, 327, 332, 336], "serialenv": [3, 77, 81, 95, 145, 323, 342], "Of": [3, 7, 324, 337, 342], "cours": [3, 4, 324, 332, 337, 342], "correspond": [3, 4, 13, 14, 18, 19, 20, 21, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 39, 41, 44, 46, 47, 56, 61, 77, 81, 91, 92, 95, 101, 133, 145, 149, 153, 155, 182, 184, 186, 191, 192, 222, 223, 225, 226, 230, 243, 246, 259, 267, 269, 270, 271, 272, 273, 330, 331, 332, 336, 337, 338], "count": [3, 78, 143, 225, 301, 305, 308, 330, 331, 332, 333, 339, 342], "make_env": [3, 103, 155, 310, 311, 330, 331, 342], "gymenv": [3, 5, 13, 14, 16, 17, 21, 22, 77, 78, 81, 83, 95, 101, 111, 114, 115, 120, 126, 127, 129, 131, 135, 136, 137, 140, 144, 145, 146, 148, 149, 155, 182, 186, 314, 317, 323, 325, 330, 331, 332, 333, 338, 339, 341, 342], "v1": [3, 13, 14, 16, 17, 21, 22, 52, 53, 77, 78, 81, 92, 95, 101, 111, 114, 121, 126, 127, 129, 135, 137, 140, 143, 144, 145, 146, 148, 182, 186, 264, 278, 279, 280, 281, 283, 284, 285, 286, 325, 331, 333, 337, 339, 341, 342], "from_pixel": [3, 75, 76, 111, 136, 314, 330, 331, 333, 338, 339, 341, 342], "9": [3, 7, 32, 35, 38, 41, 55, 56, 67, 69, 90, 96, 97, 144, 155, 239, 240, 242, 243, 245, 246, 247, 248, 252, 254, 256, 257, 258, 259, 261, 262, 267, 326, 330, 331, 332, 336, 337, 338, 339], "81": [3, 330, 331, 336, 337], "must": [3, 7, 13, 14, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 40, 44, 45, 46, 47, 53, 55, 56, 57, 58, 59, 60, 66, 67, 68, 71, 77, 78, 81, 95, 96, 97, 101, 111, 114, 120, 124, 127, 129, 131, 141, 144, 145, 146, 149, 150, 155, 167, 168, 177, 182, 186, 188, 191, 192, 193, 194, 203, 214, 220, 221, 226, 227, 228, 229, 230, 233, 234, 239, 240, 242, 243, 245, 246, 247, 248, 252, 254, 256, 257, 258, 259, 260, 261, 267, 269, 270, 271, 272, 273, 274, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 314, 330, 331, 332, 333, 335, 337, 339, 341], "print": [3, 6, 7, 13, 14, 16, 21, 22, 24, 26, 27, 28, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 45, 53, 55, 56, 57, 66, 67, 69, 73, 74, 75, 76, 77, 78, 80, 81, 82, 86, 87, 88, 89, 90, 91, 94, 95, 96, 97, 99, 100, 101, 102, 103, 105, 107, 111, 112, 116, 117, 118, 119, 126, 129, 135, 137, 140, 143, 145, 146, 147, 155, 161, 164, 165, 167, 168, 174, 177, 182, 188, 191, 192, 193, 194, 197, 200, 203, 214, 215, 216, 217, 219, 220, 222, 223, 225, 227, 229, 232, 234, 254, 314, 317, 325, 327, 331, 332, 333, 335, 336, 337, 338, 339, 341, 342], "simpli": [3, 6, 34, 36, 39, 45, 121, 141, 154, 254, 325, 326, 330, 332, 336, 342], "b": [3, 7, 8, 23, 26, 28, 34, 36, 39, 40, 41, 42, 69, 180, 181, 184, 185, 193, 194, 195, 196, 202, 211, 233, 269, 270, 271, 272, 273, 275, 288, 325, 331, 338, 339], "c": [3, 6, 7, 26, 34, 36, 39, 41, 42, 54, 129, 147, 184, 185, 331, 339], "d": [3, 35, 54, 55, 56, 57, 61, 180, 184, 226, 230, 341], "get": [3, 4, 6, 7, 8, 9, 34, 35, 36, 38, 39, 52, 58, 59, 66, 67, 68, 69, 71, 78, 95, 101, 108, 110, 112, 116, 118, 119, 127, 129, 134, 144, 145, 147, 155, 214, 222, 223, 226, 227, 230, 269, 270, 271, 272, 273, 292, 325, 330, 331, 332, 333, 336, 337, 339, 341, 342], "forc": [3, 6, 7, 13, 14, 18, 20, 21, 53, 55, 56, 331, 336, 337], "privat": [3, 77, 81, 95, 101, 154, 337, 342], "absenc": 3, "total": [3, 13, 14, 16, 17, 18, 19, 20, 21, 24, 30, 31, 33, 67, 241, 253, 256, 296, 298, 301, 305, 308, 309, 329, 330, 331, 332, 333, 335, 336, 337, 338, 339, 340, 341, 342], "unless": [3, 13, 14, 16, 17, 18, 19, 20, 21, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 44, 46, 47, 65, 77, 81, 95, 101, 332], "wa": [3, 5, 7, 35, 38, 41, 42, 52, 53, 54, 55, 56, 77, 81, 95, 101, 149, 165, 184, 251, 260, 275, 326, 331, 332, 335, 339, 341], "abov": [3, 7, 32, 77, 81, 95, 101, 183, 209, 210, 238, 326, 327, 330, 332, 336, 337, 342], "deal": [3, 330, 332, 336, 339], "proper": [3, 4, 6, 7, 269, 270, 271, 272, 331, 332, 336, 339], "behav": [3, 83, 91, 180, 184, 200, 252, 338], "accord": [3, 13, 14, 16, 17, 18, 19, 20, 21, 34, 36, 39, 40, 129, 139, 183, 195, 204, 209, 210, 267, 325, 337, 339], "develop": [3, 4, 7, 85, 330, 341], "inner": [3, 77, 81, 95, 101, 118, 327, 331, 332, 336, 342], "logic": 3, "nevertheless": [3, 332, 339], "kept": [3, 13, 14, 16, 17, 65, 67, 118, 141, 148, 157, 164, 183, 209, 210], "mind": [3, 66, 67, 336], "desig": 3, "previou": [3, 4, 10, 32, 40, 41, 145, 165, 180, 184, 205, 219, 332, 333, 337, 342], "wherev": 3, "expos": [3, 98, 116, 119, 231, 331], "modif": [3, 5, 26, 28, 32, 77, 81, 95, 101, 123, 165, 254, 332, 337], "lost": [3, 8, 154], "eras": [3, 77, 81, 95, 101, 149], "intern": [3, 328], "face": [3, 5, 8, 9, 342], "NOT": [3, 134], "outsid": [3, 16, 336, 337], "keep": [3, 4, 7, 8, 14, 42, 65, 69, 95, 101, 129, 133, 153, 155, 164, 225, 298, 305, 330, 331, 332, 333, 336, 337, 339, 341, 342], "right": [3, 6, 7, 40, 187, 331, 332, 336, 337, 342], "preliminari": 3, "warranti": 3, "affect": [3, 8, 32, 77, 81, 95, 101, 148, 149, 157, 269, 270, 271, 272], "assumpt": [3, 337, 339], "made": [3, 32, 58, 59, 60, 68, 71, 77, 81, 95, 101, 225, 243, 267, 330, 331, 333, 336, 338], "preclud": 3, "presenc": 3, "annihil": 3, "effect": [3, 26, 32, 66, 67, 77, 81, 95, 101, 111, 149, 305, 330, 339, 342], "reason": [3, 4, 8, 32, 77, 81, 95, 96, 97, 101, 133, 151, 186, 326, 330, 331, 332, 337, 339], "root": [3, 26, 28, 52, 53, 55, 56, 111, 146, 164, 183, 209, 210, 333, 336, 337, 338, 339, 342], "known": [3, 5, 7, 8, 276, 277, 330, 331], "advanc": [3, 21, 35, 38, 41, 42, 339], "explicitli": [3, 4, 331, 333, 336, 339], "place": [3, 13, 14, 16, 17, 26, 28, 32, 34, 36, 39, 58, 59, 71, 77, 78, 81, 95, 101, 115, 120, 133, 145, 148, 149, 151, 153, 154, 155, 165, 219, 229, 302, 307, 308, 331, 332, 336, 337, 339], "superse": 3, "pettingzoowrapp": [3, 323], "group": [3, 24, 25, 26, 27, 28, 29, 30, 31, 33, 44, 46, 47, 77, 81, 90, 95, 96, 97, 101, 103, 104, 325, 331, 332, 336], "associ": [3, 32, 34, 36, 39, 77, 81, 95, 101, 204, 321, 330, 339], "environemtn": 3, "__not__": 3, "constrain": [3, 127, 182, 186, 256], "li": 3, "fact": [3, 7, 8, 330, 332, 336, 337, 338, 339, 342], "predict": [3, 32, 40, 178, 189, 190, 219, 235, 245, 247, 249, 250, 268, 325, 330, 331], "know": [3, 4, 9, 35, 38, 41, 42, 218, 257, 301, 330, 331, 332, 333, 336, 339], "meaning": 3, "could": [3, 4, 6, 331, 332, 336, 338, 342], "perfectli": [3, 327, 330, 337], "case": [3, 4, 5, 7, 8, 11, 13, 14, 16, 17, 18, 19, 20, 21, 22, 26, 32, 35, 41, 53, 55, 56, 61, 77, 81, 95, 101, 116, 117, 119, 147, 149, 157, 186, 188, 194, 226, 229, 230, 232, 233, 238, 239, 240, 242, 243, 245, 246, 252, 256, 257, 258, 259, 261, 269, 270, 271, 272, 296, 307, 319, 320, 321, 325, 327, 330, 331, 332, 333, 336, 337, 339, 342], "meaningless": 3, "discard": [3, 45, 52, 53, 81, 151, 164, 287, 339, 342], "val": [3, 24, 25, 26, 27, 28, 29, 30, 31, 33, 44, 46, 47, 341], "agent0": 3, "agent1": 3, "overridden": [3, 53, 55, 56, 77, 81, 95, 101, 167, 168, 169, 170, 171, 172, 173, 174, 176, 178, 179, 180, 181, 182, 184, 185, 186, 187, 188, 193, 194, 197, 198, 199, 201, 204, 205, 207, 212, 218, 219, 221, 222, 223, 225, 228, 233, 236, 333], "overrid": [3, 24, 25, 26, 27, 28, 29, 30, 31, 33, 38, 44, 46, 47, 77, 81, 95, 101, 321, 325], "elimin": 3, "field": [3, 13, 14, 16, 17, 26, 32, 34, 36, 37, 39, 40, 41, 42, 43, 45, 53, 55, 56, 58, 59, 71, 74, 77, 81, 87, 90, 91, 94, 95, 96, 97, 99, 100, 101, 102, 103, 116, 119, 120, 121, 131, 135, 137, 141, 143, 145, 149, 164, 166, 177, 182, 186, 190, 202, 203, 211, 214, 215, 216, 217, 219, 220, 221, 225, 226, 227, 228, 229, 232, 234, 239, 240, 242, 243, 245, 246, 252, 256, 257, 258, 259, 261, 267, 309, 314, 324, 325, 331, 332, 333, 335, 336, 337, 338, 339, 341, 342], "bool": [3, 13, 14, 16, 17, 18, 19, 20, 21, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 52, 53, 54, 55, 56, 57, 65, 66, 67, 74, 75, 76, 77, 78, 79, 81, 87, 90, 91, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 108, 111, 112, 116, 118, 119, 120, 121, 123, 127, 128, 129, 131, 133, 135, 137, 139, 141, 143, 145, 147, 149, 150, 151, 153, 155, 157, 164, 165, 166, 167, 168, 170, 171, 180, 181, 182, 183, 184, 185, 186, 188, 190, 193, 194, 195, 196, 209, 210, 214, 220, 221, 225, 226, 227, 228, 229, 230, 231, 232, 233, 239, 240, 241, 242, 243, 245, 246, 247, 248, 249, 250, 252, 253, 254, 255, 256, 257, 258, 259, 261, 264, 267, 269, 270, 271, 272, 275, 278, 279, 280, 281, 283, 284, 285, 286, 287, 288, 298, 299, 301, 302, 303, 305, 314, 321, 331, 332, 333, 335, 336, 337, 338, 339, 341, 342], "pixel": [3, 7, 26, 56, 111, 113, 120, 123, 125, 129, 131, 133, 136, 147, 151, 153, 170, 198, 199, 288, 314, 325, 330, 331, 333, 338, 339, 341, 342], "500": [3, 330, 331, 337, 341, 342], "uint8": [3, 34, 36, 39, 47, 120, 131, 147, 331, 338, 339, 341, 342], "none": [3, 8, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 66, 67, 68, 69, 71, 77, 78, 81, 90, 91, 95, 96, 97, 101, 102, 103, 105, 109, 110, 111, 112, 113, 114, 115, 116, 117, 119, 123, 125, 127, 129, 130, 131, 133, 134, 135, 136, 137, 138, 139, 140, 143, 144, 145, 146, 147, 148, 149, 151, 153, 155, 156, 158, 159, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 177, 179, 180, 181, 184, 185, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 198, 199, 200, 201, 202, 203, 211, 212, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 225, 226, 227, 228, 229, 230, 232, 233, 234, 239, 240, 242, 243, 245, 246, 247, 248, 252, 254, 255, 256, 257, 258, 259, 260, 261, 267, 268, 269, 270, 271, 272, 273, 274, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 292, 293, 294, 299, 300, 301, 302, 303, 304, 305, 309, 310, 311, 314, 317, 319, 320, 321, 325, 327, 330, 331, 332, 333, 336, 337, 339, 341, 342], "is_shar": [3, 13, 14, 16, 26, 34, 36, 37, 39, 40, 41, 42, 43, 45, 53, 55, 56, 57, 58, 59, 71, 74, 77, 81, 87, 90, 91, 94, 95, 96, 97, 99, 100, 101, 102, 103, 116, 119, 120, 121, 131, 135, 137, 141, 143, 145, 155, 164, 166, 177, 182, 186, 190, 202, 203, 211, 214, 215, 216, 217, 219, 220, 221, 225, 226, 227, 228, 229, 232, 234, 239, 240, 242, 243, 245, 246, 252, 256, 257, 258, 259, 261, 267, 314, 325, 332, 333, 335, 336, 337, 338, 339, 341, 342], "launch": [3, 13, 14, 18, 19, 20, 22, 95, 101], "bottleneck": [3, 8], "so": [3, 4, 6, 7, 10, 32, 34, 36, 39, 40, 77, 81, 95, 101, 145, 155, 231, 232, 332, 333, 336, 337, 342], "onc": [3, 7, 13, 14, 16, 17, 18, 19, 20, 21, 32, 34, 36, 39, 77, 81, 95, 101, 137, 149, 218, 223, 225, 303, 327, 331, 332, 333, 337, 339, 342], "great": [3, 7, 8, 341], "speedup": [3, 8, 342], "precis": [3, 116, 119, 164, 181, 185, 330, 332], "misspecifi": 3, "caus": [3, 7, 8, 58, 59, 71, 77, 81, 85, 95, 101, 134, 342], "breakag": 3, "rais": [3, 13, 14, 16, 18, 19, 20, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 39, 44, 46, 47, 77, 81, 95, 101, 104, 111, 122, 128, 137, 144, 145, 146, 149, 157, 218, 222, 223, 225, 259, 330, 332, 336, 339], "mismatch": [3, 331], "mostli": [3, 17, 326, 339, 342], "purpos": [3, 7, 111, 180, 317, 330, 332, 333, 336, 338, 342], "want": [3, 6, 7, 8, 67, 129, 239, 240, 242, 243, 245, 246, 247, 248, 252, 254, 256, 257, 258, 259, 261, 267, 325, 330, 331, 332, 333, 336, 337, 338, 339, 341, 342], "subprocess": [3, 13, 14, 78, 95, 101], "addit": [3, 4, 32, 52, 77, 81, 92, 95, 101, 115, 133, 145, 148, 149, 151, 153, 180, 218, 219, 229, 238, 254, 269, 326, 330, 331, 336, 339], "multithread": [3, 35, 38, 41, 42, 52, 53, 54, 55, 56, 57, 92, 93, 339], "multithreadedenv": [3, 323], "underneath": 3, "higher": [3, 4, 114, 233, 330, 331, 332, 339, 342], "restrict": [3, 331, 338, 339, 342], "flexibl": [3, 9, 92, 262, 326, 327, 339, 342], "cover": [3, 324, 332, 337, 341], "popular": [3, 325, 333, 336], "atari": [3, 4, 111, 342], "classic": [3, 91, 97, 331], "benchmark_batched_env": 3, "py": [3, 107, 202, 211, 327, 329, 330, 331, 332, 333, 335, 336, 337, 338, 339, 340, 341, 342], "pipelin": [3, 7, 325, 332], "seamlessli": [3, 337], "infrastructur": [3, 336], "view": [3, 8, 27, 32, 33, 55, 77, 81, 95, 101, 108, 177, 180, 184, 188, 337, 339, 341, 342], "core": [3, 8, 314, 327, 333, 341], "decis": [3, 169, 201, 219, 244, 255, 333, 336, 339, 342], "act": [3, 4, 66, 67, 96, 97, 194, 240, 242, 252, 257, 259, 261, 333, 336], "world": [3, 5, 91, 235, 249, 336, 337, 342], "paradigm": [3, 17, 336], "decpodp": 3, "markov": [3, 342], "game": [3, 4, 5], "per": [3, 4, 13, 14, 16, 17, 18, 19, 20, 21, 85, 95, 96, 97, 114, 140, 178, 193, 194, 222, 305, 319, 320, 330, 331, 332, 333, 336, 339, 341], "accommod": [3, 13, 14, 16, 17], "thank": [3, 330], "carrier": [3, 332, 333, 339], "particular": [3, 32, 45, 52, 77, 81, 95, 101, 149, 326, 327, 331, 333, 335, 336, 339], "thu": [3, 253, 336], "hand": [3, 7, 21, 336, 337], "let": [3, 6, 7, 32, 43, 77, 81, 95, 96, 97, 101, 111, 182, 186, 193, 194, 220, 301, 326, 330, 331, 332, 333, 335, 336, 337, 338, 339, 341, 342], "understand": [3, 8, 330, 331, 336], "go": [3, 7, 90, 134, 137, 219, 275, 330, 331, 332, 333, 335, 336, 337, 338, 339, 341, 342], "vma": [3, 102, 103, 336], "robot": [3, 5, 7, 133, 151, 153, 336], "what": [3, 8, 35, 44, 77, 81, 95, 101, 120, 145, 164, 227, 324, 325, 326, 331, 332, 333, 336, 337, 338, 339, 341, 342], "vmasenv": [3, 323, 336], "balanc": [3, 330, 331], "num_env": [3, 21, 84, 102, 103, 336], "n_agent": [3, 102, 103, 193, 194, 202, 211, 267, 336], "5": [3, 24, 26, 28, 35, 38, 41, 42, 66, 67, 78, 87, 92, 99, 100, 102, 103, 110, 137, 143, 144, 166, 167, 168, 177, 178, 180, 183, 184, 187, 188, 190, 193, 194, 198, 203, 209, 210, 219, 220, 227, 233, 253, 256, 258, 261, 325, 329, 330, 331, 336, 337, 339, 340, 341, 342], "info": [3, 35, 38, 41, 42, 52, 53, 54, 55, 56, 66, 67, 77, 81, 95, 96, 97, 98, 99, 100, 101, 102, 103, 151, 154, 156, 336, 339], "ground_rew": 3, "pos_rew": [3, 336], "16": [3, 32, 55, 67, 77, 81, 95, 101, 111, 329, 330, 331, 333, 336, 337, 339, 340, 341], "style": [3, 35, 38, 41, 42, 52, 53, 54, 55, 56], "relat": [3, 4, 10, 35, 123, 239, 240, 242, 243, 245, 246, 252, 256, 257, 258, 259, 261, 331, 337], "vari": [3, 96, 97, 134, 336], "creation": [3, 95, 101, 330, 342], "info_spec": 3, "agent_i_action_spec": 3, "agent_i_reward_spec": 3, "agent_i_observation_spec": 3, "discretetensorspec": [3, 33, 77, 81, 95, 101, 108, 165, 243, 246, 267, 323, 332, 336, 342], "you": [3, 5, 6, 7, 8, 9, 10, 32, 43, 77, 81, 85, 90, 95, 96, 97, 99, 100, 101, 107, 155, 184, 324, 325, 330, 331, 332, 333, 335, 336, 337, 338, 339, 341, 342], "simpl": [3, 9, 32, 33, 77, 81, 95, 101, 170, 230, 243, 245, 254, 258, 269, 325, 326, 330, 331, 332, 336, 342], "composit": [3, 26, 28, 77, 81, 95, 101, 332, 337], "prefix": [3, 23, 32, 34, 36, 39, 45, 77, 81, 95, 101, 149, 254, 259, 287, 333, 342], "exactli": [3, 32, 77, 81, 83, 95, 101, 149, 180, 184, 259, 330, 333, 336], "action_kei": [3, 15, 77, 81, 95, 101, 108, 118, 164, 166, 189, 190, 218, 222, 223, 225, 336], "reward_kei": [3, 77, 81, 95, 101, 164, 166, 190, 299, 303, 336], "automat": [3, 5, 56, 58, 59, 71, 77, 81, 95, 96, 97, 101, 116, 119, 129, 154, 167, 214, 226, 325, 330, 332, 336, 337, 339, 341], "sure": [3, 4, 7, 54, 68, 85, 137, 220, 321, 325, 330, 332, 333, 336, 337, 339, 341, 342], "set_kei": [3, 120, 239, 241, 243, 246, 247, 252, 253, 254, 256, 257, 258, 259, 267, 273, 336], "awai": [3, 332, 336], "eas": [3, 336], "leaf": [3, 26, 28, 77, 81, 95, 101, 143, 230], "would": [3, 32, 40, 77, 81, 95, 101, 180, 182, 184, 186, 188, 193, 327, 331, 332, 333, 337, 339, 342], "full": [3, 77, 81, 95, 101, 182, 186, 221, 296, 330, 331, 332, 333, 335, 336, 337, 338, 339, 341, 342], "raw": [3, 4, 40, 183, 209, 210, 331, 337], "torchvis": [3, 133, 153, 341, 342], "transformedenv": [3, 13, 77, 78, 81, 95, 101, 108, 111, 114, 115, 116, 119, 120, 121, 123, 126, 127, 128, 129, 131, 135, 136, 137, 140, 141, 143, 144, 145, 146, 148, 155, 182, 186, 314, 330, 331, 332, 333, 335, 336, 337, 338, 339, 341, 342], "primit": [3, 4, 239, 240, 242, 243, 245, 246, 252, 256, 257, 258, 259, 261], "built": [3, 5, 7, 239, 240, 242, 243, 245, 246, 247, 248, 252, 254, 256, 257, 258, 259, 261, 262, 267, 315, 317, 318, 321, 330, 331, 332, 333, 339, 342], "base_env": [3, 77, 81, 95, 101, 108, 114, 116, 118, 119, 127, 131, 136, 143, 145, 146, 330, 331, 332, 338, 341, 342], "totensorimag": [3, 56, 111, 136, 331, 333, 339, 341, 342], "in_kei": [3, 13, 14, 16, 17, 21, 52, 91, 109, 110, 111, 112, 113, 114, 116, 118, 119, 123, 125, 127, 129, 130, 131, 133, 135, 136, 137, 138, 139, 140, 144, 146, 147, 148, 149, 151, 153, 155, 166, 176, 182, 186, 190, 202, 211, 212, 214, 215, 216, 217, 219, 220, 226, 227, 229, 230, 232, 233, 234, 239, 240, 241, 242, 243, 245, 246, 252, 253, 256, 257, 258, 259, 261, 267, 269, 270, 271, 272, 287, 288, 314, 317, 325, 330, 331, 332, 333, 335, 336, 337, 338, 339, 341, 342], "resiz": [3, 56, 111, 331, 333, 339, 342], "64": [3, 34, 36, 39, 111, 136, 170, 171, 179, 182, 186, 194, 202, 267, 330, 331, 332, 333, 335, 337, 338, 339, 341, 342], "appar": [3, 298], "bring": [3, 332, 342], "signific": [3, 5, 8, 332, 342], "kind": [3, 38, 44, 164, 339], "consult": 3, "interest": [3, 226, 230, 325, 331, 332, 336, 337, 342], "resize_par": 3, "out_kei": [3, 13, 14, 16, 17, 21, 91, 109, 110, 111, 112, 113, 114, 116, 119, 123, 125, 127, 129, 130, 131, 133, 135, 136, 137, 138, 139, 140, 144, 146, 147, 148, 151, 153, 155, 166, 176, 177, 182, 186, 190, 202, 203, 211, 212, 214, 215, 216, 217, 219, 221, 226, 227, 228, 229, 230, 232, 233, 234, 239, 240, 241, 246, 252, 253, 256, 257, 258, 259, 267, 269, 270, 271, 272, 288, 301, 317, 325, 330, 331, 332, 333, 335, 336, 337, 338, 339, 341, 342], "easi": [3, 5, 54, 218, 222, 223, 225, 325, 326, 330, 331, 332, 336, 338, 339, 342], "graph": [3, 4, 8, 265, 266, 330, 337], "inv": [3, 114, 118, 131, 137, 337], "appli": [3, 4, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 35, 38, 41, 42, 43, 44, 46, 47, 52, 53, 54, 55, 56, 77, 81, 95, 101, 108, 110, 111, 112, 115, 116, 117, 118, 120, 121, 122, 123, 124, 126, 127, 128, 132, 134, 135, 137, 140, 141, 143, 144, 145, 146, 148, 149, 151, 152, 154, 155, 180, 184, 209, 220, 269, 300, 327, 330, 331, 332, 337, 341, 342], "revers": [3, 184], "order": [3, 16, 32, 33, 35, 38, 41, 42, 52, 53, 54, 55, 56, 65, 77, 81, 95, 101, 116, 119, 131, 149, 214, 220, 229, 231, 232, 234, 239, 240, 242, 246, 252, 256, 257, 258, 259, 261, 331, 336], "chain": [3, 34, 35, 36, 38, 39, 41, 42, 52, 53, 54, 55, 56, 115, 118, 167, 168, 232, 342], "taken": [3, 77, 81, 95, 101, 136, 191, 192, 223, 326, 330, 332, 333, 336, 337], "invers": [3, 4, 35, 38, 41, 42, 52, 53, 54, 55, 56, 111, 116, 119, 129, 137, 237, 252, 337], "in_keys_inv": [3, 114, 116, 119, 129, 130, 131, 135, 137, 148, 330, 335, 337, 342], "append_transform": [3, 35, 38, 41, 42, 52, 53, 54, 55, 56, 110, 133, 145, 151, 330, 333, 337, 341, 342], "doubletofloat": [3, 314, 330, 332, 335], "float32": [3, 13, 14, 16, 26, 34, 35, 36, 39, 40, 41, 42, 44, 45, 53, 56, 58, 59, 61, 71, 74, 77, 81, 87, 91, 94, 95, 99, 100, 101, 102, 103, 116, 119, 120, 121, 129, 131, 135, 137, 141, 143, 145, 147, 161, 164, 166, 177, 182, 186, 190, 202, 203, 211, 214, 215, 216, 217, 219, 220, 225, 226, 227, 228, 229, 232, 234, 239, 240, 242, 243, 245, 246, 252, 256, 257, 258, 259, 261, 267, 314, 325, 332, 333, 335, 336, 337, 338, 339, 341, 342], "float64": [3, 32, 53, 55, 77, 81, 95, 101, 115, 116, 119, 133, 145, 148, 149, 151, 153, 229, 335, 342], "regist": [3, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 44, 46, 47, 77, 81, 95, 101, 116, 119, 120, 149, 167, 168, 169, 170, 171, 172, 173, 174, 176, 178, 179, 180, 181, 182, 184, 185, 186, 187, 188, 193, 194, 197, 198, 199, 201, 204, 205, 207, 212, 218, 219, 221, 222, 223, 225, 228, 233, 236, 239, 240, 242, 243, 245, 246, 247, 248, 252, 254, 256, 257, 258, 259, 261, 267, 296, 297, 298, 299, 300, 301, 302, 303, 304, 306, 307, 327, 330, 332, 339], "manipul": [3, 4, 8, 133, 151], "third_transform": 3, "replac": [3, 6, 7, 26, 28, 32, 66, 67, 118, 120, 164, 222, 325, 339], "unexpect": [3, 32, 77, 81, 95, 101, 149, 259, 342], "behviour": 3, "fortun": [3, 333], "ident": [3, 13, 14, 16, 32, 34, 36, 39, 95, 101, 120, 193, 194, 269, 270, 271, 272, 319, 320, 331, 336], "alreadi": [3, 8, 11, 32, 34, 36, 39, 45, 77, 81, 95, 101, 145, 165, 230, 269, 270, 271, 272, 330, 332, 336], "chang": [3, 5, 7, 32, 35, 38, 41, 42, 58, 59, 60, 65, 68, 71, 77, 81, 95, 101, 115, 116, 117, 119, 121, 127, 135, 141, 143, 148, 149, 155, 184, 239, 240, 242, 243, 245, 246, 247, 248, 252, 254, 256, 257, 258, 259, 261, 267, 326, 330, 332, 333, 336, 337, 338, 339, 342], "happen": [3, 77, 81, 95, 101, 218, 331, 338, 342], "catfram": [3, 331], "hold": [3, 265, 266, 337, 339], "notic": [3, 111, 332, 337], "parenthood": 3, "henc": [3, 35, 134, 165, 193, 325, 330, 332, 336, 337], "transform1": 3, "transform2": 3, "transform3": 3, "last_two": 3, "isinst": [3, 337], "discret": [3, 24, 27, 30, 31, 33, 47, 77, 81, 95, 96, 97, 101, 103, 118, 200, 203, 245, 246, 247, 325, 331, 332, 336, 342], "might": [3, 34, 36, 37, 39, 292, 324, 330, 342], "throughout": [3, 239, 240, 241, 246, 247, 248, 249, 250, 252, 253, 254, 256, 257, 258, 259, 261, 267, 332, 342], "action_mask": [3, 96, 97, 99, 100, 108], "unavail": [3, 96, 97], "probabl": [3, 4, 8, 40, 175, 177, 180, 182, 184, 186, 188, 191, 192, 200, 210, 222, 226, 230, 325, 331, 341], "categor": [3, 27, 31, 33, 96, 97, 103, 108, 120, 177, 200, 203, 220, 221, 226, 227, 228, 243, 246, 267, 333], "probabilistictensordictmodul": [3, 127, 230, 231, 341], "tensordictsequenti": [3, 182, 186, 220, 222, 231, 325, 330, 333, 335, 338, 341], "maskedcategor": [3, 192, 323], "linear": [3, 13, 14, 16, 17, 21, 32, 77, 81, 91, 95, 101, 115, 127, 133, 145, 148, 149, 151, 153, 166, 167, 168, 177, 188, 190, 193, 194, 195, 196, 197, 203, 204, 205, 214, 215, 216, 217, 222, 223, 224, 225, 226, 227, 229, 232, 234, 239, 240, 242, 243, 245, 246, 247, 248, 252, 254, 256, 257, 258, 259, 261, 267, 269, 270, 271, 272, 317, 325, 331, 335, 338, 341], "in_feat": 3, "out_feat": 3, "logit": [3, 36, 40, 191, 192, 200, 221, 226, 246, 325], "dist": [3, 10, 191, 192, 200], "distribution_class": [3, 127, 215, 216, 217, 219, 226, 230, 232, 239, 240, 246, 252, 256, 257, 258, 259, 325, 330, 332, 336, 341], "wrap": [3, 5, 13, 14, 16, 17, 18, 19, 20, 21, 32, 40, 53, 77, 81, 95, 96, 97, 101, 103, 157, 182, 186, 212, 215, 216, 217, 218, 223, 225, 227, 235, 267, 325, 330, 331, 332, 333, 336, 342], "actionmask": 3, "your_base_env": 3, "mask_kei": [3, 108, 134], "add": [3, 4, 6, 21, 32, 35, 38, 41, 42, 52, 53, 54, 55, 56, 63, 69, 70, 72, 77, 81, 95, 101, 111, 127, 182, 186, 195, 224, 239, 300, 332, 333, 336, 337, 339, 341], "enviorn": [3, 96, 97, 103, 336], "itself": [3, 32, 77, 81, 95, 101, 105, 254, 332], "log": [3, 4, 8, 40, 175, 176, 177, 191, 192, 200, 210, 220, 221, 226, 230, 239, 240, 241, 246, 247, 248, 249, 250, 252, 253, 254, 256, 257, 258, 259, 261, 267, 298, 299, 301, 305, 317, 325, 326, 327, 330, 331, 332, 336, 337, 341], "mission": 3, "irrespect": [3, 229, 230], "dmcontrol": [3, 330], "jumanji": [3, 86, 87], "natur": [3, 330, 333], "special": [3, 325, 330, 333, 342], "framework": [3, 4, 9, 22, 91, 180, 341, 342], "Its": [3, 32, 77, 81, 95, 101, 115, 133, 145, 148, 149, 151, 153, 155, 229, 273], "success": [3, 53, 111, 148, 222, 331, 337, 339, 341], "been": [3, 5, 7, 8, 17, 18, 20, 21, 40, 65, 77, 81, 85, 95, 101, 127, 143, 144, 148, 180, 184, 218, 223, 225, 330, 331, 332, 333, 335, 336, 337, 339, 342], "foundat": [3, 5, 96, 97, 332, 336], "inspir": [3, 337], "gone": [3, 4, 5], "sometim": [3, 333, 342], "hard": [3, 7, 251, 331, 342], "adopt": [3, 5, 330, 342], "prefer": [3, 17, 20, 35, 38, 41, 42, 134, 141, 256, 302, 325, 332, 336, 339], "moreov": 3, "maintain": [3, 5, 9, 337], "both": [3, 7, 32, 77, 78, 81, 95, 96, 97, 101, 111, 135, 149, 165, 167, 168, 182, 185, 186, 188, 193, 194, 215, 216, 217, 221, 228, 239, 241, 242, 246, 252, 253, 254, 256, 257, 258, 259, 261, 301, 325, 330, 332, 336, 337, 338, 339, 342], "concomittantli": 3, "problem": [3, 7, 8, 9, 16, 331, 332, 333, 336, 337, 339, 342], "decor": [3, 8, 11, 107, 254, 269, 270, 271, 272], "set_gym_backend": [3, 105, 323], "relev": [3, 40, 269, 270, 271, 272, 273, 337], "gym_backend": [3, 107, 323], "env1": [3, 335], "path": [3, 6, 7, 32, 34, 35, 36, 38, 39, 41, 42, 45, 52, 53, 54, 55, 56, 57, 58, 77, 81, 95, 101, 107, 133, 153, 190, 305, 327, 331], "venv": 3, "python3": [3, 6, 7, 10], "site": [3, 6, 7, 55, 107], "__init__": [3, 7, 91, 107, 108, 116, 119, 166, 177, 180, 184, 190, 234, 240, 242, 246, 252, 257, 259, 261, 327, 337, 342], "env2": [3, 335], "_env": [3, 6, 342], "classic_control": 3, "pendulumenv": [3, 337], "0x15147e190": 3, "0x1629916a0": 3, "further": [3, 5, 332], "tell": [3, 4, 7, 96, 97, 330, 333, 336], "mo_gymnasium": [3, 89, 105], "handi": 3, "side": [3, 4, 342], "v0": [3, 80, 81, 82, 86, 87, 88, 89, 115, 149, 155, 317], "26": [3, 331, 335, 337, 338, 339], "fun": [3, 11, 107, 332, 336], "reveal": 4, "bug": [4, 341], "curv": 4, "won": [4, 32, 77, 78, 81, 95, 101, 133, 153, 305, 321, 331, 332], "exploit": 4, "video": [4, 9, 288, 301, 321, 336], "cv": 4, "flip": 4, "imag": [4, 7, 75, 113, 133, 147, 153, 188, 330, 331, 336, 338, 342], "correspondingli": 4, "prescript": 4, "tune": [4, 127, 336, 338], "coeffici": [4, 40, 127, 336], "bonu": [4, 239, 241, 253, 256], "beta": [4, 35, 41, 61, 252, 253, 330, 331, 339, 341], "reduc": [4, 6, 27, 144, 331, 332], "downstream": [4, 330], "formul": [4, 336], "ob": [4, 8, 26, 28, 35, 38, 41, 42, 52, 53, 54, 55, 56, 66, 67, 69, 108, 116, 117, 119, 129, 147, 161, 164, 193, 194, 227, 234, 240, 242, 246, 252, 257, 259, 261, 269, 270, 271, 272, 331, 335, 337, 341, 342], "rate": [4, 155, 268, 331, 332, 336], "gradient": [4, 32, 77, 81, 95, 101, 149, 183, 192, 196, 200, 209, 210, 239, 241, 242, 246, 252, 253, 254, 256, 257, 258, 259, 261, 268, 269, 270, 271, 272, 305, 330, 332, 336, 337], "norm": [4, 8, 305, 330, 331, 332, 336, 337], "easier": [4, 325, 330], "behavior": [4, 32, 77, 81, 95, 101, 149, 252, 332, 333, 336, 337], "local": [4, 7, 10, 16, 21, 32, 77, 81, 95, 101, 149, 193, 194, 202, 211, 267, 293, 336], "optima": 4, "sens": [4, 337], "product": [4, 9, 180, 181, 184, 185, 319, 320], "sum": [4, 21, 31, 33, 69, 110, 140, 191, 192, 211, 249, 268, 275, 326, 330, 331, 332, 333, 336, 337, 342], "track": [4, 13, 14, 16, 17, 18, 19, 20, 21, 42, 65, 140, 155, 225, 293, 298, 331, 333, 336, 337, 339], "stat": [4, 129, 309, 321, 331, 332], "w": [4, 111, 113, 136, 147, 180, 225, 288, 331, 333, 339], "r": [4, 32, 108, 114, 129, 181, 230, 238, 268, 325, 331, 337, 342], "yield": [4, 16, 21, 32, 77, 81, 95, 101, 254, 330], "insight": 4, "auxiliari": 4, "credit": 4, "futur": [4, 32, 34, 36, 39, 77, 81, 95, 101, 133, 149, 153, 188, 239, 240, 242, 243, 245, 246, 247, 248, 252, 254, 256, 257, 258, 259, 261, 267, 324, 341], "past": [4, 331, 339], "spars": [4, 333], "ineffici": 4, "ad": [4, 13, 14, 16, 32, 35, 38, 41, 42, 49, 52, 53, 54, 55, 56, 61, 77, 81, 95, 101, 140, 149, 195, 196, 225, 239, 241, 243, 247, 253, 256, 259, 267, 331, 333, 339, 342], "intermedi": [4, 110, 182, 186, 221, 330, 338], "instrument": 4, "greatli": 4, "soccer": 4, "kick": 4, "ball": 4, "likelihood": [4, 330], "discov": 4, "score": [4, 40], "undesir": 4, "though": [4, 77, 81, 95, 101, 188, 332, 336], "unintention": 4, "valuabl": 4, "idiosyncrat": 4, "subtask": 4, "hierarch": [4, 341], "individu": [4, 18, 19, 20, 21, 32, 45, 77, 81, 95, 101, 330, 336], "select": [4, 15, 35, 38, 41, 42, 52, 53, 54, 55, 56, 96, 97, 103, 108, 110, 111, 112, 115, 116, 117, 119, 120, 121, 122, 123, 124, 126, 127, 128, 132, 134, 135, 137, 140, 141, 143, 144, 145, 146, 148, 151, 152, 154, 155, 166, 182, 186, 220, 227, 304, 330, 339], "fall": [4, 52], "explicit": [4, 11, 45, 187, 339], "mechan": [4, 32, 77, 81, 95, 101, 149, 331, 337], "curios": 4, "magnitudin": 4, "domin": 4, "smaller": [4, 34, 36, 39, 77, 81, 95, 101, 184, 252, 332, 336], "addition": 4, "timestep": [4, 40, 52, 137, 274, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 336], "realli": 4, "larg": [4, 27, 34, 36, 39, 116, 119, 151, 331, 332, 336, 339], "huge": [4, 194, 333], "std": [4, 129, 155, 197, 201, 218, 330, 342], "torchrl": [4, 5, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 323, 329, 333, 334, 335, 338, 339, 340], "initi": [4, 7, 13, 14, 16, 17, 18, 19, 20, 21, 32, 34, 36, 39, 40, 77, 81, 95, 101, 110, 129, 133, 145, 148, 149, 151, 156, 166, 180, 181, 184, 185, 190, 195, 196, 218, 222, 223, 225, 239, 240, 242, 243, 245, 246, 247, 248, 252, 253, 254, 255, 256, 257, 258, 259, 261, 267, 314, 321, 331, 333, 337, 342], "estim": [4, 66, 67, 120, 127, 215, 216, 217, 239, 240, 241, 242, 243, 245, 246, 247, 248, 252, 253, 254, 255, 256, 257, 258, 259, 261, 262, 267, 269, 270, 271, 272, 273, 274, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 326, 331, 332, 333, 335, 336, 337, 338, 339, 341, 342], "encount": [4, 324, 331, 337], "unseen": 4, "extrins": 4, "wrong": 4, "bonus": 4, "denser": 4, "prior": [4, 205, 249, 336], "freshli": 4, "doesn": [4, 11, 92, 116, 119], "drop": [4, 65, 67, 164], "meant": [4, 91], "encourag": [4, 330, 331, 339], "measur": [4, 332], "novelti": 4, "revisit": 4, "previous": [4, 332, 342], "diminish": 4, "decreas": 4, "ideal": [4, 129, 337], "down": [4, 13, 14, 16, 17, 333], "anyth": 4, "try": [4, 7, 8, 9, 26, 28, 34, 36, 39, 331, 332, 333, 336, 337, 341, 342], "distil": 4, "nois": [4, 156, 196, 213, 225, 257, 261, 301, 321, 330], "exploratori": [4, 239, 241, 253, 256], "misalign": 4, "trade": 4, "unavoid": 4, "schedul": [4, 7, 40, 301, 332, 337], "divers": [4, 95, 101], "bootstrap": [4, 247, 270, 276, 277, 330, 333], "noisi": [4, 195, 196, 213, 325], "unstabl": [4, 183, 209, 210], "inher": 4, "stochast": [4, 127, 178, 196, 198, 205, 240, 244, 246, 252, 255, 257, 259, 325, 332, 336], "enemi": 4, "variabl": [4, 7, 8, 24, 25, 26, 27, 28, 29, 30, 31, 33, 44, 46, 47, 53, 55, 56, 103, 180, 181, 182, 184, 185, 186, 190, 215, 216, 217, 254, 257, 327, 331], "pomdp": [4, 339], "loos": [4, 325, 331, 332], "nonexist": 4, "architectur": [4, 174, 336], "sequenc": [4, 13, 14, 16, 17, 26, 28, 30, 31, 35, 37, 38, 40, 43, 45, 57, 63, 69, 70, 72, 109, 110, 111, 112, 113, 116, 118, 119, 123, 125, 129, 130, 134, 135, 136, 137, 138, 139, 140, 144, 146, 147, 148, 155, 167, 168, 175, 177, 180, 184, 188, 191, 192, 193, 194, 200, 203, 207, 219, 231, 232, 244, 287, 288, 300, 301, 302, 304, 305, 314, 325, 330, 332, 333, 335, 336, 342], "lstm": [4, 185, 186, 187, 197], "rel": [4, 145, 175, 208, 330, 331, 336, 339], "tend": 4, "stabl": [4, 9, 10], "compens": 4, "descent": [4, 196], "1000": [4, 38, 66, 67, 77, 81, 95, 101, 111, 155, 222, 225, 226, 230, 251, 330, 331, 332, 333, 338, 339], "minimum": [4, 95, 101, 138, 178, 197, 208, 209, 210, 233, 236, 238, 240, 246, 254, 255, 259, 296, 330, 332, 336], "manual": [4, 18, 20, 21, 330, 333, 339], "deviat": [4, 129, 155, 166, 178, 190, 195, 196, 218, 256, 261, 330, 336], "radic": 4, "begin": [4, 13, 14, 16, 18, 19, 20, 21, 180, 181, 184, 185], "stabil": [4, 124], "stage": [4, 330, 337], "never": 4, "prevent": [4, 26, 28, 183, 209, 210, 253, 256, 303, 339], "solv": [4, 9, 10, 324, 330, 331, 332, 336, 337, 339], "entir": [4, 193, 332, 337, 339], "submit": [4, 324, 341], "suffici": [4, 330], "system": [4, 5, 332, 336, 337], "adequ": [4, 157, 332, 336], "infeas": 4, "allevi": [4, 325], "prune": 4, "fire": [4, 32, 77, 81, 95, 101], "certain": [4, 18, 20, 21, 32, 45, 77, 81, 95, 101, 107, 124, 143, 149, 181, 185, 222, 253, 325, 330, 331, 332, 336, 342], "illeg": 4, "move": [4, 21, 32, 56, 77, 81, 95, 101, 115, 117, 133, 145, 148, 149, 151, 153, 155, 164, 188, 229, 303, 330, 331, 333, 341, 342], "chess": 4, "combin": [4, 148, 331, 339], "grasp": 4, "releas": [4, 7, 10, 32, 77, 81, 95, 101, 149, 259, 341], "top": [4, 69, 166, 190], "p": [4, 78, 99, 100], "wherein": 4, "cumul": [4, 140, 144, 166, 275, 332], "q": [4, 9, 77, 81, 95, 101, 170, 171, 172, 173, 176, 177, 179, 202, 203, 211, 217, 221, 227, 228, 240, 242, 243, 245, 246, 247, 251, 252, 257, 259, 261, 267, 314, 323, 330], "flow": [4, 330, 332, 336, 337, 339], "reparameter": [4, 175, 192, 200], "soft": [4, 251, 259, 260], "critic": [4, 8, 215, 224, 239, 241, 242, 246, 252, 253, 256, 257, 258, 259, 261, 330, 332], "clip": [4, 40, 114, 138, 241, 261, 305, 332, 336, 337], "oppos": [4, 45], "incorrect": 4, "thought": [4, 77, 81, 95, 101], "bound": [4, 17, 21, 25, 26, 32, 77, 81, 95, 101, 114, 128, 155, 204, 205, 214, 220, 221, 225, 226, 227, 228, 229, 230, 233, 261, 325, 330, 331, 332, 342], "region": 4, "squash": [4, 333, 341], "tanh": [4, 167, 168, 180, 181, 183, 184, 185, 188, 194, 208, 209, 210, 233, 332, 336, 337, 338, 341], "correct": [4, 34, 36, 39, 127, 308, 332, 333], "prob": [4, 191, 192, 200, 332, 336], "rememb": 4, "remap": 4, "origin": [4, 8, 13, 14, 16, 17, 34, 36, 39, 40, 85, 117, 118, 127, 133, 149, 153, 180, 226, 229, 230, 251, 254, 256, 314, 330, 335, 337, 342], "real": [5, 230, 326, 333, 337], "histor": 5, "ceas": 5, "fork": 5, "farama": [5, 88, 89, 96, 97, 332, 337], "usag": [5, 7, 52, 53, 55, 56, 111, 120, 182, 186, 252, 259, 262, 325, 330, 331, 332, 333, 335, 336, 337, 338, 339, 341, 342], "bc": [5, 341], "break": [5, 13, 14, 16, 21, 32, 38, 42, 53, 55, 56, 57, 66, 67, 77, 81, 95, 101, 111, 137, 155, 331, 339, 341], "against": [5, 7, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 44, 46, 47, 77, 81, 95, 101, 157, 214, 220, 221, 226, 227, 228, 229, 230, 332, 336], "13": [5, 10, 11, 66, 67, 98, 154, 329, 330, 331, 336, 337, 338, 339, 340], "construct": [5, 32, 35, 38, 41, 42, 77, 81, 95, 96, 101, 116, 119, 157, 182, 186, 205, 230, 305, 325, 331, 332, 333, 337, 339, 342], "best": [5, 9, 85, 182, 186, 336, 339, 341], "gymwrapp": [5, 77, 81, 95, 101, 121, 141, 143, 154, 323, 332, 341], "feel": [5, 324, 341], "free": [5, 7, 116, 119, 239, 249, 256, 327, 332, 336, 341], "gladli": 5, "instruct": [6, 7, 10, 22, 52, 118, 120, 330, 331, 332, 333, 336, 339], "prepar": [6, 332], "conda": [6, 7, 324], "7": [6, 10, 27, 33, 35, 38, 41, 67, 144, 166, 167, 168, 187, 188, 190, 193, 275, 329, 330, 331, 336, 337, 338, 339, 340, 341], "cmake": 6, "14": [6, 11, 56, 66, 67, 129, 330, 331, 333, 337, 338, 339], "activ": [6, 7, 9, 167, 168, 174, 178, 188, 193, 194, 241, 253, 256, 325, 337, 341], "sim": 6, "bullet": 6, "physic": [6, 7, 95, 98, 327, 330, 336, 337], "headless": [6, 7], "cluster": [6, 7, 8, 18, 21, 324], "withbullet": 6, "forg": [6, 7], "aihabitat": 6, "nightli": 6, "y": [6, 7, 94, 187, 193, 212, 330, 332, 336], "git": [6, 7, 10], "facebookresearch": 6, "subdirectori": 6, "verbos": 6, "export": [6, 7], "magnum_log": 6, "quiet": 6, "habitat_sim_log": 6, "remov": [6, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 39, 44, 46, 47, 49, 77, 81, 95, 101, 142, 254, 336, 342], "command": [6, 7, 10, 332, 336, 337, 342], "readm": [6, 7], "md": [6, 7], "habitatenv": [6, 323], "_has_habitat": 6, "available_env": [6, 73, 74, 75, 76, 77, 80, 81, 82, 86, 87, 88, 89, 95, 99, 100, 101, 342], "startswith": [6, 326, 330], "oserror": 6, "libllvmlit": 6, "ionstal": 6, "pointer": [6, 78, 254, 330], "env_nam": [6, 73, 75, 80, 86, 88, 92, 98, 330, 332, 342], "llvmlite": 6, "config": [6, 7, 133, 153, 169, 174, 201, 309, 310, 311, 314, 315, 318], "var": [6, 7, 32, 77, 81, 95, 101, 149, 254, 259], "ld_preload": [6, 7], "8": [6, 7, 38, 55, 61, 66, 67, 74, 77, 81, 95, 101, 144, 167, 168, 170, 171, 179, 188, 215, 216, 217, 226, 229, 232, 252, 329, 330, 331, 332, 336, 337, 338, 339, 340, 341], "bind": 6, "deactiv": [6, 7, 220], "importerror": [6, 7, 10], "usr": [6, 7, 10], "x86_64": [6, 7], "linux": [6, 7], "gnu": [6, 7], "libopengl": [6, 7], "undefin": [6, 7, 10, 32, 77, 81, 95, 101, 149, 254, 259, 339], "symbol": [6, 7, 10], "_glapi_tls_curr": [6, 7], "link": [6, 7, 331], "mujoco_env": [6, 7], "libglvnd": [6, 7], "glx": [6, 7], "cos7": [6, 7], "reinstal": [6, 7], "xvfbwrapper": [6, 7], "sysroot": [6, 7], "lib64": [6, 7], "libgldispatch": [6, 7], "offici": [7, 52], "stand": [7, 335, 337], "joint": [7, 331], "dynam": [7, 56, 252, 332, 337], "contact": [7, 37], "engin": [7, 98, 337], "biomechan": 7, "graphic": 7, "anim": [7, 336], "area": 7, "demand": [7, 342], "fast": [7, 9, 74, 135, 257, 330, 331, 332], "accur": [7, 52, 53, 55, 56, 331, 337, 339], "articul": 7, "recent": [7, 11, 154, 342], "acquir": [7, 332], "deepmind": [7, 8, 9, 75, 76, 120, 332], "whomev": 7, "licenc": 7, "incorpor": [7, 218, 222, 223, 225, 333, 337], "relianc": 7, "obsolet": 7, "seri": [7, 8, 33, 63, 69, 70, 72, 101, 128, 148, 288, 325, 326, 330, 331, 332, 336, 339, 342], "legaci": 7, "pro": [7, 324], "tip": [7, 324], "glfw": 7, "osmesa": 7, "egl": 7, "advic": [7, 342], "sudo": [7, 324], "enabl": [7, 8, 52, 58, 59, 71, 182, 186, 225, 301, 332, 336, 337, 339], "apt": [7, 336], "libglfw3": 7, "libglew2": 7, "libgl1": 7, "mesa": 7, "libosmesa6": 7, "awar": [7, 58, 59, 60, 68, 71, 331, 333], "workflow": [7, 215, 216, 217], "glew": 7, "mesalib": 7, "anaconda": 7, "libgl": 7, "cos6": 7, "menpo": 7, "glfw3": 7, "mujoco_gl": 7, "pyopengl_platform": 7, "pre": [7, 22, 32, 45, 59, 77, 81, 95, 101, 133, 151, 153, 342], "binari": [7, 24, 27, 33, 109, 177, 203, 220, 221, 227, 228, 243, 246, 267], "setup": [7, 85], "mkdir": 7, "cd": 7, "tag": [7, 288, 293, 321], "earlier": [7, 330, 332, 333, 336, 339], "roboti": 7, "download": [7, 10, 52, 53, 55, 56, 85, 133, 153, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 341, 342], "html": [7, 92], "wget": 7, "mujoco210": 7, "tar": 7, "gz": 7, "xf": 7, "charg": [7, 13, 14, 95, 101], "obtain": [7, 40, 77, 81, 95, 101, 110, 133, 144, 153, 166, 202, 302, 330, 332, 336], "mjkei": 7, "txt": 7, "mjlib_path": 7, "home": [7, 34, 36, 45, 57], "bin": [7, 177, 221, 325], "libmujoco210": 7, "ld_library_path": 7, "mujoco_py_mujoco_path": 7, "mujoco_py_mjkey_path": 7, "reload": 7, "later": [7, 173, 226, 230, 330, 332, 339], "nvidia": [7, 85], "older": [7, 11], "hack": [7, 330], "line": [7, 32, 77, 81, 95, 101, 331, 336], "adatp": 7, "script": [7, 157, 314, 317, 321, 325, 326, 327, 330, 331, 332, 333, 335, 336, 337, 338, 339, 341, 342], "unnot": [7, 134], "until": [7, 21, 146, 148, 332, 333, 336], "complet": [7, 9, 65, 81, 111, 143, 324, 326, 330, 332, 335], "mujoco_pi": 7, "trigger": 7, "cymj": 7, "linuxgpuextensionbuild": 7, "filenam": [7, 331, 339], "troubleshoot": 7, "gl": 7, "h": [7, 111, 113, 136, 147, 180, 181, 182, 184, 185, 186, 190, 288, 331, 333, 339], "eglshim": 7, "fatal": 7, "No": 7, "directori": [7, 34, 36, 39, 45, 52, 53, 55, 56, 58, 293, 327], "devel": 7, "ubuntu": [7, 85], "libglew": 7, "dev": 7, "cento": 7, "yum": 7, "glu": 7, "38": [7, 331, 332, 336, 337, 339], "disappear": [7, 331, 333, 335], "libstdc": 7, "6": [7, 13, 14, 16, 17, 38, 55, 56, 67, 87, 99, 100, 129, 131, 144, 167, 168, 175, 181, 187, 188, 193, 194, 198, 208, 226, 234, 314, 329, 330, 331, 333, 336, 337, 339, 340, 341, 342], "glibcxx_3": 7, "29": [7, 331, 336, 337], "compil": [7, 32, 77, 81, 95, 101, 180, 181, 184, 185], "libosmesa": 7, "libgcc": 7, "Then": [7, 154, 332, 335], "filenotfounderror": 7, "errno": 7, "patchelf": 7, "fatalerror": 7, "gladloadgl": 7, "mj_env": 7, "912": 7, "glfwerror": 7, "65537": 7, "sovl": 7, "myscript": 7, "runtimeerror": [7, 8, 26, 28, 32, 77, 81, 95, 101, 128, 149, 259, 342], "job": [7, 18, 19, 20, 22], "slurm": 7, "mjrendercontext": 7, "pyx": 7, "46": [7, 331, 337], "114": [7, 337, 339], "_setup_opengl_context": 7, "opengl_context": 7, "130": [7, 337, 339], "offscreenopenglcontext": 7, "fail": [7, 22, 26, 28, 108, 157], "opengl": [7, 336], "global": [7, 32, 77, 81, 95, 96, 97, 101, 202, 211, 226, 230, 267, 327, 330, 336], "cuda_visible_devic": 7, "id": [7, 23, 40, 225, 257, 291, 314], "slurm_step_gpu": 7, "enviro": [7, 10], "black": 7, "onscreen": 7, "101": [7, 337, 339], "correctli": [7, 32, 77, 81, 95, 101], "lgl": 7, "libegl": 7, "x11": [7, 336], "xlib": 7, "libx11": 7, "xorg": 7, "loop": [8, 13, 14, 16, 17, 34, 36, 39, 81, 164, 218, 222, 223, 225, 256, 305, 327, 330, 331, 335, 339], "sketch": [8, 327], "_": [8, 35, 38, 41, 42, 52, 53, 54, 55, 56, 78, 85, 103, 112, 116, 118, 119, 127, 129, 135, 147, 155, 214, 229, 234, 238, 239, 240, 242, 246, 252, 256, 257, 259, 261, 269, 270, 271, 272, 330, 331, 332, 333, 336, 337, 339, 341], "n_training_step": 8, "datapoint": [8, 45, 339], "onlin": [8, 13, 17, 111, 174, 201, 239, 244, 255, 256, 296, 321, 332, 333, 336, 339], "n_data_per_train": 8, "no_grad": [8, 32, 77, 81, 95, 101, 127, 180, 181, 184, 185, 269, 270, 271, 272, 332, 333, 336], "replay_buff": [8, 35, 38, 41, 42, 52, 53, 54, 55, 56, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 302, 317, 330, 331, 332, 336, 339], "loss_fn": [8, 333, 341], "backward": [8, 32, 77, 81, 95, 101, 155, 180, 181, 184, 185, 239, 240, 242, 246, 252, 256, 257, 258, 259, 261, 330, 332, 333, 336, 337], "zero_grad": [8, 32, 77, 81, 95, 101, 327, 330, 332, 333, 336, 337], "backpropag": [8, 239, 240, 241, 246, 247, 248, 249, 250, 252, 253, 254, 256, 257, 258, 259, 261, 267, 336, 337], "differenti": [8, 45, 127, 269, 270, 271, 272, 333, 336, 337], "denomin": 8, "artifact": 8, "numer": [8, 38, 155, 183, 209, 210, 214, 220, 221, 226, 227, 228, 229, 230, 303, 332, 339, 342], "misconcept": 8, "freed": 8, "appear": [8, 33, 66, 67, 337, 339], "compuat": 8, "twice": 8, "fix": [8, 145, 240, 255, 259, 331, 337, 342], "retain_graph": 8, "discuss": [8, 9, 336], "inplac": [8, 32, 34, 36, 39, 77, 81, 95, 101, 149, 259, 330], "accumul": 8, "onto": [8, 33, 34, 36, 39, 161, 214, 218, 220, 221, 225, 226, 227, 228, 229, 230, 333, 337], "exclud": [8, 52, 55, 111, 121, 164, 202, 336, 339], "forward": [8, 32, 77, 81, 95, 101, 108, 110, 111, 112, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 126, 127, 129, 132, 133, 134, 135, 137, 140, 141, 143, 144, 145, 146, 148, 151, 152, 154, 155, 167, 168, 169, 170, 171, 172, 173, 174, 176, 177, 178, 179, 180, 181, 182, 184, 185, 186, 187, 188, 189, 193, 194, 195, 197, 198, 199, 201, 202, 204, 205, 207, 211, 212, 218, 219, 221, 222, 223, 225, 226, 228, 229, 230, 233, 234, 236, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 252, 253, 254, 255, 256, 257, 258, 259, 261, 267, 269, 270, 271, 272, 273, 326, 337, 341], "submodul": [8, 32, 77, 81, 95, 101, 105, 254], "param": [8, 32, 40, 77, 81, 91, 95, 101, 115, 116, 117, 121, 127, 135, 141, 143, 148, 175, 177, 208, 219, 226, 229, 232, 234, 254, 263, 266, 269, 270, 271, 272, 273, 330, 336, 337, 338, 341], "grad": [8, 32, 77, 81, 95, 101, 330, 332], "whose": [8, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 40, 44, 46, 47, 77, 81, 95, 96, 97, 101, 115, 133, 145, 148, 149, 151, 153, 197, 202, 229], "neg": [8, 13, 14, 16, 17, 18, 19, 20, 21, 35, 41, 61, 111, 123, 134, 150, 248, 326, 332, 336, 337], "ask": [8, 66, 67, 330, 332, 333, 336, 338, 342], "much": [8, 13, 14, 35, 41, 61, 95, 101, 253, 256, 332, 336, 337, 339, 342], "render": [8, 301, 330, 331, 332], "upon": [8, 337], "factor": [8, 32, 137, 183, 196, 209, 210, 218, 222, 223, 225, 240, 245, 247, 248, 250, 260, 275, 330, 331, 336, 339, 342], "fit": [8, 11, 129, 326, 327, 330], "bottlneck": 8, "brax": [8, 73, 74, 135, 342], "jax": [8, 11], "improperli": 8, "item": [8, 13, 26, 28, 32, 38, 45, 57, 69, 77, 81, 95, 101, 122, 149, 191, 192, 242, 243, 245, 259, 296, 326, 327, 330, 332, 333, 336, 337, 339], "underli": [8, 77, 81, 95, 101, 254, 337], "tedeiou": 8, "priorit": [8, 35, 41, 61, 242, 243, 245, 246, 252, 257, 259, 261, 330, 331], "amount": [8, 225, 331, 339], "contigu": [8, 55, 77, 81, 95, 101, 161, 332, 336, 337, 339, 341, 342], "costli": [8, 337], "concaten": [8, 21, 30, 31, 111, 112, 129, 148, 184, 188, 232, 330, 331, 336, 337, 339, 342], "constitut": [8, 331, 336, 337], "plain": 8, "profil": 8, "fulli": [8, 32, 77, 81, 95, 101, 181, 185, 331, 337, 339], "frequent": [8, 339], "program": [8, 252, 342], "functorch": [8, 10], "incl": 8, "suit": [8, 76, 332, 342], "mujoco_instal": 8, "valueerror": 8, "bad": 8, "fds_to_keep": 8, "expand": [8, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 36, 39, 44, 46, 47, 66, 67, 229, 232, 254, 336, 337, 341], "new_shap": 8, "permut": [8, 65, 131, 341, 342], "idea": [9, 257, 327, 333, 336], "introductori": 9, "intro": [9, 332, 333], "dai": [9, 341], "2022": [9, 10, 337, 341], "spin": 9, "deep": [9, 111, 170, 171, 172, 173, 176, 225, 239, 251, 259, 260, 330], "hug": 9, "syllabu": 9, "lectur": 9, "awesom": 9, "curat": 9, "succinct": 9, "summari": [9, 129, 155, 330, 331, 332, 333], "reddit": 9, "reagent": 9, "orient": [9, 56, 342], "baselines3": 9, "tf": 9, "bandit": [9, 94], "tensorflow": [9, 191, 192], "kera": 9, "acm": 9, "dopamin": 9, "prototyp": 9, "salina": 9, "sequenti": [9, 32, 77, 81, 95, 101, 110, 127, 231, 232, 256, 325, 332, 333, 336, 337, 338, 342], "tianshou": 9, "eleg": 9, "rlpyt": 9, "rllib": 9, "industri": [9, 341], "grade": 9, "factori": [9, 43], "throughput": [9, 330], "cherri": 9, "jaxrl": 9, "space": [9, 33, 44, 77, 81, 95, 101, 114, 118, 161, 174, 177, 193, 199, 203, 214, 218, 220, 221, 223, 225, 226, 227, 228, 229, 230, 232, 233, 234, 243, 245, 246, 261, 267, 325, 331, 332, 333, 336, 337, 341, 342], "mbrl": [9, 91, 325], "rlmeta": 9, "light": 9, "elegantrl": 9, "cloud": 9, "mtrl": 9, "baselin": 9, "689": [10, 337], "_torchrl": 10, "_zn8pybind116detail11type_casterin2at6tensoreve4loadens_6handleeb": 10, "colab": [10, 332, 333, 336], "notebook": [10, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 341, 342], "24": [10, 55, 67, 329, 330, 331, 332, 333, 336, 337, 338, 340], "11": [10, 27, 33, 45, 58, 59, 67, 71, 78, 147, 166, 190, 329, 330, 331, 332, 333, 336, 337, 339, 340], "12": [10, 55, 58, 59, 67, 71, 99, 100, 330, 331, 332, 333, 336, 337, 339], "pip": [10, 54, 336, 341, 342], "pip3": [10, 332, 333, 336], "extra": [10, 32, 77, 81, 95, 101, 111, 155, 164, 325, 332, 333, 339], "url": 10, "org": [10, 35, 56, 61, 111, 133, 151, 169, 170, 171, 172, 173, 174, 177, 178, 179, 184, 190, 191, 192, 196, 198, 199, 201, 202, 204, 205, 211, 221, 225, 239, 240, 243, 244, 245, 247, 248, 249, 250, 251, 252, 255, 256, 258, 259, 260, 269, 274, 282, 338], "whl": 10, "u": [10, 54, 180, 181, 184, 185, 337], "There": [10, 182, 186, 325, 327, 332, 333, 336, 337, 339, 342], "upgrad": 10, "relas": 10, "lib_version_her": 10, "module_nam": [11, 254], "str": [11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 52, 53, 54, 55, 56, 57, 58, 61, 75, 77, 79, 81, 94, 95, 96, 97, 98, 101, 103, 104, 105, 108, 111, 118, 120, 126, 127, 129, 133, 134, 136, 143, 144, 149, 151, 153, 154, 155, 158, 162, 164, 165, 166, 167, 168, 170, 171, 172, 173, 176, 177, 179, 182, 186, 187, 188, 189, 190, 193, 194, 195, 196, 197, 202, 203, 211, 214, 220, 221, 226, 227, 228, 229, 230, 233, 234, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 249, 250, 252, 253, 254, 255, 256, 257, 258, 259, 261, 264, 267, 268, 269, 270, 271, 272, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 306, 307, 309, 314, 315, 321, 331, 332], "callabl": [11, 13, 14, 16, 17, 18, 19, 20, 21, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 35, 38, 41, 42, 44, 45, 46, 47, 52, 53, 54, 55, 56, 77, 78, 81, 91, 95, 101, 107, 120, 238, 310, 311, 319, 320, 321, 331], "from_vers": 11, "to_vers": 11, "intersect": [11, 143], "vs": [11, 182, 186, 187, 341], "longer": [11, 331, 336, 339], "self": [11, 26, 28, 32, 34, 36, 39, 77, 81, 91, 95, 101, 108, 115, 116, 119, 133, 145, 148, 149, 151, 153, 166, 177, 190, 202, 211, 218, 222, 223, 226, 229, 234, 239, 240, 242, 243, 245, 246, 247, 248, 252, 254, 256, 257, 258, 259, 261, 267, 269, 270, 271, 272, 273, 327, 330, 331, 337, 341], "x": [11, 23, 26, 32, 38, 40, 67, 127, 147, 168, 177, 179, 180, 181, 182, 184, 185, 186, 187, 188, 190, 193, 194, 212, 220, 226, 227, 236, 238, 274, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 288, 305, 330, 332, 337, 339, 341], "23": [11, 55, 67, 330, 331, 333, 337, 339], "lambda": [11, 13, 14, 16, 17, 21, 22, 38, 77, 78, 81, 95, 101, 107, 127, 145, 212, 220, 227, 248, 250, 269, 272, 280, 281, 285, 286, 317, 326, 330, 331, 336, 339, 341, 342], "import_modul": 11, "27": [11, 329, 331, 332, 337, 340], "get_class_that_defined_method": 11, "f": [11, 81, 185, 238, 269, 270, 271, 272, 273, 274, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 330, 331, 332, 333, 336, 337, 339, 342], "otherwis": [11, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 39, 43, 44, 45, 46, 47, 52, 57, 66, 67, 77, 81, 90, 95, 96, 97, 101, 103, 111, 118, 129, 144, 145, 146, 149, 155, 180, 183, 184, 193, 194, 209, 210, 220, 227, 233, 240, 249, 254, 255, 259, 301, 302, 327, 330, 331, 332, 333, 337, 342], "classmethod": [11, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 36, 39, 44, 46, 47, 151, 169, 201], "module_set": 11, "setters_dict": 11, "dict": [11, 13, 14, 16, 17, 18, 19, 20, 21, 22, 24, 26, 27, 28, 29, 30, 32, 34, 36, 39, 55, 77, 78, 81, 95, 96, 97, 101, 103, 104, 127, 145, 149, 154, 155, 167, 168, 169, 170, 171, 172, 173, 174, 179, 187, 188, 201, 226, 230, 259, 292, 293, 301, 310, 311, 314, 319, 320, 321, 330, 331, 332, 342], "setter": 11, "setter_dict": 11, "copi": [11, 18, 19, 20, 21, 32, 34, 36, 39, 40, 45, 77, 81, 95, 101, 135, 144, 149, 164, 182, 186, 219, 254, 259, 326, 330, 331, 333, 339], "kwd": 12, "policy_weight": [12, 13, 14, 16, 17, 19, 20], "tensordictbas": [12, 13, 14, 16, 17, 18, 19, 20, 21, 23, 26, 28, 29, 32, 41, 42, 52, 53, 54, 55, 56, 77, 79, 81, 95, 101, 108, 110, 111, 112, 115, 116, 117, 120, 121, 122, 123, 126, 127, 132, 134, 135, 137, 140, 141, 143, 144, 145, 146, 148, 154, 155, 164, 165, 166, 182, 186, 189, 190, 218, 219, 221, 222, 223, 225, 228, 229, 230, 239, 240, 241, 242, 243, 244, 245, 246, 247, 252, 253, 254, 255, 256, 257, 258, 259, 261, 267, 268, 269, 270, 271, 272, 273, 305, 330, 337], "udpdat": [12, 13, 14, 16, 17, 19, 20], "create_env_fn": [13, 14, 16, 17, 18, 19, 20, 21, 78, 95, 101, 330, 341], "int": [13, 14, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 66, 67, 68, 69, 70, 71, 72, 75, 77, 81, 91, 95, 96, 97, 101, 103, 110, 111, 112, 113, 118, 123, 124, 128, 129, 131, 133, 134, 136, 142, 143, 146, 149, 150, 151, 153, 157, 161, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 177, 178, 179, 180, 181, 183, 184, 185, 187, 188, 190, 191, 192, 193, 194, 195, 196, 198, 199, 201, 202, 203, 204, 205, 207, 208, 209, 211, 212, 218, 219, 220, 221, 222, 223, 225, 226, 228, 229, 230, 239, 240, 241, 246, 248, 249, 253, 254, 255, 256, 257, 261, 274, 275, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 296, 297, 298, 301, 302, 305, 307, 314, 315, 319, 320, 321, 337], "200": [13, 14, 16, 17, 21, 32, 77, 81, 95, 101, 102, 103, 137, 170, 171, 178, 204, 205, 330, 333, 337], "total_fram": [13, 14, 16, 17, 18, 19, 20, 21, 111, 137, 305, 308, 317, 327, 330, 331, 332, 333, 336, 339, 341], "device_typ": [13, 16, 27, 30, 33, 167, 168, 169, 170, 171, 172, 173, 179, 188, 195, 196, 201], "create_env_kwarg": [13, 14, 16, 17, 78, 92, 95, 101, 330], "postproc": [13, 14, 16, 17, 18, 19, 20, 21, 137, 331, 339], "explorationtyp": [13, 14, 16, 20, 21, 254, 301, 330, 331, 332, 333, 341], "interactiontyp": [13, 16, 18, 19, 20, 21, 159, 163, 226, 230, 301], "exploration_mod": [13, 16, 18, 19, 20, 323, 325], "preemptive_threshold": [13, 14], "float": [13, 14, 25, 27, 32, 33, 35, 40, 41, 46, 61, 77, 81, 95, 101, 111, 115, 116, 119, 127, 129, 133, 137, 138, 139, 144, 145, 147, 148, 149, 151, 153, 155, 175, 178, 180, 183, 184, 188, 191, 192, 195, 196, 204, 205, 208, 210, 218, 229, 233, 236, 237, 238, 239, 240, 245, 246, 249, 250, 251, 252, 255, 257, 259, 260, 261, 268, 274, 275, 276, 277, 278, 279, 280, 281, 282, 303, 330, 331, 339, 342], "num_thread": [13, 14, 34, 36, 39, 95, 101], "num_sub_thread": [13, 14, 95, 101], "datacollector": [13, 14, 16, 17, 226, 230, 256, 332], "recept": 13, "safe": [13, 14, 24, 25, 26, 27, 28, 29, 30, 31, 33, 44, 46, 47, 214, 218, 220, 221, 225, 226, 227, 228, 229, 230, 232, 325, 341], "stepcount": [13, 77, 81, 95, 101, 148, 330, 331, 332, 333, 336, 341], "env_mak": [13, 14, 16, 21, 317, 342], "50": [13, 14, 16, 21, 37, 40, 56, 66, 67, 330, 331, 332, 333, 336, 337, 338, 339], "2000": [13, 14, 16, 45, 84, 332, 339], "enumer": [13, 14, 16, 21, 32, 38, 42, 67, 77, 81, 95, 101, 262, 326, 330, 331, 332, 333, 339, 341], "int64": [13, 14, 16, 24, 27, 30, 34, 36, 37, 39, 40, 41, 43, 45, 53, 55, 56, 57, 77, 81, 90, 94, 95, 96, 97, 99, 100, 101, 120, 131, 137, 143, 177, 203, 220, 221, 225, 226, 227, 228, 325, 332, 333, 337, 339, 341, 342], "step_count": [13, 14, 16, 77, 81, 95, 101, 143, 332, 333, 341], "shutdown": [13, 14, 16, 17, 21, 330, 341], "del": [13, 14, 16, 330, 332, 335, 341, 342], "randompolici": [13, 14, 16, 18, 19, 20, 22, 111, 137, 323, 339], "lifespan": [13, 14, 16, 18, 19, 20, 331], "divis": [13, 14, 16, 18, 19, 20, 66, 67, 336], "endless": [13, 14, 16, 18, 19, 20], "dictionari": [13, 14, 16, 17, 18, 19, 20, 21, 26, 32, 34, 36, 39, 45, 66, 67, 77, 81, 95, 101, 103, 145, 149, 226, 230, 259, 301, 319, 320, 321, 327, 331, 332, 337, 342], "span": [13, 14, 16, 17, 18, 19, 20, 21], "n_step": [13, 14, 16, 17, 18, 19, 20, 21, 32, 331, 332, 336], "ignor": [13, 14, 16, 17, 18, 19, 20, 21, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 37, 43, 44, 46, 47, 77, 81, 95, 101, 118, 121, 141, 147, 167, 168, 169, 170, 171, 172, 173, 174, 176, 178, 179, 180, 181, 182, 184, 185, 186, 187, 188, 191, 192, 193, 194, 197, 198, 199, 201, 204, 205, 207, 212, 218, 219, 221, 222, 223, 225, 228, 233, 236, 269, 339], "mainli": [13, 14, 16, 17, 18, 19, 20, 21, 40, 325, 336, 337], "round": [13, 14, 16], "closest": [13, 14, 16], "post": [13, 14, 16, 18, 19, 20, 21, 32, 53, 77, 81, 95, 101], "multistep": [13, 14, 16, 18, 19, 20, 21, 323, 331], "return_same_td": [13, 14, 16], "cautious": [13, 14, 16, 256], "whole": [13, 14, 16, 26, 28, 32, 45, 77, 81, 95, 101, 149, 226, 259, 296, 330, 332], "boolm": [13, 14], "update_policy_weight_": [13, 14], "sync": [13, 14, 18, 19, 20, 21, 307, 317, 327, 330, 341], "async": [13, 14, 18, 19, 20, 21, 154, 330, 341], "ratio": [13, 14, 40, 330, 332], "finish": [13, 14, 21, 81, 137, 342], "rest": [13, 14, 325, 332, 333, 337, 341], "earli": [13, 14, 81, 143, 341], "thread": [13, 14, 34, 36, 39, 92, 95, 101], "equal": [13, 14, 66, 67, 92, 95, 101, 128, 129, 167, 168, 176, 180, 182, 184, 186, 188, 194, 260, 264, 296, 319, 320, 330, 332, 338], "plu": [13, 14, 40, 95, 101, 337], "safeti": [13, 14, 91, 95, 101], "harm": [13, 14, 95, 101], "ordereddict": [13, 14, 16, 17, 21, 32, 77, 81, 95, 101, 149, 155, 259, 331], "form": [13, 14, 17, 32, 35, 38, 41, 42, 52, 53, 54, 55, 56, 77, 81, 95, 101, 155, 180, 182, 184, 186, 238, 239, 241, 253, 256, 305, 325, 336], "worker0": [13, 14, 17], "state_dict0": [13, 14, 17], "worker1": [13, 14, 17], "state_dict1": [13, 14, 17], "reset_idx": [13, 14, 17], "static_se": [13, 14, 16, 17, 21, 77, 81, 95, 101, 149], "integ": [13, 14, 16, 17, 23, 30, 31, 32, 33, 40, 47, 68, 77, 81, 95, 101, 120, 124, 129, 143, 167, 168, 188, 193, 194, 252, 259, 339], "increment": [13, 14, 16, 17, 77, 81, 95, 101, 253], "env_fn": [13, 14, 16, 17, 78, 319, 320], "env_fn_parallel": [13, 14, 16, 17], "100": [13, 14, 16, 17, 32, 35, 38, 41, 42, 43, 52, 53, 54, 55, 56, 58, 59, 77, 81, 95, 101, 114, 120, 129, 137, 143, 193, 221, 297, 317, 331, 332, 333, 335, 336, 337, 338, 339, 341, 342], "300": [13, 14, 16, 17, 66, 67, 172, 173, 337], "out_se": [13, 14, 16, 17, 342], "shut": [13, 14, 16, 17], "irrevers": [13, 14, 17], "kwarg": [14, 16, 17, 21, 25, 26, 32, 52, 58, 59, 69, 71, 73, 74, 75, 76, 77, 78, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 106, 108, 115, 133, 142, 145, 148, 149, 150, 152, 153, 156, 166, 167, 168, 170, 171, 172, 173, 176, 179, 182, 183, 186, 188, 189, 190, 193, 194, 200, 208, 210, 212, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 252, 253, 254, 255, 256, 257, 258, 259, 261, 263, 267, 268, 269, 270, 271, 272, 273, 288, 292, 293, 295, 298, 305, 310, 311, 314, 318, 319, 320, 326, 332, 336], "tupl": [15, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 41, 42, 44, 46, 47, 52, 53, 54, 55, 56, 77, 81, 95, 101, 108, 118, 120, 126, 127, 129, 134, 164, 170, 176, 177, 182, 185, 186, 187, 188, 194, 197, 201, 202, 203, 220, 221, 227, 228, 233, 239, 240, 242, 246, 248, 252, 254, 256, 257, 258, 259, 261, 269, 270, 271, 272, 288, 299, 301, 303, 312, 313, 330], "rand": [15, 24, 25, 26, 27, 28, 29, 30, 31, 33, 35, 38, 41, 42, 44, 46, 47, 52, 53, 54, 55, 56, 74, 87, 91, 108, 116, 119, 166, 190, 226, 239, 240, 242, 243, 245, 246, 252, 256, 257, 259, 261, 337, 341, 342], "describ": [15, 44, 112, 148, 208, 209, 243, 291, 326, 330, 332, 336, 337, 342], "tensor_spec": [15, 108, 165, 246, 256, 258], "boundedtensorspec": [15, 22, 26, 77, 81, 95, 101, 222, 223, 225, 226, 233, 239, 240, 242, 252, 256, 257, 259, 261, 323, 332, 336, 337, 341, 342], "cube": 15, "envcreat": [16, 22, 317, 318, 321, 323, 330, 331, 341, 342], "interruptor": 16, "_interruptor": 16, "start_collect": 16, "stop_collect": 16, "preeptiv": 16, "chunk": 16, "policy_state_dict": 16, "env_state_dict": 16, "close": [16, 17, 81, 92, 127, 239, 241, 253, 256, 330, 335, 337, 341], "pin_memori": [17, 35, 38, 41, 42, 52, 53, 54, 55, 56, 132, 330, 341], "regular": [17, 34, 36, 39, 77, 81, 95, 101, 149, 203, 221, 227, 228, 229, 230, 247, 307, 323, 327, 330, 331, 339, 342], "mere": 17, "greater": [17, 66, 67, 182, 186, 330, 331, 341], "sent": [17, 58, 59, 71, 155], "server": 17, "postprocessor": 17, "collector_class": [18, 19, 20, 21], "collector_kwarg": [18, 19, 20, 21], "num_workers_per_collector": [18, 19, 20, 21], "slurm_kwarg": [18, 19, 20], "update_after_each_batch": [18, 20, 21], "max_weight_update_interv": [18, 19, 20, 21], "tcp_port": [18, 19, 20, 22], "deriv": [18, 19, 20, 21, 305], "string": [18, 19, 20, 32, 37, 45, 57, 77, 81, 95, 101, 107, 133, 143, 153, 182, 186, 220, 226, 227, 238, 287, 304, 314, 326, 330, 332, 333], "respect": [18, 19, 20, 32, 77, 81, 95, 101, 109, 115, 116, 119, 133, 134, 145, 148, 149, 151, 153, 180, 184, 193, 205, 229, 234, 300, 332, 333, 336], "subnod": [18, 19, 20, 21], "readi": [18, 20, 21, 324, 331, 332, 335, 339], "serv": [18, 20, 21, 83, 339, 342], "fashion": [18, 20, 21, 34, 36, 39, 67], "executor": [18, 19, 20], "distributed_back": [18, 19], "ucc": [18, 19], "overwritten": [18, 20, 21, 53, 55, 56, 77, 81, 95, 101, 123], "seen": [18, 20, 21, 326, 330, 331, 333, 336, 339], "turn": [18, 20, 21, 34, 36, 39, 125, 150, 154, 220, 301, 326, 330, 331, 333, 337, 338], "submitit_delai": [18, 22], "former": [18, 19, 20, 35, 38, 41, 42, 52, 77, 81, 95, 101, 167, 168, 169, 170, 171, 172, 173, 174, 176, 178, 179, 180, 181, 182, 184, 185, 186, 187, 188, 193, 194, 197, 198, 199, 201, 204, 205, 207, 212, 218, 219, 221, 222, 223, 225, 228, 233, 236, 330], "whilst": [18, 19, 20], "latter": [18, 19, 20, 32, 52, 77, 81, 95, 101, 167, 168, 169, 170, 171, 172, 173, 174, 176, 178, 179, 180, 181, 182, 184, 185, 186, 187, 188, 193, 194, 197, 198, 199, 201, 204, 205, 207, 212, 218, 219, 221, 222, 223, 225, 228, 233, 236, 256, 319, 320], "homonym": [18, 19, 20, 337], "visit": [18, 19, 20], "facebookincub": [18, 19, 20], "tcp": [18, 19, 20, 22], "port": [18, 19, 20, 22], "10003": [18, 19, 20, 22], "worker_rank": [18, 19, 21], "update_interv": 19, "frequenc": [19, 330], "visible_devic": 20, "tensorpipe_opt": 20, "experiment": [20, 33, 226, 230], "tensorpiperpcbackendopt": 20, "_td": [21, 78], "ray_init_config": 21, "remote_config": 21, "num_collector": [21, 319, 320, 330, 331], "coordin": 21, "init": [21, 32, 77, 81, 95, 101, 330, 331, 332], "autodetect": 21, "similarli": [21, 32, 65, 77, 81, 95, 101, 193, 231, 232, 252, 342], "num_cpu": 21, "num_gpu": 21, "1024": [21, 174, 331, 339], "equat": [21, 81, 225, 238, 241, 260, 332, 337], "exce": [21, 332, 339], "indefinit": [21, 51], "raydistributedcollector": 21, "distributed_collector": 21, "10000": [21, 305, 330, 332, 333], "add_collector": 21, "local_polici": 21, "remote_collector": 21, "stop_remote_collector": 21, "num_job": 22, "tcpport": 22, "submitit_main_conf": 22, "slurm_cpus_per_task": 22, "32": [22, 26, 35, 38, 41, 42, 52, 53, 54, 55, 56, 67, 99, 100, 102, 103, 167, 168, 169, 170, 171, 174, 179, 188, 193, 194, 198, 199, 201, 202, 211, 267, 330, 331, 333, 337, 338, 339, 341, 342], "slurm_gpus_per_nod": 22, "slurm_partit": 22, "timeout_min": 22, "submitit_collection_conf": 22, "delai": 22, "jump": 22, "host": [22, 32, 77, 81, 95, 101, 115, 133, 145, 148, 149, 151, 153, 229], "wherea": [22, 118, 254, 327], "satellit": 22, "rendezv": 22, "hang": 22, "forev": 22, "default_config": [22, 169, 174, 201, 219], "default_slurm_conf_main": 22, "default_slurm_conf": 22, "rollout_tensordict": 23, "durat": [23, 336], "meta": [23, 44, 52, 79, 327, 332, 336, 339], "aren": [23, 144, 333], "assert_is_in": [24, 25, 26, 27, 28, 29, 30, 31, 33, 44, 46, 47], "belong": [24, 25, 26, 27, 28, 29, 30, 31, 33, 44, 46, 47, 154, 155, 325, 330, 336], "encod": [24, 25, 26, 27, 28, 29, 30, 31, 33, 35, 38, 41, 42, 44, 46, 47, 118, 199, 200, 204, 238, 325, 331, 332, 333, 337, 339], "ndarrai": [24, 25, 26, 27, 28, 29, 30, 31, 33, 44, 46, 47, 81, 225, 233], "ignore_devic": [24, 25, 26, 27, 28, 29, 30, 31, 33, 44, 46, 47], "np": [24, 25, 26, 27, 28, 29, 30, 31, 33, 44, 46, 47, 81, 233, 337], "cast": [24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 44, 46, 47, 57, 77, 81, 95, 101, 115, 116, 119, 127, 133, 145, 148, 149, 151, 153, 155, 229, 314, 342], "least": [24, 25, 26, 27, 28, 29, 30, 31, 33, 44, 46, 47, 114, 342], "complient": [24, 25, 26, 27, 28, 29, 30, 31, 33, 44, 46, 47], "singleton": [24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 44, 46, 47, 167, 168, 188, 206, 207], "implements_for_spec": [24, 25, 26, 27, 28, 29, 30, 31, 33, 44, 46, 47], "torch_funct": [24, 25, 26, 27, 28, 29, 30, 31, 33, 44, 46, 47], "tensor_to_index": [24, 25, 26, 27, 28, 29, 30, 31, 33, 44, 46, 47], "is_in": [24, 25, 26, 27, 28, 29, 30, 31, 33, 44, 46, 47, 342], "project": [24, 25, 26, 27, 28, 29, 30, 31, 33, 44, 46, 47, 118, 182, 184, 214, 218, 220, 221, 225, 226, 227, 228, 229, 230, 325, 341, 342], "uniform": [24, 25, 26, 27, 28, 29, 30, 31, 33, 35, 41, 44, 46, 47, 61], "unbound": [24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 36, 39, 44, 46, 47, 145, 161, 337, 339], "squeez": [24, 25, 26, 27, 28, 29, 30, 31, 33, 44, 46, 47, 111, 142, 144, 167, 168, 206, 207, 330, 337, 339], "dim": [24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 36, 39, 44, 46, 47, 66, 111, 112, 131, 145, 150, 155, 185, 187, 207, 212, 321, 331, 332, 337, 339], "to_numpi": [24, 25, 26, 27, 28, 29, 30, 31, 33, 44, 46, 47], "transformed_in": [24, 25, 26, 27, 28, 29, 30, 31, 33, 44, 46, 47, 148, 149, 197, 208, 321], "check_spec_encod": [24, 25, 26, 27, 28, 29, 30, 31, 33, 44, 46, 47], "to_one_hot": [24, 27, 30], "hot": [24, 27, 30, 31, 33, 96, 97, 103, 108, 118, 177, 200, 203, 220, 221, 227, 228, 239, 240, 242, 243, 245, 246, 247, 248, 252, 254, 256, 257, 258, 259, 261, 267, 333], "to_one_hot_spec": [24, 27, 30], "onehotdiscretetensorspec": [24, 27, 177, 203, 220, 227, 243, 245, 246, 267, 323, 325], "convert": [24, 27, 30, 31, 32, 33, 34, 36, 39, 45, 77, 81, 95, 101, 115, 116, 119, 133, 145, 148, 149, 151, 153, 155, 229, 238, 254, 330, 331, 332, 337, 339], "type_check": [24, 25, 26, 27, 28, 29, 30, 31, 33, 44, 46, 47], "fill": [24, 25, 26, 27, 28, 29, 30, 31, 33, 44, 46, 47, 145, 154, 186, 333, 337, 338], "upper": [25, 128], "unnam": 26, "pixels_spec": 26, "observation_vector_spec": 26, "33": [26, 32, 77, 81, 95, 101, 167, 168, 188, 329, 330, 331, 337, 338, 340, 342], "composite_spec": 26, "observation_vector": [26, 112, 314, 330], "randn": [26, 34, 35, 36, 38, 39, 41, 42, 52, 53, 54, 55, 56, 58, 59, 66, 67, 71, 110, 129, 161, 169, 174, 177, 180, 181, 184, 185, 187, 191, 192, 193, 197, 200, 201, 203, 214, 215, 216, 217, 219, 220, 226, 227, 229, 232, 233, 234, 239, 240, 242, 243, 245, 246, 252, 256, 257, 258, 259, 261, 269, 270, 271, 272, 304, 325, 341, 342], "td_project": 26, "is_empti": [26, 28, 337], "include_nest": [26, 28], "leaves_onli": [26, 28], "itemsview": 26, "immedi": [26, 28, 32, 77, 81, 95, 101, 268, 336], "children": [26, 28, 32, 77, 81, 95, 101], "keysview": [26, 28], "reflect": [26, 28, 96, 97, 154, 164, 254, 308, 331, 332, 333, 336], "lock_": [26, 28], "recurs": [26, 28, 32, 48, 49, 77, 81, 95, 101, 254], "succeed": [26, 28, 332, 336, 337], "selected_kei": [26, 28, 141, 330], "unlock_": [26, 28], "unlock": [26, 28, 34, 36, 39], "valuesview": 26, "onehottensorspec": 27, "action_valu": [27, 33, 176, 177, 203, 220, 221, 227, 228, 246, 254, 267, 325, 333], "arang": [27, 33, 177, 192, 220, 296, 325, 339], "argmax": [27, 177, 203, 221, 228], "chosen_action_valu": [27, 33, 202, 203, 211, 227, 228, 267, 325, 333], "outcom": [27, 33, 175, 208], "lazi": [28, 29, 49, 50, 77, 81, 95, 101, 103, 133, 151, 167, 195, 231, 232, 330, 331, 335, 339, 342], "represent": [28, 29, 32, 77, 81, 95, 101, 133, 151, 153, 330, 337, 338, 342], "drawn": [28, 29, 145, 222, 226, 230, 332, 336], "lazystackedtensordict": [28, 77, 81, 91, 95, 101, 335, 341], "heterogen": [28, 29, 90, 96, 97, 157, 193, 194, 330, 331], "semant": [28, 29, 325], "thrown": [29, 32, 77, 81, 95, 101, 339], "nvec": [30, 31], "cardin": [30, 31, 177, 203, 220, 221, 228, 332], "ax": [30, 195, 196], "m": [30, 32, 77, 81, 95, 101, 118, 230, 325, 331, 337], "ts": [30, 31], "multionehotdiscretetensorspec": [30, 243, 246, 267, 323], "use_regist": [31, 33], "to_categor": [31, 33], "to_categorical_spec": [31, 33], "multidiscretetensorspec": [31, 323], "gamma": [32, 137, 190, 239, 240, 242, 243, 245, 246, 247, 248, 250, 252, 254, 256, 257, 258, 259, 261, 262, 263, 267, 268, 269, 270, 271, 272, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 317, 326, 330, 331, 332, 336, 341], "sutton": [32, 326, 336], "1988": 32, "tempor": [32, 182, 186, 190, 270, 271, 276, 277], "44": [32, 331, 333, 337], "discount": [32, 78, 137, 240, 245, 247, 248, 250, 268, 269, 270, 271, 272, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 326, 331, 332, 336], "ahead": [32, 342], "add_modul": [32, 77, 81, 95, 101], "child": [32, 77, 81, 95, 101], "fn": [32, 37, 77, 81, 95, 101, 197, 319, 320], "init_weight": [32, 77, 81, 95, 101], "fill_": [32, 77, 81, 95, 101, 331, 333, 342], "net": [32, 77, 81, 95, 101, 187, 194, 239, 240, 246, 252, 256, 257, 258, 259, 314, 317, 331, 337, 338, 341], "in_featur": [32, 77, 81, 95, 101, 115, 133, 145, 148, 149, 151, 153, 167, 168, 170, 171, 172, 173, 187, 188, 194, 195, 196, 215, 229, 243, 245, 341], "out_featur": [32, 77, 81, 91, 95, 101, 115, 133, 145, 148, 149, 151, 153, 166, 167, 168, 170, 171, 172, 173, 178, 179, 182, 186, 187, 188, 190, 193, 194, 195, 196, 215, 220, 229, 243, 245, 325, 330, 333, 341], "bia": [32, 77, 81, 95, 101, 115, 133, 145, 148, 149, 151, 153, 167, 168, 178, 180, 181, 182, 184, 185, 186, 188, 194, 195, 196, 197, 222, 223, 225, 229, 236, 237, 238, 254, 259, 326, 330, 331, 332, 333, 336, 341], "requires_grad": [32, 77, 81, 95, 101, 127], "bfloat16": [32, 77, 81, 95, 101], "datatyp": [32, 77, 81, 95, 101, 339], "member": [32, 77, 81, 95, 101, 254], "xdoctest": [32, 77, 81, 95, 101, 115, 133, 145, 148, 149, 151, 153, 229, 254, 259], "skip": [32, 77, 81, 95, 101, 124, 149, 157, 226, 230, 254, 259, 269, 270, 271, 272, 287, 288, 298, 301, 330, 331, 332, 337], "buf": [32, 77, 81, 95, 101], "20l": [32, 77, 81, 95, 101, 254], "1l": [32, 77, 81, 95, 101, 254], "5l": [32, 77, 81, 95, 101, 254], "__call__": [32, 37, 77, 81, 95, 101, 230, 327], "doubl": [32, 46, 77, 81, 95, 101, 115, 116, 117, 119, 133, 145, 148, 149, 151, 153, 229, 243, 247, 251, 257, 260, 267, 330, 331, 332, 333, 342], "eval": [32, 77, 81, 95, 101, 149, 155, 330, 331, 332], "evalu": [32, 77, 81, 95, 101, 149, 175, 191, 192, 200, 210, 257, 310, 311, 331, 332], "dropout": [32, 77, 81, 95, 101, 149, 180, 182, 184, 186, 188, 333], "batchnorm": [32, 77, 81, 95, 101, 149], "disabl": [32, 77, 81, 95, 101, 149, 183, 210, 330], "comparison": [32, 77, 81, 95, 101, 149, 254, 330, 331], "similar": [32, 77, 81, 95, 96, 97, 101, 115, 133, 145, 148, 149, 151, 152, 153, 155, 215, 217, 226, 229, 230, 326, 330, 331, 332, 333, 337, 342], "confus": [32, 77, 81, 95, 101, 149], "extra_repr": [32, 77, 81, 95, 101], "shift": [32, 236, 269, 270, 271, 272, 332], "nontermin": 32, "original_reward": 32, "newli": [32, 77, 81, 95, 101], "OR": 32, "get_buff": [32, 77, 81, 95, 101], "throw": [32, 34, 36, 39, 77, 81, 95, 101, 342], "docstr": [32, 77, 81, 95, 101], "get_submodul": [32, 77, 81, 95, 101], "explan": [32, 77, 81, 95, 101], "qualifi": [32, 77, 81, 95, 101], "referenc": [32, 77, 81, 95, 101], "attributeerror": [32, 77, 81, 95, 101], "invalid": [32, 77, 81, 95, 101, 104, 191, 192], "resolv": [32, 77, 81, 95, 101], "someth": [32, 77, 81, 90, 95, 101, 324, 331, 332, 337, 342], "get_extra_st": [32, 77, 81, 95, 101, 155], "set_extra_st": [32, 77, 81, 95, 101, 155], "picklabl": [32, 77, 81, 95, 101, 155], "pickl": [32, 77, 81, 95, 101, 155], "get_paramet": [32, 77, 81, 95, 101], "sai": [32, 77, 81, 95, 101, 193, 338, 342], "net_b": [32, 77, 81, 95, 101], "net_c": [32, 77, 81, 95, 101], "conv": [32, 77, 81, 95, 101, 167, 168, 331], "conv2d": [32, 77, 81, 95, 101, 168, 193, 341], "kernel_s": [32, 77, 81, 95, 101, 167, 168, 170, 171, 193, 198, 331, 341], "stride": [32, 77, 81, 95, 101, 167, 168, 170, 171, 179, 193, 331, 341], "diagram": [32, 77, 81, 95, 101], "degre": [32, 77, 81, 95, 101], "named_modul": [32, 77, 81, 95, 101], "o": [32, 77, 81, 95, 101, 185], "transit": [32, 52, 67, 77, 81, 95, 101, 235, 330, 333, 337, 339], "half": [32, 77, 81, 95, 101, 115, 133, 145, 148, 149, 151, 153, 229, 330], "ipu": [32, 77, 81, 95, 101], "strict": [32, 34, 36, 39, 77, 81, 95, 101, 149, 259], "descend": [32, 77, 81, 95, 101, 149, 259], "persist": [32, 77, 81, 95, 101, 149, 164, 259], "enforc": [32, 65, 77, 81, 95, 101, 149, 231, 259, 337], "preserv": [32, 77, 81, 95, 101, 149, 259], "missing_kei": [32, 77, 81, 95, 101, 149, 259], "unexpected_kei": [32, 77, 81, 95, 101, 149, 259], "namedtupl": [32, 77, 81, 95, 101, 149, 259], "duplic": [32, 65, 77, 81, 95, 101, 243, 247, 254, 267], "l": [32, 77, 81, 95, 101, 180, 184, 268, 332, 337], "idx": [32, 77, 81, 95, 101], "named_buff": [32, 77, 81, 95, 101], "remove_dupl": [32, 77, 81, 95, 101, 254], "prepend": [32, 77, 81, 95, 101, 254], "running_var": [32, 77, 81, 95, 101], "named_children": [32, 77, 81, 95, 101], "conv4": [32, 77, 81, 95, 101], "conv5": [32, 77, 81, 95, 101], "memo": [32, 77, 81, 95, 101], "named_paramet": [32, 77, 81, 95, 101, 127, 254], "register_backward_hook": [32, 77, 81, 95, 101], "removablehandl": [32, 77, 81, 95, 101], "deprec": [32, 77, 81, 95, 101, 149, 158, 162, 176, 223, 239, 241, 243, 246, 247, 252, 253, 256, 257, 258, 259, 267, 269, 270, 271, 272, 277, 342], "favor": [32, 77, 81, 95, 101, 332], "register_full_backward_hook": [32, 77, 81, 95, 101], "register_buff": [32, 77, 81, 95, 101], "running_mean": [32, 77, 81, 95, 101], "alongsid": [32, 77, 81, 95, 101, 336], "num_featur": [32, 77, 81, 95, 101], "register_forward_hook": [32, 77, 81, 95, 101, 177, 203], "with_kwarg": [32, 77, 81, 95, 101], "always_cal": [32, 77, 81, 95, 101], "posit": [32, 35, 38, 41, 42, 52, 53, 54, 55, 56, 77, 81, 95, 101, 123, 124, 142, 143, 146, 149, 150, 197, 259, 326, 332, 336, 337, 339], "signatur": [32, 77, 81, 95, 101, 115, 133, 145, 148, 149, 151, 153, 229, 326, 330, 337], "register_module_forward_hook": [32, 77, 81, 95, 101], "regardless": [32, 77, 81, 95, 101, 241, 253, 256], "register_forward_pre_hook": [32, 77, 81, 95, 101], "invok": [32, 77, 81, 95, 101], "And": [32, 77, 81, 95, 101], "forward_pr": [32, 77, 81, 95, 101], "register_module_forward_pre_hook": [32, 77, 81, 95, 101], "grad_input": [32, 77, 81, 95, 101], "grad_output": [32, 77, 81, 95, 101], "subsequ": [32, 77, 81, 95, 101, 333], "technic": [32, 77, 81, 95, 101, 331, 333], "caller": [32, 77, 81, 95, 101], "register_module_full_backward_hook": [32, 77, 81, 95, 101], "register_full_backward_pre_hook": [32, 77, 81, 95, 101], "backward_pr": [32, 77, 81, 95, 101], "register_module_full_backward_pre_hook": [32, 77, 81, 95, 101], "register_load_state_dict_post_hook": [32, 77, 81, 95, 101], "incompatible_kei": [32, 77, 81, 95, 101], "clear": [32, 77, 81, 85, 95, 101, 297], "register_modul": [32, 77, 81, 95, 101, 327], "alia": [32, 77, 81, 95, 101], "register_paramet": [32, 77, 81, 95, 101], "register_state_dict_pre_hook": [32, 77, 81, 95, 101], "keep_var": [32, 34, 36, 39, 77, 81, 95, 101, 149, 259], "requires_grad_": [32, 77, 81, 95, 101], "autograd": [32, 77, 81, 95, 101, 149, 259], "freez": [32, 77, 81, 95, 101], "finetun": [32, 77, 81, 95, 101], "gan": [32, 77, 81, 95, 101], "share_memori": [32, 77, 78, 81, 95, 101, 330], "share_memory_": [32, 77, 81, 95, 101, 341], "destin": [32, 34, 36, 39, 77, 81, 95, 101, 110, 116, 117, 119, 149, 151, 155, 164, 259, 288], "averag": [32, 77, 81, 95, 101, 149, 155, 225, 248, 249, 259, 303, 330, 332], "shallow": [32, 77, 81, 95, 101, 149, 259, 333], "pleas": [32, 53, 77, 81, 95, 96, 97, 101, 111, 146, 149, 259, 324], "detach": [32, 77, 81, 95, 101, 149, 254, 259, 269, 270, 271, 272, 330], "non_block": [32, 77, 81, 95, 101, 115, 133, 145, 148, 149, 151, 153, 229, 333], "memory_format": [32, 77, 81, 95, 101, 115, 133, 145, 148, 149, 151, 153, 229], "channels_last": [32, 77, 81, 95, 101, 115, 133, 145, 148, 149, 151, 153, 229], "complex": [32, 77, 81, 95, 101, 115, 133, 145, 148, 149, 151, 153, 229, 330, 331], "integr": [32, 77, 81, 95, 101, 115, 133, 145, 148, 149, 151, 153, 173, 182, 186, 190, 229, 325, 336, 337, 338], "unchang": [32, 77, 81, 95, 101, 115, 118, 133, 145, 148, 149, 151, 153, 222, 229, 302, 330, 339], "tri": [32, 77, 81, 95, 101, 115, 133, 145, 148, 149, 151, 153, 229], "pin": [32, 77, 81, 95, 101, 115, 133, 145, 148, 149, 151, 153, 229], "4d": [32, 77, 81, 95, 101, 115, 133, 145, 148, 149, 151, 153, 229], "ignore_w": [32, 77, 81, 95, 101, 115, 133, 145, 148, 149, 151, 153, 229], "1913": [32, 77, 81, 95, 101, 115, 133, 145, 148, 149, 151, 153, 229], "3420": [32, 77, 81, 95, 101, 115, 133, 145, 148, 149, 151, 153, 229], "5113": [32, 77, 81, 95, 101, 115, 133, 145, 148, 149, 151, 153, 229], "2325": [32, 77, 81, 95, 101, 115, 133, 145, 148, 149, 151, 153, 229], "torch_doctest_cuda1": [32, 77, 81, 95, 101, 115, 133, 145, 148, 149, 151, 153, 229], "gpu1": [32, 77, 81, 95, 101, 115, 133, 145, 148, 149, 151, 153, 229], "1914": [32, 77, 81, 95, 101, 115, 133, 145, 148, 149, 151, 153, 229], "5112": [32, 77, 81, 95, 101, 115, 133, 145, 148, 149, 151, 153, 229, 337], "2324": [32, 77, 81, 95, 101, 115, 133, 145, 148, 149, 151, 153, 229], "float16": [32, 77, 81, 95, 101, 115, 133, 145, 148, 149, 151, 153, 181, 185, 229], "cdoubl": [32, 77, 81, 95, 101, 115, 133, 145, 148, 149, 151, 153, 229], "3741": [32, 77, 81, 95, 101, 115, 133, 145, 148, 149, 151, 153, 229], "j": [32, 35, 61, 77, 81, 95, 101, 115, 133, 145, 148, 149, 151, 153, 229, 327], "2382": [32, 77, 81, 95, 101, 115, 133, 145, 148, 149, 151, 153, 229], "5593": [32, 77, 81, 95, 101, 115, 133, 145, 148, 149, 151, 153, 229, 337], "4443": [32, 77, 81, 95, 101, 115, 133, 145, 148, 149, 151, 153, 229], "complex128": [32, 77, 81, 95, 101, 115, 133, 145, 148, 149, 151, 153, 229], "6122": [32, 77, 81, 95, 101, 115, 133, 145, 148, 149, 151, 153, 229], "1150": [32, 77, 81, 95, 101, 115, 133, 145, 148, 149, 151, 153, 229], "to_empti": [32, 77, 81, 95, 101], "dst_type": [32, 77, 81, 95, 101], "xpu": [32, 77, 81, 95, 101], "set_to_non": [32, 77, 81, 95, 101], "unidimension": 33, "keepdim": 33, "user_regist": 33, "priori": 33, "definit": [33, 68, 193], "uniqu": [33, 66, 67, 111, 120, 144, 145, 146, 339], "discretebox": [33, 77, 81, 95, 101, 332, 336, 342], "chosen_data": [34, 57], "rewarddata": [34, 57, 323], "rejected_data": [34, 57], "from_dataset": [34, 36, 57], "dataset_nam": [34, 36, 40, 45, 57, 94], "max_length": [34, 36, 37, 43, 45, 57], "550": [34, 36, 40, 45, 57, 66, 67, 337], "root_dir": [34, 36, 45, 57], "from_disk": [34, 36, 45, 57], "num_work": [34, 36, 45, 57, 92, 95, 101, 330, 331], "carperai": [34, 36, 40, 45], "openai_summarize_comparison": [34, 36, 45], "sequen": [34, 36], "cach": [34, 36, 45, 52, 53, 55, 56, 57, 66, 77, 81, 95, 101, 116, 119, 133, 149, 153, 297, 338], "load_from_disk": [34, 36, 45, 57], "load_dataset": [34, 36, 45, 57], "attention_mask": [34, 36, 37, 39, 40, 43, 45, 57], "memorymappedtensor": [34, 36, 45, 58, 338], "92534": 34, "input_id": [34, 36, 37, 39, 40, 43, 45, 57], "end_scor": [34, 39, 40, 57], "sub_data": [34, 36], "from_dict": [34, 36, 39, 45], "batch_dim": [34, 36, 39, 45, 321], "determin": [34, 35, 36, 39, 41, 52, 61, 77, 81, 95, 101, 133, 153, 193, 225, 331, 336], "input_dict": [34, 36, 39], "exclusinv": [34, 36, 39], "__maximum__": [34, 36, 39], "toler": [34, 36, 39, 175, 208], "sie": [34, 36, 39], "input_td": [34, 36, 39], "from_tensordict": [34, 36, 39], "non_tensordict": [34, 36, 39], "_no_default_": [34, 36, 39], "getattr": [34, 36, 39], "tensorclass": [34, 36, 39, 57, 58, 59, 71], "from_flatten": [34, 36, 39], "attemptedli": [34, 36, 39], "memmap": [34, 36, 39, 58, 95, 101, 155, 302, 339], "copy_exist": [34, 36, 39], "return_earli": [34, 36, 39], "mimic": [34, 36, 39, 77, 81, 95, 101], "renam": [34, 36, 39, 135, 137, 164, 330], "cross": [34, 36, 39, 166], "anymor": [34, 36, 39, 149, 229], "tensordictfutur": [34, 36, 39], "deepli": [34, 36, 39], "insid": [34, 36, 39, 342], "memmap_": [34, 36, 39, 155], "memmap_lik": [34, 36, 39], "contentless": [34, 36, 39], "1_000_000": [34, 35, 36, 38, 39, 41, 42, 52, 53, 54, 55, 56, 66, 330, 333], "alloc": [34, 36, 39, 59, 191, 192, 330], "setattr": [34, 36, 39], "tent": [34, 36, 39, 45], "to_tensordict": [34, 36, 39, 333], "unbind": [34, 36, 39, 182, 186], "alpha": [35, 41, 61, 167, 168, 193, 240, 246, 255, 257, 259, 330, 339, 341], "ep": [35, 41, 61, 155, 225, 241, 260, 303, 330, 331, 333], "1e": [35, 41, 61, 155, 175, 178, 197, 208, 330, 331, 332, 336], "08": [35, 41, 61, 329, 330, 331, 337, 340], "collate_fn": [35, 38, 41, 42, 52, 53, 54, 55, 56, 339, 341], "prefetch": [35, 38, 41, 42, 52, 53, 54, 55, 56, 57, 330, 331, 333, 339], "schaul": [35, 61], "quan": [35, 61], "antonogl": [35, 61], "silver": [35, 61], "2015": [35, 61], "arxiv": [35, 56, 61, 111, 133, 151, 169, 170, 171, 172, 173, 174, 177, 178, 179, 184, 190, 196, 198, 199, 201, 202, 204, 205, 211, 221, 225, 239, 240, 243, 244, 245, 247, 248, 249, 250, 251, 252, 255, 256, 259, 260, 269, 274, 282, 338], "ab": [35, 56, 61, 110, 133, 151, 155, 169, 174, 178, 179, 184, 190, 196, 198, 199, 201, 202, 204, 205, 211, 239, 240, 243, 244, 245, 248, 249, 250, 251, 252, 255, 256, 259, 338], "1511": [35, 61, 179], "05952": [35, 61], "expon": [35, 41, 61], "\u03b1": [35, 41, 61], "delta": [35, 41, 61, 180, 184, 208, 226, 230, 323, 326], "null": [35, 41, 61, 109], "max_siz": [35, 38, 41, 42, 58, 59, 60, 68, 71], "1_000": [35, 38, 41, 42, 339], "merg": [35, 38, 41, 42, 52, 53, 54, 55, 56, 337], "mini": [35, 38, 41, 42, 52, 53, 54, 55, 56, 336], "decid": [35, 38, 41, 42, 341], "meth": [35, 38, 41, 42, 254, 337], "incompat": [35, 38, 41, 42, 339], "drop_last": [35, 38, 41, 42, 65, 67], "return_info": [35, 38, 41, 42, 52, 53, 54, 55, 56, 339], "tensordictprioritizedreplaybuff": [35, 323, 341], "simplifi": [35, 337, 339], "manual_se": [35, 38, 41, 42, 55, 56, 66, 67, 108, 118, 129, 137, 140, 144, 146, 191, 192, 200, 214, 221, 222, 223, 225, 233, 239, 240, 242, 252, 259, 336, 337, 341, 342], "_weight": [35, 41, 339, 341], "arrai": [35, 40, 120, 180, 181, 184, 185, 330, 339], "update_prior": [35, 61, 302, 327, 331, 339, 341], "36278465": 35, "tempfil": [35, 38, 41, 42, 45, 52, 53, 54, 55, 56, 317, 330, 331, 339], "tqdm": [35, 38, 41, 42, 52, 53, 54, 55, 56, 305, 330, 332, 333, 336, 337], "randomsampl": [35, 38, 41, 42, 52, 53, 54, 55, 56, 323, 330], "td_error": [35, 38, 41, 42, 52, 53, 54, 55, 56, 242, 243, 245, 246, 247, 252, 254, 257, 259, 261, 267, 330, 339, 341], "update_tensordict_prior": [35, 38, 41, 42, 52, 53, 54, 55, 56, 330, 339, 341], "temporarydirectori": [35, 38, 41, 42, 45, 52, 53, 54, 55, 56, 330, 331, 339], "tmpdir": [35, 38, 41, 42, 45, 52, 53, 54, 55, 56, 330, 331], "rb_load": [35, 38, 41, 42, 52, 53, 54, 55, 56], "cursor": [35, 38, 41, 42, 52, 53, 54, 55, 56], "insert_transform": [35, 38, 41, 42, 52, 53, 54, 55, 56], "insert": [35, 38, 41, 42, 52, 53, 54, 55, 56, 63, 69, 70, 72, 150], "prompt_rindex": [36, 37, 40], "label": [36, 37, 40, 45, 330, 339], "os": [36, 45, 57, 331], "cpu_count": [36, 45, 57], "promptdatatldr": 36, "116722": 36, "prompt": [37, 40], "return_tensordict": [37, 43], "recip": [37, 77, 81, 95, 101, 167, 168, 169, 170, 171, 172, 173, 174, 176, 178, 179, 180, 181, 182, 184, 185, 186, 187, 188, 193, 194, 197, 198, 199, 201, 204, 205, 207, 212, 218, 219, 221, 222, 223, 225, 228, 233, 236], "text": [37, 40, 43, 53, 180, 181, 184, 185, 225, 332], "tensodict": [37, 43], "orign": [37, 43], "valid_sampl": 37, "identifi": 37, "eough": 37, "toknen": 37, "meet": 37, "criterion": 37, "autotoken": [37, 43, 45], "from_pretrain": [37, 40, 43], "gpt2": [37, 40, 43, 45, 169, 174, 201], "pad_token": [37, 43], "eos_token": 37, "enough": [37, 339], "inde": [37, 118, 332, 337], "roundrobinwrit": [38, 42, 52, 53, 54, 55, 56, 323], "Not": 38, "ref_model": 40, "reward_model": [40, 235], "kl_coef": 40, "max_new_token": 40, "score_clip": 40, "kl_schedul": 40, "klcontrollerbas": 40, "num_step": 40, "causal": 40, "sentenc": 40, "frozen": [40, 127], "kl": [40, 127, 249, 253], "penalti": [40, 253], "strai": 40, "far": [40, 183, 209, 210, 337, 342], "calcul": [40, 137, 180, 245], "gpt2rewardmodel": 40, "get_dataload": [40, 323], "promptdata": [40, 323], "gpt2lmheadmodel": 40, "dl": 40, "block_siz": [40, 57], "tensorclass_typ": [40, 57], "openai_summarize_tldr": 40, "config_class": 40, "model_path": 40, "rollout_from_model": 40, "rollout_from_data": 40, "600": [40, 337, 339], "reward_kl": [40, 127], "reward_raw": 40, "sample_log_prob": [40, 215, 216, 217, 226, 230, 232, 256, 314, 332, 336, 341], "create_rollout_td": 40, "log_prob": [40, 175, 191, 192, 200, 210, 230], "log_ratio": 40, "replic": 40, "rindex": 40, "multipli": [40, 180, 184, 240, 241, 246, 253, 255, 256, 257, 259, 303, 330], "term": [40, 127, 184, 185, 195, 196, 238, 239, 246, 307, 331, 332, 336], "subtract": [40, 144], "ve": [40, 330, 333], "eo": 40, "limit": [40, 91, 111, 127, 330, 331, 333, 336, 337], "generation_config": 40, "generationconfig": 40, "ti": [40, 278, 279, 280, 281, 283, 284, 285, 286, 331], "log_probs_gen": 40, "logprobs_of_label": 40, "priority_kei": [41, 42, 243, 246, 247, 252, 254, 257, 259, 261, 267, 339, 341], "reduct": [41, 61], "prioritizedreplaybuff": [41, 323, 341], "min": [41, 61, 208, 209, 210, 219, 225, 240, 241, 246, 255, 257, 259, 331, 332, 336], "median": [41, 61, 226, 230], "include_info": [41, 42, 52, 53, 54, 55, 56], "kw": [42, 63, 70], "int32": [42, 66, 87, 161], "huggingfac": [43, 56, 224], "co": [43, 120, 337], "doc": [43, 331, 336], "pad_trunc": 43, "am": 43, "worri": 43, "me": 43, "reassur": 43, "ok": 43, "tokenizer_fn": 45, "tensordicttoken": [45, 323], "pre_tokenization_hook": 45, "valid_s": 45, "tokenizer_class": 45, "tokenizer_model_nam": 45, "tokein": 45, "condit": [45, 144, 220, 221, 227, 228, 238, 330, 337, 339], "elementwis": 45, "vocabulari": 45, "loader": [45, 332], "185068": 45, "dataset_to_tensordict": 45, "data_dir": 45, "nestedkei": [45, 66, 67, 108, 109, 110, 111, 112, 113, 114, 116, 118, 119, 120, 121, 123, 125, 126, 129, 130, 131, 134, 135, 136, 137, 138, 139, 140, 141, 144, 145, 146, 147, 148, 151, 155, 164, 165, 218, 219, 222, 223, 225, 230, 243, 267, 288], "valid_mask_kei": 45, "conver": 45, "undergon": 45, "preprocess": [45, 331], "batch_dimens": 45, "filder": 45, "randint": [45, 147, 339], "data_memmap": 45, "exclus": [48, 49, 66, 67, 123, 180, 182, 184, 186, 191, 192, 220, 221, 227, 228, 260, 261, 269, 270, 271, 272, 273, 321, 325], "recurse_through_entri": 49, "recurse_through_stack": 49, "consolid": 49, "from_env": 52, "use_truncated_as_don": 52, "direct_download": 52, "terminate_on_end": 52, "env_kwarg": [52, 53, 55, 56, 319, 320, 330], "reconstruct": [52, 66, 67, 249, 330, 342], "recov": [52, 53, 55, 56, 66, 67, 218, 223, 225, 231, 252, 335], "regard": [52, 53, 55, 56, 177, 221, 239, 247, 256, 330, 332, 337], "get_dataset": 52, "qlearning_dataset": 52, "fewer": 52, "left": [52, 115, 116, 117, 121, 127, 133, 135, 141, 143, 146, 148, 151, 153, 222, 331, 332], "possess": 52, "unexpectedli": 52, "absent": [52, 77, 81, 95, 101], "traj_split": 52, "dataset_id": [52, 53, 55, 56], "observationnorm": [52, 155, 321, 330, 331, 332, 333, 341], "maze2d": 52, "umaz": 52, "128": [52, 67, 171, 174, 331, 333, 337, 338, 339], "loc": [52, 127, 129, 139, 183, 197, 209, 210, 215, 216, 217, 226, 230, 232, 239, 240, 252, 256, 257, 258, 259, 309, 314, 321, 325, 330, 331, 332, 333, 336, 341], "minari": 53, "available_dataset": [53, 55, 56, 66, 67], "currenrtli": 53, "minari_data": 53, "door": 53, "28": [53, 193, 330, 331, 337, 338], "39": [53, 331, 337, 338], "door_body_po": 53, "qpo": 53, "30": [53, 128, 204, 205, 331, 332, 336, 337], "qvel": 53, "dua": 54, "graff": 54, "2017": 54, "uci": 54, "archiv": 54, "ic": 54, "edu": 54, "ml": 54, "sklearn": 54, "adult_num": [54, 94], "adult_onehot": [54, 94], "mushroom_num": [54, 94], "mushroom_onehot": [54, 94], "covertyp": [54, 94], "shuttl": [54, 94], "magic": [54, 94], "roboset": 55, "h5": [55, 56], "mmap": [55, 56], "googl": [55, 73, 74, 332, 333, 336], "roboh": [55, 98], "excludetransform": [55, 141, 339], "fk1": 55, "v4": [55, 136, 278, 279, 280, 281, 283, 284, 285, 286, 330, 332, 338], "expert": 55, "fk1_microopenrandom_v2d": 55, "concis": 55, "17": [55, 67, 314, 330, 331, 337], "18": [55, 67, 99, 100, 102, 103, 194, 330, 331, 332, 336, 337, 338, 342], "15": [55, 67, 77, 81, 95, 101, 219, 225, 248, 330, 331, 332, 337, 339], "19": [55, 66, 67, 69, 331, 333, 337], "75": [55, 331, 337, 338], "totensor": 56, "image_s": 56, "v": [56, 155, 180, 181, 184, 185, 215, 252, 259, 325, 330, 331], "npz": 56, "2206": 56, "04779": [56, 240, 245], "vd4rl": 56, "detect": 56, "squar": [56, 113, 183, 209, 210, 288], "rectangular": [56, 167, 168], "internet": 56, "connect": 56, "walker_walk": 56, "64px": 56, "is_init": [56, 110, 126, 182, 186, 225, 333], "height": [56, 113, 136], "veloc": [56, 111, 336, 337, 342], "infinit": [57, 339], "three": [57, 325, 327, 332, 336, 337, 339, 342], "block": [57, 325, 333], "pairwisedataset": [57, 323], "256": [57, 174, 331, 332, 336, 337], "scratch_dir": [58, 330, 339], "mistak": [58, 59, 71], "myclass": [58, 59, 71], "foo": [58, 59, 71, 219, 339, 342], "bar": [58, 59, 71, 219, 298, 299, 301, 305, 327, 331], "attach": [58, 59, 60, 68, 71, 331], "entiti": [58, 59, 60, 68, 71], "auto": [59, 71, 154, 225, 240, 246, 255, 257, 259, 261, 326, 336], "zero_": [59, 71, 161], "max_capac": [61, 330, 339], "uniformli": [62, 254, 342], "roundrobin": [63, 70], "piec": [63, 70, 72, 330, 331, 332, 336, 337, 339], "consum": [65, 67, 331, 332, 336, 339], "incomplet": [65, 67], "fresh": 65, "caution": [65, 157, 342], "shuffl": [65, 336], "haven": [65, 338], "remain": [65, 110, 117, 118, 127, 144, 196], "draw": [65, 222], "num_slic": [66, 67], "slice_len": [66, 67], "end_kei": [66, 67], "traj_kei": [66, 67], "cache_valu": 66, "truncated_kei": [66, 67, 137, 143], "strict_length": [66, 67], "slicesamplerwithoutreplac": [66, 323], "Will": [66, 288], "shorter": [66, 67], "Be": [66, 67], "320": [66, 67, 331, 337, 342], "700": [66, 67], "robosetexperiencereplai": [66, 67, 323], "dataid": [66, 67], "22": [66, 67, 154, 331, 332, 337], "__len__": 68, "rank_kei": 69, "rank": [69, 166], "samplerwithoutreplac": [69, 323, 332, 336, 339], "get_insert_index": 69, "ant": [73, 74, 84, 338], "get_environ": 74, "87": [74, 331, 337, 339], "acrobot": [74, 342], "fetch": [74, 127, 338, 339], "task_nam": 75, "cheetah": [75, 76, 330], "frame_skip": [75, 76, 80, 81, 86, 88, 89, 124, 298, 301, 308, 327, 330, 331, 332, 341], "dm_control": [76, 330, 335, 342], "continuousbox": [77, 81, 95, 101, 161, 332, 336, 337, 341, 342], "unboundedcontinuoustensorspec": [77, 81, 91, 95, 101, 108, 116, 119, 145, 161, 166, 190, 214, 229, 232, 234, 258, 323, 332, 333, 336, 337, 342], "sort": [77, 81, 95, 101, 225], "depth": [77, 81, 91, 95, 101, 166, 167, 168, 170, 171, 172, 173, 178, 179, 188, 190, 193, 194, 198, 199, 220, 325, 331, 335, 336], "another_act": [77, 81, 95, 101], "mutabl": [77, 81, 95, 101], "batch_lock": [77, 79, 81, 95, 101, 145, 149, 337], "immut": [77, 81, 95, 101, 135, 149], "done_keys_group": [77, 81, 95, 101], "outer": [77, 81, 95, 101, 327, 330, 331, 342], "another_don": [77, 81, 95, 101], "empty_cach": [77, 81, 95, 101, 149], "fake_tensordict": [77, 81, 95, 101, 331], "fake": [77, 81, 95, 101, 330, 331], "afterward": [77, 81, 95, 101, 167, 168, 169, 170, 171, 172, 173, 174, 176, 178, 179, 180, 181, 182, 184, 185, 186, 187, 188, 193, 194, 197, 198, 199, 201, 204, 205, 207, 212, 218, 219, 221, 222, 223, 225, 228, 233, 236, 342], "silent": [77, 81, 95, 101, 167, 168, 169, 170, 171, 172, 173, 174, 176, 178, 179, 180, 181, 182, 184, 185, 186, 187, 188, 193, 194, 197, 198, 199, 201, 204, 205, 207, 212, 218, 219, 221, 222, 223, 225, 228, 233, 236], "braxenv": [77, 81, 95, 101, 135, 323], "envnam": [77, 81, 95, 101], "renametransform": [77, 81, 95, 101], "pipeline_st": [77, 81, 95, 101], "attibut": [77, 81, 95, 101], "speak": [77, 81, 95, 101, 330], "rand_act": [77, 81, 90, 95, 96, 97, 101], "_step": [77, 81, 95, 101, 108, 116, 119, 123, 135], "reset_kei": [77, 81, 95, 101, 111, 140, 144, 145, 146], "multitask": [77, 81, 95, 101], "multiag": [77, 81, 90, 95, 96, 97, 101, 165, 194, 202, 211, 267], "another_reward": [77, 81, 95, 101], "callback": [77, 81, 95, 101, 336], "auto_reset": [77, 81, 95, 101, 337], "auto_cast_to_devic": [77, 81, 95, 101, 336], "break_when_any_don": [77, 81, 95, 101, 336], "return_contigu": [77, 81, 95, 101, 157, 335], "soon": [77, 81, 95, 96, 97, 101], "ndim": [77, 81, 95, 101], "concomitt": [77, 81, 95, 101], "workspac": [77, 81, 95, 101], "prevail": [77, 81, 95, 101, 140, 165], "cartpol": [77, 81, 95, 101, 111, 140, 144, 331, 333, 339, 342], "creator": [78, 310, 311, 319, 320, 321], "substitut": [78, 144, 155], "vecnorm": [78, 321], "env_creat": [78, 330], "test_env1": 78, "observation_count": [78, 342], "test_env2": 78, "sleep": [78, 342], "ps": 78, "p1": 78, "p2": 78, "9934": 78, "env_str": 79, "info_dict_read": 81, "set_info_dict_read": 81, "put": [81, 103, 155, 321, 325, 331, 332, 333, 337], "read_act": 81, "read_don": 81, "reader": [81, 331], "interrupt": [81, 275], "nonsens": 81, "fallback": 81, "broken": [81, 157], "read_ob": 81, "dictat": [81, 226, 230, 256, 330, 337], "read_reward": 81, "baseinfodictread": 81, "info_dict": 81, "hoc": 81, "dict_read": 81, "default_info_dict_read": 81, "my_info_kei": 81, "some_env": 81, "placehold": [83, 120, 149], "secur": 83, "isaacgym": [84, 85], "isaacgymwrapp": [84, 323], "isaacgymenv": [85, 323], "webpag": 85, "isaac": 85, "essenc": 85, "04": [85, 330, 331, 337, 338], "snake": [86, 87], "6x6": [86, 87], "td1": [87, 239, 240, 242, 243, 245, 246, 247, 248, 252, 254, 256, 257, 258, 259, 261, 267, 330], "12x12": 87, "tsp50": 87, "tsp100": 87, "mo": [88, 89], "minecart": [88, 89], "mo_gym": 89, "qualnam": 90, "marl": [90, 104, 111, 146, 193, 336], "leverag": [90, 96, 97, 330, 336, 342], "neural": [90, 96, 97, 167, 168, 206, 229, 325, 331, 332, 333, 336, 337, 342], "group_map": [90, 96, 97, 103, 104], "constructiuon": [90, 96, 97], "premad": [90, 96, 97, 103, 267], "all_in_one_group": [90, 104], "agent_0": [90, 96, 97, 104], "agent_1": [90, 96, 97, 104], "agent_2": [90, 96, 97, 104], "agent_3": 90, "int8": [90, 96, 97], "one_group_per_ag": [90, 96, 97], "environn": 91, "constraint": [91, 332, 336], "mymbenv": [91, 166, 190], "world_model": [91, 166, 190, 249], "super": [91, 108, 116, 119, 166, 177, 190, 234, 240, 242, 246, 252, 257, 259, 261, 330, 337, 341], "hidden_observ": [91, 166, 190], "mlp": [91, 166, 167, 168, 170, 171, 172, 173, 182, 186, 187, 190, 194, 215, 220, 243, 245, 314, 325, 331, 335, 338, 341], "worldmodelwrapp": [91, 166, 190], "activation_class": [91, 166, 167, 168, 170, 171, 172, 173, 178, 179, 188, 190, 193, 194, 331, 336, 341], "relu": [91, 166, 174, 190, 197, 238], "activate_last_lay": [91, 166, 173, 188, 190], "run_type_check": 91, "less": [92, 212, 319, 320, 326, 332, 333, 339, 341], "readthedoc": 92, "en": 92, "python_interfac": 92, "task_id": 92, "106": [94, 337], "my_env_fun": [95, 101], "custom_attribute_list": [95, 101], "custom_attribut": [95, 101], "custom_method_list": [95, 101], "custom_method": [95, 101], "deploi": [95, 101], "slight": [95, 101, 331], "share_individual_td": [95, 101], "shared_memori": [95, 101], "policy_proof": [95, 101], "ll": [95, 101, 180, 181, 184, 185, 330, 331, 332, 333, 336, 342], "hidden": [95, 101, 110, 178, 180, 181, 182, 184, 185, 186, 187, 198, 199, 204, 205, 215, 216, 217, 219, 229, 232, 241, 253, 256, 325, 333, 335, 341], "introduc": [95, 101, 180, 182, 184, 186, 225, 330], "drastic": [95, 339], "influenc": 95, "rule": [95, 116, 119, 230, 325, 332], "thumb": [95, 332], "suppos": [95, 301, 327, 342], "scenario": [95, 102, 103, 330, 336, 337], "myenv": [95, 116, 119], "update_kwarg": [95, 101], "pettingzoo": [96, 97], "pet": [96, 97], "zoo": [96, 97], "guid": [96, 97, 99, 100, 144, 324, 330, 336], "__": [96, 97], "aecenv": [96, 97], "use_mask": [96, 97], "dead": [96, 97], "compulsori": [96, 97], "adversary_0": [96, 97], "adversari": [96, 97], "marlgroupmaptyp": [96, 97, 103, 104, 323], "vectoris": [96, 97, 180, 181, 184, 185], "multiwalker_v9": 96, "return_st": [96, 97], "categorical_act": [96, 97, 99, 100, 103], "n_piston": [96, 97], "pistonball_v6": [96, 97], "piston": [96, 97], "piston_0": [96, 97], "piston_1": [96, 97], "piston_20": [96, 97], "aec": [96, 97], "tictactoe_v3": [96, 97], "player": [96, 97], "player_1": [96, 97], "player_2": [96, 97], "butterfli": 97, "parallel_env": [97, 330, 341, 342], "vikashplu": 98, "read_info": 98, "pars": [98, 339], "smacv2": [99, 100], "starcraft": [99, 100], "challeng": [99, 100, 337, 338], "v2": [99, 100, 264, 278, 279, 280, 281, 283, 284, 285, 286, 314, 333], "10gen_terran": [99, 100], "10gen_zerg": [99, 100], "10gen_protoss": [99, 100], "3m": [99, 100, 338], "8m": [99, 100, 338], "25m": [99, 100], "5m_vs_6m": [99, 100], "8m_vs_9m": [99, 100], "10m_vs_11m": [99, 100], "27m_vs_30m": [99, 100], "mmm": [99, 100], "mmm2": [99, 100], "2s3z": [99, 100], "3s5z": [99, 100], "3s5z_vs_3s6z": [99, 100], "3s_vs_3z": [99, 100], "3s_vs_4z": [99, 100], "3s_vs_5z": [99, 100], "1c3s5z": [99, 100], "2m_vs_1z": [99, 100], "corridor": [99, 100], "6h_vs_8z": [99, 100], "2s_vs_1sc": [99, 100], "so_many_banel": [99, 100], "bane_vs_ban": [99, 100], "2c_vs_64zg": [99, 100], "old": [99, 100, 253, 342], "smac": [99, 100], "map_nam": [99, 100], "176": [99, 100, 337], "battle_won": [99, 100], "dead_al": [99, 100], "dead_enemi": [99, 100], "episode_limit": [99, 100], "322": [99, 100, 337], "Or": [99, 100, 193], "procedur": [99, 100], "distribution_config": [99, 100], "n_unit": [99, 100], "n_enemi": [99, 100], "team_gen": [99, 100], "dist_typ": [99, 100], "weighted_team": [99, 100], "unit_typ": [99, 100], "marin": [99, 100], "maraud": [99, 100], "medivac": [99, 100], "exception_unit_typ": [99, 100], "start_posit": [99, 100], "surrounded_and_reflect": [99, 100], "map_x": [99, 100], "map_i": [99, 100], "capability_config": [99, 100], "88": [99, 100, 330, 331, 337, 338], "131": [99, 100, 337], "starcraft2env": 100, "flock": [102, 103], "continuous_act": [102, 103, 336], "agent_collision_rew": [102, 103], "agent_distance_rew": [102, 103], "agent_nam": [103, 104], "agent_names_to_indices_map": 103, "unbatched_action_spec": [103, 336], "unbatched_observation_spec": 103, "unbatched_reward_spec": 103, "het_spec": 103, "het_specs_map": 103, "ca": 104, "environment4": 104, "get_group_map": 104, "sumbodul": 105, "model_bas": [106, 166, 190], "adapt": [108, 253, 330, 337], "masker": 108, "binarydiscretetensorspec": [108, 243, 246, 267, 323], "maskedenv": 108, "ones_lik": 108, "scatter": 108, "unsqueez": [108, 111, 112, 147, 150, 187, 330, 333, 336, 337], "_set_se": [108, 116, 119, 337], "transform_reward_spec": [109, 114, 115, 116, 117, 121, 127, 135, 138, 139, 141, 143, 148, 150], "tensordictmodulebas": [110, 212, 220, 227, 333], "burn_in": 110, "burn": 110, "date": [110, 291], "retur": 110, "burnt": 110, "grumodul": 110, "gru_modul": [110, 182], "input_s": [110, 180, 181, 182, 184, 185, 186, 187, 333], "hidden_s": [110, 180, 181, 182, 184, 185, 186, 187, 333], "set_recurrent_mod": [110, 182, 186, 333], "burn_in_transform": 110, "gru": [110, 181, 182], "num_lay": [110, 180, 182, 184, 186, 198, 199], "86": [110, 330, 331, 337], "3008": [110, 331], "37": [110, 329, 331, 337, 338, 339, 340], "0344": 110, "padding_valu": [111, 191, 192], "as_invers": 111, "account": [111, 191, 192, 325, 331, 333, 339, 342], "movement": 111, "propos": [111, 120, 189, 251, 260, 314, 325, 333, 339], "pdf": [111, 169, 170, 171, 172, 173, 177, 201, 221, 225, 247, 257, 260, 269, 274, 282, 314], "1312": [111, 331], "5602": 111, "constant": [111, 129, 144, 327, 330, 332, 333, 342], "unsqueezetransform": [111, 337, 339], "consumpt": 111, "followin": 111, "pictur": 111, "pixels_trsf": [111, 339], "grayscal": [111, 331, 333, 339, 342], "data_exclud": [111, 339], "transform_observation_spec": [111, 112, 113, 114, 115, 116, 117, 120, 121, 123, 125, 126, 127, 129, 131, 135, 136, 140, 141, 143, 144, 145, 146, 147, 148, 150, 151, 154, 337], "del_kei": [112, 151, 335, 337], "unsqueeze_if_oor": 112, "observation_posit": 112, "observation_veloc": 112, "delet": 112, "key1": [112, 296, 304], "key2": [112, 296, 304], "crop": [113, 134, 288], "center": [113, 288], "width": [113, 136], "out_keys_inv": [114, 116, 119, 129, 130, 131, 135, 148, 337], "scalar": [114, 138, 171, 173, 195, 196, 218, 222, 223, 225, 236, 239, 240, 241, 246, 247, 248, 249, 250, 251, 252, 253, 254, 256, 257, 258, 259, 260, 261, 267, 269, 270, 271, 272, 274, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 325, 331, 337], "permit": [114, 123, 150], "rewardsc": [115, 149, 330, 331, 333], "rewardclip": 115, "transformed_env": [115, 148, 149], "transform_env_devic": [115, 117, 148], "transform_input_spec": [115, 116, 117, 118, 129, 131, 135, 140, 143, 144, 145, 148, 150, 152], "transform_output_spec": [115, 116, 117, 121, 127, 135, 141, 143, 148], "untouch": [115, 116, 117, 121, 127, 135, 141, 143, 148], "transformfull_done_spec": [115, 116, 117, 121, 127, 135, 141, 143, 148], "dtype_in": 116, "dtype_out": 116, "scan": [116, 119, 231, 232], "resp": [116, 119], "not_transform": [116, 119], "constructedw": [116, 119], "orig_devic": 117, "unspecifi": 117, "transform_done_spec": [117, 148], "num_actions_effect": 118, "max_act": 118, "include_forward": 118, "dimension": [118, 182, 186, 269, 274, 282, 336], "num_act": [118, 246], "action_out": 118, "_call": [118, 123, 337], "eol_kei": 120, "life": 120, "lives_kei": 120, "eol_attribut": 120, "unwrap": 120, "al": [120, 131, 166, 342], "breakout": 120, "v5": [120, 131, 342], "210": [120, 131, 337, 342], "160": [120, 131, 331, 337, 342], "eol_transform": 120, "eol": 120, "dqnloss": [120, 239, 240, 242, 245, 246, 247, 248, 251, 252, 254, 256, 257, 258, 259, 260, 261, 262, 267, 312, 323, 326, 331, 333], "action_spac": [120, 177, 203, 220, 221, 227, 228, 239, 240, 242, 243, 245, 246, 247, 248, 252, 254, 256, 257, 258, 259, 261, 267, 333], "register_kei": 120, "loss_or_advantag": 120, "lossmodul": [120, 305, 316, 317, 323], "valueestimatorbas": [120, 254, 323], "excluded_kei": 121, "finit": [122, 339], "first_dim": 123, "last_dim": 123, "allow_positive_dim": [123, 150], "th": [123, 150, 180, 184, 337], "frameskip": 123, "repeatedli": [124, 332, 336], "init_kei": 126, "tracker": 126, "coef": 127, "pi_curr": 127, "pi_0": 127, "overfit": 127, "fine": [127, 338], "probabilist": [127, 226, 323, 332, 341], "get_dist": [127, 230, 231], "mod": [127, 182, 186, 233, 333], "normalparamextractor": [127, 325, 332, 336], "probabilisticactor": [127, 215, 216, 217, 219, 239, 240, 244, 246, 252, 255, 256, 257, 258, 259, 261, 325, 330, 332, 336], "tanhnorm": [127, 215, 216, 217, 226, 232, 239, 240, 252, 256, 257, 258, 259, 261, 323, 332, 336, 341], "n_ob": [127, 239, 240, 242, 243, 245, 246, 252, 256, 257, 258, 259, 261], "n_act": [127, 239, 240, 242, 243, 245, 246, 252, 256, 257, 258, 259, 261], "return_log_prob": [127, 215, 216, 217, 226, 230, 232, 258, 325, 332, 336, 341], "apply_": 127, "copy_": [127, 330], "formulat": 127, "diverg": [127, 182, 186, 226, 230, 249, 253], "noop": [128, 341], "trial": 128, "op": [128, 154, 218, 222, 223, 307], "randomli": [128, 129, 145, 222, 226, 230, 336, 337, 339], "standard_norm": [129, 139, 330, 331, 333], "affin": [129, 139], "layer": [129, 155, 167, 168, 170, 171, 178, 180, 181, 182, 184, 185, 186, 188, 193, 194, 195, 196, 198, 199, 206, 207, 213, 224, 233, 325, 331, 332, 333, 338], "normal": [129, 155, 167, 168, 183, 188, 191, 192, 197, 209, 210, 218, 226, 230, 241, 253, 256, 301, 303, 321, 325, 327, 333, 336, 342], "set_default_tensor_typ": 129, "doubletensor": 129, "isclos": 129, "next_ob": [129, 269, 270, 271, 272, 341], "rubric": [129, 232], "init_stat": [129, 330, 331, 332, 333], "3752e": 129, "01": [129, 225, 236, 241, 253, 256, 329, 330, 331, 333, 336, 337, 338, 340], "5087e": 129, "03": [129, 329, 330, 331, 332, 336, 337, 338, 340], "9294e": 129, "9636": 129, "5608": 129, "6408": 129, "num_it": [129, 331, 332], "reduce_dim": [129, 330, 331, 332, 333], "cat_dim": [129, 330, 331, 332, 333], "keep_dim": [129, 331, 333], "statist": [129, 155, 258, 321, 330, 331, 332, 342], "approach": [129, 330, 332, 342], "gaussian": [129, 145, 166, 190, 195, 196, 201, 218, 332], "empir": [129, 166, 190, 226, 230, 330, 332, 336], "3d": [129, 167], "third": [129, 221, 336], "reorder": 131, "in_keys_in": 131, "pong": [131, 342], "channel": [131, 147, 193, 198, 199, 331], "r3m": [133, 338], "resnet": [133, 151, 153], "visual": [133, 151, 153, 332, 337], "embed": [133, 151, 152, 153, 202, 214, 215, 216, 217, 229, 234, 338], "ego4d": [133, 151, 153], "univers": [133, 151, 153], "suraj": [133, 151], "nair": [133, 151], "aravind": [133, 151], "rajeswaran": [133, 151], "vikash": [133, 151, 153], "kumar": [133, 151, 153], "chelsea": [133, 151], "finn": [133, 151], "abhinav": [133, 151], "gupta": [133, 151], "2203": [133, 151, 190, 338], "12601": [133, 151, 338], "_init": [133, 151, 330], "snippet": [133, 151, 330], "resnet50": [133, 153, 338], "model_nam": [133, 151, 153, 291], "resnet34": 133, "resnet18": 133, "r3m_vec": [133, 338], "feed": [133, 153, 254, 325, 330, 336, 339], "244": [133, 153, 337], "stack_imag": [133, 153], "tread": [133, 153], "separet": [133, 153], "hub": [133, 153, 338], "resnet50_weight": [133, 153], "imagenet1k_v1": [133, 153], "download_path": [133, 153], "tensor_pixels_kei": [133, 153], "dest": [133, 151, 153, 229], "sub_seq_len": 134, "sample_dim": [134, 330], "primarili": 134, "hesit": 134, "request": 134, "robust": 134, "mix": [134, 202, 211, 267, 330, 336], "improp": 134, "create_copi": 135, "stuff": 135, "newnam": 135, "interpol": [136, 331, 333], "bilinear": [136, 333], "84": [136, 330, 331, 333, 337], "halfcheetah": [136, 314, 330], "r2g": 137, "99": [137, 155, 190, 250, 263, 268, 275, 317, 330, 331, 332, 337, 339, 341, 342], "reward_to_go": 137, "bernoulli_": 137, "9010": 137, "9404": [137, 275], "9701": [137, 275], "9900": [137, 275], "0000": [137, 146, 222, 223, 233, 275, 332, 333, 337, 341], "crash": 137, "clamp_min": 138, "clamp_max": 138, "clip_min": 138, "clip_max": 138, "episode_": 140, "reward1": 140, "reward2": 140, "episode_reward": [140, 336], "keep_reward": 141, "keep_don": 141, "squeeze_dim": 142, "step_count_kei": 143, "update_don": 143, "adaptec": 143, "accordingli": [143, 144, 184, 227, 333], "completet": 143, "recognis": 143, "accompani": 143, "target_return": 144, "chosen": [144, 145, 202, 203, 211, 228, 314, 325], "primer": [145, 333], "default_valu": [145, 333], "unit": [145, 166, 178, 180, 181, 198, 199, 204, 205, 332], "transfomedenv": 145, "mykei": 145, "__unless": 145, "exists__": 145, "pool": 146, "increas": [146, 225, 336], "10th": 146, "0216": 146, "1149": 146, "1990": 146, "2749": 146, "3281": 146, "9290": 146, "3702": 146, "8978": 146, "from_int": 147, "shape_toler": 147, "255": [147, 337, 339], "permuat": 147, "ri": 147, "principl": 148, "cattransform": 148, "notabl": 148, "rewardsum": [148, 336], "cache_spec": 149, "set_missing_toler": 149, "keyerror": 149, "unsqueeze_dim": [150, 337], "danger": 150, "vc1": 151, "vc1_vec": 151, "small": [151, 330, 332, 336, 342], "untrain": 151, "make_noload_model": 151, "naiv": 151, "vip": [152, 153, 338], "toward": 153, "implicit": [153, 252, 339], "jason": 153, "ma": 153, "shagun": 153, "sodhani": 153, "dinesh": 153, "jayaraman": 153, "osbert": 153, "bastani": 153, "ami": 153, "zhang": 153, "vip_vec": 153, "final_nam": 154, "sb3": 154, "terminal_obs_read": 154, "truli": [154, 341], "till": 154, "did": [154, 275, 331, 332, 339, 342], "nan": 154, "shared_td": 155, "decai": [155, 218, 222, 223, 260, 303, 330, 331, 333, 342], "9999": [155, 337], "0001": [155, 178, 197, 332, 337], "fly": [155, 253, 326, 332, 337, 339, 342], "to_observation_norm": 155, "underflow": [155, 303], "build_td_for_shared_vecnorm": 155, "memmori": 155, "queue": [155, 339], "td_share": 155, "state_dim": [156, 169, 174, 201, 204, 205, 219], "action_dim": [156, 169, 170, 172, 174, 201, 219, 330, 335], "gsde": [156, 257, 321], "func": 156, "gsdemodul": 156, "check_dtyp": 157, "short": [157, 184, 185, 331, 332, 336], "discrep": [157, 239, 241, 242, 243, 253, 256, 258, 267], "imposs": 157, "probabilistictdmodul": [162, 163, 188, 226, 230, 268, 301], "next_tensordict": 164, "keep_oth": [164, 337], "exclude_reward": 164, "exclude_don": 164, "exclude_act": 164, "next_": 164, "funtion": 164, "write_full_fals": 165, "leav": [165, 330], "_terminated_or_trunc": 165, "entropi": [166, 239, 240, 241, 246, 252, 253, 255, 256, 257, 259, 261, 336], "botev": 166, "et": 166, "2013": 166, "cem": 166, "plan": [166, 189, 190], "varianc": [166, 183, 197, 209, 210, 326, 330, 332, 336], "k": [166, 180, 181, 184, 185], "repeat": [166, 332, 336, 337], "maximis": [166, 170, 172, 190, 325, 330, 331, 332, 336], "horizon": [166, 190, 332], "modelbasedenv": [166, 190], "planning_horizon": [166, 190], "optim_step": [166, 190, 331], "mpc": [166, 189, 190], "num_candid": [166, 190], "candid": [166, 190], "top_k": [166, 190], "modelbasedenvbas": [166, 189, 190, 323], "safemodul": [166, 189, 215, 217, 230, 239, 240, 246, 252, 256, 257, 258, 259, 261, 310, 311, 317, 323, 341], "num_cel": [167, 168, 170, 171, 172, 173, 178, 179, 182, 186, 188, 193, 194, 215, 331, 332, 333, 336, 341], "elu": [167, 168, 170, 171, 172, 173, 178, 179, 193, 331, 341], "activation_kwarg": [167, 168, 188], "norm_class": [167, 168, 170, 171, 188], "norm_kwarg": [167, 168, 188], "bias_last_lay": [167, 168, 170, 171, 172, 173, 179, 188], "aggregator_class": [167, 168, 170, 171, 331, 333, 341], "squashdim": [167, 168, 170, 193, 341], "aggregator_kwarg": [167, 168, 170, 171, 331, 333], "squeeze_output": [167, 168, 170, 171, 331, 333], "convolut": [167, 168, 170, 171, 193, 206], "produc": [167, 168, 188, 194, 200, 215, 217, 219, 288, 332, 333, 339, 342], "cell": [167, 168, 180, 181, 182, 184, 185, 186, 188, 193, 194, 332], "kernel": [167, 168, 179, 187, 193], "cnet": [167, 168], "conv3d": 167, "34": [167, 168, 188, 331, 337], "35": [167, 168, 188, 329, 331, 332, 333, 337, 338, 340], "transformer_config": [169, 201, 219], "decisiontransform": [169, 201], "dtconfig": [169, 174, 201], "2202": [169, 174, 201, 255], "05607": [169, 174, 201, 255], "return_to_go": [169, 174, 201, 219], "conv_net_kwarg": [170, 171], "mlp_net_kwarg": [170, 171, 172], "use_avg_pool": [170, 171], "WITH": [170, 171, 172, 173, 225, 260], "1509": [170, 171, 172, 173, 190, 225, 243, 251, 260, 337], "02971": [170, 171, 172, 173, 225, 260], "convnet": [170, 193, 333, 341], "ndims_in": 170, "avgpool": [170, 171], "adaptiveavgpool2d": [171, 331, 333], "400": [172, 173, 336, 337, 339], "mlp_net_kwargs_net1": 173, "mlp_net_kwargs_net2": 173, "decion": 174, "desdescrib": 174, "n_embd": 174, "n_layer": [174, 180, 184], "n_head": 174, "n_inner": 174, "n_posit": 174, "resid_pdrop": 174, "attn_pdrop": 174, "gpt2config": 174, "atol": [175, 208], "06": [175, 208, 330, 331, 332, 337, 338], "rtol": [175, 208], "batch_shap": [175, 208], "event_shap": [175, 208], "absolut": [175, 208, 330], "densiti": [175, 191, 192, 200, 210], "mass": [175, 191, 192, 200, 210, 337], "rsampl": [175, 192, 200, 230], "sample_shap": [175, 191, 192, 200], "dqnet": 176, "atom": 176, "softmax": [176, 192, 200, 220, 221], "var_num": [177, 203, 220, 221, 228], "action_value_kei": [177, 203, 220, 221, 227, 228, 254, 267], "action_mask_kei": [177, 203, 220, 221, 222, 223, 227, 228], "perspect": [177, 221, 247, 332], "1707": [177, 221, 247, 256], "06887": [177, 221, 247], "mult": [177, 194, 203, 220, 221, 227, 228], "tensordict_modul": [177, 180, 181, 184, 185, 203, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 239, 240, 242, 246, 252, 256, 257, 258, 259, 261, 325], "nbin": [177, 220, 325], "customdistributionalqv": 177, "log_softmax": [177, 220], "from_modul": [177, 226, 229, 232, 234], "one_hot": [177, 192, 203], "qvalue_actor": [177, 203, 220, 227, 325], "to_modul": [177, 226, 229, 232, 234], "std_bia": 178, "std_min_val": 178, "belief": [178, 198, 204, 205], "1912": [178, 248, 249, 250], "01603": [178, 248, 249, 250], "softplu": [178, 197, 236, 237, 238], "out_features_valu": 179, "cnn_kwarg": [179, 331], "mlp_kwarg": [179, 187, 331], "duel": 179, "cnn": [179, 193, 331, 341], "06581": 179, "512": [179, 331, 337, 339], "batch_first": [180, 182, 184, 186, 333], "bidirect": [180, 184, 333], "cudnn": [180, 181, 184, 185, 333], "vmap": [180, 181, 184, 185, 212, 229, 232, 341], "rnn": [180, 181, 184, 185, 333], "device_count": [180, 181, 184, 185, 330, 331, 333, 338, 342], "els": [180, 181, 184, 185, 198, 325, 327, 330, 331, 332, 333, 336, 337, 338], "n_in": [180, 181, 184, 185], "n_out": [180, 181, 184, 185], "h0": [180, 181, 184, 185], "h1": [180, 181, 184, 185], "call_gru": [180, 181], "h_out": [180, 181, 184, 185], "batched_cal": [180, 181, 184, 185], "gate": [180, 181, 184], "r_t": 180, "sigma": [180, 181, 183, 184, 185, 201, 209, 210, 218, 225, 332], "w_": [180, 181, 184, 185], "ir": [180, 181], "x_t": [180, 184], "b_": [180, 181, 184, 185], "hr": [180, 181, 184], "h_": [180, 181, 184], "z_t": 180, "iz": [180, 181], "hz": [180, 181], "n_t": 180, "odot": [180, 181, 184, 185], "hn": [180, 181, 184], "h_t": [180, 184], "sigmoid": [180, 181, 184, 185], "hadamard": [180, 181, 184, 185], "multilay": [180, 184], "_t": [180, 184, 336, 337], "ge": [180, 184], "bernoulli": [180, 184], "b_ih": [180, 181, 184, 185, 186], "b_hh": [180, 181, 184, 185, 186], "seq": [180, 182, 184, 186, 333, 335], "h_0": [180, 184, 185], "unbatch": [180, 184], "pack": [180, 184, 332, 342], "pack_padded_sequ": [180, 184], "pack_sequ": [180, 184], "num": [180, 184], "_layer": [180, 184], "_size": [180, 181, 184, 185], "h_n": [180, 184], "packedsequ": [180, 184], "weight_ih_l": [180, 184], "learnabl": [180, 181, 184, 185], "w_ir": 180, "w_iz": 180, "w_in": 180, "num_direct": [180, 184], "weight_hh_l": [180, 184], "w_hr": 180, "w_hz": 180, "w_hn": 180, "bias_ih_l": [180, 184], "b_ir": 180, "b_iz": 180, "b_in": 180, "bias_hh_l": [180, 184], "b_hr": 180, "b_hz": 180, "b_hn": 180, "bias": [180, 181, 184, 185, 236, 326, 330], "mathcal": [180, 181, 184, 185], "sqrt": [180, 181, 184, 185, 225], "frac": [180, 181, 184, 185, 332], "seq_len": [180, 184], "subtli": 180, "matrix": [180, 184, 195, 196], "contrast": [180, 251, 339], "hx": [180, 181, 184, 185], "lstmcell": [181, 186], "gru_cel": 181, "z": 181, "weight_ih": [181, 185], "weight_hh": [181, 185], "bias_ih": [181, 185], "bias_hh": [181, 185], "rocm": [181, 185], "embedd": [182, 186, 187], "grucel": [182, 229], "proj_siz": [182, 184], "python_bas": [182, 186], "recurrent_st": [182, 333], "custom_kei": [182, 186], "recurrent_mod": [182, 186], "rs": [182, 330], "gru_module_train": 182, "policy_train": [182, 186], "traj_td": [182, 186], "policy_infer": [182, 186], "td_inf": [182, 186], "assert_clos": [182, 186], "upscal": [183, 209, 210], "tanh_loc": [183, 209, 210], "event_dim": [183, 208, 209], "ultim": [183, 209, 210], "poor": [183, 209, 210], "explos": [183, 209, 210], "switch": [183, 210], "formula": [183, 209, 210, 239, 241, 253, 256, 326, 332], "c0": [184, 185], "c1": [184, 185], "call_lstm": [184, 185], "c_out": [184, 185], "i_t": 184, "ii": [184, 185], "hi": [184, 185], "f_t": 184, "hf": [184, 185], "g_t": 184, "ig": [184, 185], "hg": [184, 185], "o_t": 184, "ho": [184, 185], "c_t": 184, "c_": 184, "forget": 184, "consequ": 184, "1402": 184, "1128": 184, "c_0": [184, 185], "proj": 184, "c_n": 184, "w_ii": 184, "w_if": 184, "w_ig": 184, "w_io": 184, "w_hi": 184, "w_hf": 184, "w_hg": 184, "w_ho": 184, "b_ii": 184, "b_if": 184, "b_ig": 184, "b_io": 184, "b_hi": 184, "b_hf": 184, "b_hg": 184, "b_ho": 184, "weight_hr_l": 184, "_revers": 184, "analog": 184, "cn": 184, "lstm_cell": 185, "h_1": 185, "c_1": 185, "time_step": [185, 187], "cx": 185, "trust": 186, "correspont": 186, "recurrent_state_h": [186, 333], "recurrent_state_c": [186, 333], "triplet": [186, 227, 228], "lstm_modul": 186, "rs_h": 186, "rs_c": 186, "hidden0": 186, "hidden1": 186, "lstm_kwarg": 187, "next_observ": [187, 239, 240, 242, 243, 245, 246, 252, 256, 257, 258, 259, 261, 335], "2d": [187, 336], "hidden0_in": 187, "hidden1_in": 187, "hidden0_out": 187, "hidden1_out": 187, "single_bias_last_lay": 188, "layer_class": 188, "layer_kwarg": 188, "perceptron": 188, "seamless": 188, "lazylinear": [188, 325, 332, 337, 338, 341], "42": [188, 239, 240, 242, 252, 259, 331, 336, 337], "noisylinear": [188, 195, 323, 331], "noisylazylinear": [188, 323], "At": [189, 222, 331, 332, 333, 335, 337, 338], "mpcplanner": 189, "tensordict_out": [189, 342], "mppi": 190, "covari": 190, "william": [190, 258], "aldrich": 190, "theodor": 190, "01149": 190, "hansen": 190, "wang": 190, "su": 190, "04955": 190, "valueoper": [190, 215, 216, 217, 239, 240, 241, 242, 246, 252, 253, 256, 257, 258, 259, 261, 317, 325, 330, 332], "tdlambdaestim": [190, 323, 330], "value_net": [190, 243, 245, 258, 269, 270, 271, 272, 332], "adv": 190, "lmbda": [190, 263, 269, 272, 274, 280, 281, 282, 285, 286, 326, 330, 332, 336], "95": [190, 263, 330, 331, 332, 333, 337], "value_network": [190, 242, 243, 245, 247, 252, 259, 269, 270, 271, 272, 326, 330, 332], "temperatur": [190, 240, 252], "neg_inf": [191, 192], "inf": [191, 192], "www": [191, 192], "api_doc": [191, 192], "tf_agent": [191, 192], "event": [191, 192, 200, 278, 279, 280, 281, 283, 284, 285, 286, 339], "unnorm": [191, 192, 200], "sparse_mask": [191, 192], "dens": [191, 192], "0831": [191, 192], "1203": [191, 192], "0928": [191, 192], "1972": [191, 192], "grad_method": [192, 200], "reparamgradientstrategi": [192, 200], "passthrough": [192, 200], "proxi": [192, 200, 326], "relaxedonehot": [192, 200], "zeros_lik": [192, 337], "sample_non_valid": 192, "centralis": [193, 194, 336], "share_param": [193, 194, 336], "basi": [193, 339], "homogen": [193, 194, 336], "agent_network": [193, 194], "modulelist": [193, 194, 314, 341], "lazyconv2d": [193, 341], "2592": [193, 331], "decentralis": [193, 336], "n_agent_input": [194, 336], "n_agent_output": [194, 336], "toech": 194, "centalis": 194, "shown": [194, 325, 335, 336, 339], "std_init": [195, 196], "initialize_paramet": 195, "isol": [195, 254], "1706": [196, 211], "10295v3": 196, "induc": 196, "aid": 196, "scale_map": 197, "biased_softplus_1": 197, "scale_lb": [197, 204, 205], "exp": [197, 238], "module_norm": 197, "decod": 198, "1803": [198, 199, 202], "10122": [198, 199], "rnn_hidden": 198, "latent": 199, "excacli": 200, "inres": 201, "mu": [201, 225, 332], "state_shap": [202, 267], "mixing_embed_dim": [202, 267], "qmix": [202, 336], "mixer": [202, 211, 267], "monoton": 202, "hyper": 202, "11485": 202, "qmixerloss": [202, 211], "qmix_vdn": [202, 211], "eventu": [202, 333, 337], "vdn": [202, 211], "greedi": [203, 221, 222, 223, 228, 331, 333], "hidden_dim": [204, 205], "posterior": [204, 249], "rssm": [204, 205, 249], "1811": [204, 205], "04551": [204, 205], "obs_embed": 204, "rnn_hidden_dim": 205, "dream": 205, "tanhtransform": 209, "decomposit": 211, "05296": 211, "hide": [212, 332, 336], "satisfi": [212, 325], "vmap_dim": 212, "lam": 212, "sample_in": 212, "sample_in_td": 212, "vm": 212, "translat": [214, 226], "character": [214, 220, 226, 227, 229, 339], "overflow": [214, 220, 221, 226, 227, 228, 229, 230], "td_modul": [214, 215, 216, 217, 226, 229, 230, 232, 234, 341], "3635": 214, "0340": 214, "1476": 214, "3911": [214, 337], "1664": [214, 331, 337], "5455": 214, "2247": 214, "4583": 214, "2916": 214, "2160": 214, "5337": 214, "5193": 214, "grad_fn": [214, 222, 223, 341], "addmmbackward0": 214, "actorvalueoper": [215, 325], "get_policy_oper": [215, 216, 217, 241, 253, 256, 325], "standalon": [215, 216, 217], "tdmodul": [215, 216, 217, 317], "get_critic_oper": 215, "common_oper": [215, 217], "policy_oper": [215, 216, 217], "value_oper": [215, 216, 217], "normalparamwrapp": [215, 216, 217, 226, 232, 239, 240, 246, 252, 256, 257, 258, 259, 261, 323, 341], "module_hidden": [215, 217], "td_module_hidden": [215, 217], "module_act": [215, 217], "td_module_act": [215, 216, 217], "module_valu": [215, 216, 217], "td_module_valu": [215, 216, 217], "state_action_valu": [215, 234, 240, 259, 268, 314, 317, 325, 330, 341], "td_clone": [215, 216, 217], "tensordictmodulewrapp": [215, 310, 311, 317], "get_policy_head": [215, 216, 217], "safesequenti": [215, 216, 217, 267], "head": [215, 217, 241, 253, 256], "get_value_head": [215, 216, 217], "get_value_oper": [215, 216, 217, 241, 253, 256], "action_modul": 216, "state_valu": [216, 217, 234, 241, 253, 256, 257, 259, 269, 270, 271, 272, 274, 276, 278, 280, 282, 283, 285, 325, 330, 332, 336], "qualiti": [217, 325], "actorcriticoper": [217, 241, 253, 256, 325], "embeddig": 217, "refet": 217, "actorcriticwrapp": [217, 325, 330], "po": [218, 223], "sigma_init": 218, "epsilon": [218, 222, 223, 225, 260, 303, 331, 332, 333], "sigma_end": 218, "annealing_num_step": [218, 222, 223, 225, 330, 331, 333], "captur": [218, 222, 223, 225], "omiss": [218, 222, 223, 225], "ommit": [218, 222, 223, 225, 339], "inferec": 219, "set_tensor_kei": 219, "dt_inference_wrapp": 219, "baz": 219, "inference_context": 219, "obs_dim": 219, "tanhdelta": [219, 323, 330], "dtactor": 219, "actor_modul": [219, 341], "dist_class": 219, "dist_kwarg": 219, "distribution_kwarg": [219, 226, 230, 332, 336], "inference_actor": 219, "sequence_length": 219, "mask_context": 219, "out_act": 219, "qvaluemodul": [220, 227, 267, 333], "distributionaldqnnet": 220, "make_log_softmax": 220, "my_action_valu": [221, 228], "chanc": 221, "thid": 221, "threshold": [222, 240, 241, 332], "eps_init": [222, 223, 225, 331, 333], "eps_end": [222, 223, 225, 331], "explorative_polici": [222, 223, 225], "9055": [222, 223, 337], "9277": [222, 223], "6295": [222, 223], "2532": [222, 223], "addbackward0": [222, 223], "lmheadmodel": 224, "extract": [224, 330, 332], "actor_head": [224, 241, 253, 256], "base_model": 224, "lm_head": 224, "ornstein": 225, "uhlenbeck": 225, "ou": [225, 330], "correl": 225, "noise_t": 225, "noise_": 225, "theta": [225, 332, 337], "sigma_t": 225, "sigma_": 225, "anneal": 225, "ou_prev_nois": 225, "ou_step": 225, "x0": 225, "sigma_min": 225, "n_steps_ann": 225, "is_init_kei": 225, "_ou_prev_nois": 225, "_ou_step": 225, "default_interaction_typ": [226, 230], "interaction_typ": [226, 230], "set_interaction_typ": [226, 230], "cache_dist": [226, 230], "n_empirical_estim": [226, 230], "compound": 226, "compositedistribut": 226, "categ": 226, "distribution_map": 226, "chose": 228, "functionalmodul": 229, "functionalmodulewithbuff": 229, "td_fmodul": 229, "td_function": 229, "td_state": 229, "ensembl": [229, 257], "params_repeat": 229, "td_vmap": [229, 232], "random_sampl": [229, 230], "suppli": 230, "fist": 230, "log_prob_kei": [230, 336], "probabilistictensordictsequenti": [231, 239, 241, 253, 256, 258, 310, 311, 341], "partial_toler": [231, 232, 335], "who": [231, 232], "AND": [231, 232], "tensordictsequenci": 232, "tensordictsequ": 232, "safeprobabilisticmodul": [232, 325], "spec1": 232, "net1": 232, "module1": 232, "td_module1": 232, "spec2": 232, "module2": 232, "td_module2": 232, "clamp": [233, 249, 305, 337], "boundari": [233, 332, 336], "resolut": 233, "simplest": [233, 330, 332, 333, 336, 339, 342], "9944": 233, "9991": 233, "3020": 233, "2299": [233, 337], "5418": 233, "2989": 233, "6849": 233, "3169": 233, "2690": 233, "9649": [233, 337], "5686": 233, "8602": 233, "0315": 233, "8455": [233, 337], "6027": 233, "4746": 233, "7843": 233, "7782": 233, "2111": 233, "5115": 233, "4687": 233, "5760": 233, "custommodul": 234, "cat": [234, 240, 242, 252, 257, 259, 261, 341], "imaginari": 235, "imagin": 235, "transition_model": 235, "get_reward_oper": 235, "get_transition_model_oper": 235, "min_val": [236, 238], "_bia": 236, "invert": [237, 332], "surject": 238, "expln": 238, "biased_softplu": [238, 323], "beggin": 238, "biased_softplus_": 238, "syntax": [238, 330], "met": [238, 337], "1602": 239, "01783v2": 239, "entropy_bonu": [239, 241, 253, 256, 332], "favour": [239, 241, 253, 256], "samples_mc_entropi": [239, 241, 253, 255, 256], "mont": [239, 241, 253, 256, 330], "carlo": [239, 241, 253, 256, 330], "entropy_coef": [239, 241, 253, 256, 332, 336], "critic_coef": [239, 241, 253, 256, 332], "loss_critic_typ": [239, 241, 253, 256, 258, 332], "l1": [239, 241, 242, 243, 246, 253, 256, 257, 258, 261, 264, 267, 325, 330], "l2": [239, 241, 242, 243, 244, 245, 246, 249, 250, 253, 256, 257, 258, 261, 264, 267, 330], "smooth_l1": [239, 240, 241, 242, 243, 246, 252, 253, 256, 257, 258, 259, 261, 264, 267, 332], "separate_loss": [239, 241, 242, 246, 252, 253, 256, 257, 258, 259, 261], "propag": [239, 241, 242, 246, 252, 253, 256, 257, 258, 259, 261, 269, 270, 271, 272, 332, 336], "advantage_kei": [239, 241, 253, 256, 258, 269, 270, 271, 272], "value_target_kei": [239, 241, 253, 256, 258, 269, 270, 271, 272, 332], "value_target": [239, 241, 253, 256, 258, 269, 270, 271, 272, 332, 336], "loss_crit": [239, 256, 332, 336], "loss_entropi": [239, 256, 332, 336], "loss_object": [239, 256, 332, 336], "recur": [239, 240, 242, 243, 245, 246, 252, 256, 257, 258, 259, 261, 269, 270, 271, 272, 273], "next_reward": [239, 240, 242, 243, 245, 246, 252, 256, 257, 258, 259, 261, 269, 270, 271, 272], "next_don": [239, 240, 242, 243, 245, 246, 252, 256, 257, 258, 259, 261, 269, 270, 271, 272], "next_termin": [239, 240, 242, 243, 245, 246, 252, 256, 257, 258, 259, 261, 269, 270, 271, 272], "loss_obj": 239, "sacloss": [239, 251, 260, 323], "select_out_kei": [239, 240, 242, 246, 252, 256, 257, 259, 261], "essenti": [239, 240, 241, 246, 247, 248, 249, 250, 252, 253, 254, 256, 257, 258, 259, 261, 267, 331, 337, 339], "make_value_estim": [239, 240, 242, 243, 245, 246, 247, 248, 252, 254, 256, 257, 258, 259, 261, 262, 267, 326, 330, 331, 336], "value_typ": [239, 240, 242, 243, 245, 246, 247, 248, 252, 254, 256, 257, 258, 259, 261, 263, 267, 330], "valueestim": [239, 240, 242, 243, 245, 246, 247, 248, 252, 254, 256, 257, 258, 259, 261, 263, 267, 323, 326, 330, 336], "hyperparam": [239, 240, 242, 243, 245, 246, 247, 248, 252, 254, 256, 257, 258, 259, 261, 267, 330], "enum": [239, 240, 242, 243, 245, 246, 247, 248, 252, 254, 256, 257, 258, 259, 261, 263, 267, 330], "default_value_estim": [239, 240, 242, 243, 245, 246, 247, 248, 252, 254, 256, 257, 258, 259, 261, 267, 330], "refin": [239, 240, 242, 243, 245, 246, 247, 248, 252, 254, 256, 257, 258, 259, 261, 267], "default_value_kwarg": [239, 240, 242, 243, 245, 246, 247, 248, 252, 254, 256, 257, 258, 259, 261, 267, 323, 330], "dqn_loss": [239, 240, 242, 243, 245, 246, 247, 248, 252, 254, 256, 257, 258, 259, 261, 262, 267], "conserv": [240, 245], "2006": [240, 245, 337], "actor_network": [240, 242, 244, 246, 252, 255, 257, 259, 261, 330], "qvalue_network": [240, 246, 252, 257, 259, 261], "loss_funct": [240, 242, 243, 244, 245, 246, 252, 257, 259, 261, 264, 267, 330], "alpha_init": [240, 246, 255, 257, 259], "min_alpha": [240, 246, 255, 257, 259], "max_alpha": [240, 246, 255, 257, 259], "fixed_alpha": [240, 246, 255, 257, 259], "target_entropi": [240, 246, 255, 257, 259], "prod": [240, 255, 259], "n_action": [240, 243, 245, 255, 259], "delay_actor": [240, 242, 259, 261], "delay_qvalu": [240, 246, 257, 259, 261], "min_q_weight": 240, "max_q_backup": 240, "backup": 240, "deterministic_backup": 240, "num_random": 240, "with_lagrang": 240, "lagrang": 240, "lagrange_thresh": 240, "valueclass": [240, 242, 246, 252, 257, 259, 261], "qvalu": [240, 246, 252, 257, 259, 261, 314], "loss_actor": [240, 242, 246, 252, 257, 258, 259, 261, 300, 330, 341], "loss_alpha": [240, 246, 257, 259], "loss_alpha_prim": 240, "loss_qvalu": [240, 246, 252, 257, 259, 261], "clip_epsilon": [241, 332, 336], "normalize_advantag": [241, 253, 256, 336], "value_kei": [241, 253, 256, 269, 270, 271, 272, 330], "somemodul": [241, 253, 256], "someactor": [241, 253, 256], "value_head": [241, 253, 256], "somevalu": [241, 253, 256], "loss_modul": [241, 251, 253, 254, 256, 260, 305, 316, 317, 326, 327, 330, 331, 332, 336, 339], "ppoloss": [241, 253, 323], "delay_valu": [242, 243, 245, 247, 258, 259, 267, 331, 333], "loss_valu": [242, 252, 258, 259, 330, 332, 336, 341], "pred_valu": [242, 261, 330, 341], "pred_value_max": [242, 330, 341], "target_valu": [242, 257, 261, 268, 326, 330, 341], "target_value_max": [242, 330, 341], "qvalueactor": [243, 245, 267, 325, 331, 333], "double_dqn": 243, "06461": [243, 251], "mult_one_hot": [243, 246, 267], "loss_val": [243, 245, 326, 330, 332, 333, 336, 339], "2106": 244, "01345": 244, "distanc": [245, 253, 264, 268, 269, 336], "loss_cql": 245, "dcql_loss": 245, "ste": 246, "num_qvalue_net": [246, 252, 257, 259, 261], "target_entropy_weight": 246, "onehotcategor": [246, 323], "disctount": 247, "distributionalqvalueactor": [247, 325], "input_tensordict": [247, 330], "actor_model": 248, "value_model": [248, 250], "model_based_env": 248, "dreamerenv": [248, 323], "imagination_horizon": 248, "unrol": [248, 274, 275, 278, 279, 280, 281, 282, 283, 284, 285, 286], "discount_loss": [248, 250], "lambda_kl": 249, "lambda_reco": 249, "lambda_reward": 249, "reco_loss": 249, "reward_loss": 249, "free_nat": 249, "nat": 249, "delayed_clamp": 249, "global_averag": 249, "value_loss": 250, "fake_data": 250, "ddpgloss": [251, 260, 317, 323, 330, 341], "td3loss": [251, 260, 323], "value_network_update_interv": 251, "2110": 252, "06169": 252, "expectil": 252, "tau": [252, 260, 330, 331], "antmaz": 252, "sticht": 252, "loss_value_diff": 252, "diff": 252, "old_polici": 253, "new_polici": 253, "apart": [253, 336], "dtarg": 253, "samples_mc_kl": 253, "analyt": 253, "decrement": 253, "loss_": [254, 300, 326, 330], "equip": [254, 333], "gh": 254, "_acceptedkei": 254, "dataclass": [254, 314], "_forward_value_estimator_kei": 254, "alter": [254, 325], "value_estim": [254, 269, 270, 271, 272, 273, 326, 330, 336], "myloss": 254, "action2": 254, "convert_to_funct": [254, 330], "expand_dim": 254, "create_target_param": [254, 330], "compare_against": [254, 330], "_param": 254, "expans": 254, "resampl": 254, "_target_param": 254, "blend": 254, "upcom": [254, 278, 279, 280, 281, 283, 284, 285, 286, 330], "proxim": [256, 332, 336], "optimis": [256, 301, 332, 336], "flavour": [256, 336, 341], "clipppoloss": [256, 323, 332, 336], "klpenppoloss": [256, 323], "regularis": 256, "06347": 256, "gae": [256, 323, 326, 330, 332, 336], "ppo_loss": 256, "tdlambda": [256, 263, 326, 330], "base_lay": 256, "randn_lik": 256, "samplelogprob": 256, "openreview": [257, 314], "ay8zfzm0tdd": [257, 314], "sub_sample_len": 257, "subsampl": [257, 296, 327], "action_log_prob_actor": 257, "state_action_value_actor": [257, 261], "connectionist": 258, "1992": 258, "doi": 258, "1007": 258, "bf00992696": 258, "actor_net": [258, 330, 332], "1801": 259, "01290": 259, "applic": [259, 267, 337], "1812": 259, "05905": 259, "redqloss": [260, 323], "math": 260, "theta_t": [260, 337], "theta_": [260, 337], "polyak": 260, "policy_nois": 261, "noise_clip": 261, "next_state_valu": [261, 274, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 323], "td0": [262, 330], "strict_shap": 264, "view_a": 264, "qmixer": [267, 323], "local_valu": 267, "visibl": [267, 336], "dafault": 267, "acceptedkei": 267, "global_valu": 267, "penultim": 267, "local_value_network": 267, "mixer_network": 267, "suggest": [267, 336], "value_modul": [267, 332, 341], "qnet": [267, 330], "next_val_kei": 268, "pred_next_v": 268, "usus": 268, "mse": 268, "q_valu": 268, "n_steps_to_next": 268, "value_next_st": 268, "1506": [269, 274, 282], "02438": [269, 274, 282], "exponenti": [269, 270, 271, 272, 274, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 303], "average_ga": [269, 332], "skip_exist": [269, 270, 271, 272], "advang": 269, "gradient_mod": 269, "value_error": [269, 270, 271, 272, 273], "sign": 269, "target_param": [269, 270, 271, 272, 273, 330, 336], "98": [269, 270, 271, 272, 329, 331, 337, 338, 340], "94": [269, 272, 331, 337], "unpack": [269, 270, 271, 272], "tensor_kei": [269, 270, 271, 272, 273], "next_valu": [269, 270, 271, 272, 273], "aka": [270, 331], "average_reward": [270, 271, 272], "tdestim": [270, 271, 273], "infti": 271, "valuefunctionbas": 273, "time_dim": [274, 275, 278, 279, 280, 281, 282, 283, 284, 285, 286], "old_stat": [274, 276, 278, 280, 282, 283, 285], "new_stat": [274, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286], "rolling_gamma": [278, 279, 280, 281, 283, 284, 285, 286], "g1": [278, 279, 280, 281, 283, 284, 285, 286], "g2": [278, 279, 280, 281, 283, 284, 285, 286], "g3": [278, 279, 280, 281, 283, 284, 285, 286], "g4": [278, 279, 280, 281, 283, 284, 285, 286], "v3": [278, 279, 280, 281, 283, 284, 285, 286], "out_file_bas": 287, "skip_reset": 287, "interv": [287, 288, 297, 307, 331, 337], "center_crop": 288, "make_grid": 288, "grid": 288, "exp_nam": [289, 290, 293, 294, 295, 317, 331], "log_dir": [289, 290, 292, 294, 331], "templat": 289, "csv": [290, 292, 331], "minim": [290, 339], "dependeci": 290, "experiment_nam": [291, 292], "uuid": [291, 331, 342], "logger_typ": 292, "logger_nam": 292, "tensorboard": [292, 294, 341], "wandb": [292, 295, 341], "mlflow": [292, 293], "wandb_kwarg": 292, "mlflow_kwarg": 292, "tracking_uri": 293, "uri": 293, "datastor": 293, "tb_log": 294, "tensoarboard": 294, "sub_traj_len": 296, "min_sub_traj_len": 296, "register_op": [296, 297, 298, 299, 300, 301, 302, 303, 304, 306, 307, 327, 331], "process_optim_batch": [296, 302, 303, 327], "td_out": [296, 304], "_process_optim_batch_hook": [296, 327], "batch_subsampl": 296, "clear_cuda": 297, "pre_optim_step": [297, 327], "counter": [298, 327], "log_pbar": [298, 299, 301, 303, 327, 331], "progress": [298, 299, 301, 305, 327, 331, 333, 342], "count_fram": 298, "pre_steps_log": [298, 299, 327], "count_frames_log": 298, "lognam": 299, "r_train": [299, 331], "log_reward": [299, 331], "loss_compon": 300, "appl": 300, "omit": [300, 332, 337, 339], "optimizer_hook": 300, "record_interv": [301, 330, 331], "record_fram": [301, 308, 330, 331], "policy_explor": [301, 317, 330, 331], "log_kei": [301, 331], "suffix": 301, "underestim": 301, "set_exploration_typ": [301, 323, 332, 333, 341], "r_evalu": [301, 330], "flatten_tensordict": [302, 331], "max_dim": 302, "rb_trainer": 302, "batch_process": [302, 303, 304, 327], "post_loss": [302, 327], "999": [303, 331], "jitter": 303, "finfo": 303, "default_dtyp": 303, "get_default_dtyp": 303, "reward_norm": 303, "update_reward_stat": 303, "normalize_reward": 303, "make_train": [304, 323], "_process_batch_hook": [304, 327], "select_kei": [304, 327], "versatil": 305, "optim_steps_per_batch": [305, 327, 331], "epoch": [305, 332, 336], "clip_grad_norm": 305, "clip_norm": 305, "progress_bar": 305, "save_trainer_interv": 305, "log_interv": [305, 331], "save_trainer_fil": [305, 327], "datacollectorbas": [307, 310, 311, 317, 323], "update_weights_interv": [307, 331], "sit": [307, 331], "update_weight": 307, "post_step": [307, 327], "cfg": [308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 321], "dictconfig": [308, 309, 310, 311, 314, 315, 316, 317, 318, 321], "divid": [308, 325, 330, 336, 337], "unknowingli": 308, "annealing_fram": [308, 330], "init_env_step": [308, 309, 330], "proof_environ": [309, 314, 330], "sta": 309, "ot": 309, "actor_model_explor": [310, 311, 330], "make_env_kwarg": [310, 311], "targetnetupdat": [312, 313, 316, 317], "redqloss_deprec": 313, "actor_net_kwarg": 314, "qvalue_net_kwarg": 314, "observation_kei": 314, "dummi": [314, 330, 342], "parser_env_arg": 314, "parser_model_args_continu": 314, "cattensor": [314, 330, 335, 337, 342], "hydra": 314, "config_stor": 314, "configstor": 314, "config_field": 314, "config_cl": 314, "redqmodelconfig": 314, "envconfig": 314, "make_dataclass": 314, "cls_name": 314, "cs": 314, "config_path": 314, "config_nam": 314, "replayargsconfig": 315, "target_net_updat": [317, 330, 331], "constitu": 317, "learnt": [317, 330, 332], "tensorboardlogg": [317, 323], "egreedywrapp": [317, 331, 333], "env_proof": 317, "obs_spec": 317, "net_valu": 317, "dir": [317, 327, 331], "gettempdir": 317, "argpars": [318, 321], "namespac": [318, 321], "parser": [318, 321], "transformed_env_constructor": [318, 323], "num_env_per_collector": [319, 320], "video_tag": 321, "norm_obs_onli": 321, "use_env_cr": 321, "custom_env_mak": 321, "custom_env": 321, "return_transformed_env": 321, "action_dim_gsd": 321, "state_dim_gsd": 321, "obs_norm_state_dict": 321, "wheter": 321, "maker": 321, "asyncdatacollector": 323, "distributedsyncdatacollector": 323, "submitit_delayed_launch": 323, "raycollector": 323, "tensordictmaxvaluewrit": 323, "d4rlexperiencereplai": 323, "minariexperiencereplai": 323, "openmlexperiencereplai": 323, "vd4rlexperiencereplai": 323, "unboundeddiscretetensorspec": [323, 342], "lazystackedtensorspec": 323, "lazystackedcompositespec": 323, "prompttensordicttoken": 323, "rolloutfrommodel": 323, "tokenizeddatasetload": 323, "create_infinite_iter": 323, "consolidate_spec": 323, "check_no_exclusive_kei": 323, "contains_lazy_spec": 323, "check_marl_group": 323, "tensordictrecord": 323, "videorecord": [323, 332], "get_available_librari": 323, "set_exploration_mod": 323, "make_composite_from_td": [323, 337], "terminated_or_trunc": 323, "braxwrapp": 323, "dmcontrolenv": [323, 330, 335, 342], "dmcontrolwrapp": [323, 342], "jumanjienv": 323, "jumanjiwrapp": 323, "mogymenv": 323, "mogymwrapp": 323, "multithreadedenvwrapp": 323, "openmlenv": 323, "pettingzooenv": 323, "robohiveenv": 323, "smacv2env": 323, "smacv2wrapp": 323, "vmaswrapp": 323, "qvaluehook": 323, "distributionalqvaluehook": 323, "reset_nois": 323, "cemplann": 323, "mpcplannerbas": 323, "mppiplann": 323, "independentnorm": 323, "truncatednorm": 323, "maskedonehotcategor": 323, "inv_softplu": 323, "vmapmodul": 323, "distributionaldqnloss": [323, 331], "discretesacloss": 323, "iqlloss": 323, "cqlloss": 323, "discretecqlloss": 323, "dtloss": 323, "onlinedtloss": 323, "a2closs": 323, "reinforceloss": 323, "dreameractorloss": 323, "dreamermodelloss": 323, "dreamervalueloss": 323, "td0estim": [323, 330], "td1estim": [323, 330], "td0_return_estim": 323, "td0_advantage_estim": 323, "td1_return_estim": 323, "vec_td1_return_estim": 323, "td1_advantage_estim": 323, "vec_td1_advantage_estim": 323, "td_lambda_return_estim": 323, "vec_td_lambda_return_estim": 323, "td_lambda_advantage_estim": 323, "vec_td_lambda_advantage_estim": 323, "generalized_advantage_estim": 323, "vec_generalized_advantage_estim": 323, "reward2go": 323, "distance_loss": [323, 330], "hold_out_net": 323, "hold_out_param": [323, 330], "softupd": [323, 330, 331, 333], "hardupd": [323, 330], "batchsubsampl": [323, 327], "clearcudacach": 323, "countframeslog": 323, "logreward": [323, 327, 331], "optimizerhook": [323, 331], "replaybuffertrain": [323, 327, 331], "rewardnorm": 323, "selectkei": [323, 327], "trainerhookbas": [323, 327, 331], "updateweight": [323, 327, 331], "make_collector_offpolici": 323, "make_collector_onpolici": 323, "make_dqn_loss": 323, "make_redq_loss": 323, "make_redq_model": 323, "make_replay_buff": [323, 330], "make_target_updat": 323, "parallel_env_constructor": [323, 330], "sync_async_collector": 323, "sync_sync_collector": 323, "correct_for_frame_skip": 323, "get_stats_random_rollout": 323, "csvlogger": [323, 331], "mlflowlogg": 323, "wandblogg": 323, "get_logg": 323, "generate_exp_nam": 323, "journei": 324, "textbook": 324, "highlight": 324, "ever": [324, 336], "bump": 324, "think": [324, 332, 336, 342], "benefit": [324, 336, 339], "pr": 324, "ground": [325, 330, 337], "categori": [325, 327], "recycl": [325, 339], "impos": 325, "violat": 325, "noisier": 325, "Their": [325, 336], "sd": 325, "prob_modul": 325, "pick": [325, 330, 331], "tabl": [325, 331], "customari": 325, "hopefulli": [325, 331], "functional_modul": 325, "make_funct": [325, 341], "mathbb": [325, 331], "rightarrow": [325, 331], "soften": 325, "backbon": [325, 333, 335, 341], "make_actor": 325, "make_valu": 325, "shared_param": 325, "make_common": 325, "reusabl": [326, 330, 339], "swappabl": [326, 330], "characterist": [326, 330, 337], "trainabl": [326, 330, 338], "whatev": [326, 330], "smth": [326, 330], "metric": [326, 330], "nutshel": [326, 330], "barto": [326, 336], "chapter": 326, "significantli": [326, 330, 331, 336], "next_stat": 326, "value_net_loss": 326, "pow": [326, 330], "therebi": 326, "room": 326, "convers": 326, "signifi": [326, 336], "underperform": 326, "thin": 326, "intric": 326, "believ": 327, "scheme": [327, 342], "substenti": 327, "_pre_steps_log_hook": 327, "_pre_optim_hook": 327, "sub_batch": 327, "_post_loss_hook": 327, "_post_optim_hook": 327, "post_optim": [327, 331], "_post_optim_log": 327, "post_optim_log": 327, "_post_steps_hook": 327, "_post_steps_log_hook": 327, "post_steps_log": 327, "comment": [327, 331, 341], "reserv": 327, "logginghook": 327, "logging_hook": 327, "save_dict": 327, "some_valu": 327, "torchsnapshot": 327, "ckpt_backend": 327, "pt": [327, 338], "filepath": 327, "save_train": 327, "load_from_fil": 327, "208": [329, 337, 340], "galleri": [329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 341, 342], "mem": [329, 340], "mb": [329, 330, 331, 332, 333, 335, 336, 337, 338, 339, 340, 341, 342], "torchrl_demo": [329, 340, 341], "59": [329, 331, 337, 340, 341], "394": [329, 337, 340, 341], "torchrl_env": [329, 340, 342], "563": [329, 337, 340, 342], "dqn_with_rnn": [329, 333, 340], "485": [329, 333, 337, 340], "1916": [329, 333, 340], "multiagent_ppo": [329, 336, 340], "034": [329, 336, 340], "coding_dqn": [329, 331, 340], "02": [329, 330, 331, 333, 336, 337, 338, 340], "52": [329, 330, 331, 337, 338, 339, 340], "900": [329, 331, 336, 340], "1086": [329, 331, 340], "40": [329, 331, 332, 333, 336, 337, 340], "730": [329, 337, 340], "rb_tutori": [329, 339, 340], "840": [329, 339, 340], "454": [329, 337, 339, 340], "coding_ddpg": [329, 330, 340], "58": [329, 330, 331, 337, 338, 340], "332": [329, 330, 337, 340], "coding_ppo": [329, 332, 340], "36": [329, 330, 331, 332, 333, 337, 338, 339, 340], "905": [329, 332, 337, 340], "pretrained_model": [329, 338, 340], "00": [329, 330, 331, 332, 333, 336, 337, 338, 340], "54": [329, 330, 331, 337, 338, 340], "123": [329, 337, 338, 339, 340], "3411": [329, 338, 340], "multi_task": [329, 335, 340], "48": [329, 330, 331, 335, 337, 338, 340], "902": [329, 335, 340], "25": [329, 330, 331, 332, 336, 337, 338, 339, 340], "author": [330, 331, 332, 333, 336, 337, 339], "vincent": [330, 331, 332, 333, 337, 339], "moen": [330, 331, 332, 333, 337, 339], "assembl": 330, "focus": 330, "straightforward": [330, 331, 339], "overview": [330, 332, 336, 341], "transpar": [330, 333], "understood": 330, "sota": [330, 331, 341], "illustr": [330, 331, 339], "loss_dict": 330, "modal": 330, "oblivi": [330, 332, 339], "elementari": 330, "didact": 330, "dilut": 330, "pessimist": [330, 331, 332], "target_actor_network_param": 330, "actor_in_kei": 330, "actor_crit": 330, "noth": [330, 332], "compromis": 330, "hp": 330, "hasattr": 330, "_value_estim": 330, "elif": [330, 331], "notimplementederror": 330, "unknown": 330, "_loss_actor": 330, "td_copi": 330, "actor_network_param": 330, "value_network_param": 330, "_loss_valu": 330, "pred_val": 330, "target_value_network_param": 330, "smooth": [330, 331], "loss_funt": 330, "glue": 330, "_forward": 330, "ndimens": 330, "remaind": 330, "focu": [330, 331, 332], "pixels_onli": [330, 331, 341, 342], "env_librari": 330, "env_task": 330, "env_arg": 330, "friendli": 330, "torchr": 330, "rescal": 330, "presum": 330, "make_transformed_env": 330, "reward_sc": 330, "double_to_float_list": 330, "double_to_float_inv_list": 330, "marker": 330, "env_per_collector": 330, "transform_state_dict": 330, "make_t_env": 330, "adjust": [330, 336, 337], "seem": [330, 333], "cheat": 330, "10m": 330, "cautiou": 330, "magnitud": 330, "thousand": [330, 333], "get_env_stat": 330, "proof_env": 330, "5000": [330, 331, 332], "maxim": [330, 337], "recal": [330, 332], "ddpgmlpactor": 330, "ddpgmlpqnet": 330, "materi": 330, "ornsteinuhlenbeckprocesswrapp": 330, "make_ddpg_actor": 330, "q_net": 330, "moduless": 330, "sugges": 330, "tight": 330, "10_000": [330, 332, 339], "traj_len": [330, 333], "make_record": 330, "recorder_obj": 330, "flavor": 330, "circular": 330, "buffer_s": [330, 331], "random_crop_len": 330, "prb": 330, "buffer_scratch_dir": 330, "temporari": 330, "dirrectori": 330, "trajecotri": 330, "sampel": 330, "dataflow": 330, "ceil_div": 330, "utd": [330, 333], "update_to_data": 330, "realiz": 330, "_must_": 330, "001": [330, 337], "outdat": 330, "trick": [330, 331], "despit": 330, "adam": [330, 331, 332, 333, 336, 337], "optimizer_actor": 330, "lr": [330, 331, 332, 333, 336, 337], "weight_decai": [330, 331], "optimizer_valu": 330, "total_collection_step": 330, "pretti": [330, 339], "rewards_ev": 330, "collected_fram": 330, "pbar": [330, 332, 333, 336, 337], "r0": 330, "numel": [330, 332, 333, 338, 339], "current_fram": 330, "sampled_tensordict": 330, "gn1": 330, "clip_grad_norm_": [330, 332, 336, 337], "gn2": 330, "gn": [330, 337], "td_record": 330, "rn": 330, "set_descript": [330, 332, 333, 336, 337], "2f": 330, "800": [330, 331], "2824": 330, "04it": [330, 331], "1600": [330, 331], "1028": 330, "70it": [330, 331, 337], "3200": [330, 331], "2123": 330, "53it": 330, "4800": [330, 331, 337], "3065": 330, "39it": [330, 331], "89": [330, 331, 337, 339], "78": [330, 331, 336, 337, 338], "31": [330, 331, 337, 338], "233": [330, 337], "56": [330, 331, 337, 338], "5600": 330, "6400": [330, 341], "1355": 330, "40it": [330, 331], "63": [330, 331, 337, 338], "224": [330, 331, 337], "79": [330, 331, 337], "72": [330, 331, 337, 338], "7200": 330, "862": 330, "17it": [330, 331], "41": [330, 331, 333, 337], "09": [330, 331, 332, 336, 337], "265": [330, 337], "57": [330, 331, 337, 338], "80": [330, 331, 332, 336, 337, 338], "8000": [330, 332], "643": [330, 337], "22it": [330, 331, 337], "61": [330, 331, 337, 338], "108": [330, 337], "60": [330, 331, 332, 336, 337, 338, 341], "245": [330, 337], "8800": 330, "545": [330, 337], "89it": 330, "83": [330, 331, 337, 338], "66": [330, 331, 337, 338], "51": [330, 331, 336, 337, 338, 339], "93": [330, 331, 337], "227": [330, 337], "45": [330, 331, 332, 333, 337, 338], "67": [330, 331, 335, 337, 338], "96": [330, 331, 337, 338], "9600": 330, "410": [330, 337], "14it": [330, 331, 337], "111": [330, 337, 339], "299": [330, 337], "82": [330, 331, 337], "10400it": 330, "402": [330, 337], "29it": [330, 331, 337], "55": [330, 331, 336, 337, 338, 339], "162": [330, 337], "07": [330, 331, 337], "230": [330, 337], "plot": [330, 332, 333, 336, 337], "mention": [330, 333, 339, 342], "matplotlib": [330, 332, 333, 336, 337, 339, 342], "pyplot": [330, 332, 333, 336, 337, 339, 342], "plt": [330, 332, 333, 336, 337, 339, 342], "zip": [330, 334], "legend": 330, "xlabel": [330, 333, 336, 337], "ylabel": [330, 336], "tight_layout": 330, "concret": [330, 332], "takeawai": [330, 331], "minut": [330, 331, 332, 333, 335, 336, 337, 338, 339, 341, 342], "jupyt": [330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 341, 342], "ipynb": [330, 331, 332, 333, 335, 336, 337, 338, 339, 341, 342], "sphinx": [330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 341, 342], "customis": [331, 336], "road": 331, "aspect": 331, "highest": 331, "prerequisit": [331, 333], "familiar": [331, 336, 342], "lookup": 331, "amort": [331, 332], "conjunct": 331, "cart": 331, "pole": 331, "un": 331, "actuat": 331, "frictionless": 331, "upright": 331, "duelingcnndqnet": 331, "is_notebook": 331, "shell": 331, "get_ipython": 331, "__class__": 331, "zmqinteractiveshel": 331, "qtconsol": 331, "terminalinteractiveshel": 331, "ipython": [331, 336, 337], "nameerror": 331, "umbrella": 331, "misplac": 331, "misus": 331, "orchestr": 331, "everyth": [331, 333], "five": [331, 332], "64x64": 331, "motion": [331, 337], "obs_norm_sd": 331, "simpler": 331, "get_norm_stat": 331, "test_env": 331, "make_model": 331, "dummy_env": 331, "output_s": [331, 333], "init_bia": 331, "actor_explor": 331, "eps_greedy_v": 331, "eps_greedy_val_env": 331, "get_replay_buff": 331, "n_optim": 331, "themselv": 331, "simplic": [331, 332, 338, 339], "get_collector": 331, "data_collector": 331, "bunch": 331, "concept": [331, 339], "power": 331, "ubiquit": 331, "get_loss_modul": 331, "target_updat": 331, "995": [331, 337], "sensit": 331, "variat": 331, "2e": [331, 337], "wd": 331, "upd": 331, "harder": [331, 341], "5_000": 331, "500000": 331, "100000": 331, "005": 331, "mandatori": [331, 332, 336, 337], "fairer": 331, "budget": [331, 332], "dqn_exp_": 331, "uuid1": [331, 342], "9895": 331, "0737": 331, "tmp": [331, 339], "tmp_lp9jyst": 331, "dqn_exp_96f69ff6": 331, "aaf0": 331, "11ee": [331, 342], "b35e": [331, 342], "0242ac110002": [331, 342], "registr": 331, "cumbersom": 331, "buffer_hook": 331, "weight_updat": 331, "descript": [331, 332], "aliv": 331, "total_reward": 331, "4045": 331, "9259": 331, "43": [331, 337, 338], "42it": 331, "05": [331, 333, 337, 338], "45it": [331, 337], "3560": 331, "28it": 331, "3621": 331, "3712": 331, "192": [331, 337], "52it": 331, "4497": 331, "03it": 331, "4375": [331, 337], "77it": [331, 337], "4345": 331, "288": [331, 337], "53": [331, 333, 337], "69it": [331, 337], "98it": 331, "4948": 331, "352": [331, 337], "71it": [331, 337], "4164": [331, 337], "384": [331, 337], "37it": 331, "4134": 331, "416": [331, 337], "80it": 331, "4524": 331, "448": [331, 337], "21it": 331, "4586": 331, "480": [331, 337, 338], "06it": 331, "93it": [331, 337], "544": [331, 337], "68": [331, 337, 339], "16it": [331, 337], "576": [331, 337], "46it": [331, 337], "608": [331, 337], "84it": [331, 332], "640": 331, "69": [331, 337, 338], "4797": 331, "672": 331, "704": 331, "12it": 331, "736": 331, "91it": [331, 332, 337], "768": 331, "82it": 331, "832": 331, "74it": [331, 332, 337], "4676": 331, "864": 331, "4526": 331, "896": 331, "928": 331, "48it": 331, "960": 331, "54it": [331, 332, 337], "992": [331, 337], "57it": 331, "23it": [331, 337], "1056": 331, "13it": 331, "1088": 331, "30it": 331, "1120": 331, "1152": 331, "1184": 331, "1216": 331, "02it": 331, "1248": 331, "26it": 331, "1280": 331, "32it": [331, 337], "1344": 331, "1376": 331, "05it": 331, "1408": 331, "76it": [331, 337], "1440": 331, "1472": [331, 342], "27it": [331, 332], "1504": 331, "59it": 331, "1536": 331, "1568": 331, "49": [331, 337, 338], "88it": 331, "43it": 331, "1632": 331, "63it": [331, 337], "1696": 331, "62it": [331, 337], "1728": 331, "47": [331, 333, 337, 338], "1760": 331, "1792": 331, "1824": 331, "1856": 331, "1888": 331, "1920": 331, "61it": [331, 333, 337], "1952": 331, "87it": 331, "1984": 331, "2016": 331, "00it": 331, "2048": [331, 338], "2080": 331, "2112": [331, 337], "2144": 331, "78it": [331, 337], "2176": 331, "20it": 331, "2208": 331, "2240": 331, "2272": 331, "90it": [331, 337], "2304": 331, "2336": 331, "2368": 331, "2400": 331, "07it": 331, "2432": 331, "2464": 331, "64it": [331, 337], "2496": 331, "68it": [331, 337], "2528": [331, 337], "2560": 331, "65it": [331, 337], "11it": 331, "2624": 331, "66it": [331, 337], "2656": [331, 337], "2688": 331, "33it": [331, 337], "2720": [331, 337], "2752": 331, "2784": 331, "2816": 331, "51it": [331, 333], "2848": 331, "49it": 331, "2880": 331, "2912": 331, "36it": 331, "2944": [331, 337], "2976": [331, 337], "92it": 331, "3040": 331, "3072": 331, "62": [331, 337, 338, 339], "3104": 331, "09it": 331, "3136": 331, "3168": 331, "31it": 331, "65": [331, 337, 338], "3232": [331, 337], "0909": 331, "3264": 331, "3296": 331, "3328": 331, "73it": [331, 337], "3360": 331, "3392": 331, "83it": 331, "3424": 331, "47it": [331, 332, 337], "3456": [331, 337], "70": [331, 332, 336, 337, 338], "3488": 331, "3520": 331, "71": [331, 337, 338], "3552": 331, "3584": 331, "3616": 331, "55it": 331, "73": [331, 337], "3648": 331, "74": [331, 337, 338, 339], "3680": 331, "19it": [331, 332], "3744": 331, "81it": 331, "76": [331, 337, 338, 339], "3776": 331, "44it": 331, "3808": 331, "77": [331, 336, 337, 339], "3840": 331, "3872": 331, "3904": 331, "3936": 331, "3968": 331, "4000": [331, 332], "4032": 331, "56it": [331, 337], "4064": 331, "4096": 331, "4128": [331, 337], "10it": [331, 332], "4160": 331, "4192": 331, "86it": 331, "4224": 331, "79it": [331, 333], "85": [331, 337, 338], "4256": [331, 337], "4288": [331, 337], "4320": 331, "4352": 331, "08it": 331, "4384": 331, "4416": 331, "4448": 331, "90": [331, 332, 336, 337, 338], "4480": 331, "4512": 331, "01it": 331, "91": [331, 336, 337], "4544": 331, "92": [331, 337, 338], "4576": 331, "99it": 331, "4608": 331, "4640": 331, "4672": [331, 337], "18it": [331, 337], "4704": 331, "41it": 331, "4736": 331, "4768": 331, "97": [331, 337, 338], "4832": 331, "4864": 331, "4896": 331, "4928": 331, "4960": 331, "4992": 331, "5024it": 331, "print_csv_files_in_fold": 331, "folder_path": 331, "csv_file": 331, "output_str": 331, "dirpath": 331, "walk": [331, 335], "endswith": 331, "strip": 331, "44965073466300964": 331, "4948333501815796": 331, "1841549128293991": 331, "15791025757789612": 331, "21994014084339142": 331, "22921696305274963": 331, "22786538302898407": 331, "25704216957092285": 331, "23679830133914948": 331, "23047594726085663": 331, "36973851919174194": 331, "grad_norm_0": 331, "1563663482666016": 331, "9132686853408813": 331, "8934968709945679": 331, "939761757850647": 331, "6853328943252563": 331, "0969748497009277": 331, "246530294418335": 331, "1395323276519775": 331, "097142457962036": 331, "10000000894069672": 331, "090909957885742": 331, "qvaluenetwork": 331, "worst": 331, "accuraci": 331, "fanci": 331, "demonstr": [332, 336, 337, 342], "talk": 332, "repetit": 332, "six": 332, "sophist": [332, 336], "invent": 332, "theta_k": 332, "pi_": 332, "exceed": 332, "discourag": [332, 337], "indispens": 332, "analyz": 332, "lingua": 332, "franca": 332, "defaultdict": [332, 337], "has_cuda": [332, 336, 342], "3e": [332, 333, 336], "max_grad_norm": [332, 336], "ourselv": [332, 342], "benefici": 332, "errat": 332, "hamper": [332, 339], "reactiv": 332, "xy": 332, "sub_batch_s": 332, "num_epoch": [332, 336], "entropy_ep": [332, 336], "generalist": 332, "interchang": [332, 338, 339], "panel": 332, "charact": 332, "inverteddoublependulum": 332, "transmit": 332, "stai": 332, "supplementari": [332, 342], "told": 332, "stringent": [332, 336], "confid": [332, 336], "ran": 332, "f_": 332, "mu_": 332, "difficulti": [332, 342], "brought": [332, 333], "d_ob": 332, "d_action": 332, "policy_modul": [332, 336], "That": 332, "said": 332, "briefli": [332, 336], "refil": [332, 336], "conveni": [332, 336, 337], "easiest": [332, 336], "mathemat": [332, 336], "tradeoff": [332, 336], "advantage_modul": 332, "lr_schedul": [332, 337], "cosineannealinglr": [332, 337], "eval_str": 332, "tensordict_data": [332, 336], "data_view": [332, 336], "subdata": [332, 336], "cum_reward_str": 332, "4f": [332, 333, 337], "stepcount_str": 332, "param_group": 332, "lr_str": 332, "eval_rollout": 332, "nice": 332, "324": [332, 337], "119": [332, 337], "5062": 332, "0860": 332, "0003": [332, 337], "325": [332, 337], "38it": [332, 337], "1107": 332, "3000": 332, "327": [332, 337], "1572": 332, "329": [332, 337], "1776": 332, "0002": [332, 337], "330": [332, 337], "1968": 332, "6000": 332, "331": [332, 337], "2136": 332, "7000": 332, "326": [332, 337], "2192": 332, "328": [332, 337], "75it": [332, 337], "2213": 332, "9000": 332, "2414": 332, "2437": 332, "cap": [332, 339], "figsiz": [332, 337], "subplot": [332, 337, 342], "titl": [332, 333, 336, 337], "bit": [332, 333, 336, 339], "lstmmodul": 333, "84x84": 333, "accessori": 333, "stamp": 333, "tensordictprim": 333, "assist": 333, "emb": 333, "n_cell": 333, "customiz": 333, "almost": 333, "wouldn": 333, "make_tensordict_prim": 333, "interpolationmod": 333, "qval": 333, "stoch_polici": 333, "opportun": 333, "coupl": [333, 337, 339], "uniniti": 333, "again": [333, 336, 338, 339, 342], "redund": 333, "strongli": 333, "million": 333, "sake": [333, 338, 339], "20_000": [333, 337], "longest": 333, "npai": 333, "action_spread": 333, "1000000": 333, "115": [333, 337], "0007": [333, 337], "118": [333, 337], "35it": 333, "0005": 333, "150": [333, 337], "154": [333, 337], "172": [333, 337], "0004": [333, 337], "tutorials_python": 334, "tutorials_jupyt": 334, "humanoid": 335, "env1_obs_kei": 335, "observation_stand": 335, "env2_obs_kei": 335, "observation_walk": 335, "tdreset1": 335, "tdreset2": 335, "tdreset": 335, "policy_common": 335, "policy_stand": 335, "policy_walk": 335, "But": 335, "exclusive_field": [335, 341], "stack_dim": [335, 341], "env1_mak": 335, "env2_mak": 335, "_single_task": 335, "td_rollout": 335, "matteo": 336, "bettini": 336, "maddpg": 336, "navig": 336, "lidar": 336, "sensor": 336, "collis": 336, "tie": 336, "mappo": 336, "ippo": 336, "phase": [336, 339], "mathbf": 336, "pi": [336, 337], "fed": [336, 339], "approxim": [336, 342], "literatur": 336, "overcom": 336, "stationari": 336, "concurr": 336, "analys": 336, "gui": 336, "visualis": 336, "multiagentmlp": 336, "divic": 336, "vmas_devic": 336, "6_000": 336, "team": [336, 341], "n_iter": 336, "minibatch_s": 336, "generalis": 336, "furthermor": 336, "simd": 336, "parallelis": 336, "warp": 336, "todai": 336, "circl": 336, "surround": 336, "dot": [336, 337], "collid": 336, "drag": 336, "elast": 336, "acceler": 336, "penalis": 336, "num_vmas_env": 336, "scenario_nam": 336, "four": [336, 337], "environmnet": 336, "final_rew": 336, "agent_collis": 336, "stress": 336, "paramount": 336, "n_rollout_step": 336, "evolut": 336, "yourself": 336, "utilis": 336, "n_actions_per_ag": 336, "n_obs_per_ag": 336, "share_parameters_polici": 336, "policy_net": 336, "denot": 336, "carefulli": [336, 342], "grant": 336, "converg": 336, "cooper": 336, "share_parameters_crit": 336, "critic_net": 336, "fantast": 336, "minibatch": 336, "desc": 336, "episode_reward_mean": 336, "episode_reward_mean_list": 336, "get_item_shap": 336, "critic_param": 336, "target_critic_param": 336, "refresh": 336, "3641679584980011": 336, "4940122067928314": 336, "0600677728652954": 336, "4344534873962402": 336, "1100871562957764": 336, "304917335510254": 336, "6943857669830322": 336, "871443748474121": 336, "8500826358795166": 336, "759843587875366": 336, "xvfb": 336, "pyvirtualdisplai": 336, "1400": [336, 337], "pil": 336, "rendering_callback": 336, "fromarrai": 336, "rgb_arrai": [336, 337], "gif": 336, "save_al": 336, "append_imag": 336, "profici": 336, "master": 336, "freeli": 337, "codebas": 337, "touch": 337, "undertaken": 337, "broader": 337, "wider": 337, "algebra": 337, "acquaint": 337, "avenu": 337, "_apply_to_composit": 337, "default_x": 337, "default_i": 337, "torqu": 337, "upward": 337, "angular": 337, "sin": 337, "rad": 337, "sec": 337, "gravit": 337, "angl": 337, "deleg": 337, "new_th": 337, "new_thdot": 337, "thdot": 337, "g_forc": 337, "max_torqu": 337, "angle_norm": 337, "max_spe": 337, "albeit": 337, "gen_param": 337, "high_th": 337, "high_thdot": 337, "low_th": 337, "low_thdot": 337, "rng": 337, "lazili": 337, "organ": [337, 339], "trivial": 337, "neither": 337, "shortcut": [337, 342], "irrelev": 337, "_make_spec": 337, "td_param": 337, "pseudo": 337, "render_mod": 337, "render_fp": 337, "random_": 337, "_make_step": 337, "staticmethod": 337, "complic": [337, 339, 342], "showcas": 337, "skeleton": 337, "_apply_transform": [337, 342], "_inv_apply_transform": [337, 342], "subset": [337, 338], "unitari": 337, "sine": 337, "cosin": 337, "sintransform": 337, "tensordict_reset": 337, "costransform": 337, "t_sin": 337, "t_co": 337, "cat_transform": 337, "mdp": 337, "simple_rollout": 337, "unexplor": 337, "recreat": 337, "init_td": 337, "traj_return": 337, "last_reward": 337, "is_ipython": 337, "inlin": 337, "get_backend": 337, "ion": 337, "gcf": 337, "clear_output": 337, "625": 337, "0488": 337, "0748": 337, "519": 337, "0499": 337, "4472": 337, "073": 337, "0685": 337, "0408": 337, "552": 337, "5154": 337, "9086": 337, "527": 337, "9385": 337, "155": 337, "2568": 337, "4981": 337, "223": 337, "72it": 337, "8929": 337, "4491": 337, "581": 337, "3233": 337, "0664": 337, "596": 337, "1021": 337, "5263": 337, "9579": 337, "5807": 337, "8075": 337, "212": 337, "2009": 337, "5525": 337, "914": 337, "2894": 337, "0115": 337, "0977": 337, "1845": 337, "1830": 337, "4858": 337, "2863": 337, "0297": 337, "464": 337, "4617": 337, "5997": 337, "904": 337, "1647": 337, "0777": 337, "901": 337, "4709": 337, "6813": 337, "8317": 337, "3221": 337, "5554": 337, "276": 337, "3353": 337, "701": 337, "8570": 337, "6656": 337, "463": 337, "7779": 337, "6911": 337, "875": 337, "0796": 337, "7082": 337, "308": 337, "0421": 337, "1496": 337, "5037": 337, "1755": 337, "5029": 337, "9454": 337, "665": 337, "9330": 337, "2118": 337, "444": 337, "0995": 337, "6294": 337, "3146": 337, "2909": 337, "461": 337, "9720": 337, "1298": 337, "9923": 337, "0345": 337, "3438": 337, "3688": 337, "424": 337, "6953": 337, "5233": 337, "411": 337, "8011": 337, "5329": 337, "2677": 337, "6969": 337, "7010": 337, "376": 337, "9352": 337, "7707": 337, "6178": 337, "5646": 337, "348": 337, "7304": 337, "9407": 337, "942": 337, "3882": 337, "7604": 337, "3507": 337, "8928": 337, "258": 337, "6978": 337, "4641": 337, "549": 337, "6047": 337, "5005": 337, "4136": 337, "2993": 337, "3222": 337, "4046": 337, "7314": 337, "275": 337, "6331": 337, "9318": 337, "961": 337, "8331": 337, "1604": 337, "4099": 337, "4761": 337, "125": [337, 339], "4262": 337, "6363": 337, "382": 337, "3593": 337, "7377": 337, "2847": 337, "3443": 337, "867": 337, "3592": 337, "4760": 337, "441": 337, "9950": 337, "8021": 337, "3528": 337, "1214": 337, "708": 337, "4023": 337, "3583": 337, "041": 337, "3801": 337, "0310": 337, "120": 337, "4244": 337, "2039": 337, "4850": 337, "8748": 337, "706": 337, "4897": 337, "9210": 337, "8964": 337, "0832": 337, "3934": 337, "456": 337, "8971": 337, "2933": 337, "3377": 337, "6996": 337, "2274": 337, "8916": 337, "098": 337, "2660": 337, "9110": 337, "4503": 337, "6956": 337, "9172": 337, "4026": 337, "946": 337, "9229": 337, "5205": 337, "294": 337, "8872": 337, "6637": 337, "019": 337, "9281": 337, "2082": 337, "724": 337, "8561": 337, "6574": 337, "357": 337, "4138": 337, "5230": 337, "385": 337, "4065": 337, "5642": 337, "921": 337, "9786": 337, "4129": 337, "5831": 337, "266": 337, "7723": 337, "4152": 337, "0898": 337, "389": 337, "5155": 337, "5376": 337, "5616": 337, "4094": 337, "283": 337, "5333": 337, "4803": 337, "895": 337, "6566": 337, "2588": 337, "662": 337, "4732": 337, "7503": 337, "068": 337, "0714": 337, "3370": 337, "059": 337, "8612": 337, "1915": 337, "3855": 337, "0349": 337, "9644": 337, "4538": 337, "445": 337, "0392": 337, "4080": 337, "1648": 337, "9599": 337, "143": 337, "4284": 337, "5946": 337, "2590": 337, "9181": 337, "4621": 337, "9075": 337, "674": 337, "1772": 337, "9444": 337, "351": 337, "9391": 337, "5595": 337, "8673": 337, "6240": 337, "5919": 337, "0018": 337, "1071": 337, "9127": 337, "251": 337, "9799": 337, "3131": 337, "9612": 337, "9705": 337, "8741": 337, "2230": 337, "0972": 337, "0337": 337, "0350": 337, "0654": 337, "102": [337, 339], "2441": 337, "4596": 337, "362": 337, "103": 337, "4362": 337, "171": 337, "104": 337, "4041": 337, "6907": 337, "105": 337, "4664": 337, "2760": 337, "0299": 337, "9712": 337, "349": 337, "107": 337, "3332": 337, "4479": 337, "772": 337, "4357": 337, "9591": 337, "543": 337, "109": [337, 339], "6216": 337, "1353": 337, "692": 337, "110": 337, "6261": 337, "7086": 337, "496": 337, "7758": 337, "9818": 337, "112": 337, "7772": 337, "5055": 337, "113": 337, "5840": 337, "3180": 337, "2083": 337, "5275": 337, "6873": 337, "116": [337, 339], "4107": 337, "1624": 337, "117": 337, "6372": 337, "2571": 337, "4039": 337, "4428": 337, "4728": 337, "5628": 337, "6767": 337, "2466": 337, "522": 337, "121": [337, 342], "5873": 337, "5072": 337, "122": [337, 342], "6548": 337, "3766": 337, "5134": 337, "1955": 337, "124": [337, 339], "2481": 337, "0591": 337, "4500": 337, "3368": 337, "126": [337, 339], "9708": 337, "7059": 337, "127": [337, 339], "3031": 337, "2534": 337, "843": 337, "3327": 337, "6193": 337, "129": 337, "4831": 337, "1172": 337, "2593": 337, "4219": 337, "962": 337, "8380": 337, "899": 337, "132": [337, 339], "2721": 337, "9048": 337, "166": 337, "133": 337, "2419": 337, "5248": 337, "134": 337, "2139": 337, "4278": 337, "135": 337, "0690": 337, "5140": 337, "136": 337, "1140": 337, "7402": 337, "137": 337, "5356": 337, "1636": 337, "138": 337, "0671": 337, "8798": 337, "139": 337, "8918": 337, "3298": 337, "307": 337, "140": 337, "1779": 337, "141": 337, "1771": 337, "3624": 337, "936": 337, "142": 337, "1683": 337, "4810": 337, "9373": 337, "4435": 337, "144": 337, "4396": 337, "8092": 337, "145": 337, "2572": 337, "146": 337, "4212": 337, "0260": 337, "147": 337, "0939": 337, "6478": 337, "605": 337, "148": 337, "6606": 337, "7289": 337, "149": 337, "9300": 337, "7193": 337, "1166": 337, "8514": 337, "151": [337, 339], "9108": 337, "0672": 337, "292": 337, "152": 337, "8591": 337, "3768": 337, "153": 337, "9976": 337, "0576": 337, "0067": 337, "935": 337, "4199": 337, "1722": 337, "156": 337, "8310": 337, "3466": 337, "157": 337, "8631": 337, "2492": 337, "158": 337, "8763": 337, "1277": 337, "159": 337, "5562": 337, "7446": 337, "1082": 337, "9830": 337, "161": 337, "0946": 337, "5229": 337, "4574": 337, "6900": 337, "163": [337, 338], "2229": 337, "0318": 337, "482": 337, "164": 337, "0543": 337, "0817": 337, "761": 337, "165": [337, 339], "2809": 337, "5118": 337, "366": 337, "1142": 337, "5635": 337, "167": 337, "1949": 337, "2327": 337, "982": 337, "168": 337, "0967": 337, "0387": 337, "457": 337, "169": [337, 339], "0782": 337, "2150": 337, "170": 337, "5222": 337, "3725": 337, "9288": 337, "9837": 337, "58it": 337, "1416": 337, "1099": 337, "173": 337, "8620": 337, "8475": 337, "174": [337, 339], "1807": 337, "175": 337, "1148": 337, "0645": 337, "2751": 337, "8313": 337, "177": 337, "9286": 337, "9770": 337, "178": 337, "60it": 337, "5735": 337, "2837": 337, "179": 337, "2926": 337, "9489": 337, "180": 337, "1507": 337, "181": 337, "8724": 337, "3567": 337, "182": 337, "3574": 337, "6140": 337, "183": 337, "7895": 337, "2518": 337, "184": 337, "6146": 337, "185": 337, "8776": 337, "7358": 337, "186": 337, "3722": 337, "8428": 337, "187": 337, "7955": 337, "188": 337, "0092": 337, "7106": 337, "829": 337, "189": 337, "2264": 337, "6919": 337, "190": 337, "1438": 337, "1362": 337, "191": 337, "0618": 337, "8217": 337, "9420": 337, "6765": 337, "193": 337, "7745": 337, "0709": 337, "194": 337, "9478": 337, "6867": 337, "195": 337, "6507": 337, "6225": 337, "196": 337, "2244": 337, "2195": 337, "197": 337, "5385": 337, "9263": 337, "198": 337, "1878": 337, "2374": 337, "199": 337, "8054": 337, "3504": 337, "557": 337, "0766": 337, "6825": 337, "201": 337, "2011": 337, "8393": 337, "202": 337, "0803": 337, "7815": 337, "203": 337, "8363": 337, "2460": 337, "204": 337, "8643": 337, "2191": 337, "593": 337, "205": 337, "0773": 337, "1343": 337, "206": 337, "8657": 337, "207": 337, "9304": 337, "7584": 337, "8752": 337, "2307": 337, "209": 337, "5250": 337, "4869": 337, "7837": 337, "5762": 337, "211": 337, "6661": 337, "8600": 337, "2502": 337, "1752": 337, "213": 337, "3075": 337, "8871": 337, "214": 337, "9406": 337, "8090": 337, "215": 337, "6291": 337, "8923": 337, "876": 337, "216": 337, "9504": 337, "21e": 337, "217": 337, "7431": 337, "7880": 337, "218": 337, "4463": 337, "5432": 337, "219": 337, "3793": 337, "3313": 337, "220": 337, "8843": 337, "0369": 337, "065": 337, "221": 337, "4828": 337, "8391": 337, "222": 337, "6265": 337, "2913": 337, "947": 337, "5541": 337, "1252": 337, "7342": 337, "2396": 337, "225": 337, "5936": 337, "1924": 337, "226": 337, "9975": 337, "2045": [337, 342], "8367": 337, "9540": 337, "228": 337, "7259": 337, "6743": 337, "229": 337, "4827": 337, "7528": 337, "7361": 337, "8756": 337, "231": 337, "7646": 337, "1116": 337, "232": 337, "5426": 337, "8385": 337, "5662": 337, "8585": 337, "234": 337, "8234": 337, "7930": 337, "235": 337, "2648": 337, "9309": 337, "236": 337, "6817": 337, "237": 337, "0943": 337, "1533": 337, "238": 337, "3045": 337, "0483": 337, "239": 337, "240": [337, 341, 342], "6415": 337, "0201": 337, "241": 337, "4437": 337, "4365": 337, "242": 337, "0358": 337, "4943": 337, "243": 337, "1272": 337, "5003": 337, "1180": 337, "2637": 337, "7197": 337, "0873": 337, "246": 337, "2917": 337, "247": 337, "0160": 337, "0738": 337, "248": 337, "3689": 337, "0120": 337, "249": 337, "5570": 337, "0475": 337, "250": 337, "4423": 337, "2220": 337, "6803": 337, "252": 337, "1465": 337, "7214": 337, "253": 337, "8801": 337, "7034": 337, "254": 337, "9136": 337, "4076": 337, "7589": 337, "5013": 337, "8150": 337, "2241": 337, "257": 337, "0753": 337, "8081": 337, "1951": 337, "8314": 337, "259": 337, "0038": 337, "260": 337, "0889": 337, "4616": 337, "261": 337, "0655": 337, "262": 337, "8333": 337, "9476": 337, "263": 337, "7554": 337, "3798": 337, "264": 337, "3717": 337, "3947": 337, "529": 337, "3060": 337, "6495": 337, "7467": 337, "8889": 337, "267": 337, "8457": 337, "591": 337, "268": 337, "7137": 337, "0536": 337, "771": 337, "269": 337, "1651": 337, "388": 337, "270": 337, "8246": 337, "5709": 337, "281": 337, "271": 337, "7502": 337, "0521": 337, "032": 337, "272": 337, "5475": 337, "7253": 337, "273": 337, "2856": 337, "7130": 337, "274": 337, "2778": 337, "4122": 337, "8368": 337, "1841": 337, "9622": 337, "1603": 337, "003e": 337, "277": 337, "0247": 337, "346": 337, "278": 337, "2238": 337, "6418": 337, "279": 337, "0626": 337, "2538": 337, "280": 337, "0149": 337, "7380": 337, "2167": 337, "8911": 337, "282": 337, "8725": 337, "1983": 337, "8142": 337, "3709": 337, "284": 337, "4989": 337, "285": 337, "6464": 337, "6210": 337, "286": 337, "9726": 337, "0820": 337, "287": 337, "6975": 337, "9091": 337, "4926": 337, "4791": 337, "289": 337, "0905": 337, "3500": 337, "290": 337, "2287": 337, "291": 337, "9918": 337, "5543": 337, "9245": 337, "6444": 337, "631": 337, "293": 337, "0448": 337, "4769": 337, "8566": 337, "7208": 337, "295": 337, "0966": 337, "296": 337, "5303": 337, "1537": 337, "023": 337, "297": 337, "2682": 337, "564": 337, "298": 337, "4318": 337, "5063": 337, "7475": 337, "4190": 337, "8186": 337, "5077": 337, "301": 337, "1883": 337, "5291": 337, "472": 337, "302": 337, "1256": 337, "3998": 337, "303": 337, "3622": 337, "0930": 337, "626": 337, "304": 337, "9500": 337, "0075": 337, "5664": 337, "305": 337, "5697": 337, "3024": 337, "306": 337, "3117": 337, "0052": 337, "006": 337, "0981": 337, "9312": 337, "3873": 337, "309": 337, "0411": 337, "2650": 337, "310": 337, "1656": 337, "0228": 337, "004": 337, "311": 337, "1196": 337, "2478": 337, "312": 337, "7353": 337, "0812": 337, "313": 337, "3022": 337, "758": 337, "314": 337, "1406": 337, "4626": 337, "315": 337, "2156": 337, "851": 337, "316": 337, "1953": 337, "3774": 337, "317": 337, "6385": 337, "9917": 337, "318": 337, "2764": 337, "319": 337, "6391": 337, "9317": 337, "9748": 337, "2679": 337, "321": 337, "8495": 337, "5125": 337, "8177": 337, "6602": 337, "323": 337, "0704": 337, "5776": 337, "9833": [337, 341], "1339": 337, "1238": 337, "9299": 337, "0227": 337, "7727": 337, "1607": 337, "336": 337, "3958": 337, "3223": 337, "763": 337, "4742": 337, "1797": 337, "0144": 337, "0085": 337, "791": 337, "8284": 337, "0428": 337, "0098": 337, "7365": 337, "333": 337, "4566": 337, "0781": 337, "086": 337, "334": 337, "3355": 337, "0230": 337, "335": 337, "9346": 337, "0423": 337, "076": 337, "3711": 337, "1335": 337, "6855": 337, "337": 337, "0304": 337, "0023": 337, "8459": 337, "338": 337, "9998": 337, "4399": 337, "339": 337, "2303": 337, "1346": 337, "340": 337, "2915": 337, "7116": 337, "341": 337, "5560": 337, "0487": 337, "342": 337, "5119": 337, "061": 337, "343": 337, "3305": 337, "3705": 337, "957": 337, "344": 337, "6068": 337, "345": 337, "5731": 337, "3897": 337, "0376": 337, "347": 337, "0434": 337, "012": 337, "1300": 337, "1215": 337, "0968": 337, "0885": 337, "350": 337, "1348": 337, "0073": 337, "5052": 337, "4184": 337, "2817": 337, "8887": 337, "353": 337, "4779": 337, "1009": 337, "354": 337, "0604": 337, "599": 337, "355": 337, "4486": 337, "1176": 337, "656": 337, "356": 337, "2436": 337, "0668": 337, "8849": 337, "0012": 337, "358": 337, "7511": 337, "8804": 337, "359": 337, "8870": 337, "6728": 337, "360": 337, "8841": 337, "5508": 337, "361": 337, "5242": 337, "0268": 337, "0013": 337, "6185": 337, "363": 337, "1378": 337, "0204": 337, "364": 337, "0355": 337, "685": 337, "365": 337, "4884": 337, "0231": 337, "0770": 337, "0014": 337, "6793": 337, "367": 337, "9834": 337, "863": 337, "368": 337, "6709": 337, "462": 337, "369": 337, "5199": 337, "9790": 337, "370": 337, "9401": 337, "7802": 337, "371": 337, "6723": 337, "372": 337, "2678": 337, "6201": 337, "373": 337, "2184": 337, "7385": 337, "374": 337, "6344": 337, "617": 337, "375": 337, "9945": 337, "0772": 337, "567": 337, "7576": 337, "0398": 337, "377": 337, "3396": 337, "0022": 337, "094": 337, "378": 337, "3073": 337, "4018": 337, "379": 337, "1869": 337, "380": 337, "0481": 337, "1117": 337, "381": 337, "6823": 337, "981": 337, "8305": 337, "0210": 337, "383": 337, "4908": 337, "0272": 337, "538": 337, "3267": 337, "0111": 337, "7965": 337, "1796": 337, "0039": 337, "5396": 337, "386": 337, "3757": 337, "0490": 337, "387": 337, "1394": 337, "4187": 337, "2986": 337, "7954": 337, "1274": 337, "0063": 337, "813": 337, "390": 337, "8706": 337, "0114": 337, "391": 337, "6922": 337, "2423": 337, "392": 337, "9115": 337, "2602": 337, "393": 337, "2449": 337, "0783": 337, "0631": 337, "0057": 337, "7444": 337, "395": 337, "3339": 337, "0167": 337, "396": 337, "4806": 337, "397": 337, "4171": 337, "067": 337, "398": 337, "2618": 337, "5809": 337, "399": 337, "0054": 337, "3364": 337, "8733": 337, "0184": 337, "401": 337, "9137": 337, "0113": 337, "025": 337, "0386": 337, "0625": 337, "403": 337, "1332": 337, "0582": 337, "7816": 337, "404": 337, "8341": 337, "0941": 337, "854": 337, "405": 337, "8615": 337, "588": 337, "406": 337, "3849": 337, "008": 337, "407": 337, "9395": 337, "0765": 337, "055": 337, "408": 337, "2685": 337, "2235": 337, "688": 337, "409": 337, "3052": 337, "4249": 337, "6806": 337, "6383": 337, "3721": 337, "9981": 337, "412": 337, "1862": 337, "822": 337, "413": 337, "9811": 337, "0171": 337, "013": 337, "414": 337, "0252": 337, "0049": 337, "6205": 337, "415": 337, "1108": 337, "4921": 337, "9142": 337, "8130": 337, "417": 337, "1725": 337, "0036": 337, "3196": 337, "418": 337, "7795": 337, "0242": 337, "799": 337, "419": 337, "7737": 337, "0138": 337, "420": 337, "1462": 337, "0053": 337, "421": 337, "9226": 337, "6139": 337, "422": 337, "9889": 337, "0403": 337, "423": 337, "6194": 337, "0032": 337, "3989": 337, "0104": 337, "425": 337, "9960": 337, "0009": 337, "6009": 337, "426": 337, "2697": 337, "0914": 337, "427": 337, "1114": 337, "428": 337, "9862": 337, "1932": 337, "429": 337, "0637": 337, "0623": 337, "082": 337, "430": 337, "9906": 337, "2031": 337, "431": 337, "9948": 337, "0895": 337, "432": 337, "1970": 337, "0256": 337, "433": 337, "4231": 337, "0449": 337, "644": 337, "434": 337, "1039": 337, "1973": 337, "435": 337, "4561": 337, "1225": 337, "436": 337, "0211": 337, "2125": 337, "437": 337, "3866": 337, "0050": 337, "7202": 337, "438": 337, "6388": 337, "0072": 337, "439": 337, "1187": 337, "0015": 337, "5116": 337, "440": 337, "0432": 337, "0025": 337, "7809": 337, "1925": 337, "0103": 337, "442": 337, "9570": 337, "443": 337, "0871": 337, "5601": 337, "0165": 337, "0047": 337, "6061": 337, "2746": 337, "0027": 337, "7887": 337, "446": 337, "1835": 337, "0035": 337, "855": 337, "447": 337, "8420": 337, "548": 337, "2653": 337, "0126": 337, "9736": 337, "449": 337, "0594": 337, "0119": 337, "6196": 337, "450": 337, "4509": 337, "0373": 337, "451": 337, "0620": 337, "452": 337, "6898": 337, "3235": 337, "687": 337, "453": 337, "5879": 337, "8406": 337, "0694": 337, "455": 337, "8259": 337, "0235": 337, "8500": 337, "0024": 337, "4054": 337, "458": 337, "2027": 337, "0894": 337, "459": 337, "5966": 337, "460": 337, "6942": 337, "0016": 337, "4254": 337, "6703": 337, "0145": 337, "8124": 337, "0218": 337, "9196": 337, "24it": 337, "0188": 337, "8986": 337, "0884": 337, "0084": 337, "5624": 337, "465": 337, "8862": 337, "0006": 337, "5384": 337, "466": 337, "5837": 337, "467": 337, "8954": 337, "0101": 337, "6751": 337, "468": 337, "8063": 337, "0122": 337, "9635": 337, "469": 337, "0692": 337, "4216": 337, "470": 337, "1227": 337, "0586": 337, "162e": 337, "471": 337, "9690": 337, "0074": 337, "4166": 337, "6324": 337, "473": 337, "0778": 337, "474": 337, "8548": 337, "0017": 337, "4408": 337, "475": 337, "8125": 337, "1515": 337, "476": 337, "2733": 337, "0044": 337, "2836": 337, "477": 337, "7497": 337, "7681": 337, "478": 337, "8547": 337, "0105": 337, "7212": 337, "479": 337, "9848": 337, "0019": 337, "6498": 337, "1987": 337, "0011": 337, "5473": 337, "481": 337, "8991": 337, "0033": 337, "6091": 337, "9189": 337, "5771": 337, "483": 337, "6781": 337, "7542": 337, "484": 337, "5959": 337, "0064": 337, "4295": 337, "2547": 337, "486": 337, "0636": 337, "547": 337, "487": 337, "0065": 337, "488": 337, "1694": 337, "0083": 337, "5759": 337, "489": 337, "0493": 337, "0021": 337, "7805": 337, "490": 337, "0950": 337, "497": 337, "491": 337, "9717": 337, "3672": 337, "492": 337, "0207": 337, "493": 337, "8266": 337, "0069": 337, "5365": 337, "494": 337, "2623": 337, "5078": 337, "495": 337, "4545": 337, "09636": 337, "8754": 337, "0010": 337, "498": 337, "0031": 337, "8269": 337, "499": 337, "4082": 337, "6642": 337, "2284": 337, "501": 337, "9130": 337, "0008": 337, "502": 337, "503": 337, "7624": 337, "0056": 337, "3858": 337, "504": 337, "0890": 337, "0042": 337, "505": 337, "7505": 337, "2157": 337, "506": 337, "8394": 337, "3413": 337, "507": 337, "9609": 337, "0041": 337, "6905": 337, "508": 337, "8467": 337, "4409": 337, "509": 337, "510": 337, "8128": 337, "3559": 337, "511": 337, "1479": 337, "0264": 337, "1589": 337, "566": 337, "513": 337, "2756": 337, "0046": 337, "5266": 337, "514": 337, "9873": 337, "0112": 337, "9314": 337, "515": 337, "3791": 337, "0721": 337, "516": 337, "4580": 337, "0758": 337, "6114": 337, "517": 337, "2431": 337, "518": 337, "1958": 337, "5553": 337, "8924": 337, "0097": 337, "520": 337, "3737": 337, "0234": 337, "521": 337, "9125": 337, "4623": 337, "3230": 337, "0589": 337, "3784": 337, "523": 337, "9482": 337, "0051": 337, "524": 337, "1979": 337, "0045": 337, "6401": 337, "525": 337, "1588": 337, "0048": 337, "6255": 337, "526": 337, "6084": 337, "3477": 337, "1475": 337, "0209": 337, "528": 337, "7611": 337, "1040": 337, "0099": 337, "0173": 337, "530": 337, "8189": 337, "4358": 337, "531": 337, "15it": 337, "9897": 337, "532": 337, "1548": 337, "9751": 337, "533": 337, "6362": 337, "7495": 337, "534": 337, "1749": 337, "9513": 337, "535": 337, "7708": 337, "0371": 337, "536": 337, "2649": 337, "0437": 337, "537": 337, "67it": 337, "5491": 337, "0276": 337, "6426": 337, "7294": 337, "078e": 337, "539": 337, "9928": 337, "540": 337, "7937": 337, "0124": 337, "9664": 337, "541": 337, "3342": 337, "542": 337, "2046": 337, "5496": 337, "0956": 337, "0059": 337, "9028": 337, "5843": 337, "546": 337, "0674": 337, "0178": 337, "797": 337, "2815": 337, "0599": 337, "1587": 337, "9276": 337, "8228": 337, "6164": 337, "551": 337, "6850": 337, "9167": 337, "3092": 337, "0670": 337, "9177": 337, "553": 337, "1599": 337, "0043": 337, "554": 337, "6367": 337, "555": 337, "3657": 337, "556": 337, "6694": 337, "2622": 337, "0372": 337, "4841": 337, "558": 337, "2707": 337, "0058": 337, "757": 337, "559": 337, "2267": 337, "5415": 337, "560": 337, "4556": 337, "0163": 337, "561": 337, "1839": 337, "0809": 337, "6262": 337, "562": 337, "0278": 337, "1112": 337, "6155": 337, "565": 337, "1427": 337, "3582": 337, "624": 337, "7870": 337, "9490": 337, "0439": 337, "8796": 337, "568": 337, "8026": 337, "612": 337, "569": 337, "3147": 337, "8486": 337, "570": 337, "7917": 337, "0129": 337, "571": 337, "9553": 337, "0020": 337, "6871": 337, "572": 337, "3132": 337, "0159": 337, "8646": 337, "573": 337, "5320": 337, "0269": 337, "574": 337, "2955": 337, "0245": 337, "575": 337, "3347": 337, "0179": 337, "9718": 337, "1629": 337, "804": 337, "577": 337, "0070": 337, "4335": 337, "578": 337, "579": 337, "3049": 337, "9063": 337, "580": 337, "8785": 337, "3295": 337, "5184": 337, "0546": 337, "582": 337, "4589": 337, "583": 337, "4697": 337, "2476": 337, "584": 337, "2397": 337, "585": 337, "4953": 337, "1775": 337, "586": 337, "2258": 337, "0110": 337, "7671": 337, "587": 337, "3981": 337, "8590": 337, "589": 337, "9820": 337, "4221": 337, "590": 337, "1293": 337, "0116": 337, "868": 337, "1675": 337, "5931": 337, "592": 337, "2910": 337, "5219": 337, "2124": 337, "1730": 337, "737": 337, "594": 337, "2914": 337, "0206": 337, "595": 337, "0172": 337, "3982": 337, "0945": 337, "0121": 337, "4789": 337, "597": 337, "3805": 337, "4074": 337, "598": 337, "3310": 337, "5065": 337, "6028": 337, "6316": 337, "6724": 337, "6523": 337, "601": 337, "0136": 337, "4298": 337, "602": 337, "3524": 337, "2629": 337, "603": 337, "2635": 337, "7839": 337, "604": 337, "6041": 337, "8027": 337, "4170": 337, "4675": 337, "606": 337, "3153": 337, "9316": 337, "607": 337, "0649": 337, "9722": 337, "7989": 337, "0329": 337, "609": 337, "1976": 337, "6852": 337, "610": 337, "4793": 337, "1255": 337, "611": 337, "4581": 337, "0394": 337, "2047": 337, "0326": 337, "613": 337, "8967": 337, "8619": 337, "614": 337, "5906": 337, "6491": 337, "615": 337, "6634": 337, "4394": 337, "616": 337, "0624": 337, "0061": 337, "5676": 337, "3259": 337, "0131": 337, "7733": 337, "618": 337, "7515": 337, "0189": 337, "5575": 337, "619": 337, "9313": 337, "6286": 337, "620": 337, "4325": 337, "7832": 337, "621": 337, "1134": 337, "622": 337, "4572": 337, "0500": 337, "5838": 337, "623": 337, "3818": 337, "8623": 337, "1253": 337, "6622": 337, "subject": 337, "saw": [337, 339], "explain": 338, "semat": 338, "r3mtransform": 338, "embodi": 338, "ai": 338, "env_transform": [338, 342], "s3": 338, "amazonaw": 338, "r3m_50": 338, "374m": 338, "107mb": 338, "0m": 338, "2mb": 338, "1mb": 338, "9mb": 338, "5m": 338, "0mb": 338, "3mb": 338, "6m": 338, "7mb": 338, "104m": 338, "115m": 338, "130m": 338, "137m": 338, "8mb": 338, "147m": 338, "6mb": 338, "162m": 338, "170m": 338, "180m": 338, "195m": 338, "202m": 338, "212m": 338, "218m": 338, "229m": 338, "244m": 338, "251m": 338, "261m": 338, "268m": 338, "277m": 338, "4mb": 338, "282m": 338, "293m": 338, "298m": 338, "310m": 338, "316m": 338, "328m": 338, "337m": 338, "344m": 338, "359m": 338, "366m": 338, "wiser": 338, "conclud": 338, "_storag": [338, 339], "supervis": [339, 342], "pull": 339, "temporarili": 339, "ram": [339, 342], "batteri": 339, "dataliststorag": 339, "datalazytensorstorag": 339, "tensordidct": 339, "datalazymemmapstorag": 339, "buffer_list": 339, "lowest": 339, "medium": 339, "buffer_lazytensor": 339, "buffer_lazymemmap": 339, "tempdir": 339, "tmpfpwnm775": 339, "fullest": 339, "convini": 339, "mydata": 339, "background": 339, "question": [339, 341], "_i": 339, "artifici": 339, "0892946e": 339, "she": 339, "augment": 339, "proport": 339, "hist": 339, "barcontain": 339, "artist": 339, "revert": 339, "expens": 339, "reappear": 339, "unfold": 339, "problemat": 339, "window": 339, "4th": 339, "demo": 341, "icml": 341, "vmoen": 341, "fb": 341, "invest": 341, "platform": 341, "media": 341, "predominantli": 341, "tensordict1": 341, "tensordict2": 341, "tensordict_sampl": 341, "_sampler": 341, "_sum_tre": 341, "modulenotfounderror": 341, "28791671991348267": 341, "gym_env": 341, "noopresetenv": [341, 342], "backbone_modul": 341, "params_expand": 341, "tensordict_exp": 341, "base_modul": 341, "0137": 341, "1524": 341, "0641": 341, "viewbackward0": 341, "asstridedbackward0": 341, "8728": 341, "1334": 341, "3494": 341, "6887": 341, "6402": 341, "_safetanhbackward": 341, "1132": 341, "1762": 341, "3430": 341, "2668": 341, "2918": 341, "6239": 341, "roughli": 341, "tensordicts_prealloc": 341, "tensordicts_stack": 341, "tensordict_rollout": [341, 342], "disclaim": 341, "concatmodul": 341, "loss_td": 341, "year": 341, "roadmap": 341, "compris": 341, "contributor": 341, "curiou": 341, "nascent": 341, "unsupervis": 342, "rom": 342, "licens": 342, "pygam": 342, "unifi": 342, "_build_env": 342, "adventur": 342, "airraid": 342, "alien": 342, "amidar": 342, "assault": 342, "8263": 342, "deserv": 342, "__episode__": 342, "__trajectory__": 342, "void": 342, "reproduct": 342, "tensordict_tprim": 342, "imshow": 342, "axesimag": 342, "0x7fcc56b040a0": 342, "inconsist": 342, "0x7fcc4e2b6a50": 342, "swingup": 342, "wrapper1": 342, "wrapper2": 342, "obviou": 342, "truth": 342, "env0": 342, "env_transformed_bi": 342, "stanc": 342, "transformeddistribut": 342, "base_dist": 342, "concat": 342, "mofidi": 342, "transformedenviron": 342, "moderet": 342, "computation": 342, "legitim": 342, "incom": 342, "amongst": 342, "wor": 342, "convention": 342, "scope": 342, "markovian": 342, "3288080526": 342, "constain": 342, "bar_": 342, "get_someth": 342, "bar_acf028aa": 342, "aaef": 342, "aargh": 342, "foo_list": 342, "batched_env": 342, "_dispatch_caller_parallel": 342, "0x7fcb39e93070": 342, "bar_b456a89": 342, "8ae1": 342, "bar_b455913": 342, "ab3f": 342, "bar_b4567af": 342, "9107": 342, "parallen": 342, "particularili": 342, "evolv": 342, "steadi": 342, "approx": 342, "2142": 342, "1790": 342, "1451": 342, "1170": 342, "_extra_st": 342, "observation_ssq": 342, "observation_sum": 342, "2007": 342, "4014": 342, "0470": 342, "2372": 342, "1714": 342, "3675": 342, "dispach": 342, "absor": 342}, "objects": {"torchrl._utils": [[11, 0, 1, "", "implement_for"]], "torchrl._utils.implement_for": [[11, 1, 1, "", "get_class_that_defined_method"], [11, 1, 1, "", "import_module"], [11, 1, 1, "", "module_set"], [11, 1, 1, "", "reset"]], "torchrl.collectors.collectors": [[12, 0, 1, "", "DataCollectorBase"], [13, 0, 1, "", "MultiSyncDataCollector"], [14, 0, 1, "", "MultiaSyncDataCollector"], [15, 0, 1, "", "RandomPolicy"], [16, 0, 1, "", "SyncDataCollector"], [17, 0, 1, "", "aSyncDataCollector"]], "torchrl.collectors.collectors.DataCollectorBase": [[12, 1, 1, "", "update_policy_weights_"]], "torchrl.collectors.collectors.MultiSyncDataCollector": [[13, 1, 1, "", "load_state_dict"], [13, 1, 1, "", "reset"], [13, 1, 1, "", "set_seed"], [13, 1, 1, "", "shutdown"], [13, 1, 1, "", "state_dict"], [13, 1, 1, "", "update_policy_weights_"]], "torchrl.collectors.collectors.MultiaSyncDataCollector": [[14, 1, 1, "", "load_state_dict"], [14, 1, 1, "", "reset"], [14, 1, 1, "", "set_seed"], [14, 1, 1, "", "shutdown"], [14, 1, 1, "", "state_dict"], [14, 1, 1, "", "update_policy_weights_"]], "torchrl.collectors.collectors.SyncDataCollector": [[16, 1, 1, "", "iterator"], [16, 1, 1, "", "load_state_dict"], [16, 1, 1, "", "reset"], [16, 1, 1, "", "rollout"], [16, 1, 1, "", "set_seed"], [16, 1, 1, "", "shutdown"], [16, 1, 1, "", "state_dict"], [16, 1, 1, "", "update_policy_weights_"]], "torchrl.collectors.collectors.aSyncDataCollector": [[17, 1, 1, "", "load_state_dict"], [17, 1, 1, "", "reset"], [17, 1, 1, "", "set_seed"], [17, 1, 1, "", "shutdown"], [17, 1, 1, "", "state_dict"], [17, 1, 1, "", "update_policy_weights_"]], "torchrl.collectors.distributed": [[18, 0, 1, "", "DistributedDataCollector"], [19, 0, 1, "", "DistributedSyncDataCollector"], [20, 0, 1, "", "RPCDataCollector"], [21, 0, 1, "", "RayCollector"], [22, 0, 1, "", "submitit_delayed_launcher"]], "torchrl.collectors.distributed.DistributedDataCollector": [[18, 1, 1, "", "update_policy_weights_"]], "torchrl.collectors.distributed.DistributedSyncDataCollector": [[19, 1, 1, "", "update_policy_weights_"]], "torchrl.collectors.distributed.RPCDataCollector": [[20, 1, 1, "", "update_policy_weights_"]], "torchrl.collectors.distributed.RayCollector": [[21, 1, 1, "", "add_collectors"], [21, 1, 1, "", "load_state_dict"], [21, 1, 1, "", "local_policy"], [21, 1, 1, "", "remote_collectors"], [21, 1, 1, "", "set_seed"], [21, 1, 1, "", "shutdown"], [21, 1, 1, "", "state_dict"], [21, 1, 1, "", "stop_remote_collectors"], [21, 1, 1, "", "update_policy_weights_"]], "torchrl.collectors.utils": [[23, 2, 1, "", "split_trajectories"]], "torchrl.data": [[24, 0, 1, "", "BinaryDiscreteTensorSpec"], [25, 0, 1, "", "BoundedTensorSpec"], [26, 0, 1, "", "CompositeSpec"], [27, 0, 1, "", "DiscreteTensorSpec"], [28, 0, 1, "", "LazyStackedCompositeSpec"], [29, 0, 1, "", "LazyStackedTensorSpec"], [30, 0, 1, "", "MultiDiscreteTensorSpec"], [31, 0, 1, "", "MultiOneHotDiscreteTensorSpec"], [32, 0, 1, "", "MultiStep"], [33, 0, 1, "", "OneHotDiscreteTensorSpec"], [34, 0, 1, "", "PairwiseDataset"], [35, 0, 1, "", "PrioritizedReplayBuffer"], [36, 0, 1, "", "PromptData"], [37, 0, 1, "", "PromptTensorDictTokenizer"], [38, 0, 1, "", "ReplayBuffer"], [39, 0, 1, "", "RewardData"], [40, 0, 1, "", "RolloutFromModel"], [41, 0, 1, "", "TensorDictPrioritizedReplayBuffer"], [42, 0, 1, "", "TensorDictReplayBuffer"], [43, 0, 1, "", "TensorDictTokenizer"], [44, 0, 1, "", "TensorSpec"], [45, 0, 1, "", "TokenizedDatasetLoader"], [46, 0, 1, "", "UnboundedContinuousTensorSpec"], [47, 0, 1, "", "UnboundedDiscreteTensorSpec"], [48, 0, 1, "", "check_no_exclusive_keys"], [49, 0, 1, "", "consolidate_spec"], [50, 0, 1, "", "contains_lazy_spec"], [51, 0, 1, "", "create_infinite_iterator"], [57, 0, 1, "", "get_dataloader"]], "torchrl.data.BinaryDiscreteTensorSpec": [[24, 1, 1, "", "assert_is_in"], [24, 1, 1, "", "encode"], [24, 1, 1, "", "expand"], [24, 1, 1, "", "implements_for_spec"], [24, 1, 1, "", "index"], [24, 1, 1, "", "is_in"], [24, 1, 1, "", "project"], [24, 1, 1, "", "rand"], [24, 1, 1, "", "squeeze"], [24, 1, 1, "", "to_numpy"], [24, 1, 1, "", "to_one_hot"], [24, 1, 1, "", "to_one_hot_spec"], [24, 1, 1, "", "type_check"], [24, 1, 1, "", "zero"]], "torchrl.data.BoundedTensorSpec": [[25, 1, 1, "", "assert_is_in"], [25, 1, 1, "", "encode"], [25, 1, 1, "", "expand"], [25, 1, 1, "", "implements_for_spec"], [25, 1, 1, "", "index"], [25, 1, 1, "", "is_in"], [25, 1, 1, "", "project"], [25, 1, 1, "", "rand"], [25, 1, 1, "", "squeeze"], [25, 1, 1, "", "to_numpy"], [25, 1, 1, "", "type_check"], [25, 1, 1, "", "zero"]], "torchrl.data.CompositeSpec": [[26, 1, 1, "", "assert_is_in"], [26, 1, 1, "", "empty"], [26, 1, 1, "", "encode"], [26, 1, 1, "", "expand"], [26, 1, 1, "", "implements_for_spec"], [26, 1, 1, "", "index"], [26, 1, 1, "", "is_empty"], [26, 1, 1, "", "is_in"], [26, 1, 1, "", "items"], [26, 1, 1, "", "keys"], [26, 1, 1, "", "lock_"], [26, 1, 1, "", "project"], [26, 1, 1, "", "rand"], [26, 1, 1, "", "squeeze"], [26, 1, 1, "", "to_numpy"], [26, 1, 1, "", "type_check"], [26, 1, 1, "", "unlock_"], [26, 1, 1, "", "values"], [26, 1, 1, "", "zero"]], "torchrl.data.DiscreteTensorSpec": [[27, 1, 1, "", "assert_is_in"], [27, 1, 1, "", "encode"], [27, 1, 1, "", "expand"], [27, 1, 1, "", "implements_for_spec"], [27, 1, 1, "", "index"], [27, 1, 1, "", "is_in"], [27, 1, 1, "", "project"], [27, 1, 1, "", "rand"], [27, 1, 1, "", "squeeze"], [27, 1, 1, "", "to_numpy"], [27, 1, 1, "", "to_one_hot"], [27, 1, 1, "", "to_one_hot_spec"], [27, 1, 1, "", "type_check"], [27, 1, 1, "", "zero"]], "torchrl.data.LazyStackedCompositeSpec": [[28, 1, 1, "", "assert_is_in"], [28, 1, 1, "", "empty"], [28, 1, 1, "", "encode"], [28, 1, 1, "", "expand"], [28, 1, 1, "", "implements_for_spec"], [28, 1, 1, "", "index"], [28, 1, 1, "", "is_empty"], [28, 1, 1, "", "is_in"], [28, 1, 1, "", "items"], [28, 1, 1, "", "keys"], [28, 1, 1, "", "lock_"], [28, 1, 1, "", "project"], [28, 1, 1, "", "rand"], [28, 1, 1, "", "squeeze"], [28, 1, 1, "", "to_numpy"], [28, 1, 1, "", "type_check"], [28, 1, 1, "", "unlock_"], [28, 1, 1, "", "values"], [28, 1, 1, "", "zero"]], "torchrl.data.LazyStackedTensorSpec": [[29, 1, 1, "", "assert_is_in"], [29, 1, 1, "", "encode"], [29, 1, 1, "", "expand"], [29, 1, 1, "", "implements_for_spec"], [29, 1, 1, "", "index"], [29, 1, 1, "", "is_in"], [29, 1, 1, "", "project"], [29, 1, 1, "", "rand"], [29, 1, 1, "", "squeeze"], [29, 1, 1, "", "to_numpy"], [29, 1, 1, "", "type_check"], [29, 1, 1, "", "zero"]], "torchrl.data.MultiDiscreteTensorSpec": [[30, 1, 1, "", "assert_is_in"], [30, 1, 1, "", "encode"], [30, 1, 1, "", "expand"], [30, 1, 1, "", "implements_for_spec"], [30, 1, 1, "", "index"], [30, 1, 1, "", "is_in"], [30, 1, 1, "", "project"], [30, 1, 1, "", "rand"], [30, 1, 1, "", "squeeze"], [30, 1, 1, "", "to_numpy"], [30, 1, 1, "", "to_one_hot"], [30, 1, 1, "", "to_one_hot_spec"], [30, 1, 1, "", "type_check"], [30, 1, 1, "", "zero"]], "torchrl.data.MultiOneHotDiscreteTensorSpec": [[31, 1, 1, "", "assert_is_in"], [31, 1, 1, "", "encode"], [31, 1, 1, "", "expand"], [31, 1, 1, "", "implements_for_spec"], [31, 1, 1, "", "index"], [31, 1, 1, "", "is_in"], [31, 1, 1, "", "project"], [31, 1, 1, "", "rand"], [31, 1, 1, "", "squeeze"], [31, 1, 1, "", "to_categorical"], [31, 1, 1, "", "to_categorical_spec"], [31, 1, 1, "", "to_numpy"], [31, 1, 1, "", "type_check"], [31, 1, 1, "", "zero"]], "torchrl.data.MultiStep": [[32, 1, 1, "", "add_module"], [32, 1, 1, "", "apply"], [32, 1, 1, "", "bfloat16"], [32, 1, 1, "", "buffers"], [32, 1, 1, "", "children"], [32, 1, 1, "", "compile"], [32, 1, 1, "", "cpu"], [32, 1, 1, "", "cuda"], [32, 1, 1, "", "double"], [32, 1, 1, "", "eval"], [32, 1, 1, "", "extra_repr"], [32, 1, 1, "", "float"], [32, 1, 1, "", "forward"], [32, 1, 1, "", "get_buffer"], [32, 1, 1, "", "get_extra_state"], [32, 1, 1, "", "get_parameter"], [32, 1, 1, "", "get_submodule"], [32, 1, 1, "", "half"], [32, 1, 1, "", "ipu"], [32, 1, 1, "", "load_state_dict"], [32, 1, 1, "", "modules"], [32, 1, 1, "", "named_buffers"], [32, 1, 1, "", "named_children"], [32, 1, 1, "", "named_modules"], [32, 1, 1, "", "named_parameters"], [32, 1, 1, "", "parameters"], [32, 1, 1, "", "register_backward_hook"], [32, 1, 1, "", "register_buffer"], [32, 1, 1, "", "register_forward_hook"], [32, 1, 1, "", "register_forward_pre_hook"], [32, 1, 1, "", "register_full_backward_hook"], [32, 1, 1, "", "register_full_backward_pre_hook"], [32, 1, 1, "", "register_load_state_dict_post_hook"], [32, 1, 1, "", "register_module"], [32, 1, 1, "", "register_parameter"], [32, 1, 1, "", "register_state_dict_pre_hook"], [32, 1, 1, "", "requires_grad_"], [32, 1, 1, "", "set_extra_state"], [32, 1, 1, "", "share_memory"], [32, 1, 1, "", "state_dict"], [32, 1, 1, "", "to"], [32, 1, 1, "", "to_empty"], [32, 1, 1, "", "train"], [32, 1, 1, "", "type"], [32, 1, 1, "", "xpu"], [32, 1, 1, "", "zero_grad"]], "torchrl.data.OneHotDiscreteTensorSpec": [[33, 1, 1, "", "assert_is_in"], [33, 1, 1, "", "encode"], [33, 1, 1, "", "expand"], [33, 1, 1, "", "implements_for_spec"], [33, 1, 1, "", "index"], [33, 1, 1, "", "is_in"], [33, 1, 1, "", "project"], [33, 1, 1, "", "rand"], [33, 1, 1, "", "squeeze"], [33, 1, 1, "", "to_categorical"], [33, 1, 1, "", "to_categorical_spec"], [33, 1, 1, "", "to_numpy"], [33, 1, 1, "", "type_check"], [33, 1, 1, "", "zero"]], "torchrl.data.PairwiseDataset": [[34, 3, 1, "", "batch_size"], [34, 3, 1, "", "device"], [34, 1, 1, "", "from_dataset"], [34, 1, 1, "", "from_dict"], [34, 1, 1, "", "from_tensordict"], [34, 1, 1, "", "get"], [34, 1, 1, "", "load_state_dict"], [34, 1, 1, "", "memmap"], [34, 1, 1, "", "memmap_"], [34, 1, 1, "", "memmap_like"], [34, 1, 1, "", "set"], [34, 1, 1, "", "state_dict"], [34, 1, 1, "", "to_tensordict"], [34, 1, 1, "", "unbind"]], "torchrl.data.PrioritizedReplayBuffer": [[35, 1, 1, "", "add"], [35, 1, 1, "", "append_transform"], [35, 1, 1, "", "dumps"], [35, 1, 1, "", "empty"], [35, 1, 1, "", "extend"], [35, 1, 1, "", "insert_transform"], [35, 1, 1, "", "loads"], [35, 1, 1, "", "sample"]], "torchrl.data.PromptData": [[36, 3, 1, "", "batch_size"], [36, 3, 1, "", "device"], [36, 1, 1, "", "from_dataset"], [36, 1, 1, "", "from_dict"], [36, 1, 1, "", "from_tensordict"], [36, 1, 1, "", "get"], [36, 1, 1, "", "load_state_dict"], [36, 1, 1, "", "memmap"], [36, 1, 1, "", "memmap_"], [36, 1, 1, "", "memmap_like"], [36, 1, 1, "", "set"], [36, 1, 1, "", "state_dict"], [36, 1, 1, "", "to_tensordict"], [36, 1, 1, "", "unbind"]], "torchrl.data.ReplayBuffer": [[38, 1, 1, "", "add"], [38, 1, 1, "", "append_transform"], [38, 1, 1, "", "dumps"], [38, 1, 1, "", "empty"], [38, 1, 1, "", "extend"], [38, 1, 1, "", "insert_transform"], [38, 1, 1, "", "loads"], [38, 1, 1, "", "sample"]], "torchrl.data.RewardData": [[39, 3, 1, "", "batch_size"], [39, 3, 1, "", "device"], [39, 1, 1, "", "from_dict"], [39, 1, 1, "", "from_tensordict"], [39, 1, 1, "", "get"], [39, 1, 1, "", "load_state_dict"], [39, 1, 1, "", "memmap"], [39, 1, 1, "", "memmap_"], [39, 1, 1, "", "memmap_like"], [39, 1, 1, "", "set"], [39, 1, 1, "", "state_dict"], [39, 1, 1, "", "to_tensordict"], [39, 1, 1, "", "unbind"]], "torchrl.data.RolloutFromModel": [[40, 1, 1, "", "create_rollout_td"], [40, 1, 1, "", "generate"], [40, 1, 1, "", "logprobs_of_labels"]], "torchrl.data.TensorDictPrioritizedReplayBuffer": [[41, 1, 1, "", "add"], [41, 1, 1, "", "append_transform"], [41, 1, 1, "", "dumps"], [41, 1, 1, "", "empty"], [41, 1, 1, "", "extend"], [41, 1, 1, "", "insert_transform"], [41, 1, 1, "", "loads"], [41, 1, 1, "", "sample"]], "torchrl.data.TensorDictReplayBuffer": [[42, 1, 1, "", "add"], [42, 1, 1, "", "append_transform"], [42, 1, 1, "", "dumps"], [42, 1, 1, "", "empty"], [42, 1, 1, "", "extend"], [42, 1, 1, "", "insert_transform"], [42, 1, 1, "", "loads"], [42, 1, 1, "", "sample"]], "torchrl.data.TensorSpec": [[44, 1, 1, "", "assert_is_in"], [44, 1, 1, "", "encode"], [44, 1, 1, "", "expand"], [44, 1, 1, "", "implements_for_spec"], [44, 1, 1, "", "index"], [44, 1, 1, "", "is_in"], [44, 1, 1, "", "project"], [44, 1, 1, "", "rand"], [44, 1, 1, "", "squeeze"], [44, 1, 1, "", "to_numpy"], [44, 1, 1, "", "type_check"], [44, 1, 1, "", "zero"]], "torchrl.data.TokenizedDatasetLoader": [[45, 1, 1, "", "dataset_to_tensordict"], [45, 1, 1, "", "load"]], "torchrl.data.UnboundedContinuousTensorSpec": [[46, 1, 1, "", "assert_is_in"], [46, 1, 1, "", "encode"], [46, 1, 1, "", "expand"], [46, 1, 1, "", "implements_for_spec"], [46, 1, 1, "", "index"], [46, 1, 1, "", "is_in"], [46, 1, 1, "", "project"], [46, 1, 1, "", "rand"], [46, 1, 1, "", "squeeze"], [46, 1, 1, "", "to_numpy"], [46, 1, 1, "", "type_check"], [46, 1, 1, "", "zero"]], "torchrl.data.UnboundedDiscreteTensorSpec": [[47, 1, 1, "", "assert_is_in"], [47, 1, 1, "", "encode"], [47, 1, 1, "", "expand"], [47, 1, 1, "", "implements_for_spec"], [47, 1, 1, "", "index"], [47, 1, 1, "", "is_in"], [47, 1, 1, "", "project"], [47, 1, 1, "", "rand"], [47, 1, 1, "", "squeeze"], [47, 1, 1, "", "to_numpy"], [47, 1, 1, "", "type_check"], [47, 1, 1, "", "zero"]], "torchrl.data.datasets": [[52, 0, 1, "", "D4RLExperienceReplay"], [53, 0, 1, "", "MinariExperienceReplay"], [54, 0, 1, "", "OpenMLExperienceReplay"], [55, 0, 1, "", "RobosetExperienceReplay"], [56, 0, 1, "", "VD4RLExperienceReplay"]], "torchrl.data.datasets.D4RLExperienceReplay": [[52, 1, 1, "", "add"], [52, 1, 1, "", "append_transform"], [52, 1, 1, "", "dumps"], [52, 1, 1, "", "empty"], [52, 1, 1, "", "extend"], [52, 1, 1, "", "insert_transform"], [52, 1, 1, "", "loads"], [52, 1, 1, "", "sample"]], "torchrl.data.datasets.MinariExperienceReplay": [[53, 1, 1, "", "add"], [53, 1, 1, "", "append_transform"], [53, 1, 1, "", "dumps"], [53, 1, 1, "", "empty"], [53, 1, 1, "", "extend"], [53, 1, 1, "", "insert_transform"], [53, 1, 1, "", "loads"], [53, 1, 1, "", "sample"]], "torchrl.data.datasets.OpenMLExperienceReplay": [[54, 1, 1, "", "add"], [54, 1, 1, "", "append_transform"], [54, 1, 1, "", "dumps"], [54, 1, 1, "", "empty"], [54, 1, 1, "", "extend"], [54, 1, 1, "", "insert_transform"], [54, 1, 1, "", "loads"], [54, 1, 1, "", "sample"]], "torchrl.data.datasets.RobosetExperienceReplay": [[55, 1, 1, "", "add"], [55, 1, 1, "", "append_transform"], [55, 1, 1, "", "dumps"], [55, 1, 1, "", "empty"], [55, 1, 1, "", "extend"], [55, 1, 1, "", "insert_transform"], [55, 1, 1, "", "loads"], [55, 1, 1, "", "sample"]], "torchrl.data.datasets.VD4RLExperienceReplay": [[56, 1, 1, "", "add"], [56, 1, 1, "", "append_transform"], [56, 1, 1, "", "dumps"], [56, 1, 1, "", "empty"], [56, 1, 1, "", "extend"], [56, 1, 1, "", "insert_transform"], [56, 1, 1, "", "loads"], [56, 1, 1, "", "sample"]], "torchrl.data.replay_buffers": [[58, 0, 1, "", "LazyMemmapStorage"], [59, 0, 1, "", "LazyTensorStorage"], [60, 0, 1, "", "ListStorage"], [61, 0, 1, "", "PrioritizedSampler"], [62, 0, 1, "", "RandomSampler"], [63, 0, 1, "", "RoundRobinWriter"], [64, 0, 1, "", "Sampler"], [65, 0, 1, "", "SamplerWithoutReplacement"], [66, 0, 1, "", "SliceSampler"], [67, 0, 1, "", "SliceSamplerWithoutReplacement"], [68, 0, 1, "", "Storage"], [69, 0, 1, "", "TensorDictMaxValueWriter"], [70, 0, 1, "", "TensorDictRoundRobinWriter"], [71, 0, 1, "", "TensorStorage"], [72, 0, 1, "", "Writer"]], "torchrl.data.replay_buffers.LazyMemmapStorage": [[58, 1, 1, "", "attach"]], "torchrl.data.replay_buffers.LazyTensorStorage": [[59, 1, 1, "", "attach"]], "torchrl.data.replay_buffers.ListStorage": [[60, 1, 1, "", "attach"]], "torchrl.data.replay_buffers.PrioritizedSampler": [[61, 1, 1, "", "update_priority"]], "torchrl.data.replay_buffers.RoundRobinWriter": [[63, 1, 1, "", "add"], [63, 1, 1, "", "extend"]], "torchrl.data.replay_buffers.Storage": [[68, 1, 1, "", "attach"]], "torchrl.data.replay_buffers.TensorDictMaxValueWriter": [[69, 1, 1, "", "add"], [69, 1, 1, "", "extend"], [69, 1, 1, "", "get_insert_index"]], "torchrl.data.replay_buffers.TensorDictRoundRobinWriter": [[70, 1, 1, "", "add"], [70, 1, 1, "", "extend"]], "torchrl.data.replay_buffers.TensorStorage": [[71, 1, 1, "", "attach"]], "torchrl.data.replay_buffers.Writer": [[72, 1, 1, "", "add"], [72, 1, 1, "", "extend"]], "torchrl.envs": [[73, 2, 1, "", "BraxEnv"], [74, 2, 1, "", "BraxWrapper"], [75, 2, 1, "", "DMControlEnv"], [76, 2, 1, "", "DMControlWrapper"], [77, 0, 1, "", "EnvBase"], [78, 0, 1, "", "EnvCreator"], [79, 0, 1, "", "EnvMetaData"], [80, 2, 1, "", "GymEnv"], [81, 0, 1, "", "GymLikeEnv"], [82, 2, 1, "", "GymWrapper"], [83, 2, 1, "", "HabitatEnv"], [84, 2, 1, "", "IsaacGymEnv"], [85, 2, 1, "", "IsaacGymWrapper"], [86, 2, 1, "", "JumanjiEnv"], [87, 2, 1, "", "JumanjiWrapper"], [88, 2, 1, "", "MOGymEnv"], [89, 2, 1, "", "MOGymWrapper"], [90, 2, 1, "", "MarlGroupMapType"], [91, 2, 1, "", "ModelBasedEnvBase"], [92, 2, 1, "", "MultiThreadedEnv"], [93, 2, 1, "", "MultiThreadedEnvWrapper"], [94, 2, 1, "", "OpenMLEnv"], [95, 0, 1, "", "ParallelEnv"], [96, 2, 1, "", "PettingZooEnv"], [97, 2, 1, "", "PettingZooWrapper"], [98, 2, 1, "", "RoboHiveEnv"], [99, 2, 1, "", "SMACv2Env"], [100, 2, 1, "", "SMACv2Wrapper"], [101, 0, 1, "", "SerialEnv"], [102, 2, 1, "", "VmasEnv"], [103, 2, 1, "", "VmasWrapper"], [104, 2, 1, "", "check_marl_grouping"], [105, 2, 1, "", "gym_backend"], [91, 1, 1, "", "rand_step"], [91, 1, 1, "", "reset"], [91, 1, 1, "", "rollout"], [107, 2, 1, "", "set_gym_backend"], [91, 1, 1, "", "set_seed"], [91, 1, 1, "", "step"]], "torchrl.envs.EnvBase": [[77, 3, 1, "", "action_key"], [77, 3, 1, "", "action_keys"], [77, 3, 1, "", "action_spec"], [77, 1, 1, "", "add_module"], [77, 1, 1, "", "apply"], [77, 3, 1, "", "batch_locked"], [77, 1, 1, "", "bfloat16"], [77, 1, 1, "", "buffers"], [77, 1, 1, "", "children"], [77, 1, 1, "", "compile"], [77, 1, 1, "", "cpu"], [77, 1, 1, "", "cuda"], [77, 3, 1, "", "done_key"], [77, 3, 1, "", "done_keys"], [77, 3, 1, "", "done_keys_groups"], [77, 3, 1, "", "done_spec"], [77, 1, 1, "", "double"], [77, 1, 1, "", "empty_cache"], [77, 1, 1, "", "eval"], [77, 1, 1, "", "extra_repr"], [77, 1, 1, "", "fake_tensordict"], [77, 1, 1, "", "float"], [77, 1, 1, "", "forward"], [77, 3, 1, "", "full_action_spec"], [77, 3, 1, "", "full_done_spec"], [77, 3, 1, "", "full_reward_spec"], [77, 3, 1, "", "full_state_spec"], [77, 1, 1, "", "get_buffer"], [77, 1, 1, "", "get_extra_state"], [77, 1, 1, "", "get_parameter"], [77, 1, 1, "", "get_submodule"], [77, 1, 1, "", "half"], [77, 3, 1, "", "input_spec"], [77, 1, 1, "", "ipu"], [77, 1, 1, "", "load_state_dict"], [77, 1, 1, "", "modules"], [77, 1, 1, "", "named_buffers"], [77, 1, 1, "", "named_children"], [77, 1, 1, "", "named_modules"], [77, 1, 1, "", "named_parameters"], [77, 3, 1, "", "observation_spec"], [77, 3, 1, "", "output_spec"], [77, 1, 1, "", "parameters"], [77, 1, 1, "", "rand_action"], [77, 1, 1, "id0", "rand_step"], [77, 1, 1, "", "register_backward_hook"], [77, 1, 1, "", "register_buffer"], [77, 1, 1, "", "register_forward_hook"], [77, 1, 1, "", "register_forward_pre_hook"], [77, 1, 1, "", "register_full_backward_hook"], [77, 1, 1, "", "register_full_backward_pre_hook"], [77, 1, 1, "", "register_load_state_dict_post_hook"], [77, 1, 1, "", "register_module"], [77, 1, 1, "", "register_parameter"], [77, 1, 1, "", "register_state_dict_pre_hook"], [77, 1, 1, "", "requires_grad_"], [77, 1, 1, "id1", "reset"], [77, 3, 1, "", "reset_keys"], [77, 3, 1, "", "reward_key"], [77, 3, 1, "", "reward_keys"], [77, 3, 1, "", "reward_spec"], [77, 1, 1, "id2", "rollout"], [77, 1, 1, "", "set_extra_state"], [77, 1, 1, "id3", "set_seed"], [77, 1, 1, "", "share_memory"], [77, 3, 1, "", "specs"], [77, 1, 1, "", "state_dict"], [77, 3, 1, "", "state_spec"], [77, 1, 1, "id4", "step"], [77, 1, 1, "", "step_and_maybe_reset"], [77, 1, 1, "", "to"], [77, 1, 1, "", "to_empty"], [77, 1, 1, "", "train"], [77, 1, 1, "", "type"], [77, 1, 1, "", "xpu"], [77, 1, 1, "", "zero_grad"]], "torchrl.envs.GymLikeEnv": [[81, 3, 1, "", "action_key"], [81, 3, 1, "", "action_keys"], [81, 3, 1, "", "action_spec"], [81, 1, 1, "", "add_module"], [81, 1, 1, "", "apply"], [81, 3, 1, "", "batch_locked"], [81, 1, 1, "", "bfloat16"], [81, 1, 1, "", "buffers"], [81, 1, 1, "", "children"], [81, 1, 1, "", "close"], [81, 1, 1, "", "compile"], [81, 1, 1, "", "cpu"], [81, 1, 1, "", "cuda"], [81, 3, 1, "", "done_key"], [81, 3, 1, "", "done_keys"], [81, 3, 1, "", "done_keys_groups"], [81, 3, 1, "", "done_spec"], [81, 1, 1, "", "double"], [81, 1, 1, "", "empty_cache"], [81, 1, 1, "", "eval"], [81, 1, 1, "", "extra_repr"], [81, 1, 1, "", "fake_tensordict"], [81, 1, 1, "", "float"], [81, 1, 1, "", "forward"], [81, 3, 1, "", "full_action_spec"], [81, 3, 1, "", "full_done_spec"], [81, 3, 1, "", "full_reward_spec"], [81, 3, 1, "", "full_state_spec"], [81, 1, 1, "", "get_buffer"], [81, 1, 1, "", "get_extra_state"], [81, 1, 1, "", "get_parameter"], [81, 1, 1, "", "get_submodule"], [81, 1, 1, "", "half"], [81, 3, 1, "", "input_spec"], [81, 1, 1, "", "ipu"], [81, 1, 1, "", "load_state_dict"], [81, 1, 1, "", "modules"], [81, 1, 1, "", "named_buffers"], [81, 1, 1, "", "named_children"], [81, 1, 1, "", "named_modules"], [81, 1, 1, "", "named_parameters"], [81, 3, 1, "", "observation_spec"], [81, 3, 1, "", "output_spec"], [81, 1, 1, "", "parameters"], [81, 1, 1, "", "rand_action"], [81, 1, 1, "", "rand_step"], [81, 1, 1, "", "read_action"], [81, 1, 1, "", "read_done"], [81, 1, 1, "", "read_obs"], [81, 1, 1, "", "read_reward"], [81, 1, 1, "", "register_backward_hook"], [81, 1, 1, "", "register_buffer"], [81, 1, 1, "", "register_forward_hook"], [81, 1, 1, "", "register_forward_pre_hook"], [81, 1, 1, "", "register_full_backward_hook"], [81, 1, 1, "", "register_full_backward_pre_hook"], [81, 1, 1, "", "register_load_state_dict_post_hook"], [81, 1, 1, "", "register_module"], [81, 1, 1, "", "register_parameter"], [81, 1, 1, "", "register_state_dict_pre_hook"], [81, 1, 1, "", "requires_grad_"], [81, 1, 1, "", "reset"], [81, 3, 1, "", "reset_keys"], [81, 3, 1, "", "reward_key"], [81, 3, 1, "", "reward_keys"], [81, 3, 1, "", "reward_spec"], [81, 1, 1, "", "rollout"], [81, 1, 1, "", "set_extra_state"], [81, 1, 1, "", "set_info_dict_reader"], [81, 1, 1, "", "set_seed"], [81, 1, 1, "", "share_memory"], [81, 3, 1, "", "specs"], [81, 1, 1, "", "state_dict"], [81, 3, 1, "", "state_spec"], [81, 1, 1, "", "step"], [81, 1, 1, "", "step_and_maybe_reset"], [81, 1, 1, "", "to"], [81, 1, 1, "", "to_empty"], [81, 1, 1, "", "train"], [81, 1, 1, "", "type"], [81, 1, 1, "", "xpu"], [81, 1, 1, "", "zero_grad"]], "torchrl.envs.ParallelEnv": [[95, 3, 1, "", "action_key"], [95, 3, 1, "", "action_keys"], [95, 3, 1, "", "action_spec"], [95, 1, 1, "", "add_module"], [95, 1, 1, "", "apply"], [95, 3, 1, "", "batch_locked"], [95, 1, 1, "", "bfloat16"], [95, 1, 1, "", "buffers"], [95, 1, 1, "", "children"], [95, 1, 1, "", "compile"], [95, 1, 1, "", "cpu"], [95, 1, 1, "", "cuda"], [95, 3, 1, "", "done_key"], [95, 3, 1, "", "done_keys"], [95, 3, 1, "", "done_keys_groups"], [95, 3, 1, "", "done_spec"], [95, 1, 1, "", "double"], [95, 1, 1, "", "empty_cache"], [95, 1, 1, "", "eval"], [95, 1, 1, "", "extra_repr"], [95, 1, 1, "", "fake_tensordict"], [95, 1, 1, "", "float"], [95, 1, 1, "", "forward"], [95, 3, 1, "", "full_action_spec"], [95, 3, 1, "", "full_done_spec"], [95, 3, 1, "", "full_reward_spec"], [95, 3, 1, "", "full_state_spec"], [95, 1, 1, "", "get_buffer"], [95, 1, 1, "", "get_extra_state"], [95, 1, 1, "", "get_parameter"], [95, 1, 1, "", "get_submodule"], [95, 1, 1, "", "half"], [95, 3, 1, "", "input_spec"], [95, 1, 1, "", "ipu"], [95, 1, 1, "", "load_state_dict"], [95, 1, 1, "", "modules"], [95, 1, 1, "", "named_buffers"], [95, 1, 1, "", "named_children"], [95, 1, 1, "", "named_modules"], [95, 1, 1, "", "named_parameters"], [95, 3, 1, "", "observation_spec"], [95, 3, 1, "", "output_spec"], [95, 1, 1, "", "parameters"], [95, 1, 1, "", "rand_action"], [95, 1, 1, "", "rand_step"], [95, 1, 1, "", "register_backward_hook"], [95, 1, 1, "", "register_buffer"], [95, 1, 1, "", "register_forward_hook"], [95, 1, 1, "", "register_forward_pre_hook"], [95, 1, 1, "", "register_full_backward_hook"], [95, 1, 1, "", "register_full_backward_pre_hook"], [95, 1, 1, "", "register_load_state_dict_post_hook"], [95, 1, 1, "", "register_module"], [95, 1, 1, "", "register_parameter"], [95, 1, 1, "", "register_state_dict_pre_hook"], [95, 1, 1, "", "requires_grad_"], [95, 1, 1, "", "reset"], [95, 3, 1, "", "reset_keys"], [95, 3, 1, "", "reward_key"], [95, 3, 1, "", "reward_keys"], [95, 3, 1, "", "reward_spec"], [95, 1, 1, "", "rollout"], [95, 1, 1, "", "set_extra_state"], [95, 1, 1, "", "set_seed"], [95, 1, 1, "", "share_memory"], [95, 3, 1, "", "specs"], [95, 1, 1, "", "state_dict"], [95, 3, 1, "", "state_spec"], [95, 1, 1, "", "step"], [95, 1, 1, "", "step_and_maybe_reset"], [95, 1, 1, "", "to"], [95, 1, 1, "", "to_empty"], [95, 1, 1, "", "train"], [95, 1, 1, "", "type"], [95, 1, 1, "", "update_kwargs"], [95, 1, 1, "", "xpu"], [95, 1, 1, "", "zero_grad"]], "torchrl.envs.SerialEnv": [[101, 3, 1, "", "action_key"], [101, 3, 1, "", "action_keys"], [101, 3, 1, "", "action_spec"], [101, 1, 1, "", "add_module"], [101, 1, 1, "", "apply"], [101, 3, 1, "", "batch_locked"], [101, 1, 1, "", "bfloat16"], [101, 1, 1, "", "buffers"], [101, 1, 1, "", "children"], [101, 1, 1, "", "compile"], [101, 1, 1, "", "cpu"], [101, 1, 1, "", "cuda"], [101, 3, 1, "", "done_key"], [101, 3, 1, "", "done_keys"], [101, 3, 1, "", "done_keys_groups"], [101, 3, 1, "", "done_spec"], [101, 1, 1, "", "double"], [101, 1, 1, "", "empty_cache"], [101, 1, 1, "", "eval"], [101, 1, 1, "", "extra_repr"], [101, 1, 1, "", "fake_tensordict"], [101, 1, 1, "", "float"], [101, 1, 1, "", "forward"], [101, 3, 1, "", "full_action_spec"], [101, 3, 1, "", "full_done_spec"], [101, 3, 1, "", "full_reward_spec"], [101, 3, 1, "", "full_state_spec"], [101, 1, 1, "", "get_buffer"], [101, 1, 1, "", "get_extra_state"], [101, 1, 1, "", "get_parameter"], [101, 1, 1, "", "get_submodule"], [101, 1, 1, "", "half"], [101, 3, 1, "", "input_spec"], [101, 1, 1, "", "ipu"], [101, 1, 1, "", "load_state_dict"], [101, 1, 1, "", "modules"], [101, 1, 1, "", "named_buffers"], [101, 1, 1, "", "named_children"], [101, 1, 1, "", "named_modules"], [101, 1, 1, "", "named_parameters"], [101, 3, 1, "", "observation_spec"], [101, 3, 1, "", "output_spec"], [101, 1, 1, "", "parameters"], [101, 1, 1, "", "rand_action"], [101, 1, 1, "", "rand_step"], [101, 1, 1, "", "register_backward_hook"], [101, 1, 1, "", "register_buffer"], [101, 1, 1, "", "register_forward_hook"], [101, 1, 1, "", "register_forward_pre_hook"], [101, 1, 1, "", "register_full_backward_hook"], [101, 1, 1, "", "register_full_backward_pre_hook"], [101, 1, 1, "", "register_load_state_dict_post_hook"], [101, 1, 1, "", "register_module"], [101, 1, 1, "", "register_parameter"], [101, 1, 1, "", "register_state_dict_pre_hook"], [101, 1, 1, "", "requires_grad_"], [101, 1, 1, "", "reset"], [101, 3, 1, "", "reset_keys"], [101, 3, 1, "", "reward_key"], [101, 3, 1, "", "reward_keys"], [101, 3, 1, "", "reward_spec"], [101, 1, 1, "", "rollout"], [101, 1, 1, "", "set_extra_state"], [101, 1, 1, "", "set_seed"], [101, 1, 1, "", "share_memory"], [101, 3, 1, "", "specs"], [101, 1, 1, "", "state_dict"], [101, 3, 1, "", "state_spec"], [101, 1, 1, "", "step"], [101, 1, 1, "", "step_and_maybe_reset"], [101, 1, 1, "", "to"], [101, 1, 1, "", "to_empty"], [101, 1, 1, "", "train"], [101, 1, 1, "", "type"], [101, 1, 1, "", "update_kwargs"], [101, 1, 1, "", "xpu"], [101, 1, 1, "", "zero_grad"]], "torchrl.envs.model_based.dreamer": [[106, 2, 1, "", "DreamerEnv"]], "torchrl.envs.transforms": [[108, 0, 1, "", "ActionMask"], [109, 0, 1, "", "BinarizeReward"], [110, 0, 1, "", "BurnInTransform"], [111, 0, 1, "", "CatFrames"], [112, 0, 1, "", "CatTensors"], [113, 0, 1, "", "CenterCrop"], [114, 0, 1, "", "ClipTransform"], [115, 0, 1, "", "Compose"], [116, 0, 1, "", "DTypeCastTransform"], [117, 0, 1, "", "DeviceCastTransform"], [118, 0, 1, "", "DiscreteActionProjection"], [119, 0, 1, "", "DoubleToFloat"], [120, 0, 1, "", "EndOfLifeTransform"], [121, 0, 1, "", "ExcludeTransform"], [122, 0, 1, "", "FiniteTensorDictCheck"], [123, 0, 1, "", "FlattenObservation"], [124, 0, 1, "", "FrameSkipTransform"], [125, 0, 1, "", "GrayScale"], [126, 0, 1, "", "InitTracker"], [127, 0, 1, "", "KLRewardTransform"], [128, 0, 1, "", "NoopResetEnv"], [129, 0, 1, "", "ObservationNorm"], [130, 0, 1, "", "ObservationTransform"], [131, 0, 1, "", "PermuteTransform"], [132, 0, 1, "", "PinMemoryTransform"], [133, 0, 1, "", "R3MTransform"], [134, 0, 1, "", "RandomCropTensorDict"], [135, 0, 1, "", "RenameTransform"], [136, 0, 1, "", "Resize"], [137, 0, 1, "", "Reward2GoTransform"], [138, 0, 1, "", "RewardClipping"], [139, 0, 1, "", "RewardScaling"], [140, 0, 1, "", "RewardSum"], [141, 0, 1, "", "SelectTransform"], [142, 0, 1, "", "SqueezeTransform"], [143, 0, 1, "", "StepCounter"], [144, 0, 1, "", "TargetReturn"], [145, 0, 1, "", "TensorDictPrimer"], [146, 0, 1, "", "TimeMaxPool"], [147, 0, 1, "", "ToTensorImage"], [148, 0, 1, "", "Transform"], [149, 0, 1, "", "TransformedEnv"], [150, 0, 1, "", "UnsqueezeTransform"], [151, 0, 1, "", "VC1Transform"], [152, 0, 1, "", "VIPRewardTransform"], [153, 0, 1, "", "VIPTransform"], [154, 0, 1, "", "VecGymEnvTransform"], [155, 0, 1, "", "VecNorm"], [156, 0, 1, "", "gSDENoise"]], "torchrl.envs.transforms.ActionMask": [[108, 1, 1, "", "forward"]], "torchrl.envs.transforms.BinarizeReward": [[109, 1, 1, "", "transform_reward_spec"]], "torchrl.envs.transforms.BurnInTransform": [[110, 1, 1, "", "forward"]], "torchrl.envs.transforms.CatFrames": [[111, 1, 1, "", "forward"], [111, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.CatTensors": [[112, 1, 1, "", "forward"], [112, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.CenterCrop": [[113, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.ClipTransform": [[114, 1, 1, "", "transform_observation_spec"], [114, 1, 1, "", "transform_reward_spec"]], "torchrl.envs.transforms.Compose": [[115, 1, 1, "", "forward"], [115, 1, 1, "", "to"], [115, 1, 1, "", "transform_env_device"], [115, 1, 1, "", "transform_input_spec"], [115, 1, 1, "", "transform_observation_spec"], [115, 1, 1, "", "transform_output_spec"], [115, 1, 1, "", "transform_reward_spec"]], "torchrl.envs.transforms.DTypeCastTransform": [[116, 1, 1, "", "forward"], [116, 1, 1, "", "transform_input_spec"], [116, 1, 1, "", "transform_observation_spec"], [116, 1, 1, "", "transform_output_spec"]], "torchrl.envs.transforms.DeviceCastTransform": [[117, 1, 1, "", "forward"], [117, 1, 1, "", "transform_done_spec"], [117, 1, 1, "", "transform_env_device"], [117, 1, 1, "", "transform_input_spec"], [117, 1, 1, "", "transform_observation_spec"], [117, 1, 1, "", "transform_output_spec"], [117, 1, 1, "", "transform_reward_spec"]], "torchrl.envs.transforms.DiscreteActionProjection": [[118, 1, 1, "", "transform_input_spec"]], "torchrl.envs.transforms.EndOfLifeTransform": [[120, 1, 1, "", "forward"], [120, 1, 1, "", "register_keys"], [120, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.ExcludeTransform": [[121, 1, 1, "", "forward"], [121, 1, 1, "", "transform_output_spec"]], "torchrl.envs.transforms.FiniteTensorDictCheck": [[122, 1, 1, "", "forward"]], "torchrl.envs.transforms.FlattenObservation": [[123, 1, 1, "", "forward"], [123, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.FrameSkipTransform": [[124, 1, 1, "", "forward"]], "torchrl.envs.transforms.GrayScale": [[125, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.InitTracker": [[126, 1, 1, "", "forward"], [126, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.KLRewardTransform": [[127, 1, 1, "", "forward"], [127, 1, 1, "", "transform_output_spec"]], "torchrl.envs.transforms.ObservationNorm": [[129, 1, 1, "", "init_stats"], [129, 1, 1, "", "transform_input_spec"], [129, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.PermuteTransform": [[131, 1, 1, "", "transform_input_spec"], [131, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.PinMemoryTransform": [[132, 1, 1, "", "forward"]], "torchrl.envs.transforms.R3MTransform": [[133, 1, 1, "", "to"]], "torchrl.envs.transforms.RandomCropTensorDict": [[134, 1, 1, "", "forward"]], "torchrl.envs.transforms.RenameTransform": [[135, 1, 1, "", "forward"], [135, 1, 1, "", "transform_input_spec"], [135, 1, 1, "", "transform_output_spec"]], "torchrl.envs.transforms.Resize": [[136, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.Reward2GoTransform": [[137, 1, 1, "", "forward"]], "torchrl.envs.transforms.RewardClipping": [[138, 1, 1, "", "transform_reward_spec"]], "torchrl.envs.transforms.RewardScaling": [[139, 1, 1, "", "transform_reward_spec"]], "torchrl.envs.transforms.RewardSum": [[140, 1, 1, "", "forward"], [140, 1, 1, "", "transform_input_spec"], [140, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.SelectTransform": [[141, 1, 1, "", "forward"], [141, 1, 1, "", "transform_output_spec"]], "torchrl.envs.transforms.StepCounter": [[143, 1, 1, "", "forward"], [143, 1, 1, "", "transform_input_spec"], [143, 1, 1, "", "transform_observation_spec"], [143, 1, 1, "", "transform_output_spec"]], "torchrl.envs.transforms.TargetReturn": [[144, 1, 1, "", "forward"], [144, 1, 1, "", "transform_input_spec"], [144, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.TensorDictPrimer": [[145, 1, 1, "", "forward"], [145, 1, 1, "", "to"], [145, 1, 1, "", "transform_input_spec"], [145, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.TimeMaxPool": [[146, 1, 1, "", "forward"], [146, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.ToTensorImage": [[147, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.Transform": [[148, 3, 1, "", "container"], [148, 1, 1, "", "forward"], [148, 3, 1, "", "parent"], [148, 1, 1, "", "to"], [148, 1, 1, "", "transform_done_spec"], [148, 1, 1, "", "transform_env_device"], [148, 1, 1, "", "transform_input_spec"], [148, 1, 1, "", "transform_observation_spec"], [148, 1, 1, "", "transform_output_spec"], [148, 1, 1, "", "transform_reward_spec"]], "torchrl.envs.transforms.TransformedEnv": [[149, 3, 1, "", "batch_locked"], [149, 1, 1, "", "empty_cache"], [149, 1, 1, "", "eval"], [149, 3, 1, "", "input_spec"], [149, 1, 1, "", "load_state_dict"], [149, 3, 1, "", "output_spec"], [149, 1, 1, "", "set_missing_tolerance"], [149, 1, 1, "", "set_seed"], [149, 1, 1, "", "state_dict"], [149, 1, 1, "", "to"], [149, 1, 1, "", "train"]], "torchrl.envs.transforms.UnsqueezeTransform": [[150, 1, 1, "", "transform_input_spec"], [150, 1, 1, "", "transform_observation_spec"], [150, 1, 1, "", "transform_reward_spec"]], "torchrl.envs.transforms.VC1Transform": [[151, 1, 1, "", "forward"], [151, 1, 1, "", "make_noload_model"], [151, 1, 1, "", "to"], [151, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.VIPRewardTransform": [[152, 1, 1, "", "forward"], [152, 1, 1, "", "transform_input_spec"]], "torchrl.envs.transforms.VIPTransform": [[153, 1, 1, "", "to"]], "torchrl.envs.transforms.VecGymEnvTransform": [[154, 1, 1, "", "forward"], [154, 1, 1, "", "transform_observation_spec"]], "torchrl.envs.transforms.VecNorm": [[155, 1, 1, "", "build_td_for_shared_vecnorm"], [155, 1, 1, "", "forward"], [155, 1, 1, "", "get_extra_state"], [155, 1, 1, "", "set_extra_state"], [155, 1, 1, "", "to_observation_norm"]], "torchrl.envs.utils": [[157, 2, 1, "", "check_env_specs"], [158, 2, 1, "", "exploration_mode"], [159, 2, 1, "", "exploration_type"], [160, 2, 1, "", "get_available_libraries"], [161, 2, 1, "", "make_composite_from_td"], [162, 2, 1, "", "set_exploration_mode"], [163, 2, 1, "", "set_exploration_type"], [164, 2, 1, "", "step_mdp"], [165, 2, 1, "", "terminated_or_truncated"]], "torchrl.modules": [[166, 0, 1, "", "CEMPlanner"], [167, 0, 1, "", "Conv3dNet"], [168, 0, 1, "", "ConvNet"], [169, 0, 1, "", "DTActor"], [170, 0, 1, "", "DdpgCnnActor"], [171, 0, 1, "", "DdpgCnnQNet"], [172, 0, 1, "", "DdpgMlpActor"], [173, 0, 1, "", "DdpgMlpQNet"], [174, 0, 1, "", "DecisionTransformer"], [175, 0, 1, "", "Delta"], [176, 0, 1, "", "DistributionalDQNnet"], [177, 0, 1, "", "DistributionalQValueHook"], [178, 0, 1, "", "DreamerActor"], [179, 0, 1, "", "DuelingCnnDQNet"], [180, 0, 1, "", "GRU"], [181, 0, 1, "", "GRUCell"], [182, 0, 1, "", "GRUModule"], [183, 0, 1, "", "IndependentNormal"], [184, 0, 1, "", "LSTM"], [185, 0, 1, "", "LSTMCell"], [186, 0, 1, "", "LSTMModule"], [187, 0, 1, "", "LSTMNet"], [188, 0, 1, "", "MLP"], [189, 0, 1, "", "MPCPlannerBase"], [190, 0, 1, "", "MPPIPlanner"], [191, 0, 1, "", "MaskedCategorical"], [192, 0, 1, "", "MaskedOneHotCategorical"], [193, 0, 1, "", "MultiAgentConvNet"], [194, 0, 1, "", "MultiAgentMLP"], [195, 0, 1, "", "NoisyLazyLinear"], [196, 0, 1, "", "NoisyLinear"], [197, 0, 1, "", "NormalParamWrapper"], [198, 0, 1, "", "ObsDecoder"], [199, 0, 1, "", "ObsEncoder"], [200, 0, 1, "", "OneHotCategorical"], [201, 0, 1, "", "OnlineDTActor"], [202, 0, 1, "", "QMixer"], [203, 0, 1, "", "QValueHook"], [204, 0, 1, "", "RSSMPosterior"], [205, 0, 1, "", "RSSMPrior"], [206, 0, 1, "", "Squeeze2dLayer"], [207, 0, 1, "", "SqueezeLayer"], [208, 0, 1, "", "TanhDelta"], [209, 0, 1, "", "TanhNormal"], [210, 0, 1, "", "TruncatedNormal"], [211, 0, 1, "", "VDNMixer"], [212, 0, 1, "", "VmapModule"], [213, 0, 1, "", "reset_noise"]], "torchrl.modules.CEMPlanner": [[166, 1, 1, "", "planning"]], "torchrl.modules.Conv3dNet": [[167, 1, 1, "", "forward"]], "torchrl.modules.ConvNet": [[168, 1, 1, "", "forward"]], "torchrl.modules.DTActor": [[169, 1, 1, "", "default_config"], [169, 1, 1, "", "forward"]], "torchrl.modules.DdpgCnnActor": [[170, 1, 1, "", "forward"]], "torchrl.modules.DdpgCnnQNet": [[171, 1, 1, "", "forward"]], "torchrl.modules.DdpgMlpActor": [[172, 1, 1, "", "forward"]], "torchrl.modules.DdpgMlpQNet": [[173, 1, 1, "", "forward"]], "torchrl.modules.DecisionTransformer": [[174, 0, 1, "", "DTConfig"], [174, 1, 1, "", "forward"]], "torchrl.modules.Delta": [[175, 1, 1, "", "log_prob"], [175, 3, 1, "", "mean"], [175, 3, 1, "", "mode"], [175, 1, 1, "", "rsample"], [175, 1, 1, "", "sample"]], "torchrl.modules.DistributionalDQNnet": [[176, 1, 1, "", "forward"]], "torchrl.modules.DreamerActor": [[178, 1, 1, "", "forward"]], "torchrl.modules.DuelingCnnDQNet": [[179, 1, 1, "", "forward"]], "torchrl.modules.GRU": [[180, 1, 1, "", "forward"]], "torchrl.modules.GRUCell": [[181, 1, 1, "", "forward"]], "torchrl.modules.GRUModule": [[182, 1, 1, "", "forward"], [182, 1, 1, "id0", "set_recurrent_mode"]], "torchrl.modules.IndependentNormal": [[183, 3, 1, "", "mode"]], "torchrl.modules.LSTM": [[184, 1, 1, "", "forward"]], "torchrl.modules.LSTMCell": [[185, 1, 1, "", "forward"]], "torchrl.modules.LSTMModule": [[186, 1, 1, "", "forward"], [186, 1, 1, "id0", "set_recurrent_mode"]], "torchrl.modules.LSTMNet": [[187, 1, 1, "", "forward"]], "torchrl.modules.MLP": [[188, 1, 1, "", "forward"]], "torchrl.modules.MPCPlannerBase": [[189, 1, 1, "", "forward"], [189, 1, 1, "", "planning"]], "torchrl.modules.MPPIPlanner": [[190, 1, 1, "", "planning"]], "torchrl.modules.MaskedCategorical": [[191, 1, 1, "", "log_prob"], [191, 1, 1, "", "sample"]], "torchrl.modules.MaskedOneHotCategorical": [[192, 1, 1, "", "log_prob"], [192, 1, 1, "", "rsample"], [192, 1, 1, "", "sample"]], "torchrl.modules.MultiAgentConvNet": [[193, 1, 1, "", "forward"]], "torchrl.modules.MultiAgentMLP": [[194, 1, 1, "", "forward"]], "torchrl.modules.NoisyLazyLinear": [[195, 1, 1, "", "initialize_parameters"]], "torchrl.modules.NormalParamWrapper": [[197, 1, 1, "", "forward"]], "torchrl.modules.ObsDecoder": [[198, 1, 1, "", "forward"]], "torchrl.modules.ObsEncoder": [[199, 1, 1, "", "forward"]], "torchrl.modules.OneHotCategorical": [[200, 1, 1, "", "log_prob"], [200, 3, 1, "", "mode"], [200, 1, 1, "", "rsample"], [200, 1, 1, "", "sample"]], "torchrl.modules.OnlineDTActor": [[201, 1, 1, "", "default_config"], [201, 1, 1, "", "forward"]], "torchrl.modules.QMixer": [[202, 1, 1, "", "mix"]], "torchrl.modules.RSSMPosterior": [[204, 1, 1, "", "forward"]], "torchrl.modules.RSSMPrior": [[205, 1, 1, "", "forward"]], "torchrl.modules.SqueezeLayer": [[207, 1, 1, "", "forward"]], "torchrl.modules.TanhDelta": [[208, 3, 1, "", "mean"], [208, 3, 1, "", "mode"]], "torchrl.modules.TanhNormal": [[209, 3, 1, "", "mode"]], "torchrl.modules.TruncatedNormal": [[210, 1, 1, "", "log_prob"], [210, 3, 1, "", "mode"]], "torchrl.modules.VDNMixer": [[211, 1, 1, "", "mix"]], "torchrl.modules.VmapModule": [[212, 1, 1, "", "forward"]], "torchrl.modules.tensordict_module": [[214, 0, 1, "", "Actor"], [215, 0, 1, "", "ActorCriticOperator"], [216, 0, 1, "", "ActorCriticWrapper"], [217, 0, 1, "", "ActorValueOperator"], [218, 0, 1, "", "AdditiveGaussianWrapper"], [219, 0, 1, "", "DecisionTransformerInferenceWrapper"], [220, 0, 1, "", "DistributionalQValueActor"], [221, 0, 1, "", "DistributionalQValueModule"], [222, 0, 1, "", "EGreedyModule"], [223, 0, 1, "", "EGreedyWrapper"], [224, 0, 1, "", "LMHeadActorValueOperator"], [225, 0, 1, "", "OrnsteinUhlenbeckProcessWrapper"], [226, 0, 1, "", "ProbabilisticActor"], [227, 0, 1, "", "QValueActor"], [228, 0, 1, "", "QValueModule"], [229, 0, 1, "", "SafeModule"], [230, 0, 1, "", "SafeProbabilisticModule"], [231, 0, 1, "", "SafeProbabilisticTensorDictSequential"], [232, 0, 1, "", "SafeSequential"], [233, 0, 1, "", "TanhModule"], [234, 0, 1, "", "ValueOperator"], [235, 0, 1, "", "WorldModelWrapper"]], "torchrl.modules.tensordict_module.ActorCriticOperator": [[215, 1, 1, "", "get_critic_operator"], [215, 1, 1, "", "get_policy_head"], [215, 1, 1, "", "get_value_head"], [215, 1, 1, "", "get_value_operator"]], "torchrl.modules.tensordict_module.ActorCriticWrapper": [[216, 1, 1, "", "get_policy_head"], [216, 1, 1, "", "get_policy_operator"], [216, 1, 1, "", "get_value_head"], [216, 1, 1, "", "get_value_operator"]], "torchrl.modules.tensordict_module.ActorValueOperator": [[217, 1, 1, "", "get_policy_head"], [217, 1, 1, "", "get_policy_operator"], [217, 1, 1, "", "get_value_head"], [217, 1, 1, "", "get_value_operator"]], "torchrl.modules.tensordict_module.AdditiveGaussianWrapper": [[218, 1, 1, "", "forward"], [218, 1, 1, "", "step"]], "torchrl.modules.tensordict_module.DecisionTransformerInferenceWrapper": [[219, 1, 1, "", "forward"], [219, 1, 1, "", "mask_context"], [219, 1, 1, "", "set_tensor_keys"]], "torchrl.modules.tensordict_module.DistributionalQValueModule": [[221, 1, 1, "", "forward"]], "torchrl.modules.tensordict_module.EGreedyModule": [[222, 1, 1, "", "forward"], [222, 1, 1, "", "step"]], "torchrl.modules.tensordict_module.EGreedyWrapper": [[223, 1, 1, "", "forward"], [223, 1, 1, "", "step"]], "torchrl.modules.tensordict_module.OrnsteinUhlenbeckProcessWrapper": [[225, 1, 1, "", "forward"], [225, 1, 1, "", "step"]], "torchrl.modules.tensordict_module.QValueModule": [[228, 1, 1, "", "forward"]], "torchrl.modules.tensordict_module.SafeModule": [[229, 1, 1, "", "random"], [229, 1, 1, "", "random_sample"], [229, 1, 1, "", "to"]], "torchrl.modules.tensordict_module.SafeProbabilisticModule": [[230, 1, 1, "", "random"], [230, 1, 1, "", "random_sample"]], "torchrl.modules.tensordict_module.TanhModule": [[233, 1, 1, "", "forward"]], "torchrl.modules.tensordict_module.WorldModelWrapper": [[235, 1, 1, "", "get_reward_operator"], [235, 1, 1, "", "get_transition_model_operator"]], "torchrl.modules.utils": [[236, 0, 1, "", "biased_softplus"], [237, 0, 1, "", "inv_softplus"], [238, 0, 1, "", "mappings"]], "torchrl.modules.utils.biased_softplus": [[236, 1, 1, "", "forward"]], "torchrl.objectives": [[239, 0, 1, "", "A2CLoss"], [240, 0, 1, "", "CQLLoss"], [241, 0, 1, "", "ClipPPOLoss"], [242, 0, 1, "", "DDPGLoss"], [243, 0, 1, "", "DQNLoss"], [244, 0, 1, "", "DTLoss"], [245, 0, 1, "", "DiscreteCQLLoss"], [246, 0, 1, "", "DiscreteSACLoss"], [247, 0, 1, "", "DistributionalDQNLoss"], [248, 0, 1, "", "DreamerActorLoss"], [249, 0, 1, "", "DreamerModelLoss"], [250, 0, 1, "", "DreamerValueLoss"], [251, 0, 1, "", "HardUpdate"], [252, 0, 1, "", "IQLLoss"], [253, 0, 1, "", "KLPENPPOLoss"], [254, 0, 1, "", "LossModule"], [255, 0, 1, "", "OnlineDTLoss"], [256, 0, 1, "", "PPOLoss"], [257, 0, 1, "", "REDQLoss"], [258, 0, 1, "", "ReinforceLoss"], [259, 0, 1, "", "SACLoss"], [260, 0, 1, "", "SoftUpdate"], [261, 0, 1, "", "TD3Loss"], [262, 0, 1, "", "ValueEstimators"], [263, 0, 1, "", "default_value_kwargs"], [264, 0, 1, "", "distance_loss"], [265, 0, 1, "", "hold_out_net"], [266, 0, 1, "", "hold_out_params"], [268, 0, 1, "", "next_state_value"]], "torchrl.objectives.A2CLoss": [[239, 1, 1, "", "forward"], [239, 1, 1, "", "make_value_estimator"]], "torchrl.objectives.CQLLoss": [[240, 1, 1, "", "forward"], [240, 1, 1, "", "make_value_estimator"]], "torchrl.objectives.ClipPPOLoss": [[241, 1, 1, "", "forward"]], "torchrl.objectives.DDPGLoss": [[242, 1, 1, "", "forward"], [242, 1, 1, "", "make_value_estimator"]], "torchrl.objectives.DQNLoss": [[243, 1, 1, "", "forward"], [243, 1, 1, "", "make_value_estimator"]], "torchrl.objectives.DTLoss": [[244, 1, 1, "", "forward"]], "torchrl.objectives.DiscreteCQLLoss": [[245, 1, 1, "", "forward"], [245, 1, 1, "", "make_value_estimator"]], "torchrl.objectives.DiscreteSACLoss": [[246, 1, 1, "", "forward"], [246, 1, 1, "", "make_value_estimator"]], "torchrl.objectives.DistributionalDQNLoss": [[247, 1, 1, "", "forward"], [247, 1, 1, "", "make_value_estimator"]], "torchrl.objectives.DreamerActorLoss": [[248, 1, 1, "", "forward"], [248, 1, 1, "", "make_value_estimator"]], "torchrl.objectives.DreamerModelLoss": [[249, 1, 1, "", "forward"]], "torchrl.objectives.DreamerValueLoss": [[250, 1, 1, "", "forward"]], "torchrl.objectives.IQLLoss": [[252, 1, 1, "", "forward"], [252, 1, 1, "", "loss_value_diff"], [252, 1, 1, "", "make_value_estimator"]], "torchrl.objectives.KLPENPPOLoss": [[253, 1, 1, "", "forward"]], "torchrl.objectives.LossModule": [[254, 1, 1, "", "convert_to_functional"], [254, 1, 1, "", "forward"], [254, 1, 1, "", "make_value_estimator"], [254, 1, 1, "", "named_parameters"], [254, 1, 1, "", "parameters"], [254, 1, 1, "", "set_keys"], [254, 3, 1, "", "value_estimator"]], "torchrl.objectives.OnlineDTLoss": [[255, 1, 1, "", "forward"]], "torchrl.objectives.PPOLoss": [[256, 1, 1, "", "forward"], [256, 1, 1, "", "make_value_estimator"]], "torchrl.objectives.REDQLoss": [[257, 1, 1, "", "forward"], [257, 1, 1, "", "make_value_estimator"]], "torchrl.objectives.ReinforceLoss": [[258, 1, 1, "", "forward"], [258, 1, 1, "", "make_value_estimator"]], "torchrl.objectives.SACLoss": [[259, 1, 1, "", "forward"], [259, 1, 1, "", "load_state_dict"], [259, 1, 1, "", "make_value_estimator"], [259, 1, 1, "", "state_dict"]], "torchrl.objectives.TD3Loss": [[261, 1, 1, "", "forward"], [261, 1, 1, "", "make_value_estimator"]], "torchrl.objectives.multiagent": [[267, 0, 1, "", "QMixerLoss"]], "torchrl.objectives.multiagent.QMixerLoss": [[267, 1, 1, "", "forward"], [267, 1, 1, "", "make_value_estimator"]], "torchrl.objectives.value": [[269, 0, 1, "", "GAE"], [270, 0, 1, "", "TD0Estimator"], [271, 0, 1, "", "TD1Estimator"], [272, 0, 1, "", "TDLambdaEstimator"], [273, 0, 1, "", "ValueEstimatorBase"]], "torchrl.objectives.value.GAE": [[269, 1, 1, "", "forward"], [269, 1, 1, "", "value_estimate"]], "torchrl.objectives.value.TD0Estimator": [[270, 1, 1, "", "forward"], [270, 1, 1, "", "value_estimate"]], "torchrl.objectives.value.TD1Estimator": [[271, 1, 1, "", "forward"], [271, 1, 1, "", "value_estimate"]], "torchrl.objectives.value.TDLambdaEstimator": [[272, 1, 1, "", "forward"], [272, 1, 1, "", "value_estimate"]], "torchrl.objectives.value.ValueEstimatorBase": [[273, 1, 1, "", "forward"], [273, 1, 1, "", "set_keys"], [273, 1, 1, "", "value_estimate"]], "torchrl.objectives.value.functional": [[274, 0, 1, "", "generalized_advantage_estimate"], [275, 0, 1, "", "reward2go"], [276, 0, 1, "", "td0_advantage_estimate"], [277, 0, 1, "", "td0_return_estimate"], [278, 0, 1, "", "td1_advantage_estimate"], [279, 0, 1, "", "td1_return_estimate"], [280, 0, 1, "", "td_lambda_advantage_estimate"], [281, 0, 1, "", "td_lambda_return_estimate"], [282, 0, 1, "", "vec_generalized_advantage_estimate"], [283, 0, 1, "", "vec_td1_advantage_estimate"], [284, 0, 1, "", "vec_td1_return_estimate"], [285, 0, 1, "", "vec_td_lambda_advantage_estimate"], [286, 0, 1, "", "vec_td_lambda_return_estimate"]], "torchrl.record": [[287, 2, 1, "", "TensorDictRecorder"], [288, 2, 1, "", "VideoRecorder"]], "torchrl.record.loggers": [[289, 2, 1, "", "Logger"], [291, 2, 1, "", "generate_exp_name"], [292, 2, 1, "", "get_logger"]], "torchrl.record.loggers.csv": [[290, 2, 1, "", "CSVLogger"]], "torchrl.record.loggers.mlflow": [[293, 2, 1, "", "MLFlowLogger"]], "torchrl.record.loggers.tensorboard": [[294, 2, 1, "", "TensorboardLogger"]], "torchrl.record.loggers.wandb": [[295, 2, 1, "", "WandbLogger"]], "torchrl.trainers": [[296, 0, 1, "", "BatchSubSampler"], [297, 0, 1, "", "ClearCudaCache"], [298, 0, 1, "", "CountFramesLog"], [299, 0, 1, "", "LogReward"], [300, 0, 1, "", "OptimizerHook"], [301, 0, 1, "", "Recorder"], [302, 0, 1, "", "ReplayBufferTrainer"], [303, 0, 1, "", "RewardNormalizer"], [304, 0, 1, "", "SelectKeys"], [305, 0, 1, "", "Trainer"], [306, 0, 1, "", "TrainerHookBase"], [307, 0, 1, "", "UpdateWeights"]], "torchrl.trainers.BatchSubSampler": [[296, 1, 1, "", "register"]], "torchrl.trainers.ClearCudaCache": [[297, 1, 1, "", "register"]], "torchrl.trainers.CountFramesLog": [[298, 1, 1, "", "register"]], "torchrl.trainers.LogReward": [[299, 1, 1, "", "register"]], "torchrl.trainers.OptimizerHook": [[300, 1, 1, "", "register"]], "torchrl.trainers.Recorder": [[301, 1, 1, "", "register"]], "torchrl.trainers.ReplayBufferTrainer": [[302, 1, 1, "", "register"]], "torchrl.trainers.RewardNormalizer": [[303, 1, 1, "", "register"]], "torchrl.trainers.SelectKeys": [[304, 1, 1, "", "register"]], "torchrl.trainers.TrainerHookBase": [[306, 1, 1, "", "register"]], "torchrl.trainers.UpdateWeights": [[307, 1, 1, "", "register"]], "torchrl.trainers.helpers": [[308, 2, 1, "", "correct_for_frame_skip"], [309, 2, 1, "", "get_stats_random_rollout"], [310, 2, 1, "", "make_collector_offpolicy"], [311, 2, 1, "", "make_collector_onpolicy"], [312, 2, 1, "", "make_dqn_loss"], [313, 2, 1, "", "make_redq_loss"], [314, 2, 1, "", "make_redq_model"], [315, 2, 1, "", "make_replay_buffer"], [316, 2, 1, "", "make_target_updater"], [317, 2, 1, "", "make_trainer"], [318, 2, 1, "", "parallel_env_constructor"], [319, 2, 1, "", "sync_async_collector"], [320, 2, 1, "", "sync_sync_collector"], [321, 2, 1, "", "transformed_env_constructor"]]}, "objtypes": {"0": "py:class", "1": "py:method", "2": "py:function", "3": "py:property"}, "objnames": {"0": ["py", "class", "Python class"], "1": ["py", "method", "Python method"], "2": ["py", "function", "Python function"], "3": ["py", "property", "Python property"]}, "titleterms": {"torchrl": [0, 1, 2, 3, 6, 9, 325, 326, 327, 328, 330, 331, 332, 336, 337, 341, 342], "tutori": [0, 332, 336], "basic": [0, 339], "intermedi": [0, 8], "advanc": 0, "refer": [0, 323], "knowledg": [0, 324], "base": [0, 7, 324], "indic": 0, "tabl": 0, "collector": [1, 330, 331, 332, 333, 336, 341], "packag": [1, 2, 3, 325, 326, 327, 328], "singl": [1, 4], "node": 1, "data": [1, 2, 4, 330, 331, 332, 336, 341], "distribut": [1, 325], "helper": [1, 3], "function": [1, 4, 326, 331, 332, 336, 341], "replai": [2, 330, 331, 332, 333, 336, 339, 341], "buffer": [2, 330, 331, 332, 333, 336, 339, 341], "compos": [2, 115], "share": 2, "across": 2, "process": 2, "store": [2, 331], "trajectori": 2, "checkpoint": [2, 327], "dataset": 2, "tensorspec": [2, 44], "reinforc": [2, 326, 332, 336], "learn": [2, 4, 332, 336], "from": [2, 6, 7], "human": 2, "feedback": 2, "rlhf": 2, "util": [2, 325, 326, 327], "env": [3, 337, 341, 342], "vector": [3, 341], "multi": [3, 325, 326, 335, 336], "agent": [3, 4, 325, 326, 336], "environ": [3, 4, 6, 7, 330, 331, 332, 333, 335, 336, 337, 341, 342], "transform": [3, 148, 330, 332, 336, 337, 339, 341, 342], "clone": [3, 7], "mask": 3, "action": [3, 4, 333, 337], "record": [3, 301, 327, 330], "domain": [3, 325], "specif": [3, 325, 335], "librari": [3, 341], "thing": [4, 330, 337], "consid": 4, "when": [4, 7], "debug": 4, "rl": [4, 9, 341], "gener": [4, 325], "have": 4, "you": 4, "valid": 4, "your": [4, 6, 330, 337], "algorithm": [4, 325], "implement": 4, "few": 4, "small": 4, "toi": 4, "problem": 4, "known": 4, "optim": [4, 330, 331], "return": [4, 326], "e": 4, "g": 4, "gridworld": 4, "mountaincar": 4, "visual": 4, "Be": 4, "veri": 4, "care": 4, "ani": 4, "augment": 4, "polici": [4, 330, 332, 333, 335, 336, 337], "doe": 4, "entropi": 4, "converg": 4, "too": [4, 8], "quickli": 4, "slowli": 4, "chang": [4, 341], "drastic": 4, "reward": 4, "beyond": 4, "go": 4, "up": [4, 6], "Is": 4, "favor": 4, "compon": 4, "i": 4, "veloc": 4, "vs": 4, "l2": 4, "magnitud": 4, "task": [4, 335], "horizon": 4, "extrem": 4, "long": 4, "ar": 4, "normal": [4, 330, 331, 332], "standard": 4, "explor": [4, 325, 330, 331], "valu": [4, 325, 326, 330, 332, 333], "loss": [4, 330, 331, 332, 333, 336], "earli": 4, "train": [4, 8, 326, 330, 332, 333, 336, 337], "roughli": 4, "uniformli": 4, "random": [4, 336], "intrins": 4, "decai": 4, "progress": 4, "singleton": 4, "episod": 4, "remain": 4, "constant": [4, 331], "increas": 4, "an": [4, 332, 333, 337], "dynam": [4, 339], "can": 4, "low": 4, "forward": [4, 330], "model": [4, 325, 330, 331, 333, 338, 341], "also": 4, "us": [4, 6, 9, 333, 338, 339, 341], "offlin": 4, "observ": [4, 330], "space": 4, "effect": [4, 337], "dramat": 4, "dure": [4, 7], "high": 4, "dimension": 4, "work": [5, 6, 7], "gym": [5, 342], "what": 5, "openai": 5, "version": [5, 7, 10], "habitat": 6, "lab": 6, "set": 6, "instal": [6, 7, 341], "pip": [6, 7], "common": [6, 7, 8], "issu": [6, 7, 10], "mujoco": 7, "prerequisit": 7, "render": [7, 336, 342], "all": 7, "new": 7, "bindindg": 7, "2": 7, "1": 7, "old": 7, "bind": 7, "py": 7, "option": 7, "repo": [7, 9], "import": [7, 330], "pytorch": [8, 9, 10], "error": 8, "solut": 8, "gradient": 8, "relat": 8, "newcom": 8, "my": 8, "slow": 8, "bug": 8, "resourc": 9, "paper": 9, "document": 9, "functorch": 9, "blog": 9, "websit": 9, "educ": 9, "forum": 9, "how": 10, "reproduc": [10, 337], "workaround": 10, "implement_for": 11, "datacollectorbas": 12, "multisyncdatacollector": 13, "multiasyncdatacollector": 14, "randompolici": 15, "syncdatacollector": 16, "asyncdatacollector": 17, "distributeddatacollector": 18, "distributedsyncdatacollector": 19, "rpcdatacollector": 20, "raycollector": 21, "submitit_delayed_launch": 22, "split_trajectori": 23, "binarydiscretetensorspec": 24, "boundedtensorspec": 25, "compositespec": 26, "discretetensorspec": 27, "lazystackedcompositespec": 28, "lazystackedtensorspec": 29, "multidiscretetensorspec": 30, "multionehotdiscretetensorspec": 31, "multistep": 32, "onehotdiscretetensorspec": 33, "pairwisedataset": 34, "prioritizedreplaybuff": 35, "promptdata": 36, "prompttensordicttoken": 37, "replaybuff": 38, "rewarddata": 39, "rolloutfrommodel": 40, "tensordictprioritizedreplaybuff": 41, "tensordictreplaybuff": 42, "tensordicttoken": 43, "tokenizeddatasetload": 45, "unboundedcontinuoustensorspec": 46, "unboundeddiscretetensorspec": 47, "check_no_exclusive_kei": 48, "consolidate_spec": 49, "contains_lazy_spec": 50, "create_infinite_iter": 51, "d4rlexperiencereplai": 52, "minariexperiencereplai": 53, "openmlexperiencereplai": 54, "robosetexperiencereplai": 55, "vd4rlexperiencereplai": 56, "get_dataload": 57, "lazymemmapstorag": 58, "lazytensorstorag": 59, "liststorag": 60, "prioritizedsampl": 61, "randomsampl": 62, "roundrobinwrit": 63, "sampler": 64, "samplerwithoutreplac": 65, "slicesampl": 66, "slicesamplerwithoutreplac": 67, "storag": [68, 330, 339], "tensordictmaxvaluewrit": 69, "tensordictroundrobinwrit": 70, "tensorstorag": 71, "writer": 72, "braxenv": 73, "braxwrapp": 74, "dmcontrolenv": 75, "dmcontrolwrapp": 76, "envbas": [77, 337], "envcreat": 78, "envmetadata": 79, "gymenv": 80, "gymlikeenv": 81, "gymwrapp": 82, "habitatenv": 83, "isaacgymenv": 84, "isaacgymwrapp": 85, "jumanjienv": 86, "jumanjiwrapp": 87, "mogymenv": 88, "mogymwrapp": 89, "marlgroupmaptyp": 90, "modelbasedenvbas": 91, "multithreadedenv": 92, "multithreadedenvwrapp": 93, "openmlenv": 94, "parallelenv": 95, "pettingzooenv": 96, "pettingzoowrapp": 97, "robohiveenv": 98, "smacv2env": 99, "smacv2wrapp": 100, "serialenv": 101, "vmasenv": 102, "vmaswrapp": 103, "check_marl_group": 104, "gym_backend": 105, "dreamerenv": 106, "set_gym_backend": 107, "actionmask": 108, "binarizereward": 109, "burnintransform": 110, "catfram": [111, 339], "cattensor": 112, "centercrop": 113, "cliptransform": 114, "dtypecasttransform": 116, "devicecasttransform": 117, "discreteactionproject": 118, "doubletofloat": 119, "endoflifetransform": 120, "excludetransform": 121, "finitetensordictcheck": 122, "flattenobserv": 123, "frameskiptransform": 124, "grayscal": 125, "inittrack": 126, "klrewardtransform": 127, "noopresetenv": 128, "observationnorm": 129, "observationtransform": 130, "permutetransform": 131, "pinmemorytransform": 132, "r3mtransform": 133, "randomcroptensordict": 134, "renametransform": 135, "resiz": 136, "reward2gotransform": 137, "rewardclip": 138, "rewardsc": 139, "rewardsum": 140, "selecttransform": 141, "squeezetransform": 142, "stepcount": 143, "targetreturn": 144, "tensordictprim": 145, "timemaxpool": 146, "totensorimag": 147, "transformedenv": 149, "unsqueezetransform": 150, "vc1transform": 151, "viprewardtransform": 152, "viptransform": 153, "vecgymenvtransform": 154, "vecnorm": [155, 342], "gsdenois": 156, "check_env_spec": 157, "exploration_mod": 158, "exploration_typ": 159, "get_available_librari": 160, "make_composite_from_td": 161, "set_exploration_mod": 162, "set_exploration_typ": 163, "step_mdp": 164, "terminated_or_trunc": 165, "cemplann": 166, "conv3dnet": 167, "convnet": 168, "dtactor": 169, "ddpgcnnactor": 170, "ddpgcnnqnet": 171, "ddpgmlpactor": 172, "ddpgmlpqnet": 173, "decisiontransform": 174, "delta": 175, "distributionaldqnnet": 176, "distributionalqvaluehook": 177, "dreameractor": 178, "duelingcnndqnet": 179, "gru": 180, "grucel": 181, "grumodul": 182, "independentnorm": 183, "lstm": [184, 333], "lstmcell": 185, "lstmmodul": 186, "lstmnet": 187, "mlp": [188, 333], "mpcplannerbas": 189, "mppiplann": 190, "maskedcategor": 191, "maskedonehotcategor": 192, "multiagentconvnet": 193, "multiagentmlp": 194, "noisylazylinear": 195, "noisylinear": 196, "normalparamwrapp": 197, "obsdecod": 198, "obsencod": 199, "onehotcategor": 200, "onlinedtactor": 201, "qmixer": [202, 326], "qvaluehook": 203, "rssmposterior": 204, "rssmprior": 205, "squeeze2dlay": 206, "squeezelay": 207, "tanhdelta": 208, "tanhnorm": 209, "truncatednorm": 210, "vdnmixer": 211, "vmapmodul": 212, "reset_nois": 213, "actor": [214, 325, 330], "actorcriticoper": 215, "actorcriticwrapp": 216, "actorvalueoper": 217, "additivegaussianwrapp": 218, "decisiontransformerinferencewrapp": 219, "distributionalqvalueactor": 220, "distributionalqvaluemodul": 221, "egreedymodul": 222, "egreedywrapp": 223, "lmheadactorvalueoper": 224, "ornsteinuhlenbeckprocesswrapp": 225, "probabilisticactor": 226, "qvalueactor": 227, "qvaluemodul": 228, "safemodul": [229, 325], "safeprobabilisticmodul": 230, "safeprobabilistictensordictsequenti": 231, "safesequenti": 232, "tanhmodul": 233, "valueoper": 234, "worldmodelwrapp": 235, "biased_softplu": 236, "inv_softplu": 237, "map": 238, "a2closs": 239, "cqlloss": 240, "clipppoloss": 241, "ddpgloss": 242, "dqnloss": 243, "dtloss": 244, "discretecqlloss": 245, "discretesacloss": 246, "distributionaldqnloss": 247, "dreameractorloss": 248, "dreamermodelloss": 249, "dreamervalueloss": 250, "hardupd": 251, "iqlloss": 252, "klpenppoloss": 253, "lossmodul": [254, 330], "onlinedtloss": 255, "ppoloss": 256, "redqloss": 257, "reinforceloss": 258, "sacloss": 259, "softupd": 260, "td3loss": 261, "valueestim": 262, "default_value_kwarg": 263, "distance_loss": 264, "hold_out_net": 265, "hold_out_param": 266, "qmixerloss": 267, "next_state_valu": 268, "gae": 269, "td0estim": 270, "td1estim": 271, "tdlambdaestim": 272, "valueestimatorbas": 273, "generalized_advantage_estim": 274, "reward2go": 275, "td0_advantage_estim": 276, "td0_return_estim": 277, "td1_advantage_estim": 278, "td1_return_estim": 279, "td_lambda_advantage_estim": 280, "td_lambda_return_estim": 281, "vec_generalized_advantage_estim": 282, "vec_td1_advantage_estim": 283, "vec_td1_return_estim": 284, "vec_td_lambda_advantage_estim": 285, "vec_td_lambda_return_estim": 286, "tensordictrecord": 287, "videorecord": 288, "logger": [289, 327], "csvlogger": 290, "generate_exp_nam": 291, "get_logg": 292, "mlflowlogg": 293, "tensorboardlogg": 294, "wandblogg": 295, "batchsubsampl": 296, "clearcudacach": 297, "countframeslog": 298, "logreward": 299, "optimizerhook": 300, "replaybuffertrain": 302, "rewardnorm": 303, "selectkei": 304, "trainer": [305, 327, 331], "trainerhookbas": 306, "updateweight": 307, "correct_for_frame_skip": 308, "get_stats_random_rollout": 309, "make_collector_offpolici": 310, "make_collector_onpolici": 311, "make_dqn_loss": 312, "make_redq_loss": 313, "make_redq_model": 314, "make_replay_buff": 315, "make_target_updat": 316, "make_train": 317, "parallel_env_constructor": 318, "sync_async_collector": 319, "sync_sync_collector": 320, "transformed_env_constructor": 321, "readm": [322, 334], "tuto": [322, 334], "api": 323, "contribut": [324, 341], "content": 324, "modul": [325, 330, 333, 341], "tensordict": [325, 339, 341], "wrapper": 325, "probabilist": 325, "q": [325, 331, 333], "oper": 325, "join": 325, "hook": [325, 327, 331], "regular": 325, "planner": 325, "object": [326, 330, 341], "dqn": [326, 331, 333], "ddpg": [326, 330], "sac": 326, "redq": 326, "iql": 326, "cql": 326, "dt": 326, "td3": 326, "ppo": [326, 332, 336], "a2c": 326, "dreamer": 326, "builder": 327, "_util": 328, "comput": [329, 331, 337, 340], "time": [329, 330, 340], "code": [330, 337], "setup": [330, 333], "The": 330, "__init__": 330, "method": 330, "estim": 330, "put": 330, "togeth": [330, 337], "call": 330, "parallel": [330, 335, 342], "execut": [330, 335, 337], "stat": 330, "build": [330, 331, 339], "evalu": 330, "batch": [330, 337, 339], "size": [330, 339], "construct": 330, "target": [330, 331], "network": [330, 331, 332, 333, 336], "updat": 330, "experi": [330, 337], "result": [330, 332, 336], "conclus": [330, 331, 332, 333, 336, 337, 339], "A": [331, 339], "exampl": [331, 339], "deep": 331, "collect": [331, 332], "paramet": [331, 332], "hyperparamet": [331, 332, 336], "regist": 331, "possibl": 331, "improv": 331, "defin": [332, 336], "loop": [332, 333, 336, 337], "next": [332, 336], "step": [332, 336, 342], "recurr": 333, "overview": 333, "convolut": 333, "select": 333, "further": 333, "read": 333, "divers": 335, "rollout": [335, 336, 337, 342], "critic": 336, "pendulum": 337, "write": 337, "_step": 337, "reset": [337, 342], "simul": 337, "_reset": 337, "metadata": 337, "_spec": 337, "spec": [337, 342], "shape": 337, "seed": [337, 342], "wrap": 337, "class": [337, 341], "test": 337, "our": 337, "custom": [337, 339], "simpl": 337, "pretrain": 338, "vanilla": 339, "integr": 339, "tensorclass": 339, "sampl": 339, "iter": 339, "over": 339, "fix": 339, "priorit": 339, "save": 339, "raw": 339, "imag": 339, "more": 339, "complex": 339, "introduct": 341, "config": 341, "tensordictmodul": 341, "sequenc": 341, "program": 341, "ensembl": 341, "meta": 341, "special": 341, "state": 341, "frame_skip": 342, "deepmind": 342, "control": 342, "devic": 342, "run": 342, "close": 342, "access": 342, "attribut": 342, "kwarg": 342}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 6, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.viewcode": 1, "sphinx.ext.intersphinx": 1, "sphinx": 56}})